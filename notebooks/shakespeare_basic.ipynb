{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/markNZed/GPT-NeoX-Colab/blob/main/notebooks/shakespeare_basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52lBrppZd_A0"
      },
      "source": [
        "# Training a tiny langauge model (TLM) on a corpus of Shakespeare\n",
        "The intention of this notebook is to demonstrate a basic setup of GPT-NeoX for experimenting with a TLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBH4eN9Id_A7"
      },
      "outputs": [],
      "source": [
        "# We could modify these paths to \"stub\" behavior for test/dev\n",
        "workspaceDir = \"/content\"\n",
        "gpt_neox_colabDir = f\"{workspaceDir}/GPT-NeoX-Colab\"\n",
        "GPTNeoXDirName = \"gpt-neox\"\n",
        "GPTNeoXDir = f\"{workspaceDir}/{GPTNeoXDirName}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74e27VRVq07s"
      },
      "source": [
        "# Cloning Git Repos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "j_hUsQxlhnou"
      },
      "outputs": [],
      "source": [
        "!git clone --depth 1 https://github.com/markNZed/GPT-NeoX-Colab.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "FjLEIFCR6d8m"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "#@title Clone GPT-NeoX\n",
        "%cd {workspaceDir}\n",
        "!git clone -b pipe_parallel_size_1 --depth 1 https://github.com/markNZed/gpt-neox.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "AUmdStRWhrUR"
      },
      "outputs": [],
      "source": [
        "%pip install -q torch==2.3 torchaudio==2.3.0 torchvision==0.18.0 transformers==4.38.0 sentence-transformers==2.2.2\n",
        "%pip install -q fsspec==2024.2.0 datasets==2.18.0 evaluate==0.4.3 lm-eval==0.4.1 tensorboard==2.17.1 tensorflow==2.17.1\n",
        "%cd {GPTNeoXDir}\n",
        "%pip install -q -r ./requirements/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jzX5ohGax6p"
      },
      "source": [
        "# Preparing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-hmZjCc-WnV"
      },
      "outputs": [],
      "source": [
        "#@title Converting text data to jsonl format\n",
        "%cd {GPTNeoXDir}\n",
        "!mkdir -p data\n",
        "\n",
        "import json\n",
        "input_txt_file = f\"{gpt_neox_colabDir}/notebooks/shakespeare.txt\"\n",
        "output_jsonl_file = f\"{GPTNeoXDir}/data/shakespeare.jsonl\"\n",
        "\n",
        "lines = []\n",
        "with open(input_txt_file, encoding=\"utf8\") as f:\n",
        "    for line in f.read().splitlines():\n",
        "        if line:\n",
        "            lines.append({\"text\": line})\n",
        "json_lines = [json.dumps(data) for data in lines]\n",
        "with open(output_jsonl_file, \"w\") as f:\n",
        "    f.write(\"\\n\".join(json_lines))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x57thNaLa-yN"
      },
      "source": [
        "# Tokenizing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyD8RujkEUsr"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "#@title Tokenizing jsonl formatted data\n",
        "import os\n",
        "\n",
        "%cd {GPTNeoXDir}\n",
        "!mkdir -p processed_data\n",
        "%cd processed_data\n",
        "cmd = f\"\"\"\n",
        "python {GPTNeoXDir}/tools/datasets/preprocess_data.py \\\n",
        "    --input {GPTNeoXDir}/data/shakespeare.jsonl \\\n",
        "    --output-prefix shakespeare \\\n",
        "    --tokenizer-type CharLevelTokenizer \\\n",
        "    --dataset-impl mmap \\\n",
        "    --append-eod\n",
        "\"\"\"\n",
        "print(f\"Command: {cmd}\")\n",
        "!{cmd}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QszVj7_vSP7L"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtOHyiVDhrUZ",
        "outputId": "a9698f63-3d8f-4ff8-f5ac-d748a08bf0dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gpt-neox\n",
            "[2024-12-03 14:07:34,504] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "NeoXArgs.from_ymls() ['/content/GPT-NeoX-Colab/configs/shakespeare.yml', '/content/GPT-NeoX-Colab/configs/shakespeare_deepy.yml']\n",
            "INFO:root:NeoXArgs.calculate_derived() Total number of GPUs determined to be: 1\n",
            "-------------------- arguments --------------------\n",
            "  attention_config ................ ['global', 'global', 'global', 'global']updated\n",
            "  batch_size ...................... 256.........................updated\n",
            "  checkpoint_factor ............... 50..........................updated\n",
            "  config_files .................... {'shakespeare.yml': '{\\n  \"pipe_parallel_size\": 0, # Because running on one GPU\\n  \"model_parallel_size\": 1, # Because running on one GPU\\n\\n  # model settings\\n  \"num_layers\": 4,\\n  \"hidden_size\": 256,\\n  \"num_attention_heads\": 4,\\n  \"seq_length\": 512,\\n  \"max_position_embeddings\": 512,\\n  \"pos_emb\": \"rotary\",\\n  \"no_weight_tying\": false, # Sharing embedding and output weights\\n  \"gpt_j_residual\": false,\\n  \"output_layer_parallelism\": \"column\",\\n\\n  \"scaled_upper_triang_masked_softmax_fusion\": false,\\n  \"bias_gelu_fusion\": false,\\n  \"rope_fusion\": false,\\n  \"layernorm_fusion\": false,\\n\\n  # init methods\\n  \"init_method\": \"small_init\",\\n  \"output_layer_init_method\": \"wang_init\",\\n\\n  \"optimizer\": {\\n    \"type\": \"Adam\",\\n    \"params\": {\\n      \"lr\": 0.001,\\n      \"betas\": [0.9, 0.95],\\n      \"eps\": 1.0e-8\\n    }\\n  },\\n  \"min_lr\": 0.0001,\\n\\n  \"zero_optimization\": {\\n    \"stage\": 1,\\n    \"allgather_partitions\": true,\\n    \"allgather_bucket_size\": 500000000,\\n    \"overlap_comm\": true,\\n    \"reduce_scatter\": true,\\n    \"reduce_bucket_size\": 500000000,\\n    \"contiguous_gradients\": true\\n  },\\n\\n  \"train_micro_batch_size_per_gpu\": 256, # 8, #8 for 4GB #256 for 16GB\\n  \"gradient_accumulation_steps\": 1,\\n  \"data_impl\": \"mmap\",\\n  \"num_workers\": 1,\\n\\n  # activation checkpointing\\n  \"checkpoint_activations\": false, # We are not memory bound\\n  \"checkpoint_num_layers\": 1,\\n  \"partition_activations\": true,\\n  \"synchronize_each_layer\": true,\\n\\n  # regularization\\n  \"gradient_clipping\": 1.0,\\n  \"weight_decay\": 0.1,\\n  \"hidden_dropout\": 0,\\n  \"attention_dropout\": 0,\\n\\n  # precision settings\\n  \"fp16\": {\\n    \"fp16\": true,\\n    \"enabled\": true,\\n    \"loss_scale\": 0,\\n    \"loss_scale_window\": 1000,\\n    \"initial_scale_power\": 12,\\n    \"hysteresis\": 2,\\n    \"min_loss_scale\": 1\\n  },\\n\\n  \"train_iters\": 800,\\n  \"lr_decay_iters\": 800,\\n  \"distributed_backend\": \"nccl\",\\n  \"lr_decay_style\": \"linear\",\\n  \"warmup\": 0.01,\\n  \"checkpoint_factor\": 50, # Must be defined if save is set\\n  \"eval_interval\": 30,\\n  \"eval_iters\": 2,\\n\\n  \"log_interval\": 100,\\n  \"steps_per_print\": 100,\\n  \"wall_clock_breakdown\": false,\\n\\n  # Required for model conversion into HF format\\n  \"tokenizer_type\": \"CharLevelTokenizer\",\\n\\n  # additional deepspeed args not specified above\\n  \"deepspeed_extra_args\": {\\n    \"comms_logger\": {\\n      \"enabled\":  false,\\n      \"verbose\":  false,\\n      \"prof_all\": false,\\n      \"debug\":    false\\n    }\\n  }\\n}\\n', 'shakespeare_deepy.yml': '# Suggested data paths when using GPT-NeoX locally\\n{\\n  \"data_path\": \"processed_data/shakespeare_text_document\",\\n\\n  # or for weighted datasets:\\n  # \"train-data-paths\": [\"data/enwik8/enwik8_text_document\", \"data/enwik8/enwik8_text_document\"],\\n  # \"test-data-paths\": [\"data/enwik8/enwik8_text_document\", \"data/enwik8/enwik8_text_document\"],\\n  # \"valid-data-paths\": [\"data/enwik8/enwik8_text_document\", \"data/enwik8/enwik8_text_document\"],\\n  # \"train-data-weights\": [1., 2.],\\n  # \"test-data-weights\": [2., 1.],\\n  # \"valid-data-weights\": [0.5, 0.4],\\n\\n  # If weight_by_num_documents is True, Builds dataset weights from a multinomial distribution over groups of data according to the number of documents in each group.\\n  # WARNING: setting this to True will override any user provided weights\\n  # \"weight_by_num_documents\": false,\\n  # \"weighted_sampler_alpha\": 0.3,\\n\\n  #\"tokenizer_type\": \"CharLevelTokenizer\",\\n  #\"vocab_file\": \"tokenizer/gpt2-vocab.json\",\\n  #\"merge_file\": \"tokenizer/gpt2-merges.txt\",\\n\\n  \"save\": \"checkpoints\",\\n  \"load\": \"checkpoints\",\\n  \"checkpoint_validation_with_forward_pass\": False,\\n\\n  \"tensorboard_dir\": \"tensorboard\",\\n  \"log_dir\": \"logs\",\\n}'}updated\n",
            "  data_impl ....................... mmap........................updated\n",
            "  data_path ....................... processed_data/shakespeare_text_documentupdated\n",
            "  deepspeed_extra_args ............ {'comms_logger': {'enabled': False, 'verbose': False, 'prof_all': False, 'debug': False}}updated\n",
            "  dynamic_loss_scale .............. True........................updated\n",
            "  eval_interval ................... 30..........................updated\n",
            "  eval_iters ...................... 2...........................updated\n",
            "  fp16 ............................ {'fp16': True, 'enabled': True, 'loss_scale': 0, 'loss_scale_window': 1000, 'initial_scale_power': 12, 'hysteresis': 2, 'min_loss_scale': 1}updated\n",
            "  global_num_gpus ................. 1...........................updated\n",
            "  hidden_size ..................... 256.........................updated\n",
            "  init_method ..................... small_init..................updated\n",
            "  load ............................ checkpoints.................updated\n",
            "  log_dir ......................... logs........................updated\n",
            "  lr .............................. 0.001.......................updated\n",
            "  lr_decay_iters .................. 800.........................updated\n",
            "  max_position_embeddings ......... 512.........................updated\n",
            "  min_lr .......................... 0.0001......................updated\n",
            "  num_attention_heads ............. 4...........................updated\n",
            "  num_layers ...................... 4...........................updated\n",
            "  num_workers ..................... 1...........................updated\n",
            "  optimizer ....................... {'type': 'Adam', 'params': {'lr': 0.001, 'betas': [0.9, 0.95], 'eps': 1e-08}}updated\n",
            "  optimizer_type .................. Adam........................updated\n",
            "  output_layer_init_method ........ wang_init...................updated\n",
            "  partition_activations ........... True........................updated\n",
            "  pos_emb ......................... rotary......................updated\n",
            "  precision ....................... fp16........................updated\n",
            "  save ............................ checkpoints.................updated\n",
            "  seq_length ...................... 512.........................updated\n",
            "  sparsity_config ................. {}..........................updated\n",
            "  steps_per_print ................. 100.........................updated\n",
            "  synchronize_each_layer .......... True........................updated\n",
            "  tensorboard_dir ................. tensorboard.................updated\n",
            "  text_gen_type ................... unconditional...............updated\n",
            "  tokenizer_type .................. CharLevelTokenizer..........updated\n",
            "  train_batch_size ................ 256.........................updated\n",
            "  train_iters ..................... 800.........................updated\n",
            "  train_micro_batch_size_per_gpu .. 256.........................updated\n",
            "  user_script ..................... train.py....................updated\n",
            "  zero_allgather_bucket_size ...... 500000000...................updated\n",
            "  zero_contiguous_gradients ....... True........................updated\n",
            "  zero_optimization ............... {'stage': 1, 'allgather_partitions': True, 'allgather_bucket_size': 500000000, 'overlap_comm': True, 'reduce_scatter': True, 'reduce_bucket_size': 500000000, 'contiguous_gradients': True}updated\n",
            "  zero_reduce_bucket_size ......... 500000000...................updated\n",
            "  zero_reduce_scatter ............. True........................updated\n",
            "  zero_stage ...................... 1...........................updated\n",
            "  account ......................... None........................default\n",
            "  activation ...................... gelu........................default\n",
            "  activation_checkpointing ........ None........................default\n",
            "  adlr_autoresume ................. False.......................default\n",
            "  adlr_autoresume_interval ........ 1000........................default\n",
            "  allow_chopped ................... True........................default\n",
            "  amp ............................. None........................default\n",
            "  apply_query_key_layer_scaling ... False.......................default\n",
            "  attention_dropout ............... 0...........................default\n",
            "  attention_softmax_in_fp32 ....... False.......................default\n",
            "  autotuning ...................... None........................default\n",
            "  autotuning_run .................. None........................default\n",
            "  base_shapes_file ................ None........................default\n",
            "  bf16 ............................ None........................default\n",
            "  bias_dropout_fusion ............. False.......................default\n",
            "  bias_gelu_fusion ................ False.......................default\n",
            "  char_level_ppl .................. False.......................default\n",
            "  checkpoint ...................... None........................default\n",
            "  checkpoint_activations .......... False.......................default\n",
            "  checkpoint_in_cpu ............... False.......................default\n",
            "  checkpoint_num_layers ........... 1...........................default\n",
            "  checkpoint_scale ................ linear......................default\n",
            "  checkpoint_validation_with_forward_pass  False................default\n",
            "  clip_grad ....................... 1.0.........................default\n",
            "  comet_experiment ................ None........................default\n",
            "  comet_experiment_name ........... None........................default\n",
            "  comet_others .................... None........................default\n",
            "  comet_project ................... None........................default\n",
            "  comet_tags ...................... None........................default\n",
            "  comet_workspace ................. None........................default\n",
            "  comment ......................... None........................default\n",
            "  comms_logger .................... None........................default\n",
            "  communication_data_type ......... None........................default\n",
            "  compression_training ............ None........................default\n",
            "  contiguous_checkpointing ........ False.......................default\n",
            "  coord_check ..................... False.......................default\n",
            "  create_moe_param_group .......... True........................default\n",
            "  csv_monitor ..................... None........................default\n",
            "  curriculum_learning ............. None........................default\n",
            "  curriculum_seqlen ............... 0...........................default\n",
            "  data_efficiency ................. None........................default\n",
            "  data_types ...................... None........................default\n",
            "  dataset_impl .................... gpt2........................default\n",
            "  deepscale ....................... False.......................default\n",
            "  deepscale_config ................ None........................default\n",
            "  deepspeed ....................... True........................default\n",
            "  deepspeed_activation_checkpointing  True......................default\n",
            "  deepspeed_mpi ................... False.......................default\n",
            "  deepspeed_slurm ................. False.......................default\n",
            "  detect_nvlink_pairs ............. False.......................default\n",
            "  dim_att ......................... None........................default\n",
            "  distributed_backend ............. nccl........................default\n",
            "  do_test ......................... None........................default\n",
            "  do_train ........................ None........................default\n",
            "  do_valid ........................ None........................default\n",
            "  dpo_beta ........................ 0.1.........................default\n",
            "  dpo_fp32 ........................ True........................default\n",
            "  dpo_reference_free .............. False.......................default\n",
            "  dump_state ...................... False.......................default\n",
            "  elasticity ...................... None........................default\n",
            "  enable_expert_tensor_parallelism  False.......................default\n",
            "  eod_mask_loss ................... False.......................default\n",
            "  eval_results_prefix ............. ............................default\n",
            "  eval_tasks ...................... None........................default\n",
            "  exclude ......................... None........................default\n",
            "  exit_interval ................... None........................default\n",
            "  expansion_factor ................ None........................default\n",
            "  expert_interval ................. 2...........................default\n",
            "  extra_save_iters ................ None........................default\n",
            "  ffn_dim ......................... None........................default\n",
            "  finetune ........................ False.......................default\n",
            "  flops_profiler .................. None........................default\n",
            "  force_multi ..................... False.......................default\n",
            "  fp16_lm_cross_entropy ........... False.......................default\n",
            "  fp32_allreduce .................. False.......................default\n",
            "  git_hash ........................ 73865bc.....................default\n",
            "  gmlp_attn_dim ................... 64..........................default\n",
            "  gpt_j_residual .................. False.......................default\n",
            "  gpt_j_tied ...................... False.......................default\n",
            "  gradient_accumulation_steps ..... 1...........................default\n",
            "  gradient_clipping ............... 1.0.........................default\n",
            "  gradient_noise_scale_cpu_offload  False.......................default\n",
            "  gradient_noise_scale_n_batches .. 5...........................default\n",
            "  gradient_predivide_factor ....... 1.0.........................default\n",
            "  head_size ....................... None........................default\n",
            "  hidden_dropout .................. 0...........................default\n",
            "  hostfile ........................ None........................default\n",
            "  hysteresis ...................... 2...........................default\n",
            "  include ......................... None........................default\n",
            "  init_method_std ................. 0.02........................default\n",
            "  intermediate_size ............... None........................default\n",
            "  is_pipe_parallel ................ False.......................default\n",
            "  iteration ....................... None........................default\n",
            "  keep_last_n_checkpoints ......... None........................default\n",
            "  kto_beta ........................ 0.1.........................default\n",
            "  kto_desirable_weight ............ 1.0.........................default\n",
            "  kto_fp32 ........................ True........................default\n",
            "  kto_undesirable_weight .......... 1.0.........................default\n",
            "  launcher ........................ pdsh........................default\n",
            "  layernorm_epsilon ............... 1e-05.......................default\n",
            "  layernorm_fusion ................ False.......................default\n",
            "  lazy_mpu_init ................... False.......................default\n",
            "  local_rank ...................... None........................default\n",
            "  log_grad_norm ................... False.......................default\n",
            "  log_grad_pct_zeros .............. False.......................default\n",
            "  log_gradient_noise_scale ........ False.......................default\n",
            "  log_interval .................... 100.........................default\n",
            "  log_optimizer_states ............ False.......................default\n",
            "  log_param_norm .................. False.......................default\n",
            "  loss_scale ...................... None........................default\n",
            "  loss_scale_window ............... 1000.0......................default\n",
            "  lr_decay_fraction ............... None........................default\n",
            "  lr_decay_style .................. linear......................default\n",
            "  make_vocab_size_divisible_by .... 128.........................default\n",
            "  mamba_causal_conv_fusion ........ False.......................default\n",
            "  mamba_inner_func_fusion ......... False.......................default\n",
            "  mamba_selective_fp32_params ..... True........................default\n",
            "  mamba_selective_scan_fusion ..... False.......................default\n",
            "  mamba_use_bias_in_conv .......... True........................default\n",
            "  mamba_use_bias_in_linears ....... False.......................default\n",
            "  master_addr ..................... None........................default\n",
            "  master_port ..................... 29500.......................default\n",
            "  maximum_tokens .................. 64..........................default\n",
            "  memory_profiling ................ False.......................default\n",
            "  memory_profiling_path ........... None........................default\n",
            "  merge_file ...................... None........................default\n",
            "  min_scale ....................... 1.0.........................default\n",
            "  mlp_multiple_of ................. 1...........................default\n",
            "  mmap_warmup ..................... False.......................default\n",
            "  model_parallel_size ............. 1...........................default\n",
            "  moe_eval_capacity_factor ........ 1.0.........................default\n",
            "  moe_expert_parallel_size ........ 1...........................default\n",
            "  moe_glu ......................... False.......................default\n",
            "  moe_jitter_eps .................. None........................default\n",
            "  moe_lbl_in_fp32 ................. False.......................default\n",
            "  moe_loss_coeff .................. 0.1.........................default\n",
            "  moe_min_capacity ................ 4...........................default\n",
            "  moe_num_experts ................. 1...........................default\n",
            "  moe_token_dropping .............. False.......................default\n",
            "  moe_top_k ....................... 1...........................default\n",
            "  moe_train_capacity_factor ....... 1.0.........................default\n",
            "  moe_type ........................ megablocks..................default\n",
            "  moe_use_residual ................ True........................default\n",
            "  mup_attn_temp ................... 1.0.........................default\n",
            "  mup_embedding_mult .............. 1.0.........................default\n",
            "  mup_init_scale .................. 1.0.........................default\n",
            "  mup_output_temp ................. 1.0.........................default\n",
            "  mup_rp_embedding_mult ........... 1.0.........................default\n",
            "  mup_width_scale ................. 2...........................default\n",
            "  neg_test_data_paths ............. None........................default\n",
            "  neg_test_label_data_paths ....... None........................default\n",
            "  neg_train_data_paths ............ None........................default\n",
            "  neg_train_label_data_paths ...... None........................default\n",
            "  neg_valid_data_paths ............ None........................default\n",
            "  neg_valid_label_data_paths ...... None........................default\n",
            "  no_load_optim ................... False.......................default\n",
            "  no_load_rng ..................... False.......................default\n",
            "  no_save_optim ................... False.......................default\n",
            "  no_save_rng ..................... False.......................default\n",
            "  no_ssh_check .................... False.......................default\n",
            "  no_weight_tying ................. False.......................default\n",
            "  norm ............................ layernorm...................default\n",
            "  num_gpus ........................ None........................default\n",
            "  num_kv_heads .................... None........................default\n",
            "  num_nodes ....................... -1..........................default\n",
            "  num_samples ..................... 1...........................default\n",
            "  num_unique_layers ............... None........................default\n",
            "  onnx_safe ....................... False.......................default\n",
            "  opt_pos_emb_offset .............. 0...........................default\n",
            "  output_layer_parallelism ........ column......................default\n",
            "  override_lr_scheduler ........... False.......................default\n",
            "  pack_impl ....................... packed......................default\n",
            "  padded_vocab_size ............... None........................default\n",
            "  param_sharing_style ............. grouped.....................default\n",
            "  pipe_parallel_size .............. 0...........................default\n",
            "  pipe_partition_method ........... type:transformer|mlp........default\n",
            "  pos_test_data_paths ............. None........................default\n",
            "  pos_test_label_data_paths ....... None........................default\n",
            "  pos_train_data_paths ............ None........................default\n",
            "  pos_train_label_data_paths ...... None........................default\n",
            "  pos_valid_data_paths ............ None........................default\n",
            "  pos_valid_label_data_paths ...... None........................default\n",
            "  precompute_model_name ........... None........................default\n",
            "  prescale_gradients .............. False.......................default\n",
            "  profile ......................... False.......................default\n",
            "  profile_backward ................ False.......................default\n",
            "  profile_step_start .............. 10..........................default\n",
            "  profile_step_stop ............... 12..........................default\n",
            "  prompt_end ...................... \n",
            "...........................default\n",
            "  rank ............................ None........................default\n",
            "  recompute ....................... False.......................default\n",
            "  return_logits ................... False.......................default\n",
            "  rms_norm_epsilon ................ 1e-08.......................default\n",
            "  rmsnorm_fusion .................. False.......................default\n",
            "  rope_fusion ..................... False.......................default\n",
            "  rotary_emb_base ................. 10000.......................default\n",
            "  rotary_pct ...................... 1.0.........................default\n",
            "  rotary_save_freqs_buffer ........ False.......................default\n",
            "  rpe_max_distance ................ 128.........................default\n",
            "  rpe_num_buckets ................. 32..........................default\n",
            "  s3_chunk_size ................... 104857600...................default\n",
            "  s3_path ......................... None........................default\n",
            "  sample_input_file ............... None........................default\n",
            "  sample_output_file .............. samples.txt.................default\n",
            "  save_base_shapes ................ False.......................default\n",
            "  scaled_masked_softmax_fusion .... False.......................default\n",
            "  scaled_upper_triang_masked_softmax_fusion  False..............default\n",
            "  scalenorm_epsilon ............... 1e-08.......................default\n",
            "  scheduler ....................... None........................default\n",
            "  seed ............................ 1234........................default\n",
            "  sequence_parallel ............... False.......................default\n",
            "  short_seq_prob .................. 0.1.........................default\n",
            "  sliding_window_width ............ None........................default\n",
            "  soft_prompt_tuning .............. None........................default\n",
            "  sparse_attention ................ None........................default\n",
            "  sparse_gradients ................ False.......................default\n",
            "  split ........................... 969, 30, 1..................default\n",
            "  temperature ..................... 0.0.........................default\n",
            "  tensorboard ..................... None........................default\n",
            "  test_data_paths ................. None........................default\n",
            "  test_data_weights ............... None........................default\n",
            "  test_label_data_paths ........... None........................default\n",
            "  test_reward_data_paths .......... None........................default\n",
            "  top_k ........................... 0...........................default\n",
            "  top_p ........................... 0.0.........................default\n",
            "  train_data_paths ................ None........................default\n",
            "  train_data_weights .............. None........................default\n",
            "  train_epochs .................... None........................default\n",
            "  train_impl ...................... normal......................default\n",
            "  train_label_data_paths .......... None........................default\n",
            "  train_reward_data_paths ......... None........................default\n",
            "  use_bias_in_attn_linear ......... True........................default\n",
            "  use_bias_in_mlp ................. True........................default\n",
            "  use_bias_in_norms ............... True........................default\n",
            "  use_bnb_optimizer ............... False.......................default\n",
            "  use_checkpoint_lr_scheduler ..... False.......................default\n",
            "  use_comet ....................... None........................default\n",
            "  use_cpu_initialization .......... False.......................default\n",
            "  use_flashattn_swiglu ............ False.......................default\n",
            "  use_mup ......................... False.......................default\n",
            "  use_qk_layernorm ................ False.......................default\n",
            "  use_shared_fs ................... True........................default\n",
            "  use_tutel ....................... False.......................default\n",
            "  use_wandb ....................... None........................default\n",
            "  valid_data_paths ................ None........................default\n",
            "  valid_data_weights .............. None........................default\n",
            "  valid_label_data_paths .......... None........................default\n",
            "  valid_reward_data_paths ......... None........................default\n",
            "  vocab_file ...................... None........................default\n",
            "  wall_clock_breakdown ............ False.......................default\n",
            "  wandb ........................... None........................default\n",
            "  wandb_group ..................... None........................default\n",
            "  wandb_host ...................... https://api.wandb.ai........default\n",
            "  wandb_init_all_ranks ............ False.......................default\n",
            "  wandb_project ................... neox........................default\n",
            "  wandb_team ...................... None........................default\n",
            "  warmup .......................... 0.01........................default\n",
            "  weight_by_num_documents ......... False.......................default\n",
            "  weight_decay .................... 0.1.........................default\n",
            "  weighted_sampler_alpha .......... 1.0.........................default\n",
            "  world_size ...................... None........................default\n",
            "  z_loss .......................... 0.0.........................default\n",
            "---------------- end of arguments ----------------\n",
            "NeoXArgs.configure_distributed_args() using world size: 1 and model-parallel size: 1 \n",
            "[2024-12-03 14:07:37,276] [WARNING] [runner.py:217:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
            "[2024-12-03 14:07:37,277] [INFO] [runner.py:586:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None train.py --deepspeed_config eyJ0cmFpbl9iYXRjaF9zaXplIjogMjU2LCAidHJhaW5fbWljcm9fYmF0Y2hfc2l6ZV9wZXJfZ3B1IjogMjU2LCAib3B0aW1pemVyIjogeyJ0eXBlIjogIkFkYW0iLCAicGFyYW1zIjogeyJsciI6IDAuMDAxLCAiYmV0YXMiOiBbMC45LCAwLjk1XSwgImVwcyI6IDFlLTA4fX0sICJmcDE2IjogeyJmcDE2IjogdHJ1ZSwgImVuYWJsZWQiOiB0cnVlLCAibG9zc19zY2FsZSI6IDAsICJsb3NzX3NjYWxlX3dpbmRvdyI6IDEwMDAsICJpbml0aWFsX3NjYWxlX3Bvd2VyIjogMTIsICJoeXN0ZXJlc2lzIjogMiwgIm1pbl9sb3NzX3NjYWxlIjogMX0sICJ6ZXJvX29wdGltaXphdGlvbiI6IHsic3RhZ2UiOiAxLCAiYWxsZ2F0aGVyX3BhcnRpdGlvbnMiOiB0cnVlLCAiYWxsZ2F0aGVyX2J1Y2tldF9zaXplIjogNTAwMDAwMDAwLCAib3ZlcmxhcF9jb21tIjogdHJ1ZSwgInJlZHVjZV9zY2F0dGVyIjogdHJ1ZSwgInJlZHVjZV9idWNrZXRfc2l6ZSI6IDUwMDAwMDAwMCwgImNvbnRpZ3VvdXNfZ3JhZGllbnRzIjogdHJ1ZX0sICJzdGVwc19wZXJfcHJpbnQiOiAxMDAsICJjb21tc19sb2dnZXIiOiB7ImVuYWJsZWQiOiBmYWxzZSwgInZlcmJvc2UiOiBmYWxzZSwgInByb2ZfYWxsIjogZmFsc2UsICJkZWJ1ZyI6IGZhbHNlfX0= --megatron_config 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\n",
            "[2024-12-03 14:07:38,747] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2024-12-03 14:07:40,978] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.19.3-1+cuda12.2\n",
            "[2024-12-03 14:07:40,978] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.19.3-1\n",
            "[2024-12-03 14:07:40,978] [INFO] [launch.py:138:main] 0 NCCL_VERSION=2.19.3-1\n",
            "[2024-12-03 14:07:40,978] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n",
            "[2024-12-03 14:07:40,979] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.19.3-1+cuda12.2\n",
            "[2024-12-03 14:07:40,979] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n",
            "[2024-12-03 14:07:40,979] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.19.3-1\n",
            "[2024-12-03 14:07:40,979] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0]}\n",
            "[2024-12-03 14:07:40,979] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0\n",
            "[2024-12-03 14:07:40,979] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
            "[2024-12-03 14:07:40,979] [INFO] [launch.py:163:main] dist_world_size=1\n",
            "[2024-12-03 14:07:40,979] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0\n",
            "[2024-12-03 14:07:42,589] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba\n",
            "For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer\n",
            "NeoXArgs.configure_distributed_args() using world size: 1 and model-parallel size: 1 \n",
            "> building CharLevelTokenizer tokenizer ...\n",
            " > padded vocab (size: 512) with 0 dummy tokens (new size: 512)\n",
            "2024-12-03 14:07:46.062132: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-03 14:07:46.081958: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-03 14:07:46.088361: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-03 14:07:47.121143: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "> setting up tensorboard ...\n",
            "> initializing torch distributed ...\n",
            "[2024-12-03 14:07:47,854] [INFO] [comm.py:637:init_distributed] cdb=None\n",
            "[2024-12-03 14:07:47,854] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
            "> initializing model parallel with size 1\n",
            "MPU DP: [0]\n",
            "MPU PP: [0]\n",
            "MPU MP: [0]\n",
            "> setting random seeds to 1234 ...\n",
            "[2024-12-03 14:07:47,859] [INFO] [checkpointing.py:227:model_parallel_cuda_manual_seed] > initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234\n",
            "make: Entering directory '/content/gpt-neox/megatron/data'\n",
            "make: Nothing to be done for 'default'.\n",
            "make: Leaving directory '/content/gpt-neox/megatron/data'\n",
            "> building train, validation, and test datasets ...\n",
            "    reading sizes...\n",
            "    reading pointers...\n",
            "    reading document index...\n",
            "    creating numpy buffer of mmap...\n",
            "    creating memory view of numpy buffer...\n",
            " > dataset split:\n",
            "    train:\n",
            "     document indices in [0, 31761) total of 31761 documents\n",
            "    validation:\n",
            "     document indices in [31761, 32744) total of 983 documents\n",
            "    test:\n",
            "     document indices in [32744, 32777) total of 33 documents\n",
            "/content/gpt-neox/megatron/data/gpt2_dataset.py:373: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n",
            "  counts = torch.cuda.LongTensor([1])\n",
            " > loading doc-idx mapping from processed_data/shakespeare_text_document_train_indexmap_204800ns_512sl_1234s_packedpi_ac_doc_idx.npy\n",
            " > loading sample-idx mapping from processed_data/shakespeare_text_document_train_indexmap_204800ns_512sl_1234s_packedpi_ac_sample_idx.npy\n",
            " > loading shuffle-idx mapping from processed_data/shakespeare_text_document_train_indexmap_204800ns_512sl_1234s_packedpi_ac_shuffle_idx.npy\n",
            "    loaded indexed file in 0.001 seconds\n",
            "    total number of samples: 206363\n",
            "    total number of epochs: 98\n",
            " > loading doc-idx mapping from processed_data/shakespeare_text_document_valid_indexmap_13824ns_512sl_1234s_packedpi_ac_doc_idx.npy\n",
            " > loading sample-idx mapping from processed_data/shakespeare_text_document_valid_indexmap_13824ns_512sl_1234s_packedpi_ac_sample_idx.npy\n",
            " > loading shuffle-idx mapping from processed_data/shakespeare_text_document_valid_indexmap_13824ns_512sl_1234s_packedpi_ac_shuffle_idx.npy\n",
            "    loaded indexed file in 0.001 seconds\n",
            "    total number of samples: 13868\n",
            "    total number of epochs: 244\n",
            " > loading doc-idx mapping from processed_data/shakespeare_text_document_test_indexmap_512ns_512sl_1234s_packedpi_ac_doc_idx.npy\n",
            " > loading sample-idx mapping from processed_data/shakespeare_text_document_test_indexmap_512ns_512sl_1234s_packedpi_ac_sample_idx.npy\n",
            " > loading shuffle-idx mapping from processed_data/shakespeare_text_document_test_indexmap_512ns_512sl_1234s_packedpi_ac_shuffle_idx.npy\n",
            "    loaded indexed file in 0.018 seconds\n",
            "    total number of samples: 513\n",
            "    total number of epochs: 281\n",
            "building GPT2 model ...\n",
            "SEED_LAYERS=False BASE_SEED=1234 SEED_FN=None\n",
            "Using topology: {ProcessCoord(pipe=0, data=0, model=0): 0}\n",
            "[2024-12-03 14:07:48,418] [INFO] [module.py:375:_partition_layers] Partitioning pipeline stages with method type:transformer|mlp\n",
            "stage=0 layers=9\n",
            "     0: EmbeddingPipe\n",
            "     1: _pre_transformer_block\n",
            "     2: ParallelTransformerLayerPipe\n",
            "     3: ParallelTransformerLayerPipe\n",
            "     4: ParallelTransformerLayerPipe\n",
            "     5: ParallelTransformerLayerPipe\n",
            "     6: _post_transformer_block\n",
            "     7: NormPipe\n",
            "     8: EmbeddingPipe\n",
            "  loss: partial\n",
            "Configuring Optimizer type: Adam with params: {'lr': 0.001, 'betas': [0.9, 0.95], 'eps': 1e-08}\n",
            "WARNING: APEX not installed - defaulting to deepspeed's fused adam\n",
            "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py310_cu121/fused_adam/build.ninja...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n",
            "Building extension module fused_adam...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "ninja: no work to do.\n",
            "Loading extension module fused_adam...\n",
            "Time to load fused_adam op: 0.030070781707763672 seconds\n",
            "> learning rate decay style: linear\n",
            "DeepSpeed is enabled.\n",
            "[2024-12-03 14:07:49,096] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.12.4+02e2ebf, git-hash=02e2ebf, git-branch=HEAD\n",
            "[2024-12-03 14:07:49,104] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
            "[2024-12-03 14:07:49,105] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
            "[2024-12-03 14:07:49,105] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
            "[2024-12-03 14:07:49,106] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam\n",
            "[2024-12-03 14:07:49,106] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>\n",
            "[2024-12-03 14:07:49,106] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 1 optimizer\n",
            "[2024-12-03 14:07:49,106] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 500000000\n",
            "[2024-12-03 14:07:49,106] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 500000000\n",
            "[2024-12-03 14:07:49,106] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
            "[2024-12-03 14:07:49,106] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
            "[2024-12-03 14:07:49,401] [INFO] [utils.py:802:see_memory_usage] Before initializing optimizer states\n",
            "[2024-12-03 14:07:49,402] [INFO] [utils.py:803:see_memory_usage] MA 0.02 GB         Max_MA 0.02 GB         CA 0.04 GB         Max_CA 0 GB \n",
            "[2024-12-03 14:07:49,402] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 3.33 GB, percent = 6.5%\n",
            "[2024-12-03 14:07:49,665] [INFO] [utils.py:802:see_memory_usage] After initializing optimizer states\n",
            "[2024-12-03 14:07:49,665] [INFO] [utils.py:803:see_memory_usage] MA 0.05 GB         Max_MA 0.06 GB         CA 0.07 GB         Max_CA 0 GB \n",
            "[2024-12-03 14:07:49,666] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 3.33 GB, percent = 6.5%\n",
            "[2024-12-03 14:07:49,666] [INFO] [stage_1_and_2.py:517:__init__] optimizer state initialized\n",
            "[2024-12-03 14:07:49,933] [INFO] [utils.py:802:see_memory_usage] After initializing ZeRO optimizer\n",
            "[2024-12-03 14:07:49,933] [INFO] [utils.py:803:see_memory_usage] MA 0.05 GB         Max_MA 0.05 GB         CA 0.07 GB         Max_CA 0 GB \n",
            "[2024-12-03 14:07:49,934] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 3.33 GB, percent = 6.5%\n",
            "[2024-12-03 14:07:49,936] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam\n",
            "[2024-12-03 14:07:49,936] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
            "[2024-12-03 14:07:49,937] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <megatron.learning_rates.AnnealingLR object at 0x7eb9017bf550>\n",
            "[2024-12-03 14:07:49,937] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[[0.9, 0.95], [0.9, 0.95]]\n",
            "[2024-12-03 14:07:49,937] [INFO] [config.py:979:print] DeepSpeedEngine configuration:\n",
            "[2024-12-03 14:07:49,938] [INFO] [config.py:983:print]   activation_checkpointing_config  {\n",
            "    \"partition_activations\": false, \n",
            "    \"contiguous_memory_optimization\": false, \n",
            "    \"cpu_checkpointing\": false, \n",
            "    \"number_checkpoints\": null, \n",
            "    \"synchronize_checkpoint_boundary\": false, \n",
            "    \"profile\": false\n",
            "}\n",
            "[2024-12-03 14:07:49,938] [INFO] [config.py:983:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
            "[2024-12-03 14:07:49,938] [INFO] [config.py:983:print]   amp_enabled .................. False\n",
            "[2024-12-03 14:07:49,938] [INFO] [config.py:983:print]   amp_params ................... False\n",
            "[2024-12-03 14:07:49,938] [INFO] [config.py:983:print]   autotuning_config ............ {\n",
            "    \"enabled\": false, \n",
            "    \"start_step\": null, \n",
            "    \"end_step\": null, \n",
            "    \"metric_path\": null, \n",
            "    \"arg_mappings\": null, \n",
            "    \"metric\": \"throughput\", \n",
            "    \"model_info\": null, \n",
            "    \"results_dir\": \"autotuning_results\", \n",
            "    \"exps_dir\": \"autotuning_exps\", \n",
            "    \"overwrite\": true, \n",
            "    \"fast\": true, \n",
            "    \"start_profile_step\": 3, \n",
            "    \"end_profile_step\": 5, \n",
            "    \"tuner_type\": \"gridsearch\", \n",
            "    \"tuner_early_stopping\": 5, \n",
            "    \"tuner_num_trials\": 50, \n",
            "    \"model_info_path\": null, \n",
            "    \"mp_size\": 1, \n",
            "    \"max_train_batch_size\": null, \n",
            "    \"min_train_batch_size\": 1, \n",
            "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
            "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
            "    \"num_tuning_micro_batch_sizes\": 3\n",
            "}\n",
            "[2024-12-03 14:07:49,938] [INFO] [config.py:983:print]   bfloat16_enabled ............. False\n",
            "[2024-12-03 14:07:49,938] [INFO] [config.py:983:print]   checkpoint_parallel_write_pipeline  False\n",
            "[2024-12-03 14:07:49,938] [INFO] [config.py:983:print]   checkpoint_tag_validation_enabled  True\n",
            "[2024-12-03 14:07:49,938] [INFO] [config.py:983:print]   checkpoint_tag_validation_fail  False\n",
            "[2024-12-03 14:07:49,938] [INFO] [config.py:983:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7eb8d2296020>\n",
            "[2024-12-03 14:07:49,939] [INFO] [config.py:983:print]   communication_data_type ...... None\n",
            "[2024-12-03 14:07:49,939] [INFO] [config.py:983:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
            "[2024-12-03 14:07:49,939] [INFO] [config.py:983:print]   curriculum_enabled_legacy .... False\n",
            "[2024-12-03 14:07:49,939] [INFO] [config.py:983:print]   curriculum_params_legacy ..... False\n",
            "[2024-12-03 14:07:49,939] [INFO] [config.py:983:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
            "[2024-12-03 14:07:49,939] [INFO] [config.py:983:print]   data_efficiency_enabled ...... False\n",
            "[2024-12-03 14:07:49,939] [INFO] [config.py:983:print]   dataloader_drop_last ......... False\n",
            "[2024-12-03 14:07:49,939] [INFO] [config.py:983:print]   disable_allgather ............ False\n",
            "[2024-12-03 14:07:49,939] [INFO] [config.py:983:print]   dump_state ................... False\n",
            "[2024-12-03 14:07:49,939] [INFO] [config.py:983:print]   dynamic_loss_scale_args ...... {'init_scale': 4096, 'scale_window': 1000, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}\n",
            "[2024-12-03 14:07:49,939] [INFO] [config.py:983:print]   eigenvalue_enabled ........... False\n",
            "[2024-12-03 14:07:49,939] [INFO] [config.py:983:print]   eigenvalue_gas_boundary_resolution  1\n",
            "[2024-12-03 14:07:49,939] [INFO] [config.py:983:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
            "[2024-12-03 14:07:49,939] [INFO] [config.py:983:print]   eigenvalue_layer_num ......... 0\n",
            "[2024-12-03 14:07:49,939] [INFO] [config.py:983:print]   eigenvalue_max_iter .......... 100\n",
            "[2024-12-03 14:07:49,939] [INFO] [config.py:983:print]   eigenvalue_stability ......... 1e-06\n",
            "[2024-12-03 14:07:49,939] [INFO] [config.py:983:print]   eigenvalue_tol ............... 0.01\n",
            "[2024-12-03 14:07:49,939] [INFO] [config.py:983:print]   eigenvalue_verbose ........... False\n",
            "[2024-12-03 14:07:49,939] [INFO] [config.py:983:print]   elasticity_enabled ........... False\n",
            "[2024-12-03 14:07:49,939] [INFO] [config.py:983:print]   flops_profiler_config ........ {\n",
            "    \"enabled\": false, \n",
            "    \"recompute_fwd_factor\": 0.0, \n",
            "    \"profile_step\": 1, \n",
            "    \"module_depth\": -1, \n",
            "    \"top_modules\": 1, \n",
            "    \"detailed\": true, \n",
            "    \"output_file\": null\n",
            "}\n",
            "[2024-12-03 14:07:49,939] [INFO] [config.py:983:print]   fp16_auto_cast ............... False\n",
            "[2024-12-03 14:07:49,939] [INFO] [config.py:983:print]   fp16_enabled ................. True\n",
            "[2024-12-03 14:07:49,939] [INFO] [config.py:983:print]   fp16_master_weights_and_gradients  False\n",
            "[2024-12-03 14:07:49,939] [INFO] [config.py:983:print]   global_rank .................. 0\n",
            "[2024-12-03 14:07:49,940] [INFO] [config.py:983:print]   grad_accum_dtype ............. None\n",
            "[2024-12-03 14:07:49,940] [INFO] [config.py:983:print]   gradient_accumulation_steps .. 1\n",
            "[2024-12-03 14:07:49,940] [INFO] [config.py:983:print]   gradient_clipping ............ 0.0\n",
            "[2024-12-03 14:07:49,940] [INFO] [config.py:983:print]   gradient_predivide_factor .... 1.0\n",
            "[2024-12-03 14:07:49,940] [INFO] [config.py:983:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
            "[2024-12-03 14:07:49,940] [INFO] [config.py:983:print]   initial_dynamic_scale ........ 4096\n",
            "[2024-12-03 14:07:49,940] [INFO] [config.py:983:print]   load_universal_checkpoint .... False\n",
            "[2024-12-03 14:07:49,940] [INFO] [config.py:983:print]   loss_scale ................... 0\n",
            "[2024-12-03 14:07:49,940] [INFO] [config.py:983:print]   memory_breakdown ............. False\n",
            "[2024-12-03 14:07:49,940] [INFO] [config.py:983:print]   mics_hierarchial_params_gather  False\n",
            "[2024-12-03 14:07:49,940] [INFO] [config.py:983:print]   mics_shard_size .............. -1\n",
            "[2024-12-03 14:07:49,940] [INFO] [config.py:983:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
            "[2024-12-03 14:07:49,940] [INFO] [config.py:983:print]   nebula_config ................ {\n",
            "    \"enabled\": false, \n",
            "    \"persistent_storage_path\": null, \n",
            "    \"persistent_time_interval\": 100, \n",
            "    \"num_of_version_in_retention\": 2, \n",
            "    \"enable_nebula_load\": true, \n",
            "    \"load_path\": null\n",
            "}\n",
            "[2024-12-03 14:07:49,940] [INFO] [config.py:983:print]   optimizer_legacy_fusion ...... False\n",
            "[2024-12-03 14:07:49,940] [INFO] [config.py:983:print]   optimizer_name ............... adam\n",
            "[2024-12-03 14:07:49,940] [INFO] [config.py:983:print]   optimizer_params ............. {'lr': 0.001, 'betas': [0.9, 0.95], 'eps': 1e-08}\n",
            "[2024-12-03 14:07:49,940] [INFO] [config.py:983:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
            "[2024-12-03 14:07:49,940] [INFO] [config.py:983:print]   pld_enabled .................. False\n",
            "[2024-12-03 14:07:49,940] [INFO] [config.py:983:print]   pld_params ................... False\n",
            "[2024-12-03 14:07:49,940] [INFO] [config.py:983:print]   prescale_gradients ........... False\n",
            "[2024-12-03 14:07:49,940] [INFO] [config.py:983:print]   scheduler_name ............... None\n",
            "[2024-12-03 14:07:49,940] [INFO] [config.py:983:print]   scheduler_params ............. None\n",
            "[2024-12-03 14:07:49,940] [INFO] [config.py:983:print]   seq_parallel_communication_data_type  torch.float32\n",
            "[2024-12-03 14:07:49,941] [INFO] [config.py:983:print]   sparse_attention ............. None\n",
            "[2024-12-03 14:07:49,941] [INFO] [config.py:983:print]   sparse_gradients_enabled ..... False\n",
            "[2024-12-03 14:07:49,941] [INFO] [config.py:983:print]   steps_per_print .............. 100\n",
            "[2024-12-03 14:07:49,941] [INFO] [config.py:983:print]   train_batch_size ............. 256\n",
            "[2024-12-03 14:07:49,941] [INFO] [config.py:983:print]   train_micro_batch_size_per_gpu  256\n",
            "[2024-12-03 14:07:49,941] [INFO] [config.py:983:print]   use_data_before_expert_parallel_  False\n",
            "[2024-12-03 14:07:49,941] [INFO] [config.py:983:print]   use_node_local_storage ....... False\n",
            "[2024-12-03 14:07:49,941] [INFO] [config.py:983:print]   wall_clock_breakdown ......... False\n",
            "[2024-12-03 14:07:49,941] [INFO] [config.py:983:print]   weight_quantization_config ... None\n",
            "[2024-12-03 14:07:49,941] [INFO] [config.py:983:print]   world_size ................... 1\n",
            "[2024-12-03 14:07:49,941] [INFO] [config.py:983:print]   zero_allow_untested_optimizer  False\n",
            "[2024-12-03 14:07:49,941] [INFO] [config.py:983:print]   zero_config .................. stage=1 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
            "[2024-12-03 14:07:49,941] [INFO] [config.py:983:print]   zero_enabled ................. True\n",
            "[2024-12-03 14:07:49,941] [INFO] [config.py:983:print]   zero_force_ds_cpu_optimizer .. True\n",
            "[2024-12-03 14:07:49,941] [INFO] [config.py:983:print]   zero_optimization_stage ...... 1\n",
            "[2024-12-03 14:07:49,941] [INFO] [config.py:969:print_user_config]   json = {\n",
            "    \"train_batch_size\": 256, \n",
            "    \"train_micro_batch_size_per_gpu\": 256, \n",
            "    \"optimizer\": {\n",
            "        \"type\": \"Adam\", \n",
            "        \"params\": {\n",
            "            \"lr\": 0.001, \n",
            "            \"betas\": [0.9, 0.95], \n",
            "            \"eps\": 1e-08\n",
            "        }\n",
            "    }, \n",
            "    \"fp16\": {\n",
            "        \"fp16\": true, \n",
            "        \"enabled\": true, \n",
            "        \"loss_scale\": 0, \n",
            "        \"loss_scale_window\": 1000, \n",
            "        \"initial_scale_power\": 12, \n",
            "        \"hysteresis\": 2, \n",
            "        \"min_loss_scale\": 1\n",
            "    }, \n",
            "    \"zero_optimization\": {\n",
            "        \"stage\": 1, \n",
            "        \"allgather_partitions\": true, \n",
            "        \"allgather_bucket_size\": 5.000000e+08, \n",
            "        \"overlap_comm\": true, \n",
            "        \"reduce_scatter\": true, \n",
            "        \"reduce_bucket_size\": 5.000000e+08, \n",
            "        \"contiguous_gradients\": true\n",
            "    }, \n",
            "    \"steps_per_print\": 100, \n",
            "    \"comms_logger\": {\n",
            "        \"enabled\": false, \n",
            "        \"verbose\": false, \n",
            "        \"prof_all\": false, \n",
            "        \"debug\": false\n",
            "    }\n",
            "}\n",
            " > number of parameters on model parallel rank 0: 3290624\n",
            " > total params: 3,290,624\n",
            "[2024-12-03 14:07:49,980] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at checkpoints/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.\n",
            "Unable to load checkpoint.\n",
            "Loading checkpoint and starting from iteration 0\n",
            "setting training data start iteration to 0\n",
            "setting validation data start iteration to 0\n",
            "done with setups ...\n",
            "time (ms) | train/valid/test data loaders: 300.34 | model and optimizer: 1564.59 | train/valid/test data iterators: 90.26\n",
            "training ...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "-------------------------------------------------------------------------------------------------------\n",
            " validation results at iteration 30 | lm_loss value: 2.874833E+00 | lm_loss_ppl value: 1.772247E+01 | \n",
            "-------------------------------------------------------------------------------------------------------\n",
            "[2024-12-03 14:08:24,506] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step50 is about to be saved!\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1898: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
            "  warnings.warn(\n",
            "[2024-12-03 14:08:24,523] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: checkpoints/global_step50/mp_rank_00_model_states.pt\n",
            "[2024-12-03 14:08:24,523] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/global_step50/mp_rank_00_model_states.pt...\n",
            "[2024-12-03 14:08:24,539] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/global_step50/mp_rank_00_model_states.pt.\n",
            "[2024-12-03 14:08:24,540] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/global_step50/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
            "[2024-12-03 14:08:24,612] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/global_step50/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
            "[2024-12-03 14:08:24,612] [INFO] [engine.py:3426:_save_zero_checkpoint] zero checkpoint saved checkpoints/global_step50/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
            "[2024-12-03 14:08:24,612] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step50 is ready now!\n",
            "-------------------------------------------------------------------------------------------------------\n",
            " validation results at iteration 60 | lm_loss value: 2.471807E+00 | lm_loss_ppl value: 1.184382E+01 | \n",
            "-------------------------------------------------------------------------------------------------------\n",
            "-------------------------------------------------------------------------------------------------------\n",
            " validation results at iteration 90 | lm_loss value: 2.305954E+00 | lm_loss_ppl value: 1.003375E+01 | \n",
            "-------------------------------------------------------------------------------------------------------\n",
            "[2024-12-03 14:08:58,915] [INFO] [logging.py:96:log_dist] [Rank 0] step=100, skipped=0, lr=[0.0008838383838383839, 0.0008838383838383839], mom=[[0.9, 0.95], [0.9, 0.95]]\n",
            "[2024-12-03 14:08:58,916] [INFO] [timer.py:260:stop] epoch=0/micro_step=100/global_step=100, RunningAvgSamplesPerSec=387.23700661415154, CurrSamplesPerSec=378.1227095449639, MemAllocated=0.06GB, MaxMemAllocated=7.76GB\n",
            " samples/sec: 371.848 | iteration      100/     800 | elapsed time per iteration (ms): 688.5 | learning rate: 8.838E-04 | approx flops per GPU: 4.9TFLOPS | lm_loss: 2.869912E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
            "after 100 iterations memory (MB) | allocated: 66.47705078125 | max allocated: 7948.60888671875 | reserved: 8694.0 | max reserved: 8694.0\n",
            "time (ms) | forward: 198.63 | backward: 466.57 | backward-backward: 466.54 | backward-allreduce: 0.00 | optimizer: 7.99 | batch generator: 2.37\n",
            "[2024-12-03 14:08:58,919] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step100 is about to be saved!\n",
            "[2024-12-03 14:08:58,922] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: checkpoints/global_step100/mp_rank_00_model_states.pt\n",
            "[2024-12-03 14:08:58,922] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/global_step100/mp_rank_00_model_states.pt...\n",
            "[2024-12-03 14:08:58,937] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/global_step100/mp_rank_00_model_states.pt.\n",
            "[2024-12-03 14:08:58,938] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/global_step100/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
            "[2024-12-03 14:08:59,000] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/global_step100/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
            "[2024-12-03 14:08:59,000] [INFO] [engine.py:3426:_save_zero_checkpoint] zero checkpoint saved checkpoints/global_step100/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
            "[2024-12-03 14:08:59,000] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!\n",
            "--------------------------------------------------------------------------------------------------------\n",
            " validation results at iteration 120 | lm_loss value: 2.163496E+00 | lm_loss_ppl value: 8.701501E+00 | \n",
            "--------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "%cd {GPTNeoXDir}\n",
        "!python ./deepy.py train.py --conf_dir {gpt_neox_colabDir}/configs shakespeare shakespeare_deepy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sk8DhmmEZFyz"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "PKb0Ar6NZFyz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e501c919-10b9-48d0-bd86-abe236b0323d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gpt-neox\n",
            "[2024-12-03 13:22:43,891] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "NeoXArgs.from_ymls() ['/content/GPT-NeoX-Colab/configs/shakespeare.yml', '/content/GPT-NeoX-Colab/configs/shakespeare_gen.yml']\n",
            "INFO:root:NeoXArgs.calculate_derived() Total number of GPUs determined to be: 1\n",
            "-------------------- arguments --------------------\n",
            "  attention_config ................ ['global', 'global', 'global', 'global']updated\n",
            "  batch_size ...................... 256.........................updated\n",
            "  checkpoint_factor ............... 50..........................updated\n",
            "  config_files .................... {'shakespeare.yml': '{\\n  \"pipe_parallel_size\": 0, # Because running on one GPU\\n  \"model_parallel_size\": 1, # Because running on one GPU\\n\\n  # model settings\\n  \"num_layers\": 4,\\n  \"hidden_size\": 256,\\n  \"num_attention_heads\": 4,\\n  \"seq_length\": 512,\\n  \"max_position_embeddings\": 512,\\n  \"pos_emb\": \"rotary\",\\n  \"no_weight_tying\": false, # Sharing embedding and output weights\\n  \"gpt_j_residual\": false,\\n  \"output_layer_parallelism\": \"column\",\\n\\n  \"scaled_upper_triang_masked_softmax_fusion\": false,\\n  \"bias_gelu_fusion\": false,\\n  \"rope_fusion\": false,\\n  \"layernorm_fusion\": false,\\n\\n  # init methods\\n  \"init_method\": \"small_init\",\\n  \"output_layer_init_method\": \"wang_init\",\\n\\n  \"optimizer\": {\\n    \"type\": \"Adam\",\\n    \"params\": {\\n      \"lr\": 0.001,\\n      \"betas\": [0.9, 0.95],\\n      \"eps\": 1.0e-8\\n    }\\n  },\\n  \"min_lr\": 0.0001,\\n\\n  \"zero_optimization\": {\\n    \"stage\": 1,\\n    \"allgather_partitions\": true,\\n    \"allgather_bucket_size\": 500000000,\\n    \"overlap_comm\": true,\\n    \"reduce_scatter\": true,\\n    \"reduce_bucket_size\": 500000000,\\n    \"contiguous_gradients\": true\\n  },\\n\\n  \"train_micro_batch_size_per_gpu\": 256, # 8, #8 for 4GB #256 for 16GB\\n  \"gradient_accumulation_steps\": 1,\\n  \"data_impl\": \"mmap\",\\n  \"num_workers\": 1,\\n\\n  # activation checkpointing\\n  \"checkpoint_activations\": false, # We are not memory bound\\n  \"checkpoint_num_layers\": 1,\\n  \"partition_activations\": true,\\n  \"synchronize_each_layer\": true,\\n\\n  # regularization\\n  \"gradient_clipping\": 1.0,\\n  \"weight_decay\": 0.1,\\n  \"hidden_dropout\": 0,\\n  \"attention_dropout\": 0,\\n\\n  # precision settings\\n  \"fp16\": {\\n    \"fp16\": true,\\n    \"enabled\": true,\\n    \"loss_scale\": 0,\\n    \"loss_scale_window\": 1000,\\n    \"initial_scale_power\": 12,\\n    \"hysteresis\": 2,\\n    \"min_loss_scale\": 1\\n  },\\n\\n  \"train_iters\": 800,\\n  \"lr_decay_iters\": 800,\\n  \"distributed_backend\": \"nccl\",\\n  \"lr_decay_style\": \"linear\",\\n  \"warmup\": 0.01,\\n  \"checkpoint_factor\": 50, # Must be defined if save is set\\n  \"eval_interval\": 30,\\n  \"eval_iters\": 2,\\n\\n  \"log_interval\": 100,\\n  \"steps_per_print\": 100,\\n  \"wall_clock_breakdown\": true,\\n\\n  # Required for model conversion into HF format\\n  \"tokenizer_type\": \"CharLevelTokenizer\",\\n\\n  # additional deepspeed args not specified above\\n  \"deepspeed_extra_args\": {\\n    \"comms_logger\": {\\n      \"enabled\":  false,\\n      \"verbose\":  false,\\n      \"prof_all\": false,\\n      \"debug\":    false\\n    }\\n  }\\n}\\n', 'shakespeare_gen.yml': '# Parameters used for text generation\\n{\\n  # Text gen type: `input-file`, `unconditional` or `interactive`\\n  \"text_gen_type\": \"unconditional\",\\n\\n  # Params for all\\n  \"maximum_tokens\": 102,\\n  \"prompt_end\": \"\\\\n\",\\n  \"temperature\": 1.0,\\n  \"top_p\": 0.0,\\n  \"top_k\": 0,\\n  \"recompute\": false,\\n\\n  # `unconditional`: samples\\n  \"num_samples\": 10,\\n\\n  # input/output file\\n  \"sample_input_file\": \"sample_input.txt\",\\n  \"sample_output_file\": \"sample_output.txt\",\\n\\n  \"data_path\": \"processed_data/shakespeare_text_document\",\\n\\n  \"save\": \"checkpoints\",\\n  \"load\": \"checkpoints\",\\n  \"checkpoint_validation_with_forward_pass\": False,\\n\\n  \"tensorboard_dir\": \"tensorboard_gen\",\\n  \"log_dir\": \"logs_gen\",\\n}'}updated\n",
            "  data_impl ....................... mmap........................updated\n",
            "  data_path ....................... processed_data/shakespeare_text_documentupdated\n",
            "  deepspeed_extra_args ............ {'comms_logger': {'enabled': False, 'verbose': False, 'prof_all': False, 'debug': False}}updated\n",
            "  dynamic_loss_scale .............. True........................updated\n",
            "  eval_interval ................... 30..........................updated\n",
            "  eval_iters ...................... 2...........................updated\n",
            "  fp16 ............................ {'fp16': True, 'enabled': True, 'loss_scale': 0, 'loss_scale_window': 1000, 'initial_scale_power': 12, 'hysteresis': 2, 'min_loss_scale': 1}updated\n",
            "  global_num_gpus ................. 1...........................updated\n",
            "  hidden_size ..................... 256.........................updated\n",
            "  init_method ..................... small_init..................updated\n",
            "  load ............................ checkpoints.................updated\n",
            "  log_dir ......................... logs_gen....................updated\n",
            "  lr .............................. 0.001.......................updated\n",
            "  lr_decay_iters .................. 800.........................updated\n",
            "  max_position_embeddings ......... 512.........................updated\n",
            "  maximum_tokens .................. 102.........................updated\n",
            "  min_lr .......................... 0.0001......................updated\n",
            "  num_attention_heads ............. 4...........................updated\n",
            "  num_layers ...................... 4...........................updated\n",
            "  num_samples ..................... 10..........................updated\n",
            "  num_workers ..................... 1...........................updated\n",
            "  optimizer ....................... {'type': 'Adam', 'params': {'lr': 0.001, 'betas': [0.9, 0.95], 'eps': 1e-08}}updated\n",
            "  optimizer_type .................. Adam........................updated\n",
            "  output_layer_init_method ........ wang_init...................updated\n",
            "  partition_activations ........... True........................updated\n",
            "  pos_emb ......................... rotary......................updated\n",
            "  precision ....................... fp16........................updated\n",
            "  sample_input_file ............... sample_input.txt............updated\n",
            "  sample_output_file .............. sample_output.txt...........updated\n",
            "  save ............................ checkpoints.................updated\n",
            "  seq_length ...................... 512.........................updated\n",
            "  sparsity_config ................. {}..........................updated\n",
            "  steps_per_print ................. 100.........................updated\n",
            "  synchronize_each_layer .......... True........................updated\n",
            "  temperature ..................... 1.0.........................updated\n",
            "  tensorboard_dir ................. tensorboard_gen.............updated\n",
            "  text_gen_type ................... unconditional...............updated\n",
            "  tokenizer_type .................. CharLevelTokenizer..........updated\n",
            "  train_batch_size ................ 256.........................updated\n",
            "  train_iters ..................... 800.........................updated\n",
            "  train_micro_batch_size_per_gpu .. 256.........................updated\n",
            "  user_script ..................... generate.py.................updated\n",
            "  wall_clock_breakdown ............ True........................updated\n",
            "  zero_allgather_bucket_size ...... 500000000...................updated\n",
            "  zero_contiguous_gradients ....... True........................updated\n",
            "  zero_optimization ............... {'stage': 1, 'allgather_partitions': True, 'allgather_bucket_size': 500000000, 'overlap_comm': True, 'reduce_scatter': True, 'reduce_bucket_size': 500000000, 'contiguous_gradients': True}updated\n",
            "  zero_reduce_bucket_size ......... 500000000...................updated\n",
            "  zero_reduce_scatter ............. True........................updated\n",
            "  zero_stage ...................... 1...........................updated\n",
            "  account ......................... None........................default\n",
            "  activation ...................... gelu........................default\n",
            "  activation_checkpointing ........ None........................default\n",
            "  adlr_autoresume ................. False.......................default\n",
            "  adlr_autoresume_interval ........ 1000........................default\n",
            "  allow_chopped ................... True........................default\n",
            "  amp ............................. None........................default\n",
            "  apply_query_key_layer_scaling ... False.......................default\n",
            "  attention_dropout ............... 0...........................default\n",
            "  attention_softmax_in_fp32 ....... False.......................default\n",
            "  autotuning ...................... None........................default\n",
            "  autotuning_run .................. None........................default\n",
            "  base_shapes_file ................ None........................default\n",
            "  bf16 ............................ None........................default\n",
            "  bias_dropout_fusion ............. False.......................default\n",
            "  bias_gelu_fusion ................ False.......................default\n",
            "  char_level_ppl .................. False.......................default\n",
            "  checkpoint ...................... None........................default\n",
            "  checkpoint_activations .......... False.......................default\n",
            "  checkpoint_in_cpu ............... False.......................default\n",
            "  checkpoint_num_layers ........... 1...........................default\n",
            "  checkpoint_scale ................ linear......................default\n",
            "  checkpoint_validation_with_forward_pass  False................default\n",
            "  clip_grad ....................... 1.0.........................default\n",
            "  comet_experiment ................ None........................default\n",
            "  comet_experiment_name ........... None........................default\n",
            "  comet_others .................... None........................default\n",
            "  comet_project ................... None........................default\n",
            "  comet_tags ...................... None........................default\n",
            "  comet_workspace ................. None........................default\n",
            "  comment ......................... None........................default\n",
            "  comms_logger .................... None........................default\n",
            "  communication_data_type ......... None........................default\n",
            "  compression_training ............ None........................default\n",
            "  contiguous_checkpointing ........ False.......................default\n",
            "  coord_check ..................... False.......................default\n",
            "  create_moe_param_group .......... True........................default\n",
            "  csv_monitor ..................... None........................default\n",
            "  curriculum_learning ............. None........................default\n",
            "  curriculum_seqlen ............... 0...........................default\n",
            "  data_efficiency ................. None........................default\n",
            "  data_types ...................... None........................default\n",
            "  dataset_impl .................... gpt2........................default\n",
            "  deepscale ....................... False.......................default\n",
            "  deepscale_config ................ None........................default\n",
            "  deepspeed ....................... True........................default\n",
            "  deepspeed_activation_checkpointing  True......................default\n",
            "  deepspeed_mpi ................... False.......................default\n",
            "  deepspeed_slurm ................. False.......................default\n",
            "  detect_nvlink_pairs ............. False.......................default\n",
            "  dim_att ......................... None........................default\n",
            "  distributed_backend ............. nccl........................default\n",
            "  do_test ......................... None........................default\n",
            "  do_train ........................ None........................default\n",
            "  do_valid ........................ None........................default\n",
            "  dpo_beta ........................ 0.1.........................default\n",
            "  dpo_fp32 ........................ True........................default\n",
            "  dpo_reference_free .............. False.......................default\n",
            "  dump_state ...................... False.......................default\n",
            "  elasticity ...................... None........................default\n",
            "  enable_expert_tensor_parallelism  False.......................default\n",
            "  eod_mask_loss ................... False.......................default\n",
            "  eval_results_prefix ............. ............................default\n",
            "  eval_tasks ...................... None........................default\n",
            "  exclude ......................... None........................default\n",
            "  exit_interval ................... None........................default\n",
            "  expansion_factor ................ None........................default\n",
            "  expert_interval ................. 2...........................default\n",
            "  extra_save_iters ................ None........................default\n",
            "  ffn_dim ......................... None........................default\n",
            "  finetune ........................ False.......................default\n",
            "  flops_profiler .................. None........................default\n",
            "  force_multi ..................... False.......................default\n",
            "  fp16_lm_cross_entropy ........... False.......................default\n",
            "  fp32_allreduce .................. False.......................default\n",
            "  git_hash ........................ 73865bc.....................default\n",
            "  gmlp_attn_dim ................... 64..........................default\n",
            "  gpt_j_residual .................. False.......................default\n",
            "  gpt_j_tied ...................... False.......................default\n",
            "  gradient_accumulation_steps ..... 1...........................default\n",
            "  gradient_clipping ............... 1.0.........................default\n",
            "  gradient_noise_scale_cpu_offload  False.......................default\n",
            "  gradient_noise_scale_n_batches .. 5...........................default\n",
            "  gradient_predivide_factor ....... 1.0.........................default\n",
            "  head_size ....................... None........................default\n",
            "  hidden_dropout .................. 0...........................default\n",
            "  hostfile ........................ None........................default\n",
            "  hysteresis ...................... 2...........................default\n",
            "  include ......................... None........................default\n",
            "  init_method_std ................. 0.02........................default\n",
            "  intermediate_size ............... None........................default\n",
            "  is_pipe_parallel ................ False.......................default\n",
            "  iteration ....................... None........................default\n",
            "  keep_last_n_checkpoints ......... None........................default\n",
            "  kto_beta ........................ 0.1.........................default\n",
            "  kto_desirable_weight ............ 1.0.........................default\n",
            "  kto_fp32 ........................ True........................default\n",
            "  kto_undesirable_weight .......... 1.0.........................default\n",
            "  launcher ........................ pdsh........................default\n",
            "  layernorm_epsilon ............... 1e-05.......................default\n",
            "  layernorm_fusion ................ False.......................default\n",
            "  lazy_mpu_init ................... False.......................default\n",
            "  local_rank ...................... None........................default\n",
            "  log_grad_norm ................... False.......................default\n",
            "  log_grad_pct_zeros .............. False.......................default\n",
            "  log_gradient_noise_scale ........ False.......................default\n",
            "  log_interval .................... 100.........................default\n",
            "  log_optimizer_states ............ False.......................default\n",
            "  log_param_norm .................. False.......................default\n",
            "  loss_scale ...................... None........................default\n",
            "  loss_scale_window ............... 1000.0......................default\n",
            "  lr_decay_fraction ............... None........................default\n",
            "  lr_decay_style .................. linear......................default\n",
            "  make_vocab_size_divisible_by .... 128.........................default\n",
            "  mamba_causal_conv_fusion ........ False.......................default\n",
            "  mamba_inner_func_fusion ......... False.......................default\n",
            "  mamba_selective_fp32_params ..... True........................default\n",
            "  mamba_selective_scan_fusion ..... False.......................default\n",
            "  mamba_use_bias_in_conv .......... True........................default\n",
            "  mamba_use_bias_in_linears ....... False.......................default\n",
            "  master_addr ..................... None........................default\n",
            "  master_port ..................... 29500.......................default\n",
            "  memory_profiling ................ False.......................default\n",
            "  memory_profiling_path ........... None........................default\n",
            "  merge_file ...................... None........................default\n",
            "  min_scale ....................... 1.0.........................default\n",
            "  mlp_multiple_of ................. 1...........................default\n",
            "  mmap_warmup ..................... False.......................default\n",
            "  model_parallel_size ............. 1...........................default\n",
            "  moe_eval_capacity_factor ........ 1.0.........................default\n",
            "  moe_expert_parallel_size ........ 1...........................default\n",
            "  moe_glu ......................... False.......................default\n",
            "  moe_jitter_eps .................. None........................default\n",
            "  moe_lbl_in_fp32 ................. False.......................default\n",
            "  moe_loss_coeff .................. 0.1.........................default\n",
            "  moe_min_capacity ................ 4...........................default\n",
            "  moe_num_experts ................. 1...........................default\n",
            "  moe_token_dropping .............. False.......................default\n",
            "  moe_top_k ....................... 1...........................default\n",
            "  moe_train_capacity_factor ....... 1.0.........................default\n",
            "  moe_type ........................ megablocks..................default\n",
            "  moe_use_residual ................ True........................default\n",
            "  mup_attn_temp ................... 1.0.........................default\n",
            "  mup_embedding_mult .............. 1.0.........................default\n",
            "  mup_init_scale .................. 1.0.........................default\n",
            "  mup_output_temp ................. 1.0.........................default\n",
            "  mup_rp_embedding_mult ........... 1.0.........................default\n",
            "  mup_width_scale ................. 2...........................default\n",
            "  neg_test_data_paths ............. None........................default\n",
            "  neg_test_label_data_paths ....... None........................default\n",
            "  neg_train_data_paths ............ None........................default\n",
            "  neg_train_label_data_paths ...... None........................default\n",
            "  neg_valid_data_paths ............ None........................default\n",
            "  neg_valid_label_data_paths ...... None........................default\n",
            "  no_load_optim ................... False.......................default\n",
            "  no_load_rng ..................... False.......................default\n",
            "  no_save_optim ................... False.......................default\n",
            "  no_save_rng ..................... False.......................default\n",
            "  no_ssh_check .................... False.......................default\n",
            "  no_weight_tying ................. False.......................default\n",
            "  norm ............................ layernorm...................default\n",
            "  num_gpus ........................ None........................default\n",
            "  num_kv_heads .................... None........................default\n",
            "  num_nodes ....................... -1..........................default\n",
            "  num_unique_layers ............... None........................default\n",
            "  onnx_safe ....................... False.......................default\n",
            "  opt_pos_emb_offset .............. 0...........................default\n",
            "  output_layer_parallelism ........ column......................default\n",
            "  override_lr_scheduler ........... False.......................default\n",
            "  pack_impl ....................... packed......................default\n",
            "  padded_vocab_size ............... None........................default\n",
            "  param_sharing_style ............. grouped.....................default\n",
            "  pipe_parallel_size .............. 0...........................default\n",
            "  pipe_partition_method ........... type:transformer|mlp........default\n",
            "  pos_test_data_paths ............. None........................default\n",
            "  pos_test_label_data_paths ....... None........................default\n",
            "  pos_train_data_paths ............ None........................default\n",
            "  pos_train_label_data_paths ...... None........................default\n",
            "  pos_valid_data_paths ............ None........................default\n",
            "  pos_valid_label_data_paths ...... None........................default\n",
            "  precompute_model_name ........... None........................default\n",
            "  prescale_gradients .............. False.......................default\n",
            "  profile ......................... False.......................default\n",
            "  profile_backward ................ False.......................default\n",
            "  profile_step_start .............. 10..........................default\n",
            "  profile_step_stop ............... 12..........................default\n",
            "  prompt_end ...................... \n",
            "...........................default\n",
            "  rank ............................ None........................default\n",
            "  recompute ....................... False.......................default\n",
            "  return_logits ................... False.......................default\n",
            "  rms_norm_epsilon ................ 1e-08.......................default\n",
            "  rmsnorm_fusion .................. False.......................default\n",
            "  rope_fusion ..................... False.......................default\n",
            "  rotary_emb_base ................. 10000.......................default\n",
            "  rotary_pct ...................... 1.0.........................default\n",
            "  rotary_save_freqs_buffer ........ False.......................default\n",
            "  rpe_max_distance ................ 128.........................default\n",
            "  rpe_num_buckets ................. 32..........................default\n",
            "  s3_chunk_size ................... 104857600...................default\n",
            "  s3_path ......................... None........................default\n",
            "  save_base_shapes ................ False.......................default\n",
            "  scaled_masked_softmax_fusion .... False.......................default\n",
            "  scaled_upper_triang_masked_softmax_fusion  False..............default\n",
            "  scalenorm_epsilon ............... 1e-08.......................default\n",
            "  scheduler ....................... None........................default\n",
            "  seed ............................ 1234........................default\n",
            "  sequence_parallel ............... False.......................default\n",
            "  short_seq_prob .................. 0.1.........................default\n",
            "  sliding_window_width ............ None........................default\n",
            "  soft_prompt_tuning .............. None........................default\n",
            "  sparse_attention ................ None........................default\n",
            "  sparse_gradients ................ False.......................default\n",
            "  split ........................... 969, 30, 1..................default\n",
            "  tensorboard ..................... None........................default\n",
            "  test_data_paths ................. None........................default\n",
            "  test_data_weights ............... None........................default\n",
            "  test_label_data_paths ........... None........................default\n",
            "  test_reward_data_paths .......... None........................default\n",
            "  top_k ........................... 0...........................default\n",
            "  top_p ........................... 0.0.........................default\n",
            "  train_data_paths ................ None........................default\n",
            "  train_data_weights .............. None........................default\n",
            "  train_epochs .................... None........................default\n",
            "  train_impl ...................... normal......................default\n",
            "  train_label_data_paths .......... None........................default\n",
            "  train_reward_data_paths ......... None........................default\n",
            "  use_bias_in_attn_linear ......... True........................default\n",
            "  use_bias_in_mlp ................. True........................default\n",
            "  use_bias_in_norms ............... True........................default\n",
            "  use_bnb_optimizer ............... False.......................default\n",
            "  use_checkpoint_lr_scheduler ..... False.......................default\n",
            "  use_comet ....................... None........................default\n",
            "  use_cpu_initialization .......... False.......................default\n",
            "  use_flashattn_swiglu ............ False.......................default\n",
            "  use_mup ......................... False.......................default\n",
            "  use_qk_layernorm ................ False.......................default\n",
            "  use_shared_fs ................... True........................default\n",
            "  use_tutel ....................... False.......................default\n",
            "  use_wandb ....................... None........................default\n",
            "  valid_data_paths ................ None........................default\n",
            "  valid_data_weights .............. None........................default\n",
            "  valid_label_data_paths .......... None........................default\n",
            "  valid_reward_data_paths ......... None........................default\n",
            "  vocab_file ...................... None........................default\n",
            "  wandb ........................... None........................default\n",
            "  wandb_group ..................... None........................default\n",
            "  wandb_host ...................... https://api.wandb.ai........default\n",
            "  wandb_init_all_ranks ............ False.......................default\n",
            "  wandb_project ................... neox........................default\n",
            "  wandb_team ...................... None........................default\n",
            "  warmup .......................... 0.01........................default\n",
            "  weight_by_num_documents ......... False.......................default\n",
            "  weight_decay .................... 0.1.........................default\n",
            "  weighted_sampler_alpha .......... 1.0.........................default\n",
            "  world_size ...................... None........................default\n",
            "  z_loss .......................... 0.0.........................default\n",
            "---------------- end of arguments ----------------\n",
            "NeoXArgs.configure_distributed_args() using world size: 1 and model-parallel size: 1 \n",
            "[2024-12-03 13:22:46,631] [WARNING] [runner.py:217:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
            "[2024-12-03 13:22:46,631] [INFO] [runner.py:586:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None generate.py --deepspeed_config eyJ0cmFpbl9iYXRjaF9zaXplIjogMjU2LCAidHJhaW5fbWljcm9fYmF0Y2hfc2l6ZV9wZXJfZ3B1IjogMjU2LCAib3B0aW1pemVyIjogeyJ0eXBlIjogIkFkYW0iLCAicGFyYW1zIjogeyJsciI6IDAuMDAxLCAiYmV0YXMiOiBbMC45LCAwLjk1XSwgImVwcyI6IDFlLTA4fX0sICJmcDE2IjogeyJmcDE2IjogdHJ1ZSwgImVuYWJsZWQiOiB0cnVlLCAibG9zc19zY2FsZSI6IDAsICJsb3NzX3NjYWxlX3dpbmRvdyI6IDEwMDAsICJpbml0aWFsX3NjYWxlX3Bvd2VyIjogMTIsICJoeXN0ZXJlc2lzIjogMiwgIm1pbl9sb3NzX3NjYWxlIjogMX0sICJ6ZXJvX29wdGltaXphdGlvbiI6IHsic3RhZ2UiOiAxLCAiYWxsZ2F0aGVyX3BhcnRpdGlvbnMiOiB0cnVlLCAiYWxsZ2F0aGVyX2J1Y2tldF9zaXplIjogNTAwMDAwMDAwLCAib3ZlcmxhcF9jb21tIjogdHJ1ZSwgInJlZHVjZV9zY2F0dGVyIjogdHJ1ZSwgInJlZHVjZV9idWNrZXRfc2l6ZSI6IDUwMDAwMDAwMCwgImNvbnRpZ3VvdXNfZ3JhZGllbnRzIjogdHJ1ZX0sICJzdGVwc19wZXJfcHJpbnQiOiAxMDAsICJ3YWxsX2Nsb2NrX2JyZWFrZG93biI6IHRydWUsICJjb21tc19sb2dnZXIiOiB7ImVuYWJsZWQiOiBmYWxzZSwgInZlcmJvc2UiOiBmYWxzZSwgInByb2ZfYWxsIjogZmFsc2UsICJkZWJ1ZyI6IGZhbHNlfX0= --megatron_config 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\n",
            "[2024-12-03 13:22:48,163] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2024-12-03 13:22:50,424] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.19.3-1+cuda12.2\n",
            "[2024-12-03 13:22:50,425] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.19.3-1\n",
            "[2024-12-03 13:22:50,425] [INFO] [launch.py:138:main] 0 NCCL_VERSION=2.19.3-1\n",
            "[2024-12-03 13:22:50,425] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n",
            "[2024-12-03 13:22:50,425] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.19.3-1+cuda12.2\n",
            "[2024-12-03 13:22:50,425] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n",
            "[2024-12-03 13:22:50,425] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.19.3-1\n",
            "[2024-12-03 13:22:50,425] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0]}\n",
            "[2024-12-03 13:22:50,425] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0\n",
            "[2024-12-03 13:22:50,425] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
            "[2024-12-03 13:22:50,425] [INFO] [launch.py:163:main] dist_world_size=1\n",
            "[2024-12-03 13:22:50,425] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0\n",
            "[2024-12-03 13:22:51,966] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba\n",
            "For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer\n",
            "NeoXArgs.configure_distributed_args() using world size: 1 and model-parallel size: 1 \n",
            "> building CharLevelTokenizer tokenizer ...\n",
            " > padded vocab (size: 512) with 0 dummy tokens (new size: 512)\n",
            "> initializing torch distributed ...\n",
            "[2024-12-03 13:22:55,081] [INFO] [comm.py:637:init_distributed] cdb=None\n",
            "[2024-12-03 13:22:55,082] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
            "> initializing model parallel with size 1\n",
            "MPU DP: [0]\n",
            "MPU PP: [0]\n",
            "MPU MP: [0]\n",
            "> setting random seeds to 1234 ...\n",
            "[2024-12-03 13:22:55,085] [INFO] [checkpointing.py:227:model_parallel_cuda_manual_seed] > initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234\n",
            "make: Entering directory '/content/gpt-neox/megatron/data'\n",
            "make: Nothing to be done for 'default'.\n",
            "make: Leaving directory '/content/gpt-neox/megatron/data'\n",
            "building GPT2 model ...\n",
            "SEED_LAYERS=False BASE_SEED=1234 SEED_FN=None\n",
            "Using topology: {ProcessCoord(pipe=0, data=0, model=0): 0}\n",
            "[2024-12-03 13:22:55,112] [INFO] [module.py:375:_partition_layers] Partitioning pipeline stages with method type:transformer|mlp\n",
            "stage=0 layers=9\n",
            "     0: EmbeddingPipe\n",
            "     1: _pre_transformer_block\n",
            "     2: ParallelTransformerLayerPipe\n",
            "     3: ParallelTransformerLayerPipe\n",
            "     4: ParallelTransformerLayerPipe\n",
            "     5: ParallelTransformerLayerPipe\n",
            "     6: _post_transformer_block\n",
            "     7: NormPipe\n",
            "     8: EmbeddingPipe\n",
            "  loss: partial\n",
            "Configuring Optimizer type: adam with params: {'lr': 0.0}\n",
            "WARNING: APEX not installed - defaulting to deepspeed's fused adam\n",
            "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py310_cu121/fused_adam/build.ninja...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n",
            "Building extension module fused_adam...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "ninja: no work to do.\n",
            "Loading extension module fused_adam...\n",
            "Time to load fused_adam op: 0.031055450439453125 seconds\n",
            "/usr/local/lib/python3.10/dist-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n",
            "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
            "> learning rate decay style: linear\n",
            "DeepSpeed is enabled.\n",
            "[2024-12-03 13:22:55,850] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.12.4+02e2ebf, git-hash=02e2ebf, git-branch=HEAD\n",
            "[2024-12-03 13:22:56,114] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
            "[2024-12-03 13:22:56,114] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
            "[2024-12-03 13:22:56,114] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
            "[2024-12-03 13:22:56,114] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam\n",
            "[2024-12-03 13:22:56,114] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>\n",
            "[2024-12-03 13:22:56,115] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 1 optimizer\n",
            "[2024-12-03 13:22:56,115] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 500000000\n",
            "[2024-12-03 13:22:56,115] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 500000000\n",
            "[2024-12-03 13:22:56,115] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
            "[2024-12-03 13:22:56,115] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
            "[2024-12-03 13:22:56,314] [INFO] [utils.py:802:see_memory_usage] Before initializing optimizer states\n",
            "[2024-12-03 13:22:56,315] [INFO] [utils.py:803:see_memory_usage] MA 0.01 GB         Max_MA 0.01 GB         CA 0.01 GB         Max_CA 0 GB \n",
            "[2024-12-03 13:22:56,315] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 3.16 GB, percent = 6.2%\n",
            "[2024-12-03 13:22:56,491] [INFO] [utils.py:802:see_memory_usage] After initializing optimizer states\n",
            "[2024-12-03 13:22:56,491] [INFO] [utils.py:803:see_memory_usage] MA 0.01 GB         Max_MA 0.01 GB         CA 0.02 GB         Max_CA 0 GB \n",
            "[2024-12-03 13:22:56,492] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 3.16 GB, percent = 6.2%\n",
            "[2024-12-03 13:22:56,492] [INFO] [stage_1_and_2.py:517:__init__] optimizer state initialized\n",
            "[2024-12-03 13:22:56,665] [INFO] [utils.py:802:see_memory_usage] After initializing ZeRO optimizer\n",
            "[2024-12-03 13:22:56,666] [INFO] [utils.py:803:see_memory_usage] MA 0.01 GB         Max_MA 0.01 GB         CA 0.02 GB         Max_CA 0 GB \n",
            "[2024-12-03 13:22:56,666] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 3.16 GB, percent = 6.2%\n",
            "[2024-12-03 13:22:56,666] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam\n",
            "[2024-12-03 13:22:56,666] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
            "[2024-12-03 13:22:56,666] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <megatron.learning_rates.AnnealingLR object at 0x7c91a1cbdc90>\n",
            "[2024-12-03 13:22:56,667] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0], mom=[(0.9, 0.999)]\n",
            "[2024-12-03 13:22:56,667] [INFO] [config.py:979:print] DeepSpeedEngine configuration:\n",
            "[2024-12-03 13:22:56,667] [INFO] [config.py:983:print]   activation_checkpointing_config  {\n",
            "    \"partition_activations\": false, \n",
            "    \"contiguous_memory_optimization\": false, \n",
            "    \"cpu_checkpointing\": false, \n",
            "    \"number_checkpoints\": null, \n",
            "    \"synchronize_checkpoint_boundary\": false, \n",
            "    \"profile\": false\n",
            "}\n",
            "[2024-12-03 13:22:56,667] [INFO] [config.py:983:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
            "[2024-12-03 13:22:56,667] [INFO] [config.py:983:print]   amp_enabled .................. False\n",
            "[2024-12-03 13:22:56,667] [INFO] [config.py:983:print]   amp_params ................... False\n",
            "[2024-12-03 13:22:56,667] [INFO] [config.py:983:print]   autotuning_config ............ {\n",
            "    \"enabled\": false, \n",
            "    \"start_step\": null, \n",
            "    \"end_step\": null, \n",
            "    \"metric_path\": null, \n",
            "    \"arg_mappings\": null, \n",
            "    \"metric\": \"throughput\", \n",
            "    \"model_info\": null, \n",
            "    \"results_dir\": \"autotuning_results\", \n",
            "    \"exps_dir\": \"autotuning_exps\", \n",
            "    \"overwrite\": true, \n",
            "    \"fast\": true, \n",
            "    \"start_profile_step\": 3, \n",
            "    \"end_profile_step\": 5, \n",
            "    \"tuner_type\": \"gridsearch\", \n",
            "    \"tuner_early_stopping\": 5, \n",
            "    \"tuner_num_trials\": 50, \n",
            "    \"model_info_path\": null, \n",
            "    \"mp_size\": 1, \n",
            "    \"max_train_batch_size\": null, \n",
            "    \"min_train_batch_size\": 1, \n",
            "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
            "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
            "    \"num_tuning_micro_batch_sizes\": 3\n",
            "}\n",
            "[2024-12-03 13:22:56,667] [INFO] [config.py:983:print]   bfloat16_enabled ............. False\n",
            "[2024-12-03 13:22:56,667] [INFO] [config.py:983:print]   checkpoint_parallel_write_pipeline  False\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   checkpoint_tag_validation_enabled  True\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   checkpoint_tag_validation_fail  False\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7c917e01ba60>\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   communication_data_type ...... None\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   curriculum_enabled_legacy .... False\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   curriculum_params_legacy ..... False\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   data_efficiency_enabled ...... False\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   dataloader_drop_last ......... False\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   disable_allgather ............ False\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   dump_state ................... False\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   dynamic_loss_scale_args ...... {'init_scale': 4096, 'scale_window': 1000, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   eigenvalue_enabled ........... False\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   eigenvalue_gas_boundary_resolution  1\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   eigenvalue_layer_num ......... 0\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   eigenvalue_max_iter .......... 100\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   eigenvalue_stability ......... 1e-06\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   eigenvalue_tol ............... 0.01\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   eigenvalue_verbose ........... False\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   elasticity_enabled ........... False\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   flops_profiler_config ........ {\n",
            "    \"enabled\": false, \n",
            "    \"recompute_fwd_factor\": 0.0, \n",
            "    \"profile_step\": 1, \n",
            "    \"module_depth\": -1, \n",
            "    \"top_modules\": 1, \n",
            "    \"detailed\": true, \n",
            "    \"output_file\": null\n",
            "}\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   fp16_auto_cast ............... False\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   fp16_enabled ................. True\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   fp16_master_weights_and_gradients  False\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   global_rank .................. 0\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   grad_accum_dtype ............. None\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   gradient_accumulation_steps .. 1\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   gradient_clipping ............ 0.0\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   gradient_predivide_factor .... 1.0\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   initial_dynamic_scale ........ 4096\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   load_universal_checkpoint .... False\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   loss_scale ................... 0\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   memory_breakdown ............. False\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   mics_hierarchial_params_gather  False\n",
            "[2024-12-03 13:22:56,668] [INFO] [config.py:983:print]   mics_shard_size .............. -1\n",
            "[2024-12-03 13:22:56,669] [INFO] [config.py:983:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
            "[2024-12-03 13:22:56,669] [INFO] [config.py:983:print]   nebula_config ................ {\n",
            "    \"enabled\": false, \n",
            "    \"persistent_storage_path\": null, \n",
            "    \"persistent_time_interval\": 100, \n",
            "    \"num_of_version_in_retention\": 2, \n",
            "    \"enable_nebula_load\": true, \n",
            "    \"load_path\": null\n",
            "}\n",
            "[2024-12-03 13:22:56,669] [INFO] [config.py:983:print]   optimizer_legacy_fusion ...... False\n",
            "[2024-12-03 13:22:56,669] [INFO] [config.py:983:print]   optimizer_name ............... None\n",
            "[2024-12-03 13:22:56,669] [INFO] [config.py:983:print]   optimizer_params ............. None\n",
            "[2024-12-03 13:22:56,669] [INFO] [config.py:983:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
            "[2024-12-03 13:22:56,669] [INFO] [config.py:983:print]   pld_enabled .................. False\n",
            "[2024-12-03 13:22:56,669] [INFO] [config.py:983:print]   pld_params ................... False\n",
            "[2024-12-03 13:22:56,669] [INFO] [config.py:983:print]   prescale_gradients ........... False\n",
            "[2024-12-03 13:22:56,669] [INFO] [config.py:983:print]   scheduler_name ............... None\n",
            "[2024-12-03 13:22:56,669] [INFO] [config.py:983:print]   scheduler_params ............. None\n",
            "[2024-12-03 13:22:56,669] [INFO] [config.py:983:print]   seq_parallel_communication_data_type  torch.float32\n",
            "[2024-12-03 13:22:56,669] [INFO] [config.py:983:print]   sparse_attention ............. None\n",
            "[2024-12-03 13:22:56,669] [INFO] [config.py:983:print]   sparse_gradients_enabled ..... False\n",
            "[2024-12-03 13:22:56,669] [INFO] [config.py:983:print]   steps_per_print .............. 100\n",
            "[2024-12-03 13:22:56,669] [INFO] [config.py:983:print]   train_batch_size ............. 256\n",
            "[2024-12-03 13:22:56,669] [INFO] [config.py:983:print]   train_micro_batch_size_per_gpu  256\n",
            "[2024-12-03 13:22:56,669] [INFO] [config.py:983:print]   use_data_before_expert_parallel_  False\n",
            "[2024-12-03 13:22:56,669] [INFO] [config.py:983:print]   use_node_local_storage ....... False\n",
            "[2024-12-03 13:22:56,669] [INFO] [config.py:983:print]   wall_clock_breakdown ......... True\n",
            "[2024-12-03 13:22:56,669] [INFO] [config.py:983:print]   weight_quantization_config ... None\n",
            "[2024-12-03 13:22:56,669] [INFO] [config.py:983:print]   world_size ................... 1\n",
            "[2024-12-03 13:22:56,669] [INFO] [config.py:983:print]   zero_allow_untested_optimizer  False\n",
            "[2024-12-03 13:22:56,669] [INFO] [config.py:983:print]   zero_config .................. stage=1 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
            "[2024-12-03 13:22:56,669] [INFO] [config.py:983:print]   zero_enabled ................. True\n",
            "[2024-12-03 13:22:56,669] [INFO] [config.py:983:print]   zero_force_ds_cpu_optimizer .. True\n",
            "[2024-12-03 13:22:56,669] [INFO] [config.py:983:print]   zero_optimization_stage ...... 1\n",
            "[2024-12-03 13:22:56,669] [INFO] [config.py:969:print_user_config]   json = {\n",
            "    \"train_batch_size\": 256, \n",
            "    \"train_micro_batch_size_per_gpu\": 256, \n",
            "    \"optimizer\": {\n",
            "        \"params\": {\n",
            "            \"lr\": 0.0\n",
            "        }\n",
            "    }, \n",
            "    \"fp16\": {\n",
            "        \"fp16\": true, \n",
            "        \"enabled\": true, \n",
            "        \"loss_scale\": 0, \n",
            "        \"loss_scale_window\": 1000, \n",
            "        \"initial_scale_power\": 12, \n",
            "        \"hysteresis\": 2, \n",
            "        \"min_loss_scale\": 1\n",
            "    }, \n",
            "    \"zero_optimization\": {\n",
            "        \"stage\": 1, \n",
            "        \"allgather_partitions\": true, \n",
            "        \"allgather_bucket_size\": 5.000000e+08, \n",
            "        \"overlap_comm\": true, \n",
            "        \"reduce_scatter\": true, \n",
            "        \"reduce_bucket_size\": 5.000000e+08, \n",
            "        \"contiguous_gradients\": true\n",
            "    }, \n",
            "    \"steps_per_print\": 100, \n",
            "    \"wall_clock_breakdown\": true, \n",
            "    \"comms_logger\": {\n",
            "        \"enabled\": false, \n",
            "        \"verbose\": false, \n",
            "        \"prof_all\": false, \n",
            "        \"debug\": false\n",
            "    }\n",
            "}\n",
            " > number of parameters on model parallel rank 0: 3290624\n",
            " > total params: 3,290,624\n",
            "[2024-12-03 13:22:56,706] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from checkpoints/global_step800/mp_rank_00_model_states.pt...\n",
            "[2024-12-03 13:22:56,713] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from checkpoints/global_step800/mp_rank_00_model_states.pt.\n",
            "[2024-12-03 13:22:56,713] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from checkpoints/global_step800/mp_rank_00_model_states.pt...\n",
            "[2024-12-03 13:22:56,719] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from checkpoints/global_step800/mp_rank_00_model_states.pt.\n",
            " > validated currently set args with arguments in the checkpoint ...\n",
            "  successfully loaded checkpoints/global_step800/mp_rank_00_model_states.pt\n",
            "Loading checkpoint and starting from iteration 800\n",
            "Finished loading model\n",
            "Generating samples unconditionally and saving results to sample_output.txt\n",
            "generate_samples_unconditional() generating...\n",
            "generate_samples_unconditional() done\n",
            "[2024-12-03 13:23:02,439] [INFO] [launch.py:347:main] Process 17851 exits successfully.\n",
            "{\"context\": \"\", \"text\": \"Haccul to his littlel: I being his own.\", \"length\": 39, \"finished\": true, \"message\": null, \"duration_seconds\": 1.407752275466919}\n",
            "{\"context\": \"\", \"text\": \"Ques, I cannot?\", \"length\": 15, \"finished\": true, \"message\": null, \"duration_seconds\": 0.12213134765625}\n",
            "{\"context\": \"\", \"text\": \"Servant:\", \"length\": 8, \"finished\": true, \"message\": null, \"duration_seconds\": 0.06062126159667969}\n",
            "{\"context\": \"\", \"text\": \"How would do calls this deserve his maid\", \"length\": 40, \"finished\": true, \"message\": null, \"duration_seconds\": 0.28314948081970215}\n",
            "{\"context\": \"\", \"text\": \"MENENIUS:\", \"length\": 9, \"finished\": true, \"message\": null, \"duration_seconds\": 0.06785082817077637}\n",
            "{\"context\": \"\", \"text\": \"May see their frozen life no give up,\", \"length\": 37, \"finished\": true, \"message\": null, \"duration_seconds\": 0.2580277919769287}\n",
            "{\"context\": \"\", \"text\": \"Sweet Oxford.\", \"length\": 13, \"finished\": true, \"message\": null, \"duration_seconds\": 0.0938119888305664}\n",
            "{\"context\": \"\", \"text\": \"Not that bear with him this worthless choner us\", \"length\": 47, \"finished\": true, \"message\": null, \"duration_seconds\": 0.333113431930542}\n",
            "{\"context\": \"\", \"text\": \"And says I think in the cartless of Hercules this\", \"length\": 49, \"finished\": true, \"message\": null, \"duration_seconds\": 0.33298373222351074}\n",
            "{\"context\": \"\", \"text\": \"Good for some new-a-councide, the bitter to ride.\", \"length\": 49, \"finished\": true, \"message\": null, \"duration_seconds\": 0.33809828758239746}\n",
            "CPU times: user 139 ms, sys: 15.7 ms, total: 155 ms\n",
            "Wall time: 22.8 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "%cd {GPTNeoXDir}\n",
        "# This has issues if used during training -  The server socket has failed to bind to [::]:29500 (errno: 98 - Address already\n",
        "# This will write over the logs\n",
        "!python ./deepy.py generate.py -d configs {gpt_neox_colabDir}/configs/shakespeare {gpt_neox_colabDir}/configs/shakespeare_gen\n",
        "!cat sample_output.txt"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}