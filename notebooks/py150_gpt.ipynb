{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Clone CodeXGLUE Repo"
      ],
      "metadata": {
        "id": "OpgI19mPrtvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/microsoft/CodeXGLUE.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOySwjeyktsH",
        "outputId": "417b2e09-fcb2-4869-dc59-9ac9697879fe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CodeXGLUE'...\n",
            "remote: Enumerating objects: 3373, done.\u001b[K\n",
            "remote: Counting objects: 100% (3372/3372), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1534/1534), done.\u001b[K\n",
            "remote: Total 3373 (delta 1748), reused 3326 (delta 1733), pack-reused 1 (from 1)\u001b[K\n",
            "Receiving objects: 100% (3373/3373), 213.15 MiB | 16.59 MiB/s, done.\n",
            "Resolving deltas: 100% (1748/1748), done.\n",
            "Updating files: 100% (400/400), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading and Preprocessing Dataset"
      ],
      "metadata": {
        "id": "-UV1kBtFXkKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/CodeXGLUE/Code-Code/CodeCompletion-token/dataset/py150\n",
        "!bash /content/CodeXGLUE/Code-Code/CodeCompletion-token/dataset/py150/download_and_extract.sh\n",
        "!python preprocess.py --base_dir=py150_files --output_dir=token_completion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fn0Wy7g7lGGe",
        "outputId": "b5a42241-2be0-4369-a03a-bea588f2bfad"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CodeXGLUE/Code-Code/CodeCompletion-token/dataset/py150\n",
            "train: 0 are done\n",
            "train: 10000 are done\n",
            "train: 20000 are done\n",
            "train: 30000 are done\n",
            "train: 40000 are done\n",
            "train: 50000 are done\n",
            "train: 60000 are done\n",
            "train: 70000 are done\n",
            "train: 80000 are done\n",
            "train: 90000 are done\n",
            "dev: 0 are done\n",
            "test: 0 are done\n",
            "test: 10000 are done\n",
            "test: 20000 are done\n",
            "test: 30000 are done\n",
            "test: 40000 are done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cloning GPT-NeoX Repo"
      ],
      "metadata": {
        "id": "Y_0FMSSnXzW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/EleutherAI/gpt-neox.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OguN3qpTQAQs",
        "outputId": "d41c5f12-bf77-4b94-a94e-252f8f7210f0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'gpt-neox'...\n",
            "remote: Enumerating objects: 19496, done.\u001b[K\n",
            "remote: Counting objects: 100% (1699/1699), done.\u001b[K\n",
            "remote: Compressing objects: 100% (822/822), done.\u001b[K\n",
            "remote: Total 19496 (delta 1252), reused 1206 (delta 869), pack-reused 17797 (from 1)\u001b[K\n",
            "Receiving objects: 100% (19496/19496), 113.65 MiB | 21.58 MiB/s, done.\n",
            "Resolving deltas: 100% (14109/14109), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/markNZed/GPT-NeoX-Colab.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4IqZlX9QNxx",
        "outputId": "d087d2d3-7adf-4455-8150-530c90bea525"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GPT-NeoX-Colab'...\n",
            "remote: Enumerating objects: 331, done.\u001b[K\n",
            "remote: Counting objects: 100% (130/130), done.\u001b[K\n",
            "remote: Compressing objects: 100% (106/106), done.\u001b[K\n",
            "remote: Total 331 (delta 69), reused 63 (delta 24), pack-reused 201 (from 1)\u001b[K\n",
            "Receiving objects: 100% (331/331), 11.70 MiB | 11.51 MiB/s, done.\n",
            "Resolving deltas: 100% (184/184), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Dependencies"
      ],
      "metadata": {
        "id": "NWTuy456X7Yl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "%cd /content/gpt-neox\n",
        "# Could not redirect to /dev/null in the standard Colab notebook (maybe no output for a particular time?)\n",
        "# Currently deepspeed from GTP-NeoX is not compatible with logging in torch >= 2.4\n",
        "!pip install torch==2.3 torchaudio==2.3.0 torchvision==0.18.0 transformers==4.41.0 sentence-transformers==2.2.2\n",
        "!pip install -r ./requirements/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QH7iL-O-Qq3A",
        "outputId": "04c0660e-3bd7-4a7e-df4a-134987a5dc00"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gpt-neox\n",
            "Requirement already satisfied: torch==2.3 in /usr/local/lib/python3.10/dist-packages (2.3.0)\n",
            "Requirement already satisfied: torchaudio==2.3.0 in /usr/local/lib/python3.10/dist-packages (2.3.0)\n",
            "Requirement already satisfied: torchvision==0.18.0 in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Collecting transformers==4.41.0\n",
            "  Using cached transformers-4.41.0-py3-none-any.whl.metadata (43 kB)\n",
            "Requirement already satisfied: sentence-transformers==2.2.2 in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3) (2024.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.3) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.3) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.3) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.3) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.3) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3) (2.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.18.0) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.18.0) (10.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.0) (0.24.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.0) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.0) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.0) (2.32.3)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers==4.41.0)\n",
            "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.0) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.0) (4.66.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (1.13.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (0.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3) (12.6.77)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3) (3.0.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers==2.2.2) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers==2.2.2) (1.4.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.41.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.41.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.41.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.41.0) (2024.8.30)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers==2.2.2) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3) (1.3.0)\n",
            "Using cached transformers-4.41.0-py3-none-any.whl (9.1 MB)\n",
            "Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.2\n",
            "    Uninstalling tokenizers-0.15.2:\n",
            "      Successfully uninstalled tokenizers-0.15.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.38.0\n",
            "    Uninstalling transformers-4.38.0:\n",
            "      Successfully uninstalled transformers-4.38.0\n",
            "Successfully installed tokenizers-0.19.1 transformers-4.41.0\n",
            "Collecting deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed (from -r ./requirements/requirements.txt (line 1))\n",
            "  Using cached deepspeed-0.12.4+02e2ebf-py3-none-any.whl\n",
            "Collecting lm_dataformat@ git+https://github.com/EleutherAI/lm_dataformat.git@4eec05349977071bf67fc072290b95e31c8dd836 (from -r ./requirements/requirements.txt (line 5))\n",
            "  Using cached lm_dataformat-0.0.20-py3-none-any.whl\n",
            "Requirement already satisfied: ftfy>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements/requirements.txt (line 2)) (6.3.1)\n",
            "Requirement already satisfied: huggingface_hub>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements/requirements.txt (line 3)) (0.24.7)\n",
            "Requirement already satisfied: jinja2==3.1.4 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements/requirements.txt (line 4)) (3.1.4)\n",
            "Requirement already satisfied: lm_eval<=0.4.1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements/requirements.txt (line 6)) (0.4.1)\n",
            "Requirement already satisfied: mpi4py>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements/requirements.txt (line 7)) (4.0.1)\n",
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements/requirements.txt (line 8)) (1.26.4)\n",
            "Requirement already satisfied: pybind11>=2.6.2 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements/requirements.txt (line 9)) (2.13.6)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from -r ./requirements/requirements.txt (line 10)) (2024.9.11)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from -r ./requirements/requirements.txt (line 11)) (0.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from -r ./requirements/requirements.txt (line 12)) (1.16.0)\n",
            "Requirement already satisfied: tiktoken>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements/requirements.txt (line 13)) (0.8.0)\n",
            "Requirement already satisfied: tokenizers>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements/requirements.txt (line 14)) (0.19.1)\n",
            "Collecting transformers==4.38.0 (from -r ./requirements/requirements.txt (line 15))\n",
            "  Using cached transformers-4.38.0-py3-none-any.whl.metadata (131 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2==3.1.4->-r ./requirements/requirements.txt (line 4)) (3.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0->-r ./requirements/requirements.txt (line 15)) (3.16.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0->-r ./requirements/requirements.txt (line 15)) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0->-r ./requirements/requirements.txt (line 15)) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0->-r ./requirements/requirements.txt (line 15)) (2.32.3)\n",
            "Collecting tokenizers>=0.12.1 (from -r ./requirements/requirements.txt (line 14))\n",
            "  Using cached tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0->-r ./requirements/requirements.txt (line 15)) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0->-r ./requirements/requirements.txt (line 15)) (4.66.6)\n",
            "Requirement already satisfied: hjson in /usr/local/lib/python3.10/dist-packages (from deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (1.11.1.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (9.0.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (2.9.2)\n",
            "Requirement already satisfied: pynvml in /usr/local/lib/python3.10/dist-packages (from deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (11.5.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy>=6.0.1->-r ./requirements/requirements.txt (line 2)) (0.2.13)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.11.0->-r ./requirements/requirements.txt (line 3)) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.11.0->-r ./requirements/requirements.txt (line 3)) (4.12.2)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.10/dist-packages (from lm_dataformat@ git+https://github.com/EleutherAI/lm_dataformat.git@4eec05349977071bf67fc072290b95e31c8dd836->-r ./requirements/requirements.txt (line 5)) (0.23.0)\n",
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.10/dist-packages (from lm_dataformat@ git+https://github.com/EleutherAI/lm_dataformat.git@4eec05349977071bf67fc072290b95e31c8dd836->-r ./requirements/requirements.txt (line 5)) (4.0.0)\n",
            "Requirement already satisfied: ujson in /usr/local/lib/python3.10/dist-packages (from lm_dataformat@ git+https://github.com/EleutherAI/lm_dataformat.git@4eec05349977071bf67fc072290b95e31c8dd836->-r ./requirements/requirements.txt (line 5)) (5.10.0)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (0.34.2)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (from lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (3.1.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (2.10.1)\n",
            "Requirement already satisfied: peft>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (0.13.2)\n",
            "Requirement already satisfied: pytablewriter in /usr/local/lib/python3.10/dist-packages (from lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (1.2.0)\n",
            "Requirement already satisfied: rouge-score>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (0.1.2)\n",
            "Requirement already satisfied: sacrebleu>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (2.4.3)\n",
            "Requirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (1.5.2)\n",
            "Requirement already satisfied: sqlitedict in /usr/local/lib/python3.10/dist-packages (from lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (2.1.0)\n",
            "Requirement already satisfied: tqdm-multiprocess in /usr/local/lib/python3.10/dist-packages (from lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (0.0.11)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (3.10.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.0->-r ./requirements/requirements.txt (line 15)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.0->-r ./requirements/requirements.txt (line 15)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.0->-r ./requirements/requirements.txt (line 15)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.0->-r ./requirements/requirements.txt (line 15)) (2024.8.30)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (3.8.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (2.10.1)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (5.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (3.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->lm_dataformat@ git+https://github.com/EleutherAI/lm_dataformat.git@4eec05349977071bf67fc072290b95e31c8dd836->-r ./requirements/requirements.txt (line 5)) (24.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (2.23.4)\n",
            "Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (75.1.0)\n",
            "Requirement already satisfied: DataProperty<2,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (1.0.1)\n",
            "Requirement already satisfied: mbstrdecoder<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (1.1.3)\n",
            "Requirement already satisfied: pathvalidate<4,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (3.2.1)\n",
            "Requirement already satisfied: tabledata<2,>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (1.3.3)\n",
            "Requirement already satisfied: tcolorpy<1,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (0.1.6)\n",
            "Requirement already satisfied: typepy<2,>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (1.3.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (4.0.3)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (5.2.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.9 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (2024.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score>=0.0.4->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (8.1.7)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (2024.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (0.2.0)\n",
            "Using cached transformers-4.38.0-py3-none-any.whl (8.5 MB)\n",
            "Using cached tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.41.0\n",
            "    Uninstalling transformers-4.41.0:\n",
            "      Successfully uninstalled transformers-4.41.0\n",
            "Successfully installed tokenizers-0.15.2 transformers-4.38.0\n",
            "CPU times: user 162 ms, sys: 23 ms, total: 185 ms\n",
            "Wall time: 22.7 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing Custom Dataset\n"
      ],
      "metadata": {
        "id": "VwrfbvLpYXAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gpt-neox\n",
        "!!mkdir -p data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDlSqS1iyU8k",
        "outputId": "7b732af7-1270-44c0-adf1-b12ec631e8e9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gpt-neox\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Generate a list of dictionaries\n",
        "lines = []\n",
        "with open(\"/content/CodeXGLUE/Code-Code/CodeCompletion-token/dataset/py150/py150_files/token_completion/train.txt\", encoding=\"utf8\") as f:\n",
        "    for line in f.read().splitlines():\n",
        "        if line:\n",
        "            lines.append({\"text\": line})\n",
        "\n",
        "# Convert to a list of JSON strings\n",
        "json_lines = [json.dumps(l) for l in lines]\n",
        "\n",
        "# Join lines and save to .jsonl file\n",
        "json_data = '\\n'.join(json_lines)\n",
        "with open('/content/gpt-neox/data/py95K_train.jsonl', 'w') as f:\n",
        "    f.write(json_data)"
      ],
      "metadata": {
        "id": "StUBNuLhHUPm"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Byte-Pair Encoding Tokenizer"
      ],
      "metadata": {
        "id": "AZ7f8hTqipgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd data\n",
        "!wget https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json\n",
        "!wget https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmOgA5alzT2A",
        "outputId": "28267490-8a87-4fac-cb79-da064ceab3c6"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gpt-neox/processed_data\n",
            "--2024-11-01 23:24:10--  https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.185.181, 52.216.48.152, 16.15.184.191, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.185.181|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1042301 (1018K) [application/json]\n",
            "Saving to: ‘gpt2-vocab.json’\n",
            "\n",
            "gpt2-vocab.json     100%[===================>]   1018K   896KB/s    in 1.1s    \n",
            "\n",
            "2024-11-01 23:24:12 (896 KB/s) - ‘gpt2-vocab.json’ saved [1042301/1042301]\n",
            "\n",
            "--2024-11-01 23:24:12--  https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.185.181, 52.216.48.152, 16.15.184.191, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.185.181|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 456318 (446K) [text/plain]\n",
            "Saving to: ‘gpt2-merges.txt’\n",
            "\n",
            "gpt2-merges.txt     100%[===================>] 445.62K   589KB/s    in 0.8s    \n",
            "\n",
            "2024-11-01 23:24:14 (589 KB/s) - ‘gpt2-merges.txt’ saved [456318/456318]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "%cd /content/gpt-neox\n",
        "!mkdir -p processed_data\n",
        "!python tools/datasets/preprocess_data.py \\\n",
        "    --input ./data/py95K_train.jsonl \\\n",
        "    --vocab ./data/gpt2-vocab.json \\\n",
        "    --merge-file ./data/gpt2-merges.txt \\\n",
        "    --output-prefix ./processed_data/py150 \\\n",
        "    --tokenizer-type GPT2BPETokenizer \\\n",
        "    --dataset-impl mmap \\\n",
        "    --append-eod"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Xh49c3aQ1WW",
        "outputId": "19776ed6-1a28-419e-cd45-33001e0c9779"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gpt-neox\n",
            "[2024-11-01 22:23:21,548] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "> building GPT2BPETokenizer tokenizer ...\n",
            " > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)\n",
            "Vocab size: 50257\n",
            "Output prefix: ./processed_data/py150\n",
            "> building GPT2BPETokenizer tokenizer ...\n",
            " > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)\n",
            "Processed 95000 documents (119.29 docs/s, 0.53 MB/s).: : 95000it [13:16, 119.29it/s]\n",
            "CPU times: user 5.05 s, sys: 544 ms, total: 5.6 s\n",
            "Wall time: 13min 22s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "miolaIFSa8sS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "a_t7Dpd3Wn0Y"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gpt-neox\n",
        "!python ./deepy.py train.py --conf_dir /content/GPT-NeoX-Colab/configs CC19M.yml cc_setup.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQknkkSEbMXa",
        "outputId": "8a3733d7-2c8a-4128-cace-8058b70e75c0"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gpt-neox\n",
            "[2024-11-01 22:57:54,155] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "NeoXArgs.from_ymls() ['configs/19M.yml', 'configs/local_setup.yml']\n",
            "INFO:root:NeoXArgs.calculate_derived() Total number of GPUs determined to be: 1\n",
            "-------------------- arguments --------------------\n",
            "  attention_config ................ ['global', 'global', 'global', 'global', 'global', 'global']updated\n",
            "  batch_size ...................... 4...........................updated\n",
            "  checkpoint_activations .......... True........................updated\n",
            "  checkpoint_factor ............... 1000........................updated\n",
            "  config_files .................... {'19M.yml': '{\\n  \"pipe_parallel_size\": 0,\\n  \"model_parallel_size\": 1,\\n\\n  # model settings\\n  \"num_layers\": 6,\\n  \"hidden_size\": 512,\\n  \"num_attention_heads\": 8,\\n  \"seq_length\": 2048,\\n  \"max_position_embeddings\": 2048,\\n  \"pos_emb\": \"rotary\",\\n  \"no_weight_tying\": true,\\n  \"gpt_j_residual\": false,\\n  \"output_layer_parallelism\": \"column\",\\n\\n  \"scaled_upper_triang_masked_softmax_fusion\": false,\\n  \"bias_gelu_fusion\": false,\\n  \"rope_fusion\": false,\\n  \"layernorm_fusion\": false,\\n\\n  # init methods\\n  \"init_method\": \"small_init\",\\n  \"output_layer_init_method\": \"wang_init\",\\n\\n  \"optimizer\": {\\n    \"type\": \"Adam\",\\n    \"params\": {\\n      \"lr\": 0.001,\\n      \"betas\": [0.9, 0.95],\\n      \"eps\": 1.0e-8,\\n    }\\n  },\\n  \"min_lr\": 0.0001,\\n\\n  # for all zero_optimization options, see https://www.deepspeed.ai/docs/config-json/#zero-optimizations-for-fp16-training\\n  \"zero_optimization\": {\\n    \"stage\": 1,\\n    \"allgather_partitions\": True,\\n    \"allgather_bucket_size\": 500000000,\\n    \"overlap_comm\": True,\\n    \"reduce_scatter\": True,\\n    \"reduce_bucket_size\": 500000000,\\n    \"contiguous_gradients\": True,\\n  },\\n\\n  \"train_micro_batch_size_per_gpu\": 4, #32,\\n  \"gradient_accumulation_steps\": 1,\\n  \"data_impl\": \"mmap\",\\n  \"num_workers\": 1,\\n\\n  # activation checkpointing\\n  \"checkpoint_activations\": true,\\n  \"checkpoint_num_layers\": 1,\\n  \"partition_activations\": true,\\n  \"synchronize_each_layer\": true,\\n\\n  # regularization\\n  \"gradient_clipping\": 1.0,\\n  \"weight_decay\": 0.1,\\n  \"hidden_dropout\": 0,\\n  \"attention_dropout\": 0,\\n\\n  # precision settings\\n  \"fp16\": {\\n    \"fp16\": true,\\n    \"enabled\": true,\\n    \"loss_scale\": 0,\\n    \"loss_scale_window\": 1000,\\n    \"initial_scale_power\": 12,\\n    \"hysteresis\": 2,\\n    \"min_loss_scale\": 1,\\n  },\\n\\n  \"train_iters\": 100,\\n  \"lr_decay_iters\": 100,\\n  \"distributed_backend\": \"nccl\",\\n  \"lr_decay_style\": \"cosine\",\\n  \"warmup\": 0.01,\\n  \"checkpoint_factor\": 1000,\\n  \"eval_interval\": 50,\\n  \"eval_iters\": 10,\\n\\n  \"log_interval\": 10,\\n  \"steps_per_print\": 10,\\n  \"wall_clock_breakdown\": true,\\n\\n  # additional deepspeed args not specified above\\n  \"deepspeed_extra_args\": {\\n    \"comms_logger\": {\\n        \"enabled\": true,\\n        \"verbose\": true,\\n        \"prof_all\": true,\\n        \"debug\": false\\n    },\\n  }\\n\\n}\\n', 'local_setup.yml': '# Suggested data paths when using GPT-NeoX locally\\n{\\n  \"data_path\": \"processed_data/py150_text_document\",\\n\\n  # or for weighted datasets:\\n  # \"train-data-paths\": [\"data/enwik8/enwik8_text_document\", \"data/enwik8/enwik8_text_document\"],\\n  # \"test-data-paths\": [\"data/enwik8/enwik8_text_document\", \"data/enwik8/enwik8_text_document\"],\\n  # \"valid-data-paths\": [\"data/enwik8/enwik8_text_document\", \"data/enwik8/enwik8_text_document\"],\\n  # \"train-data-weights\": [1., 2.],\\n  # \"test-data-weights\": [2., 1.],\\n  # \"valid-data-weights\": [0.5, 0.4],\\n\\n  # If weight_by_num_documents is True, Builds dataset weights from a multinomial distribution over groups of data according to the number of documents in each group.\\n  # WARNING: setting this to True will override any user provided weights\\n  # \"weight_by_num_documents\": false,\\n  # \"weighted_sampler_alpha\": 0.3,\\n\\n  \"vocab_file\": \"data/gpt2-vocab.json\",\\n  \"merge_file\": \"data/gpt2-merges.txt\",\\n\\n  \"save\": \"checkpoints\",\\n  \"load\": \"checkpoints\",\\n  \"checkpoint_validation_with_forward_pass\": False,\\n\\n  \"tensorboard_dir\": \"tensorboard\",\\n  \"log_dir\": \"logs\",\\n}\\n'}updated\n",
            "  data_impl ....................... mmap........................updated\n",
            "  data_path ....................... processed_data/py150_text_documentupdated\n",
            "  deepspeed_extra_args ............ {'comms_logger': {'enabled': True, 'verbose': True, 'prof_all': True, 'debug': False}}updated\n",
            "  dynamic_loss_scale .............. True........................updated\n",
            "  eval_interval ................... 50..........................updated\n",
            "  eval_iters ...................... 10..........................updated\n",
            "  fp16 ............................ {'fp16': True, 'enabled': True, 'loss_scale': 0, 'loss_scale_window': 1000, 'initial_scale_power': 12, 'hysteresis': 2, 'min_loss_scale': 1}updated\n",
            "  global_num_gpus ................. 1...........................updated\n",
            "  hidden_size ..................... 512.........................updated\n",
            "  init_method ..................... small_init..................updated\n",
            "  load ............................ checkpoints.................updated\n",
            "  log_dir ......................... logs........................updated\n",
            "  log_interval .................... 10..........................updated\n",
            "  lr .............................. 0.001.......................updated\n",
            "  lr_decay_iters .................. 100.........................updated\n",
            "  lr_decay_style .................. cosine......................updated\n",
            "  max_position_embeddings ......... 2048........................updated\n",
            "  merge_file ...................... data/gpt2-merges.txt........updated\n",
            "  min_lr .......................... 0.0001......................updated\n",
            "  no_weight_tying ................. True........................updated\n",
            "  num_attention_heads ............. 8...........................updated\n",
            "  num_layers ...................... 6...........................updated\n",
            "  num_workers ..................... 1...........................updated\n",
            "  optimizer ....................... {'type': 'Adam', 'params': {'lr': 0.001, 'betas': [0.9, 0.95], 'eps': 1e-08}}updated\n",
            "  optimizer_type .................. Adam........................updated\n",
            "  output_layer_init_method ........ wang_init...................updated\n",
            "  partition_activations ........... True........................updated\n",
            "  pos_emb ......................... rotary......................updated\n",
            "  precision ....................... fp16........................updated\n",
            "  save ............................ checkpoints.................updated\n",
            "  seq_length ...................... 2048........................updated\n",
            "  sparsity_config ................. {}..........................updated\n",
            "  synchronize_each_layer .......... True........................updated\n",
            "  tensorboard_dir ................. tensorboard.................updated\n",
            "  text_gen_type ................... unconditional...............updated\n",
            "  train_batch_size ................ 4...........................updated\n",
            "  train_iters ..................... 100.........................updated\n",
            "  train_micro_batch_size_per_gpu .. 4...........................updated\n",
            "  user_script ..................... train.py....................updated\n",
            "  vocab_file ...................... data/gpt2-vocab.json........updated\n",
            "  wall_clock_breakdown ............ True........................updated\n",
            "  zero_allgather_bucket_size ...... 500000000...................updated\n",
            "  zero_contiguous_gradients ....... True........................updated\n",
            "  zero_optimization ............... {'stage': 1, 'allgather_partitions': True, 'allgather_bucket_size': 500000000, 'overlap_comm': True, 'reduce_scatter': True, 'reduce_bucket_size': 500000000, 'contiguous_gradients': True}updated\n",
            "  zero_reduce_bucket_size ......... 500000000...................updated\n",
            "  zero_reduce_scatter ............. True........................updated\n",
            "  zero_stage ...................... 1...........................updated\n",
            "  account ......................... None........................default\n",
            "  activation ...................... gelu........................default\n",
            "  activation_checkpointing ........ None........................default\n",
            "  adlr_autoresume ................. False.......................default\n",
            "  adlr_autoresume_interval ........ 1000........................default\n",
            "  allow_chopped ................... True........................default\n",
            "  amp ............................. None........................default\n",
            "  apply_query_key_layer_scaling ... False.......................default\n",
            "  attention_dropout ............... 0...........................default\n",
            "  attention_softmax_in_fp32 ....... False.......................default\n",
            "  autotuning ...................... None........................default\n",
            "  autotuning_run .................. None........................default\n",
            "  base_shapes_file ................ None........................default\n",
            "  bf16 ............................ None........................default\n",
            "  bias_dropout_fusion ............. False.......................default\n",
            "  bias_gelu_fusion ................ False.......................default\n",
            "  char_level_ppl .................. False.......................default\n",
            "  checkpoint ...................... None........................default\n",
            "  checkpoint_in_cpu ............... False.......................default\n",
            "  checkpoint_num_layers ........... 1...........................default\n",
            "  checkpoint_scale ................ linear......................default\n",
            "  checkpoint_validation_with_forward_pass  False................default\n",
            "  clip_grad ....................... 1.0.........................default\n",
            "  comet_experiment ................ None........................default\n",
            "  comet_experiment_name ........... None........................default\n",
            "  comet_others .................... None........................default\n",
            "  comet_project ................... None........................default\n",
            "  comet_tags ...................... None........................default\n",
            "  comet_workspace ................. None........................default\n",
            "  comment ......................... None........................default\n",
            "  comms_logger .................... None........................default\n",
            "  communication_data_type ......... None........................default\n",
            "  compression_training ............ None........................default\n",
            "  contiguous_checkpointing ........ False.......................default\n",
            "  coord_check ..................... False.......................default\n",
            "  create_moe_param_group .......... True........................default\n",
            "  csv_monitor ..................... None........................default\n",
            "  curriculum_learning ............. None........................default\n",
            "  curriculum_seqlen ............... 0...........................default\n",
            "  data_efficiency ................. None........................default\n",
            "  data_types ...................... None........................default\n",
            "  dataset_impl .................... gpt2........................default\n",
            "  deepscale ....................... False.......................default\n",
            "  deepscale_config ................ None........................default\n",
            "  deepspeed ....................... True........................default\n",
            "  deepspeed_activation_checkpointing  True......................default\n",
            "  deepspeed_mpi ................... False.......................default\n",
            "  deepspeed_slurm ................. False.......................default\n",
            "  detect_nvlink_pairs ............. False.......................default\n",
            "  dim_att ......................... None........................default\n",
            "  distributed_backend ............. nccl........................default\n",
            "  do_test ......................... None........................default\n",
            "  do_train ........................ None........................default\n",
            "  do_valid ........................ None........................default\n",
            "  dpo_beta ........................ 0.1.........................default\n",
            "  dpo_fp32 ........................ True........................default\n",
            "  dpo_reference_free .............. False.......................default\n",
            "  dump_state ...................... False.......................default\n",
            "  elasticity ...................... None........................default\n",
            "  enable_expert_tensor_parallelism  False.......................default\n",
            "  eod_mask_loss ................... False.......................default\n",
            "  eval_results_prefix ............. ............................default\n",
            "  eval_tasks ...................... None........................default\n",
            "  exclude ......................... None........................default\n",
            "  exit_interval ................... None........................default\n",
            "  expansion_factor ................ None........................default\n",
            "  expert_interval ................. 2...........................default\n",
            "  extra_save_iters ................ None........................default\n",
            "  ffn_dim ......................... None........................default\n",
            "  finetune ........................ False.......................default\n",
            "  flops_profiler .................. None........................default\n",
            "  force_multi ..................... False.......................default\n",
            "  fp16_lm_cross_entropy ........... False.......................default\n",
            "  fp32_allreduce .................. False.......................default\n",
            "  git_hash ........................ 59a5236d....................default\n",
            "  gmlp_attn_dim ................... 64..........................default\n",
            "  gpt_j_residual .................. False.......................default\n",
            "  gpt_j_tied ...................... False.......................default\n",
            "  gradient_accumulation_steps ..... 1...........................default\n",
            "  gradient_clipping ............... 1.0.........................default\n",
            "  gradient_noise_scale_cpu_offload  False.......................default\n",
            "  gradient_noise_scale_n_batches .. 5...........................default\n",
            "  gradient_predivide_factor ....... 1.0.........................default\n",
            "  head_size ....................... None........................default\n",
            "  hidden_dropout .................. 0...........................default\n",
            "  hostfile ........................ None........................default\n",
            "  hysteresis ...................... 2...........................default\n",
            "  include ......................... None........................default\n",
            "  init_method_std ................. 0.02........................default\n",
            "  intermediate_size ............... None........................default\n",
            "  is_pipe_parallel ................ False.......................default\n",
            "  iteration ....................... None........................default\n",
            "  keep_last_n_checkpoints ......... None........................default\n",
            "  kto_beta ........................ 0.1.........................default\n",
            "  kto_desirable_weight ............ 1.0.........................default\n",
            "  kto_fp32 ........................ True........................default\n",
            "  kto_undesirable_weight .......... 1.0.........................default\n",
            "  launcher ........................ pdsh........................default\n",
            "  layernorm_epsilon ............... 1e-05.......................default\n",
            "  layernorm_fusion ................ False.......................default\n",
            "  lazy_mpu_init ................... False.......................default\n",
            "  local_rank ...................... None........................default\n",
            "  log_grad_norm ................... False.......................default\n",
            "  log_grad_pct_zeros .............. False.......................default\n",
            "  log_gradient_noise_scale ........ False.......................default\n",
            "  log_optimizer_states ............ False.......................default\n",
            "  log_param_norm .................. False.......................default\n",
            "  loss_scale ...................... None........................default\n",
            "  loss_scale_window ............... 1000.0......................default\n",
            "  lr_decay_fraction ............... None........................default\n",
            "  make_vocab_size_divisible_by .... 128.........................default\n",
            "  mamba_causal_conv_fusion ........ False.......................default\n",
            "  mamba_inner_func_fusion ......... False.......................default\n",
            "  mamba_selective_fp32_params ..... True........................default\n",
            "  mamba_selective_scan_fusion ..... False.......................default\n",
            "  mamba_use_bias_in_conv .......... True........................default\n",
            "  mamba_use_bias_in_linears ....... False.......................default\n",
            "  master_addr ..................... None........................default\n",
            "  master_port ..................... 29500.......................default\n",
            "  maximum_tokens .................. 64..........................default\n",
            "  memory_profiling ................ False.......................default\n",
            "  memory_profiling_path ........... None........................default\n",
            "  min_scale ....................... 1.0.........................default\n",
            "  mlp_multiple_of ................. 1...........................default\n",
            "  mmap_warmup ..................... False.......................default\n",
            "  model_parallel_size ............. 1...........................default\n",
            "  moe_eval_capacity_factor ........ 1.0.........................default\n",
            "  moe_expert_parallel_size ........ 1...........................default\n",
            "  moe_glu ......................... False.......................default\n",
            "  moe_jitter_eps .................. None........................default\n",
            "  moe_lbl_in_fp32 ................. False.......................default\n",
            "  moe_loss_coeff .................. 0.1.........................default\n",
            "  moe_min_capacity ................ 4...........................default\n",
            "  moe_num_experts ................. 1...........................default\n",
            "  moe_token_dropping .............. False.......................default\n",
            "  moe_top_k ....................... 1...........................default\n",
            "  moe_train_capacity_factor ....... 1.0.........................default\n",
            "  moe_type ........................ megablocks..................default\n",
            "  moe_use_residual ................ True........................default\n",
            "  mup_attn_temp ................... 1.0.........................default\n",
            "  mup_embedding_mult .............. 1.0.........................default\n",
            "  mup_init_scale .................. 1.0.........................default\n",
            "  mup_output_temp ................. 1.0.........................default\n",
            "  mup_rp_embedding_mult ........... 1.0.........................default\n",
            "  mup_width_scale ................. 2...........................default\n",
            "  neg_test_data_paths ............. None........................default\n",
            "  neg_test_label_data_paths ....... None........................default\n",
            "  neg_train_data_paths ............ None........................default\n",
            "  neg_train_label_data_paths ...... None........................default\n",
            "  neg_valid_data_paths ............ None........................default\n",
            "  neg_valid_label_data_paths ...... None........................default\n",
            "  no_load_optim ................... False.......................default\n",
            "  no_load_rng ..................... False.......................default\n",
            "  no_save_optim ................... False.......................default\n",
            "  no_save_rng ..................... False.......................default\n",
            "  no_ssh_check .................... False.......................default\n",
            "  norm ............................ layernorm...................default\n",
            "  num_gpus ........................ None........................default\n",
            "  num_kv_heads .................... None........................default\n",
            "  num_nodes ....................... -1..........................default\n",
            "  num_samples ..................... 1...........................default\n",
            "  num_unique_layers ............... None........................default\n",
            "  onnx_safe ....................... False.......................default\n",
            "  opt_pos_emb_offset .............. 0...........................default\n",
            "  output_layer_parallelism ........ column......................default\n",
            "  override_lr_scheduler ........... False.......................default\n",
            "  pack_impl ....................... packed......................default\n",
            "  padded_vocab_size ............... None........................default\n",
            "  param_sharing_style ............. grouped.....................default\n",
            "  pipe_parallel_size .............. 0...........................default\n",
            "  pipe_partition_method ........... type:transformer|mlp........default\n",
            "  pos_test_data_paths ............. None........................default\n",
            "  pos_test_label_data_paths ....... None........................default\n",
            "  pos_train_data_paths ............ None........................default\n",
            "  pos_train_label_data_paths ...... None........................default\n",
            "  pos_valid_data_paths ............ None........................default\n",
            "  pos_valid_label_data_paths ...... None........................default\n",
            "  precompute_model_name ........... None........................default\n",
            "  prescale_gradients .............. False.......................default\n",
            "  profile ......................... False.......................default\n",
            "  profile_backward ................ False.......................default\n",
            "  profile_step_start .............. 10..........................default\n",
            "  profile_step_stop ............... 12..........................default\n",
            "  prompt_end ...................... \n",
            "...........................default\n",
            "  rank ............................ None........................default\n",
            "  recompute ....................... False.......................default\n",
            "  return_logits ................... False.......................default\n",
            "  rms_norm_epsilon ................ 1e-08.......................default\n",
            "  rmsnorm_fusion .................. False.......................default\n",
            "  rope_fusion ..................... False.......................default\n",
            "  rotary_emb_base ................. 10000.......................default\n",
            "  rotary_pct ...................... 1.0.........................default\n",
            "  rotary_save_freqs_buffer ........ False.......................default\n",
            "  rpe_max_distance ................ 128.........................default\n",
            "  rpe_num_buckets ................. 32..........................default\n",
            "  s3_chunk_size ................... 104857600...................default\n",
            "  s3_path ......................... None........................default\n",
            "  sample_input_file ............... None........................default\n",
            "  sample_output_file .............. samples.txt.................default\n",
            "  save_base_shapes ................ False.......................default\n",
            "  scaled_masked_softmax_fusion .... False.......................default\n",
            "  scaled_upper_triang_masked_softmax_fusion  False..............default\n",
            "  scalenorm_epsilon ............... 1e-08.......................default\n",
            "  scheduler ....................... None........................default\n",
            "  seed ............................ 1234........................default\n",
            "  sequence_parallel ............... False.......................default\n",
            "  short_seq_prob .................. 0.1.........................default\n",
            "  sliding_window_width ............ None........................default\n",
            "  soft_prompt_tuning .............. None........................default\n",
            "  sparse_attention ................ None........................default\n",
            "  sparse_gradients ................ False.......................default\n",
            "  split ........................... 969, 30, 1..................default\n",
            "  steps_per_print ................. 10..........................default\n",
            "  temperature ..................... 0.0.........................default\n",
            "  tensorboard ..................... None........................default\n",
            "  test_data_paths ................. None........................default\n",
            "  test_data_weights ............... None........................default\n",
            "  test_label_data_paths ........... None........................default\n",
            "  test_reward_data_paths .......... None........................default\n",
            "  tokenizer_type .................. GPT2BPETokenizer............default\n",
            "  top_k ........................... 0...........................default\n",
            "  top_p ........................... 0.0.........................default\n",
            "  train_data_paths ................ None........................default\n",
            "  train_data_weights .............. None........................default\n",
            "  train_epochs .................... None........................default\n",
            "  train_impl ...................... normal......................default\n",
            "  train_label_data_paths .......... None........................default\n",
            "  train_reward_data_paths ......... None........................default\n",
            "  use_bias_in_attn_linear ......... True........................default\n",
            "  use_bias_in_mlp ................. True........................default\n",
            "  use_bias_in_norms ............... True........................default\n",
            "  use_bnb_optimizer ............... False.......................default\n",
            "  use_checkpoint_lr_scheduler ..... False.......................default\n",
            "  use_comet ....................... None........................default\n",
            "  use_cpu_initialization .......... False.......................default\n",
            "  use_flashattn_swiglu ............ False.......................default\n",
            "  use_mup ......................... False.......................default\n",
            "  use_qk_layernorm ................ False.......................default\n",
            "  use_shared_fs ................... True........................default\n",
            "  use_tutel ....................... False.......................default\n",
            "  use_wandb ....................... None........................default\n",
            "  valid_data_paths ................ None........................default\n",
            "  valid_data_weights .............. None........................default\n",
            "  valid_label_data_paths .......... None........................default\n",
            "  valid_reward_data_paths ......... None........................default\n",
            "  wandb ........................... None........................default\n",
            "  wandb_group ..................... None........................default\n",
            "  wandb_host ...................... https://api.wandb.ai........default\n",
            "  wandb_init_all_ranks ............ False.......................default\n",
            "  wandb_project ................... neox........................default\n",
            "  wandb_team ...................... None........................default\n",
            "  warmup .......................... 0.01........................default\n",
            "  weight_by_num_documents ......... False.......................default\n",
            "  weight_decay .................... 0.1.........................default\n",
            "  weighted_sampler_alpha .......... 1.0.........................default\n",
            "  world_size ...................... None........................default\n",
            "  z_loss .......................... 0.0.........................default\n",
            "---------------- end of arguments ----------------\n",
            "NeoXArgs.configure_distributed_args() using world size: 1 and model-parallel size: 1 \n",
            "[2024-11-01 22:57:57,498] [WARNING] [runner.py:217:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
            "[2024-11-01 22:57:57,498] [INFO] [runner.py:586:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None train.py --deepspeed_config eyJ0cmFpbl9iYXRjaF9zaXplIjogNCwgInRyYWluX21pY3JvX2JhdGNoX3NpemVfcGVyX2dwdSI6IDQsICJvcHRpbWl6ZXIiOiB7InR5cGUiOiAiQWRhbSIsICJwYXJhbXMiOiB7ImxyIjogMC4wMDEsICJiZXRhcyI6IFswLjksIDAuOTVdLCAiZXBzIjogMWUtMDh9fSwgImZwMTYiOiB7ImZwMTYiOiB0cnVlLCAiZW5hYmxlZCI6IHRydWUsICJsb3NzX3NjYWxlIjogMCwgImxvc3Nfc2NhbGVfd2luZG93IjogMTAwMCwgImluaXRpYWxfc2NhbGVfcG93ZXIiOiAxMiwgImh5c3RlcmVzaXMiOiAyLCAibWluX2xvc3Nfc2NhbGUiOiAxfSwgInplcm9fb3B0aW1pemF0aW9uIjogeyJzdGFnZSI6IDEsICJhbGxnYXRoZXJfcGFydGl0aW9ucyI6IHRydWUsICJhbGxnYXRoZXJfYnVja2V0X3NpemUiOiA1MDAwMDAwMDAsICJvdmVybGFwX2NvbW0iOiB0cnVlLCAicmVkdWNlX3NjYXR0ZXIiOiB0cnVlLCAicmVkdWNlX2J1Y2tldF9zaXplIjogNTAwMDAwMDAwLCAiY29udGlndW91c19ncmFkaWVudHMiOiB0cnVlfSwgIndhbGxfY2xvY2tfYnJlYWtkb3duIjogdHJ1ZSwgImNvbW1zX2xvZ2dlciI6IHsiZW5hYmxlZCI6IHRydWUsICJ2ZXJib3NlIjogdHJ1ZSwgInByb2ZfYWxsIjogdHJ1ZSwgImRlYnVnIjogZmFsc2V9fQ== --megatron_config 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\n",
            "[2024-11-01 22:57:58,986] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2024-11-01 22:58:01,203] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.19.3-1+cuda12.2\n",
            "[2024-11-01 22:58:01,203] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.19.3-1\n",
            "[2024-11-01 22:58:01,203] [INFO] [launch.py:138:main] 0 NCCL_VERSION=2.19.3-1\n",
            "[2024-11-01 22:58:01,203] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n",
            "[2024-11-01 22:58:01,203] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.19.3-1+cuda12.2\n",
            "[2024-11-01 22:58:01,203] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n",
            "[2024-11-01 22:58:01,203] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.19.3-1\n",
            "[2024-11-01 22:58:01,203] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0]}\n",
            "[2024-11-01 22:58:01,203] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0\n",
            "[2024-11-01 22:58:01,203] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
            "[2024-11-01 22:58:01,203] [INFO] [launch.py:163:main] dist_world_size=1\n",
            "[2024-11-01 22:58:01,203] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0\n",
            "[2024-11-01 22:58:02,824] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba\n",
            "For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3\n",
            "For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer\n",
            "NeoXArgs.configure_distributed_args() using world size: 1 and model-parallel size: 1 \n",
            "> building GPT2BPETokenizer tokenizer ...\n",
            " > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)\n",
            "2024-11-01 22:58:06.662968: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-01 22:58:06.695642: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-01 22:58:06.705859: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-01 22:58:08.328786: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "> setting up tensorboard ...\n",
            "> initializing torch distributed ...\n",
            "[2024-11-01 22:58:09,393] [INFO] [comm.py:637:init_distributed] cdb=None\n",
            "[2024-11-01 22:58:09,393] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
            "> initializing model parallel with size 1\n",
            "MPU DP: [0]\n",
            "MPU PP: [0]\n",
            "MPU MP: [0]\n",
            "> setting random seeds to 1234 ...\n",
            "[2024-11-01 22:58:09,400] [INFO] [checkpointing.py:227:model_parallel_cuda_manual_seed] > initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234\n",
            "make: Entering directory '/content/gpt-neox/megatron/data'\n",
            "make: Nothing to be done for 'default'.\n",
            "make: Leaving directory '/content/gpt-neox/megatron/data'\n",
            "> building train, validation, and test datasets ...\n",
            "    reading sizes...\n",
            "    reading pointers...\n",
            "    reading document index...\n",
            "    creating numpy buffer of mmap...\n",
            "    creating memory view of numpy buffer...\n",
            " > dataset split:\n",
            "    train:\n",
            "     document indices in [0, 92055) total of 92055 documents\n",
            "    validation:\n",
            "     document indices in [92055, 94905) total of 2850 documents\n",
            "    test:\n",
            "     document indices in [94905, 95000) total of 95 documents\n",
            "/content/gpt-neox/megatron/data/gpt2_dataset.py:373: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n",
            "  counts = torch.cuda.LongTensor([1])\n",
            " > loading doc-idx mapping from processed_data/py150_text_document_train_indexmap_400ns_2048sl_1234s_packedpi_ac_doc_idx.npy\n",
            " > loading sample-idx mapping from processed_data/py150_text_document_train_indexmap_400ns_2048sl_1234s_packedpi_ac_sample_idx.npy\n",
            " > loading shuffle-idx mapping from processed_data/py150_text_document_train_indexmap_400ns_2048sl_1234s_packedpi_ac_shuffle_idx.npy\n",
            "    loaded indexed file in 0.001 seconds\n",
            "    total number of samples: 86775\n",
            "    total number of epochs: 1\n",
            " > loading doc-idx mapping from processed_data/py150_text_document_valid_indexmap_120ns_2048sl_1234s_packedpi_ac_doc_idx.npy\n",
            " > loading sample-idx mapping from processed_data/py150_text_document_valid_indexmap_120ns_2048sl_1234s_packedpi_ac_sample_idx.npy\n",
            " > loading shuffle-idx mapping from processed_data/py150_text_document_valid_indexmap_120ns_2048sl_1234s_packedpi_ac_shuffle_idx.npy\n",
            "    loaded indexed file in 0.001 seconds\n",
            "    total number of samples: 2371\n",
            "    total number of epochs: 1\n",
            " > loading doc-idx mapping from processed_data/py150_text_document_test_indexmap_40ns_2048sl_1234s_packedpi_ac_doc_idx.npy\n",
            " > loading sample-idx mapping from processed_data/py150_text_document_test_indexmap_40ns_2048sl_1234s_packedpi_ac_sample_idx.npy\n",
            " > loading shuffle-idx mapping from processed_data/py150_text_document_test_indexmap_40ns_2048sl_1234s_packedpi_ac_shuffle_idx.npy\n",
            "    loaded indexed file in 0.005 seconds\n",
            "    total number of samples: 68\n",
            "    total number of epochs: 1\n",
            "building GPT2 model ...\n",
            "SEED_LAYERS=False BASE_SEED=1234 SEED_FN=None\n",
            "Using topology: {ProcessCoord(pipe=0, data=0, model=0): 0}\n",
            "[2024-11-01 22:58:10,282] [INFO] [module.py:375:_partition_layers] Partitioning pipeline stages with method type:transformer|mlp\n",
            "stage=0 layers=11\n",
            "     0: EmbeddingPipe\n",
            "     1: _pre_transformer_block\n",
            "     2: ParallelTransformerLayerPipe\n",
            "     3: ParallelTransformerLayerPipe\n",
            "     4: ParallelTransformerLayerPipe\n",
            "     5: ParallelTransformerLayerPipe\n",
            "     6: ParallelTransformerLayerPipe\n",
            "     7: ParallelTransformerLayerPipe\n",
            "     8: _post_transformer_block\n",
            "     9: NormPipe\n",
            "    10: ParallelLinearPipe\n",
            "  loss: partial\n",
            "Configuring Optimizer type: Adam with params: {'lr': 0.001, 'betas': [0.9, 0.95], 'eps': 1e-08}\n",
            "WARNING: APEX not installed - defaulting to deepspeed's fused adam\n",
            "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py310_cu121/fused_adam/build.ninja...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n",
            "Building extension module fused_adam...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "ninja: no work to do.\n",
            "Loading extension module fused_adam...\n",
            "Time to load fused_adam op: 0.15965008735656738 seconds\n",
            "> learning rate decay style: cosine\n",
            "DeepSpeed is enabled.\n",
            "[2024-11-01 22:58:11,580] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.12.4+02e2ebf, git-hash=02e2ebf, git-branch=HEAD\n",
            "[2024-11-01 22:58:11,590] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.37 | msg size: 49.12 MB | algbw (Gbps): 1124.80 | busbw (Gbps): 1124.80\n",
            "[2024-11-01 22:58:11,590] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.25 | msg size: 1.0 KB | algbw (Gbps): 0.03 | busbw (Gbps): 0.03\n",
            "[2024-11-01 22:58:11,591] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.22 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 22:58:11,592] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.20 | msg size: 1.5 MB | algbw (Gbps): 62.45 | busbw (Gbps): 62.45\n",
            "[2024-11-01 22:58:11,593] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.21 | msg size: 3.0 KB | algbw (Gbps): 0.12 | busbw (Gbps): 0.12\n",
            "[2024-11-01 22:58:11,594] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.21 | msg size: 512.0 KB | algbw (Gbps): 20.06 | busbw (Gbps): 20.06\n",
            "[2024-11-01 22:58:11,594] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.22 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 22:58:11,595] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.20 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 22:58:11,595] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.20 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 22:58:11,596] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.21 | msg size: 2.0 MB | algbw (Gbps): 78.05 | busbw (Gbps): 78.05\n",
            "[2024-11-01 22:58:11,597] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.19 | msg size: 4.0 KB | algbw (Gbps): 0.17 | busbw (Gbps): 0.17\n",
            "[2024-11-01 22:58:11,597] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.20 | msg size: 2.0 MB | algbw (Gbps): 83.61 | busbw (Gbps): 83.61\n",
            "[2024-11-01 22:58:11,598] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.23 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 22:58:11,599] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.21 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 22:58:11,599] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.20 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 22:58:11,600] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.24 | msg size: 1.5 MB | algbw (Gbps): 53.41 | busbw (Gbps): 53.41\n",
            "[2024-11-01 22:58:11,601] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.20 | msg size: 3.0 KB | algbw (Gbps): 0.12 | busbw (Gbps): 0.12\n",
            "[2024-11-01 22:58:11,601] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.19 | msg size: 512.0 KB | algbw (Gbps): 21.58 | busbw (Gbps): 21.58\n",
            "[2024-11-01 22:58:11,602] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.23 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 22:58:11,603] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.21 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 22:58:11,604] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.20 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 22:58:11,604] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.30 | msg size: 2.0 MB | algbw (Gbps): 55.23 | busbw (Gbps): 55.23\n",
            "[2024-11-01 22:58:11,606] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.22 | msg size: 4.0 KB | algbw (Gbps): 0.15 | busbw (Gbps): 0.15\n",
            "[2024-11-01 22:58:11,607] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.24 | msg size: 2.0 MB | algbw (Gbps): 71.23 | busbw (Gbps): 71.23\n",
            "[2024-11-01 22:58:11,608] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.21 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 22:58:11,608] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.20 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 22:58:11,609] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.22 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 22:58:11,610] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.23 | msg size: 1.5 MB | algbw (Gbps): 55.35 | busbw (Gbps): 55.35\n",
            "[2024-11-01 22:58:11,611] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.20 | msg size: 3.0 KB | algbw (Gbps): 0.13 | busbw (Gbps): 0.13\n",
            "[2024-11-01 22:58:11,611] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.21 | msg size: 512.0 KB | algbw (Gbps): 19.81 | busbw (Gbps): 19.81\n",
            "[2024-11-01 22:58:11,612] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.23 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 22:58:11,613] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.25 | msg size: 1.0 KB | algbw (Gbps): 0.03 | busbw (Gbps): 0.03\n",
            "[2024-11-01 22:58:11,613] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.20 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 22:58:11,614] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.20 | msg size: 2.0 MB | algbw (Gbps): 84.55 | busbw (Gbps): 84.55\n",
            "[2024-11-01 22:58:11,615] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.21 | msg size: 4.0 KB | algbw (Gbps): 0.16 | busbw (Gbps): 0.16\n",
            "[2024-11-01 22:58:11,615] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.21 | msg size: 2.0 MB | algbw (Gbps): 81.06 | busbw (Gbps): 81.06\n",
            "[2024-11-01 22:58:11,616] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.23 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 22:58:11,617] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.20 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 22:58:11,618] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.20 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 22:58:11,618] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.20 | msg size: 1.5 MB | algbw (Gbps): 61.43 | busbw (Gbps): 61.43\n",
            "[2024-11-01 22:58:11,619] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.19 | msg size: 3.0 KB | algbw (Gbps): 0.13 | busbw (Gbps): 0.13\n",
            "[2024-11-01 22:58:11,619] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.19 | msg size: 512.0 KB | algbw (Gbps): 21.56 | busbw (Gbps): 21.56\n",
            "[2024-11-01 22:58:11,620] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.20 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 22:58:11,621] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.20 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 22:58:11,621] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.19 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 22:58:11,622] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.24 | msg size: 2.0 MB | algbw (Gbps): 71.23 | busbw (Gbps): 71.23\n",
            "[2024-11-01 22:58:11,623] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.19 | msg size: 4.0 KB | algbw (Gbps): 0.17 | busbw (Gbps): 0.17\n",
            "[2024-11-01 22:58:11,623] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.20 | msg size: 2.0 MB | algbw (Gbps): 83.30 | busbw (Gbps): 83.30\n",
            "[2024-11-01 22:58:11,624] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.24 | msg size: 1.0 KB | algbw (Gbps): 0.03 | busbw (Gbps): 0.03\n",
            "[2024-11-01 22:58:11,625] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.19 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 22:58:11,625] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.20 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 22:58:11,626] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.23 | msg size: 1.5 MB | algbw (Gbps): 55.36 | busbw (Gbps): 55.36\n",
            "[2024-11-01 22:58:11,627] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.21 | msg size: 3.0 KB | algbw (Gbps): 0.12 | busbw (Gbps): 0.12\n",
            "[2024-11-01 22:58:11,627] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.20 | msg size: 512.0 KB | algbw (Gbps): 21.16 | busbw (Gbps): 21.16\n",
            "[2024-11-01 22:58:11,628] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.25 | msg size: 1.0 KB | algbw (Gbps): 0.03 | busbw (Gbps): 0.03\n",
            "[2024-11-01 22:58:11,629] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.20 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 22:58:11,629] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.20 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 22:58:11,630] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.26 | msg size: 2.0 MB | algbw (Gbps): 65.53 | busbw (Gbps): 65.53\n",
            "[2024-11-01 22:58:11,631] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.20 | msg size: 4.0 KB | algbw (Gbps): 0.17 | busbw (Gbps): 0.17\n",
            "[2024-11-01 22:58:11,631] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.20 | msg size: 2.0 MB | algbw (Gbps): 85.33 | busbw (Gbps): 85.33\n",
            "[2024-11-01 22:58:11,632] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.22 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 22:58:11,633] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.19 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 22:58:11,633] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.22 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 22:58:11,634] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.19 | msg size: 1.5 MB | algbw (Gbps): 64.74 | busbw (Gbps): 64.74\n",
            "[2024-11-01 22:58:11,634] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.19 | msg size: 3.0 KB | algbw (Gbps): 0.13 | busbw (Gbps): 0.13\n",
            "[2024-11-01 22:58:11,635] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.21 | msg size: 512.0 KB | algbw (Gbps): 19.71 | busbw (Gbps): 19.71\n",
            "[2024-11-01 22:58:11,636] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.20 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 22:58:11,636] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.20 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 22:58:11,637] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.21 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 22:58:11,638] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.19 | msg size: 2.0 MB | algbw (Gbps): 86.47 | busbw (Gbps): 86.47\n",
            "[2024-11-01 22:58:11,638] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.20 | msg size: 4.0 KB | algbw (Gbps): 0.17 | busbw (Gbps): 0.17\n",
            "[2024-11-01 22:58:11,639] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.22 | msg size: 2.0 MB | algbw (Gbps): 75.79 | busbw (Gbps): 75.79\n",
            "[2024-11-01 22:58:11,640] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.19 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 22:58:11,640] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.20 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 22:58:11,641] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.21 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 22:58:11,642] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.20 | msg size: 49.12 MB | algbw (Gbps): 2035.05 | busbw (Gbps): 2035.05\n",
            "[2024-11-01 22:58:11,642] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
            "[2024-11-01 22:58:11,642] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
            "[2024-11-01 22:58:11,643] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
            "[2024-11-01 22:58:11,645] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam\n",
            "[2024-11-01 22:58:11,645] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>\n",
            "[2024-11-01 22:58:11,645] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 1 optimizer\n",
            "[2024-11-01 22:58:11,645] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 500000000\n",
            "[2024-11-01 22:58:11,645] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 500000000\n",
            "[2024-11-01 22:58:11,645] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
            "[2024-11-01 22:58:11,645] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
            "[2024-11-01 22:58:12,204] [INFO] [utils.py:802:see_memory_usage] Before initializing optimizer states\n",
            "[2024-11-01 22:58:12,205] [INFO] [utils.py:803:see_memory_usage] MA 0.39 GB         Max_MA 0.39 GB         CA 0.4 GB         Max_CA 0 GB \n",
            "[2024-11-01 22:58:12,205] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 4.75 GB, percent = 37.4%\n",
            "[2024-11-01 22:58:12,462] [INFO] [utils.py:802:see_memory_usage] After initializing optimizer states\n",
            "[2024-11-01 22:58:12,464] [INFO] [utils.py:803:see_memory_usage] MA 0.92 GB         Max_MA 1.18 GB         CA 1.19 GB         Max_CA 1 GB \n",
            "[2024-11-01 22:58:12,464] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 4.75 GB, percent = 37.4%\n",
            "[2024-11-01 22:58:12,464] [INFO] [stage_1_and_2.py:517:__init__] optimizer state initialized\n",
            "[2024-11-01 22:58:12,731] [INFO] [utils.py:802:see_memory_usage] After initializing ZeRO optimizer\n",
            "[2024-11-01 22:58:12,732] [INFO] [utils.py:803:see_memory_usage] MA 0.92 GB         Max_MA 0.92 GB         CA 1.19 GB         Max_CA 1 GB \n",
            "[2024-11-01 22:58:12,732] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 4.75 GB, percent = 37.5%\n",
            "[2024-11-01 22:58:12,735] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam\n",
            "[2024-11-01 22:58:12,735] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
            "[2024-11-01 22:58:12,735] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <megatron.learning_rates.AnnealingLR object at 0x13502b23dc90>\n",
            "[2024-11-01 22:58:12,735] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[[0.9, 0.95], [0.9, 0.95]]\n",
            "[2024-11-01 22:58:12,735] [INFO] [config.py:979:print] DeepSpeedEngine configuration:\n",
            "[2024-11-01 22:58:12,736] [INFO] [config.py:983:print]   activation_checkpointing_config  {\n",
            "    \"partition_activations\": false, \n",
            "    \"contiguous_memory_optimization\": false, \n",
            "    \"cpu_checkpointing\": false, \n",
            "    \"number_checkpoints\": null, \n",
            "    \"synchronize_checkpoint_boundary\": false, \n",
            "    \"profile\": false\n",
            "}\n",
            "[2024-11-01 22:58:12,736] [INFO] [config.py:983:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
            "[2024-11-01 22:58:12,736] [INFO] [config.py:983:print]   amp_enabled .................. False\n",
            "[2024-11-01 22:58:12,736] [INFO] [config.py:983:print]   amp_params ................... False\n",
            "[2024-11-01 22:58:12,736] [INFO] [config.py:983:print]   autotuning_config ............ {\n",
            "    \"enabled\": false, \n",
            "    \"start_step\": null, \n",
            "    \"end_step\": null, \n",
            "    \"metric_path\": null, \n",
            "    \"arg_mappings\": null, \n",
            "    \"metric\": \"throughput\", \n",
            "    \"model_info\": null, \n",
            "    \"results_dir\": \"autotuning_results\", \n",
            "    \"exps_dir\": \"autotuning_exps\", \n",
            "    \"overwrite\": true, \n",
            "    \"fast\": true, \n",
            "    \"start_profile_step\": 3, \n",
            "    \"end_profile_step\": 5, \n",
            "    \"tuner_type\": \"gridsearch\", \n",
            "    \"tuner_early_stopping\": 5, \n",
            "    \"tuner_num_trials\": 50, \n",
            "    \"model_info_path\": null, \n",
            "    \"mp_size\": 1, \n",
            "    \"max_train_batch_size\": null, \n",
            "    \"min_train_batch_size\": 1, \n",
            "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
            "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
            "    \"num_tuning_micro_batch_sizes\": 3\n",
            "}\n",
            "[2024-11-01 22:58:12,736] [INFO] [config.py:983:print]   bfloat16_enabled ............. False\n",
            "[2024-11-01 22:58:12,736] [INFO] [config.py:983:print]   checkpoint_parallel_write_pipeline  False\n",
            "[2024-11-01 22:58:12,736] [INFO] [config.py:983:print]   checkpoint_tag_validation_enabled  True\n",
            "[2024-11-01 22:58:12,737] [INFO] [config.py:983:print]   checkpoint_tag_validation_fail  False\n",
            "[2024-11-01 22:58:12,737] [INFO] [config.py:983:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x134fff99bee0>\n",
            "[2024-11-01 22:58:12,737] [INFO] [config.py:983:print]   communication_data_type ...... None\n",
            "[2024-11-01 22:58:12,737] [INFO] [config.py:983:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
            "[2024-11-01 22:58:12,737] [INFO] [config.py:983:print]   curriculum_enabled_legacy .... False\n",
            "[2024-11-01 22:58:12,737] [INFO] [config.py:983:print]   curriculum_params_legacy ..... False\n",
            "[2024-11-01 22:58:12,737] [INFO] [config.py:983:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
            "[2024-11-01 22:58:12,737] [INFO] [config.py:983:print]   data_efficiency_enabled ...... False\n",
            "[2024-11-01 22:58:12,737] [INFO] [config.py:983:print]   dataloader_drop_last ......... False\n",
            "[2024-11-01 22:58:12,737] [INFO] [config.py:983:print]   disable_allgather ............ False\n",
            "[2024-11-01 22:58:12,737] [INFO] [config.py:983:print]   dump_state ................... False\n",
            "[2024-11-01 22:58:12,737] [INFO] [config.py:983:print]   dynamic_loss_scale_args ...... {'init_scale': 4096, 'scale_window': 1000, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}\n",
            "[2024-11-01 22:58:12,737] [INFO] [config.py:983:print]   eigenvalue_enabled ........... False\n",
            "[2024-11-01 22:58:12,737] [INFO] [config.py:983:print]   eigenvalue_gas_boundary_resolution  1\n",
            "[2024-11-01 22:58:12,737] [INFO] [config.py:983:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
            "[2024-11-01 22:58:12,737] [INFO] [config.py:983:print]   eigenvalue_layer_num ......... 0\n",
            "[2024-11-01 22:58:12,737] [INFO] [config.py:983:print]   eigenvalue_max_iter .......... 100\n",
            "[2024-11-01 22:58:12,737] [INFO] [config.py:983:print]   eigenvalue_stability ......... 1e-06\n",
            "[2024-11-01 22:58:12,737] [INFO] [config.py:983:print]   eigenvalue_tol ............... 0.01\n",
            "[2024-11-01 22:58:12,737] [INFO] [config.py:983:print]   eigenvalue_verbose ........... False\n",
            "[2024-11-01 22:58:12,737] [INFO] [config.py:983:print]   elasticity_enabled ........... False\n",
            "[2024-11-01 22:58:12,737] [INFO] [config.py:983:print]   flops_profiler_config ........ {\n",
            "    \"enabled\": false, \n",
            "    \"recompute_fwd_factor\": 0.0, \n",
            "    \"profile_step\": 1, \n",
            "    \"module_depth\": -1, \n",
            "    \"top_modules\": 1, \n",
            "    \"detailed\": true, \n",
            "    \"output_file\": null\n",
            "}\n",
            "[2024-11-01 22:58:12,737] [INFO] [config.py:983:print]   fp16_auto_cast ............... False\n",
            "[2024-11-01 22:58:12,738] [INFO] [config.py:983:print]   fp16_enabled ................. True\n",
            "[2024-11-01 22:58:12,738] [INFO] [config.py:983:print]   fp16_master_weights_and_gradients  False\n",
            "[2024-11-01 22:58:12,738] [INFO] [config.py:983:print]   global_rank .................. 0\n",
            "[2024-11-01 22:58:12,738] [INFO] [config.py:983:print]   grad_accum_dtype ............. None\n",
            "[2024-11-01 22:58:12,738] [INFO] [config.py:983:print]   gradient_accumulation_steps .. 1\n",
            "[2024-11-01 22:58:12,738] [INFO] [config.py:983:print]   gradient_clipping ............ 0.0\n",
            "[2024-11-01 22:58:12,738] [INFO] [config.py:983:print]   gradient_predivide_factor .... 1.0\n",
            "[2024-11-01 22:58:12,738] [INFO] [config.py:983:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
            "[2024-11-01 22:58:12,738] [INFO] [config.py:983:print]   initial_dynamic_scale ........ 4096\n",
            "[2024-11-01 22:58:12,738] [INFO] [config.py:983:print]   load_universal_checkpoint .... False\n",
            "[2024-11-01 22:58:12,738] [INFO] [config.py:983:print]   loss_scale ................... 0\n",
            "[2024-11-01 22:58:12,738] [INFO] [config.py:983:print]   memory_breakdown ............. False\n",
            "[2024-11-01 22:58:12,738] [INFO] [config.py:983:print]   mics_hierarchial_params_gather  False\n",
            "[2024-11-01 22:58:12,738] [INFO] [config.py:983:print]   mics_shard_size .............. -1\n",
            "[2024-11-01 22:58:12,738] [INFO] [config.py:983:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
            "[2024-11-01 22:58:12,738] [INFO] [config.py:983:print]   nebula_config ................ {\n",
            "    \"enabled\": false, \n",
            "    \"persistent_storage_path\": null, \n",
            "    \"persistent_time_interval\": 100, \n",
            "    \"num_of_version_in_retention\": 2, \n",
            "    \"enable_nebula_load\": true, \n",
            "    \"load_path\": null\n",
            "}\n",
            "[2024-11-01 22:58:12,738] [INFO] [config.py:983:print]   optimizer_legacy_fusion ...... False\n",
            "[2024-11-01 22:58:12,738] [INFO] [config.py:983:print]   optimizer_name ............... adam\n",
            "[2024-11-01 22:58:12,738] [INFO] [config.py:983:print]   optimizer_params ............. {'lr': 0.001, 'betas': [0.9, 0.95], 'eps': 1e-08}\n",
            "[2024-11-01 22:58:12,738] [INFO] [config.py:983:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
            "[2024-11-01 22:58:12,738] [INFO] [config.py:983:print]   pld_enabled .................. False\n",
            "[2024-11-01 22:58:12,738] [INFO] [config.py:983:print]   pld_params ................... False\n",
            "[2024-11-01 22:58:12,739] [INFO] [config.py:983:print]   prescale_gradients ........... False\n",
            "[2024-11-01 22:58:12,739] [INFO] [config.py:983:print]   scheduler_name ............... None\n",
            "[2024-11-01 22:58:12,739] [INFO] [config.py:983:print]   scheduler_params ............. None\n",
            "[2024-11-01 22:58:12,739] [INFO] [config.py:983:print]   seq_parallel_communication_data_type  torch.float32\n",
            "[2024-11-01 22:58:12,739] [INFO] [config.py:983:print]   sparse_attention ............. None\n",
            "[2024-11-01 22:58:12,739] [INFO] [config.py:983:print]   sparse_gradients_enabled ..... False\n",
            "[2024-11-01 22:58:12,739] [INFO] [config.py:983:print]   steps_per_print .............. 10\n",
            "[2024-11-01 22:58:12,739] [INFO] [config.py:983:print]   train_batch_size ............. 4\n",
            "[2024-11-01 22:58:12,739] [INFO] [config.py:983:print]   train_micro_batch_size_per_gpu  4\n",
            "[2024-11-01 22:58:12,739] [INFO] [config.py:983:print]   use_data_before_expert_parallel_  False\n",
            "[2024-11-01 22:58:12,739] [INFO] [config.py:983:print]   use_node_local_storage ....... False\n",
            "[2024-11-01 22:58:12,739] [INFO] [config.py:983:print]   wall_clock_breakdown ......... True\n",
            "[2024-11-01 22:58:12,739] [INFO] [config.py:983:print]   weight_quantization_config ... None\n",
            "[2024-11-01 22:58:12,739] [INFO] [config.py:983:print]   world_size ................... 1\n",
            "[2024-11-01 22:58:12,739] [INFO] [config.py:983:print]   zero_allow_untested_optimizer  False\n",
            "[2024-11-01 22:58:12,739] [INFO] [config.py:983:print]   zero_config .................. stage=1 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
            "[2024-11-01 22:58:12,739] [INFO] [config.py:983:print]   zero_enabled ................. True\n",
            "[2024-11-01 22:58:12,739] [INFO] [config.py:983:print]   zero_force_ds_cpu_optimizer .. True\n",
            "[2024-11-01 22:58:12,739] [INFO] [config.py:983:print]   zero_optimization_stage ...... 1\n",
            "[2024-11-01 22:58:12,740] [INFO] [config.py:969:print_user_config]   json = {\n",
            "    \"train_batch_size\": 4, \n",
            "    \"train_micro_batch_size_per_gpu\": 4, \n",
            "    \"optimizer\": {\n",
            "        \"type\": \"Adam\", \n",
            "        \"params\": {\n",
            "            \"lr\": 0.001, \n",
            "            \"betas\": [0.9, 0.95], \n",
            "            \"eps\": 1e-08\n",
            "        }\n",
            "    }, \n",
            "    \"fp16\": {\n",
            "        \"fp16\": true, \n",
            "        \"enabled\": true, \n",
            "        \"loss_scale\": 0, \n",
            "        \"loss_scale_window\": 1000, \n",
            "        \"initial_scale_power\": 12, \n",
            "        \"hysteresis\": 2, \n",
            "        \"min_loss_scale\": 1\n",
            "    }, \n",
            "    \"zero_optimization\": {\n",
            "        \"stage\": 1, \n",
            "        \"allgather_partitions\": true, \n",
            "        \"allgather_bucket_size\": 5.000000e+08, \n",
            "        \"overlap_comm\": true, \n",
            "        \"reduce_scatter\": true, \n",
            "        \"reduce_bucket_size\": 5.000000e+08, \n",
            "        \"contiguous_gradients\": true\n",
            "    }, \n",
            "    \"wall_clock_breakdown\": true, \n",
            "    \"comms_logger\": {\n",
            "        \"enabled\": true, \n",
            "        \"verbose\": true, \n",
            "        \"prof_all\": true, \n",
            "        \"debug\": false\n",
            "    }\n",
            "}\n",
            " > number of parameters on model parallel rank 0: 70426624\n",
            " > total params: 70,426,624\n",
            "[2024-11-01 22:58:12,792] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at checkpoints/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.\n",
            "Unable to load checkpoint.\n",
            "Loading checkpoint and starting from iteration 0\n",
            "setting training data start iteration to 0\n",
            "setting validation data start iteration to 0\n",
            "done with setups ...\n",
            "time (ms) | train/valid/test data loaders: 558.08 | model and optimizer: 2512.86 | train/valid/test data iterators: 97.83\n",
            "training ...\n",
            "[2024-11-01 22:58:13,400] [INFO] [checkpointing.py:540:forward] Activation Checkpointing Information\n",
            "[2024-11-01 22:58:13,401] [INFO] [checkpointing.py:541:forward] ----Partition Activations True, CPU CHECKPOINTING False\n",
            "[2024-11-01 22:58:13,401] [INFO] [checkpointing.py:542:forward] ----contiguous Memory Checkpointing False with 6 total layers\n",
            "[2024-11-01 22:58:13,401] [INFO] [checkpointing.py:544:forward] ----Synchronization True\n",
            "[2024-11-01 22:58:13,401] [INFO] [checkpointing.py:545:forward] ----Profiling time in checkpointing False\n",
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "[2024-11-01 22:58:14,665] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 33973.29 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:14,673] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:14,704] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:14,708] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:14,726] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 14861.84 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:14,727] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.19 | msg size: 80.0 KB | algbw (Gbps): 3.40 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:14,728] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.84 | optimizer_gradients: 6.02 | optimizer_step: 12.09\n",
            "[2024-11-01 22:58:14,728] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1066.13 | bwd_microstep: 536.79 | bwd_inner_microstep: 530.17 | bwd_allreduce_microstep: 6.45 | step_microstep: 61.39\n",
            "[2024-11-01 22:58:14,728] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 1066.09 | bwd: 536.77 | bwd_inner: 530.17 | bwd_allreduce: 6.42 | step: 61.39\n",
            "[2024-11-01 22:58:15,229] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.05 | msg size: 134.33 MB | algbw (Gbps): 47617.73 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:15,238] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:15,245] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:15,248] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:15,267] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 15809.90 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:15,267] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.16 | msg size: 80.0 KB | algbw (Gbps): 4.17 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:15,268] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.80 | optimizer_gradients: 5.92 | optimizer_step: 11.94\n",
            "[2024-11-01 22:58:15,268] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 94.37 | bwd_microstep: 339.76 | bwd_inner_microstep: 334.56 | bwd_allreduce_microstep: 5.15 | step_microstep: 36.94\n",
            "[2024-11-01 22:58:15,269] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 94.35 | bwd: 339.75 | bwd_inner: 334.55 | bwd_allreduce: 5.16 | step: 36.94\n",
            "[2024-11-01 22:58:15,775] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 29210.55 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:15,783] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:15,791] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:15,794] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:15,812] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 15655.18 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:15,813] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.14 | msg size: 80.0 KB | algbw (Gbps): 4.74 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:15,814] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.75 | optimizer_gradients: 5.94 | optimizer_step: 11.92\n",
            "[2024-11-01 22:58:15,814] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 86.91 | bwd_microstep: 352.85 | bwd_inner_microstep: 347.70 | bwd_allreduce_microstep: 5.11 | step_microstep: 36.79\n",
            "[2024-11-01 22:58:15,814] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 86.89 | bwd: 352.83 | bwd_inner: 347.69 | bwd_allreduce: 5.11 | step: 36.80\n",
            "[2024-11-01 22:58:16,315] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.06 | msg size: 134.33 MB | algbw (Gbps): 36699.65 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:16,324] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:16,331] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:16,334] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:16,352] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 17184.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:16,353] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.13 | msg size: 80.0 KB | algbw (Gbps): 4.87 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:16,353] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.68 | optimizer_gradients: 5.91 | optimizer_step: 11.99\n",
            "[2024-11-01 22:58:16,354] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 93.28 | bwd_microstep: 341.20 | bwd_inner_microstep: 336.13 | bwd_allreduce_microstep: 5.03 | step_microstep: 36.46\n",
            "[2024-11-01 22:58:16,354] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 93.26 | bwd: 341.19 | bwd_inner: 336.12 | bwd_allreduce: 5.03 | step: 36.46\n",
            "[2024-11-01 22:58:16,854] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.10 | msg size: 134.33 MB | algbw (Gbps): 22813.94 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:16,862] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:16,869] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:16,872] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:16,890] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 17092.20 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:16,891] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.23 | msg size: 80.0 KB | algbw (Gbps): 2.91 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:16,892] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.07 | optimizer_gradients: 5.92 | optimizer_step: 11.91\n",
            "[2024-11-01 22:58:16,893] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 94.01 | bwd_microstep: 339.89 | bwd_inner_microstep: 334.23 | bwd_allreduce_microstep: 5.62 | step_microstep: 36.92\n",
            "[2024-11-01 22:58:16,893] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 93.98 | bwd: 339.88 | bwd_inner: 334.22 | bwd_allreduce: 5.62 | step: 36.93\n",
            "[2024-11-01 22:58:17,416] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 134.33 MB | algbw (Gbps): 15171.61 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:17,424] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:17,432] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:17,435] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:17,453] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 15544.54 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:17,454] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.16 | msg size: 80.0 KB | algbw (Gbps): 4.20 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:17,455] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.77 | optimizer_gradients: 5.92 | optimizer_step: 11.96\n",
            "[2024-11-01 22:58:17,455] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 86.59 | bwd_microstep: 369.56 | bwd_inner_microstep: 364.25 | bwd_allreduce_microstep: 5.27 | step_microstep: 36.91\n",
            "[2024-11-01 22:58:17,455] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 86.57 | bwd: 369.55 | bwd_inner: 364.24 | bwd_allreduce: 5.27 | step: 36.91\n",
            "[2024-11-01 22:58:17,957] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.06 | msg size: 134.33 MB | algbw (Gbps): 37945.38 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:17,965] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:17,972] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:17,975] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:17,994] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 15182.41 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:17,994] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.17 | msg size: 80.0 KB | algbw (Gbps): 3.75 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:17,995] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 5.91 | optimizer_step: 11.99\n",
            "[2024-11-01 22:58:17,995] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 93.85 | bwd_microstep: 341.55 | bwd_inner_microstep: 336.28 | bwd_allreduce_microstep: 5.22 | step_microstep: 36.26\n",
            "[2024-11-01 22:58:17,996] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 93.82 | bwd: 341.54 | bwd_inner: 336.27 | bwd_allreduce: 5.22 | step: 36.27\n",
            "[2024-11-01 22:58:18,497] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.06 | msg size: 134.33 MB | algbw (Gbps): 39300.57 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:18,505] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:18,512] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:18,515] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:18,533] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 16173.18 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:18,534] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.16 | msg size: 80.0 KB | algbw (Gbps): 3.97 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:18,535] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.74 | optimizer_gradients: 5.90 | optimizer_step: 11.90\n",
            "[2024-11-01 22:58:18,535] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 93.98 | bwd_microstep: 341.20 | bwd_inner_microstep: 335.95 | bwd_allreduce_microstep: 5.20 | step_microstep: 36.39\n",
            "[2024-11-01 22:58:18,535] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 93.95 | bwd: 341.18 | bwd_inner: 335.94 | bwd_allreduce: 5.20 | step: 36.39\n",
            "[2024-11-01 22:58:19,033] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.05 | msg size: 134.33 MB | algbw (Gbps): 44772.17 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:19,041] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:19,048] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:19,051] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:19,069] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 15704.07 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:19,070] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.18 | msg size: 80.0 KB | algbw (Gbps): 3.68 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:19,071] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.75 | optimizer_gradients: 5.93 | optimizer_step: 11.94\n",
            "[2024-11-01 22:58:19,071] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 94.34 | bwd_microstep: 337.06 | bwd_inner_microstep: 331.95 | bwd_allreduce_microstep: 5.04 | step_microstep: 36.23\n",
            "[2024-11-01 22:58:19,071] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 94.30 | bwd: 337.03 | bwd_inner: 331.93 | bwd_allreduce: 5.04 | step: 36.20\n",
            "[2024-11-01 22:58:19,572] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.04 | msg size: 134.33 MB | algbw (Gbps): 53760.78 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:19,580] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:19,588] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:19,591] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:19,609] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 14880.69 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:19,609] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.16 | msg size: 80.0 KB | algbw (Gbps): 4.10 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:19,610] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.80 | optimizer_gradients: 5.94 | optimizer_step: 11.94\n",
            "[2024-11-01 22:58:19,610] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=0, lr=[0.000981771838126524, 0.000981771838126524], mom=[[0.9, 0.95], [0.9, 0.95]]\n",
            "[2024-11-01 22:58:19,611] [INFO] [timer.py:260:stop] epoch=0/micro_step=10/global_step=10, RunningAvgSamplesPerSec=7.422313271494422, CurrSamplesPerSec=7.4645457550697705, MemAllocated=0.93GB, MaxMemAllocated=3.31GB\n",
            "[2024-11-01 22:58:19,611] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 95.11 | bwd_microstep: 339.72 | bwd_inner_microstep: 334.61 | bwd_allreduce_microstep: 5.07 | step_microstep: 36.95\n",
            "[2024-11-01 22:58:19,611] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 95.08 | bwd: 339.71 | bwd_inner: 334.60 | bwd_allreduce: 5.07 | step: 36.95\n",
            " samples/sec: 5.952 | iteration       10/     100 | elapsed time per iteration (ms): 672.0 | learning rate: 9.818E-04 | approx flops per GPU: 5.0TFLOPS | lm_loss: 8.465297E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
            "after 10 iterations memory (MB) | allocated: 956.5537109375 | max allocated: 3387.07763671875 | reserved: 4092.0 | max reserved: 4092.0\n",
            "time (ms) | forward: 265.69 | backward: 365.04 | backward-backward: 365.00 | backward-allreduce: 0.00 | optimizer: 39.65 | batch generator: 5.30\n",
            "[2024-11-01 22:58:20,114] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 34270.86 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:20,122] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:20,130] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:20,133] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:20,151] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 15711.09 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:20,151] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.15 | msg size: 80.0 KB | algbw (Gbps): 4.27 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:20,152] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.75 | optimizer_gradients: 5.90 | optimizer_step: 11.91\n",
            "[2024-11-01 22:58:20,153] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 94.99 | bwd_microstep: 340.99 | bwd_inner_microstep: 335.73 | bwd_allreduce_microstep: 5.21 | step_microstep: 36.34\n",
            "[2024-11-01 22:58:20,153] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 94.97 | bwd: 340.97 | bwd_inner: 335.72 | bwd_allreduce: 5.21 | step: 36.35\n",
            "[2024-11-01 22:58:20,653] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.04 | msg size: 134.33 MB | algbw (Gbps): 55150.06 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:20,661] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:20,668] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:20,671] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:20,690] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 14476.69 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:20,690] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.15 | msg size: 80.0 KB | algbw (Gbps): 4.39 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:20,691] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.76 | optimizer_gradients: 5.93 | optimizer_step: 11.94\n",
            "[2024-11-01 22:58:20,691] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 94.90 | bwd_microstep: 338.64 | bwd_inner_microstep: 333.64 | bwd_allreduce_microstep: 4.96 | step_microstep: 36.18\n",
            "[2024-11-01 22:58:20,692] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 94.87 | bwd: 338.63 | bwd_inner: 333.63 | bwd_allreduce: 4.96 | step: 36.18\n",
            "[2024-11-01 22:58:21,194] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.05 | msg size: 134.33 MB | algbw (Gbps): 41354.45 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:21,202] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:21,210] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:21,213] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:21,231] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 17158.86 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:21,231] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.14 | msg size: 80.0 KB | algbw (Gbps): 4.79 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:21,232] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.71 | optimizer_gradients: 5.89 | optimizer_step: 11.96\n",
            "[2024-11-01 22:58:21,233] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 94.07 | bwd_microstep: 342.27 | bwd_inner_microstep: 337.22 | bwd_allreduce_microstep: 5.01 | step_microstep: 36.52\n",
            "[2024-11-01 22:58:21,233] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 94.05 | bwd: 342.25 | bwd_inner: 337.21 | bwd_allreduce: 5.01 | step: 36.52\n",
            "[2024-11-01 22:58:21,736] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.06 | msg size: 134.33 MB | algbw (Gbps): 37945.38 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:21,747] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.25 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:21,755] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:21,760] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:21,778] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 12228.23 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:21,779] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.19 | msg size: 80.0 KB | algbw (Gbps): 3.36 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:21,780] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.01 | optimizer_gradients: 5.94 | optimizer_step: 11.96\n",
            "[2024-11-01 22:58:21,781] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 94.59 | bwd_microstep: 343.18 | bwd_inner_microstep: 337.33 | bwd_allreduce_microstep: 5.80 | step_microstep: 42.46\n",
            "[2024-11-01 22:58:21,781] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 94.57 | bwd: 343.17 | bwd_inner: 337.32 | bwd_allreduce: 5.80 | step: 42.47\n",
            "[2024-11-01 22:58:22,296] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.09 | msg size: 134.33 MB | algbw (Gbps): 25731.32 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:22,305] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.24 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:22,314] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:22,318] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:22,336] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 13683.06 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:22,337] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.16 | msg size: 80.0 KB | algbw (Gbps): 4.05 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:22,338] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.85 | optimizer_gradients: 5.95 | optimizer_step: 11.95\n",
            "[2024-11-01 22:58:22,338] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 104.12 | bwd_microstep: 344.12 | bwd_inner_microstep: 338.28 | bwd_allreduce_microstep: 5.78 | step_microstep: 40.31\n",
            "[2024-11-01 22:58:22,339] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 104.09 | bwd: 344.10 | bwd_inner: 338.26 | bwd_allreduce: 5.78 | step: 40.29\n",
            "[2024-11-01 22:58:22,844] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 28675.33 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:22,853] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:22,865] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:22,869] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:22,887] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.10 | msg size: 134.25 MB | algbw (Gbps): 11222.20 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:22,888] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.23 | msg size: 80.0 KB | algbw (Gbps): 2.85 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:22,889] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.19 | optimizer_gradients: 5.94 | optimizer_step: 11.94\n",
            "[2024-11-01 22:58:22,890] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 95.16 | bwd_microstep: 341.82 | bwd_inner_microstep: 336.12 | bwd_allreduce_microstep: 5.64 | step_microstep: 43.60\n",
            "[2024-11-01 22:58:22,890] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 95.14 | bwd: 341.80 | bwd_inner: 336.10 | bwd_allreduce: 5.64 | step: 43.60\n",
            "[2024-11-01 22:58:23,400] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.10 | msg size: 134.33 MB | algbw (Gbps): 22821.33 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:23,410] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.26 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:23,418] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:23,423] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.24 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:23,442] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.10 | msg size: 134.25 MB | algbw (Gbps): 11222.20 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:23,442] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.22 | msg size: 80.0 KB | algbw (Gbps): 3.02 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:23,444] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.20 | optimizer_gradients: 5.97 | optimizer_step: 12.00\n",
            "[2024-11-01 22:58:23,444] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 98.58 | bwd_microstep: 341.94 | bwd_inner_microstep: 335.97 | bwd_allreduce_microstep: 5.91 | step_microstep: 42.39\n",
            "[2024-11-01 22:58:23,445] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 98.56 | bwd: 341.92 | bwd_inner: 335.93 | bwd_allreduce: 5.91 | step: 42.38\n",
            "[2024-11-01 22:58:23,957] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.09 | msg size: 134.33 MB | algbw (Gbps): 26466.22 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:23,967] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:23,981] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:23,987] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:24,006] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.10 | msg size: 134.25 MB | algbw (Gbps): 11258.10 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:24,007] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.19 | msg size: 80.0 KB | algbw (Gbps): 3.44 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:24,008] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.93 | optimizer_gradients: 6.02 | optimizer_step: 12.04\n",
            "[2024-11-01 22:58:24,008] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 96.18 | bwd_microstep: 346.10 | bwd_inner_microstep: 340.04 | bwd_allreduce_microstep: 5.92 | step_microstep: 48.77\n",
            "[2024-11-01 22:58:24,009] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 96.15 | bwd: 346.07 | bwd_inner: 340.06 | bwd_allreduce: 5.90 | step: 48.77\n",
            "[2024-11-01 22:58:24,516] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.09 | msg size: 134.33 MB | algbw (Gbps): 24938.61 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:24,526] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:24,534] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:24,539] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.24 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:24,557] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 12962.37 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:24,558] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.22 | msg size: 80.0 KB | algbw (Gbps): 3.02 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:24,559] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.01 | optimizer_gradients: 5.97 | optimizer_step: 11.97\n",
            "[2024-11-01 22:58:24,560] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 94.59 | bwd_microstep: 343.38 | bwd_inner_microstep: 337.41 | bwd_allreduce_microstep: 5.90 | step_microstep: 41.30\n",
            "[2024-11-01 22:58:24,560] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 94.56 | bwd: 343.35 | bwd_inner: 337.39 | bwd_allreduce: 5.90 | step: 41.31\n",
            "[2024-11-01 22:58:25,069] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.10 | msg size: 134.33 MB | algbw (Gbps): 23696.71 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:25,079] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:25,087] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:25,091] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:25,110] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 13260.30 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:25,110] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.18 | msg size: 80.0 KB | algbw (Gbps): 3.56 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:25,111] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.93 | optimizer_gradients: 5.95 | optimizer_step: 11.95\n",
            "[2024-11-01 22:58:25,112] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=0, lr=[0.0009206544616434248, 0.0009206544616434248], mom=[[0.9, 0.95], [0.9, 0.95]]\n",
            "[2024-11-01 22:58:25,112] [INFO] [timer.py:260:stop] epoch=0/micro_step=20/global_step=20, RunningAvgSamplesPerSec=7.379868710672016, CurrSamplesPerSec=7.332244240086498, MemAllocated=0.93GB, MaxMemAllocated=3.31GB\n",
            "[2024-11-01 22:58:25,113] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 95.24 | bwd_microstep: 344.41 | bwd_inner_microstep: 338.48 | bwd_allreduce_microstep: 5.79 | step_microstep: 41.19\n",
            "[2024-11-01 22:58:25,113] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 95.22 | bwd: 344.40 | bwd_inner: 338.46 | bwd_allreduce: 5.81 | step: 41.20\n",
            " samples/sec: 7.270 | iteration       20/     100 | elapsed time per iteration (ms): 550.2 | learning rate: 9.207E-04 | approx flops per GPU: 6.0TFLOPS | lm_loss: 4.689962E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
            "time (ms) | forward: 163.76 | backward: 342.95 | backward-backward: 342.91 | backward-allreduce: 0.00 | optimizer: 41.54 | batch generator: 2.92\n",
            "[2024-11-01 22:58:25,620] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 30567.11 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:25,631] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.25 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:25,639] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:25,643] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:25,661] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 13161.12 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:25,662] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.19 | msg size: 80.0 KB | algbw (Gbps): 3.45 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:25,663] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.93 | optimizer_gradients: 5.94 | optimizer_step: 11.94\n",
            "[2024-11-01 22:58:25,664] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 95.08 | bwd_microstep: 343.03 | bwd_inner_microstep: 336.39 | bwd_allreduce_microstep: 6.55 | step_microstep: 40.09\n",
            "[2024-11-01 22:58:25,664] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 95.06 | bwd: 343.00 | bwd_inner: 336.37 | bwd_allreduce: 6.55 | step: 40.09\n",
            "[2024-11-01 22:58:26,172] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 29653.32 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:26,181] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:26,189] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:26,193] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:26,211] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 13747.20 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:26,212] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.19 | msg size: 80.0 KB | algbw (Gbps): 3.48 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:26,213] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.92 | optimizer_gradients: 5.94 | optimizer_step: 11.96\n",
            "[2024-11-01 22:58:26,214] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 95.44 | bwd_microstep: 342.54 | bwd_inner_microstep: 336.75 | bwd_allreduce_microstep: 5.72 | step_microstep: 39.81\n",
            "[2024-11-01 22:58:26,214] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 95.41 | bwd: 342.51 | bwd_inner: 336.73 | bwd_allreduce: 5.72 | step: 39.81\n",
            "[2024-11-01 22:58:26,725] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.06 | msg size: 134.33 MB | algbw (Gbps): 35497.29 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:26,735] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:26,743] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:26,747] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:26,765] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 13926.72 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:26,766] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.17 | msg size: 80.0 KB | algbw (Gbps): 3.81 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:26,767] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.89 | optimizer_gradients: 5.94 | optimizer_step: 12.00\n",
            "[2024-11-01 22:58:26,768] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 87.39 | bwd_microstep: 354.38 | bwd_inner_microstep: 348.59 | bwd_allreduce_microstep: 5.72 | step_microstep: 40.77\n",
            "[2024-11-01 22:58:26,768] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 87.37 | bwd: 354.35 | bwd_inner: 348.57 | bwd_allreduce: 5.72 | step: 40.78\n",
            "[2024-11-01 22:58:27,277] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 33345.94 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:27,287] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.24 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:27,295] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:27,299] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:27,317] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 14009.89 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:27,318] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.17 | msg size: 80.0 KB | algbw (Gbps): 3.94 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:27,319] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.87 | optimizer_gradients: 5.94 | optimizer_step: 11.95\n",
            "[2024-11-01 22:58:27,320] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 94.75 | bwd_microstep: 345.80 | bwd_inner_microstep: 339.87 | bwd_allreduce_microstep: 5.82 | step_microstep: 39.98\n",
            "[2024-11-01 22:58:27,320] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 94.72 | bwd: 345.80 | bwd_inner: 339.85 | bwd_allreduce: 5.84 | step: 39.99\n",
            "[2024-11-01 22:58:27,833] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.11 | msg size: 134.33 MB | algbw (Gbps): 20104.66 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:27,843] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:27,851] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:27,855] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:27,873] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 13300.39 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:27,874] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.18 | msg size: 80.0 KB | algbw (Gbps): 3.64 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:27,875] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.92 | optimizer_gradients: 5.93 | optimizer_step: 11.93\n",
            "[2024-11-01 22:58:27,876] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 95.35 | bwd_microstep: 349.44 | bwd_inner_microstep: 342.66 | bwd_allreduce_microstep: 6.71 | step_microstep: 40.27\n",
            "[2024-11-01 22:58:27,876] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 95.33 | bwd: 349.41 | bwd_inner: 342.65 | bwd_allreduce: 6.71 | step: 40.28\n",
            "[2024-11-01 22:58:28,390] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 31426.43 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:28,402] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:28,412] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:28,418] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:28,438] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 12435.63 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:28,439] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.18 | msg size: 80.0 KB | algbw (Gbps): 3.61 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:28,440] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.39 | optimizer_gradients: 6.23 | optimizer_step: 11.99\n",
            "[2024-11-01 22:58:28,442] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 96.90 | bwd_microstep: 346.30 | bwd_inner_microstep: 340.13 | bwd_allreduce_microstep: 6.11 | step_microstep: 49.30\n",
            "[2024-11-01 22:58:28,443] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 96.88 | bwd: 346.27 | bwd_inner: 340.11 | bwd_allreduce: 6.11 | step: 49.60\n",
            "[2024-11-01 22:58:28,954] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 31666.65 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:28,964] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.24 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:28,972] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.24 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:28,976] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:28,994] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.10 | msg size: 134.25 MB | algbw (Gbps): 11046.09 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:28,995] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.22 | msg size: 80.0 KB | algbw (Gbps): 3.01 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:28,996] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.98 | optimizer_gradients: 5.97 | optimizer_step: 11.97\n",
            "[2024-11-01 22:58:28,997] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 96.85 | bwd_microstep: 345.22 | bwd_inner_microstep: 339.21 | bwd_allreduce_microstep: 5.94 | step_microstep: 40.37\n",
            "[2024-11-01 22:58:28,997] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 96.83 | bwd: 345.19 | bwd_inner: 339.19 | bwd_allreduce: 5.94 | step: 40.38\n",
            "[2024-11-01 22:58:29,514] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 30943.16 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:29,523] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:29,532] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:29,536] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.33 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:29,554] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.10 | msg size: 134.25 MB | algbw (Gbps): 11222.20 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:29,555] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.20 | msg size: 80.0 KB | algbw (Gbps): 3.30 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:29,556] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.95 | optimizer_gradients: 6.00 | optimizer_step: 11.92\n",
            "[2024-11-01 22:58:29,557] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 95.23 | bwd_microstep: 352.96 | bwd_inner_microstep: 346.90 | bwd_allreduce_microstep: 5.92 | step_microstep: 40.53\n",
            "[2024-11-01 22:58:29,557] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 95.21 | bwd: 352.96 | bwd_inner: 346.88 | bwd_allreduce: 5.95 | step: 40.54\n",
            "[2024-11-01 22:58:30,065] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.04 | msg size: 134.33 MB | algbw (Gbps): 55106.91 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:30,073] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:30,081] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:30,084] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:30,102] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 15143.22 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:30,103] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.15 | msg size: 80.0 KB | algbw (Gbps): 4.26 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:30,103] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.74 | optimizer_gradients: 5.90 | optimizer_step: 11.92\n",
            "[2024-11-01 22:58:30,104] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 95.77 | bwd_microstep: 343.79 | bwd_inner_microstep: 338.68 | bwd_allreduce_microstep: 5.05 | step_microstep: 36.54\n",
            "[2024-11-01 22:58:30,104] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 95.75 | bwd: 343.76 | bwd_inner: 338.66 | bwd_allreduce: 5.05 | step: 36.55\n",
            "[2024-11-01 22:58:30,609] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 32365.18 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:30,617] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:30,624] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:30,627] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:30,645] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 15327.89 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:30,646] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.16 | msg size: 80.0 KB | algbw (Gbps): 4.07 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:30,647] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.80 | optimizer_gradients: 5.89 | optimizer_step: 11.90\n",
            "[2024-11-01 22:58:30,647] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=0, lr=[0.00082252435921195, 0.00082252435921195], mom=[[0.9, 0.95], [0.9, 0.95]]\n",
            "[2024-11-01 22:58:30,648] [INFO] [timer.py:260:stop] epoch=0/micro_step=30/global_step=30, RunningAvgSamplesPerSec=7.3568051709395, CurrSamplesPerSec=7.405871119990606, MemAllocated=0.93GB, MaxMemAllocated=3.31GB\n",
            "[2024-11-01 22:58:30,648] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 95.00 | bwd_microstep: 343.96 | bwd_inner_microstep: 338.86 | bwd_allreduce_microstep: 5.06 | step_microstep: 37.43\n",
            "[2024-11-01 22:58:30,648] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 94.98 | bwd: 343.94 | bwd_inner: 338.84 | bwd_allreduce: 5.06 | step: 37.43\n",
            " samples/sec: 7.227 | iteration       30/     100 | elapsed time per iteration (ms): 553.5 | learning rate: 8.225E-04 | approx flops per GPU: 6.0TFLOPS | lm_loss: 3.738137E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
            "time (ms) | forward: 163.33 | backward: 347.05 | backward-backward: 347.00 | backward-allreduce: 0.00 | optimizer: 41.25 | batch generator: 3.95\n",
            "[2024-11-01 22:58:31,153] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.06 | msg size: 134.33 MB | algbw (Gbps): 38802.55 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:31,161] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:31,168] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.27 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:31,171] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:31,189] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.05 | msg size: 134.25 MB | algbw (Gbps): 23508.91 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:31,190] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.13 | msg size: 80.0 KB | algbw (Gbps): 5.04 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:31,190] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.71 | optimizer_gradients: 5.90 | optimizer_step: 11.86\n",
            "[2024-11-01 22:58:31,191] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 95.53 | bwd_microstep: 342.18 | bwd_inner_microstep: 336.85 | bwd_allreduce_microstep: 5.29 | step_microstep: 36.06\n",
            "[2024-11-01 22:58:31,191] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 95.51 | bwd: 342.17 | bwd_inner: 336.84 | bwd_allreduce: 5.29 | step: 36.06\n",
            "[2024-11-01 22:58:31,698] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 30567.11 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:31,706] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:31,714] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:31,717] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:31,735] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.05 | msg size: 134.25 MB | algbw (Gbps): 20985.59 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:31,736] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.15 | msg size: 80.0 KB | algbw (Gbps): 4.37 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:31,736] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 5.90 | optimizer_step: 11.86\n",
            "[2024-11-01 22:58:31,737] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 96.85 | bwd_microstep: 342.80 | bwd_inner_microstep: 337.73 | bwd_allreduce_microstep: 5.03 | step_microstep: 37.18\n",
            "[2024-11-01 22:58:31,737] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 96.83 | bwd: 342.78 | bwd_inner: 337.72 | bwd_allreduce: 5.03 | step: 37.18\n",
            "[2024-11-01 22:58:32,242] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.05 | msg size: 134.33 MB | algbw (Gbps): 48805.70 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:32,250] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:32,258] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:32,261] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:32,279] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 16944.07 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:32,279] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.14 | msg size: 80.0 KB | algbw (Gbps): 4.85 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:32,280] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.73 | optimizer_gradients: 5.92 | optimizer_step: 11.93\n",
            "[2024-11-01 22:58:32,281] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 95.34 | bwd_microstep: 342.87 | bwd_inner_microstep: 337.60 | bwd_allreduce_microstep: 5.23 | step_microstep: 36.59\n",
            "[2024-11-01 22:58:32,281] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 95.31 | bwd: 342.86 | bwd_inner: 337.59 | bwd_allreduce: 5.23 | step: 36.60\n",
            "[2024-11-01 22:58:32,788] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.06 | msg size: 134.33 MB | algbw (Gbps): 38505.54 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:32,796] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:32,803] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:32,806] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:32,824] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 15071.88 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:32,825] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.14 | msg size: 80.0 KB | algbw (Gbps): 4.85 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:32,826] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.77 | optimizer_gradients: 5.92 | optimizer_step: 11.91\n",
            "[2024-11-01 22:58:32,826] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 94.46 | bwd_microstep: 345.66 | bwd_inner_microstep: 340.55 | bwd_allreduce_microstep: 4.97 | step_microstep: 36.17\n",
            "[2024-11-01 22:58:32,826] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 94.43 | bwd: 345.63 | bwd_inner: 340.53 | bwd_allreduce: 4.98 | step: 36.18\n",
            "[2024-11-01 22:58:33,331] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.05 | msg size: 134.33 MB | algbw (Gbps): 44405.19 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:33,340] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.24 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:33,347] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:33,350] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:33,368] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 15817.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:33,369] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.18 | msg size: 80.0 KB | algbw (Gbps): 3.56 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:33,370] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.76 | optimizer_gradients: 5.94 | optimizer_step: 11.92\n",
            "[2024-11-01 22:58:33,370] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 94.62 | bwd_microstep: 343.70 | bwd_inner_microstep: 338.50 | bwd_allreduce_microstep: 5.15 | step_microstep: 36.66\n",
            "[2024-11-01 22:58:33,370] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 94.59 | bwd: 343.68 | bwd_inner: 338.49 | bwd_allreduce: 5.15 | step: 36.66\n",
            "[2024-11-01 22:58:33,880] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.06 | msg size: 134.33 MB | algbw (Gbps): 40568.33 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:33,888] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:33,896] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:33,899] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:33,917] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 12910.06 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:33,917] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.14 | msg size: 80.0 KB | algbw (Gbps): 4.81 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:33,918] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 5.93 | optimizer_step: 11.89\n",
            "[2024-11-01 22:58:33,918] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 97.54 | bwd_microstep: 345.71 | bwd_inner_microstep: 340.63 | bwd_allreduce_microstep: 5.04 | step_microstep: 36.07\n",
            "[2024-11-01 22:58:33,919] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 97.52 | bwd: 345.70 | bwd_inner: 340.62 | bwd_allreduce: 5.04 | step: 36.08\n",
            "[2024-11-01 22:58:34,423] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.05 | msg size: 134.33 MB | algbw (Gbps): 49249.39 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:34,431] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:34,439] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:34,444] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:34,462] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 14099.69 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:34,462] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.14 | msg size: 80.0 KB | algbw (Gbps): 4.64 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:34,463] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.75 | optimizer_gradients: 5.96 | optimizer_step: 11.94\n",
            "[2024-11-01 22:58:34,464] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 94.66 | bwd_microstep: 343.20 | bwd_inner_microstep: 338.13 | bwd_allreduce_microstep: 5.02 | step_microstep: 38.78\n",
            "[2024-11-01 22:58:34,464] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 94.64 | bwd: 343.18 | bwd_inner: 338.12 | bwd_allreduce: 5.02 | step: 38.79\n",
            "[2024-11-01 22:58:34,972] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.06 | msg size: 134.33 MB | algbw (Gbps): 36339.85 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:34,980] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:34,988] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.36 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:34,992] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:35,011] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 16491.49 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:35,011] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.14 | msg size: 80.0 KB | algbw (Gbps): 4.69 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:35,012] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.75 | optimizer_gradients: 5.92 | optimizer_step: 11.89\n",
            "[2024-11-01 22:58:35,012] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 96.67 | bwd_microstep: 344.84 | bwd_inner_microstep: 339.70 | bwd_allreduce_microstep: 5.09 | step_microstep: 38.20\n",
            "[2024-11-01 22:58:35,012] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 96.64 | bwd: 344.82 | bwd_inner: 339.69 | bwd_allreduce: 5.09 | step: 38.20\n",
            "[2024-11-01 22:58:35,517] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 33377.55 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:35,525] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:35,533] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:35,535] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:35,554] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 16099.19 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:35,554] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.13 | msg size: 80.0 KB | algbw (Gbps): 4.91 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:35,555] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.74 | optimizer_gradients: 5.93 | optimizer_step: 11.95\n",
            "[2024-11-01 22:58:35,555] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 95.12 | bwd_microstep: 342.79 | bwd_inner_microstep: 337.74 | bwd_allreduce_microstep: 5.00 | step_microstep: 36.35\n",
            "[2024-11-01 22:58:35,556] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 95.08 | bwd: 342.77 | bwd_inner: 337.73 | bwd_allreduce: 5.00 | step: 36.35\n",
            "[2024-11-01 22:58:36,064] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.06 | msg size: 134.33 MB | algbw (Gbps): 35160.57 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:36,072] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:36,079] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:36,082] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:36,100] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 15368.05 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:36,101] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.16 | msg size: 80.0 KB | algbw (Gbps): 4.21 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:36,102] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.76 | optimizer_gradients: 5.89 | optimizer_step: 11.95\n",
            "[2024-11-01 22:58:36,102] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=0, lr=[0.0006971805834928398, 0.0006971805834928398], mom=[[0.9, 0.95], [0.9, 0.95]]\n",
            "[2024-11-01 22:58:36,102] [INFO] [timer.py:260:stop] epoch=0/micro_step=40/global_step=40, RunningAvgSamplesPerSec=7.364771770402604, CurrSamplesPerSec=7.363378973669577, MemAllocated=0.93GB, MaxMemAllocated=3.31GB\n",
            "[2024-11-01 22:58:36,103] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 96.51 | bwd_microstep: 345.67 | bwd_inner_microstep: 340.58 | bwd_allreduce_microstep: 5.05 | step_microstep: 36.64\n",
            "[2024-11-01 22:58:36,103] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 96.48 | bwd: 345.66 | bwd_inner: 340.57 | bwd_allreduce: 5.05 | step: 36.64\n",
            " samples/sec: 7.334 | iteration       40/     100 | elapsed time per iteration (ms): 545.4 | learning rate: 6.972E-04 | approx flops per GPU: 6.1TFLOPS | lm_loss: 3.487418E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
            "time (ms) | forward: 162.37 | backward: 344.15 | backward-backward: 344.11 | backward-allreduce: 0.00 | optimizer: 37.41 | batch generator: 1.66\n",
            "[2024-11-01 22:58:36,612] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.05 | msg size: 134.33 MB | algbw (Gbps): 45820.84 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:36,620] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:36,628] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:36,631] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:36,649] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 16663.27 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:36,649] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.16 | msg size: 80.0 KB | algbw (Gbps): 4.06 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:36,650] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.73 | optimizer_gradients: 5.91 | optimizer_step: 11.94\n",
            "[2024-11-01 22:58:36,651] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 95.95 | bwd_microstep: 346.25 | bwd_inner_microstep: 341.21 | bwd_allreduce_microstep: 4.99 | step_microstep: 36.69\n",
            "[2024-11-01 22:58:36,651] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 95.92 | bwd: 346.24 | bwd_inner: 341.20 | bwd_allreduce: 4.99 | step: 36.68\n",
            "[2024-11-01 22:58:37,160] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.05 | msg size: 134.33 MB | algbw (Gbps): 50018.91 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:37,168] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:37,176] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:37,178] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:37,197] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.06 | msg size: 134.25 MB | algbw (Gbps): 19627.90 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:37,197] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.14 | msg size: 80.0 KB | algbw (Gbps): 4.85 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:37,198] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.73 | optimizer_gradients: 5.94 | optimizer_step: 11.89\n",
            "[2024-11-01 22:58:37,198] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 96.96 | bwd_microstep: 346.19 | bwd_inner_microstep: 341.11 | bwd_allreduce_microstep: 5.04 | step_microstep: 36.70\n",
            "[2024-11-01 22:58:37,199] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 96.93 | bwd: 346.18 | bwd_inner: 341.10 | bwd_allreduce: 5.04 | step: 36.71\n",
            "[2024-11-01 22:58:37,707] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.04 | msg size: 134.33 MB | algbw (Gbps): 51937.04 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:37,715] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:37,723] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:37,726] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:37,744] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 17184.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:37,744] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.14 | msg size: 80.0 KB | algbw (Gbps): 4.85 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:37,745] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.70 | optimizer_gradients: 5.91 | optimizer_step: 11.94\n",
            "[2024-11-01 22:58:37,746] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 95.70 | bwd_microstep: 346.13 | bwd_inner_microstep: 341.13 | bwd_allreduce_microstep: 4.95 | step_microstep: 37.06\n",
            "[2024-11-01 22:58:37,746] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 95.66 | bwd: 346.11 | bwd_inner: 341.12 | bwd_allreduce: 4.95 | step: 37.06\n",
            "[2024-11-01 22:58:38,256] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.09 | msg size: 134.33 MB | algbw (Gbps): 24218.23 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:38,266] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.25 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:38,275] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:38,278] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:38,297] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 13720.40 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:38,297] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.17 | msg size: 80.0 KB | algbw (Gbps): 3.80 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:38,299] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.88 | optimizer_gradients: 5.95 | optimizer_step: 11.93\n",
            "[2024-11-01 22:58:38,299] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 96.31 | bwd_microstep: 347.94 | bwd_inner_microstep: 341.83 | bwd_allreduce_microstep: 6.00 | step_microstep: 40.19\n",
            "[2024-11-01 22:58:38,299] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 96.29 | bwd: 347.94 | bwd_inner: 341.82 | bwd_allreduce: 6.03 | step: 40.19\n",
            "[2024-11-01 22:58:38,814] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.05 | msg size: 134.33 MB | algbw (Gbps): 50018.91 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:38,822] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:38,830] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:38,835] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.24 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:38,853] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 15537.67 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:38,853] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.16 | msg size: 80.0 KB | algbw (Gbps): 4.05 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:38,855] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.86 | optimizer_gradients: 5.93 | optimizer_step: 11.92\n",
            "[2024-11-01 22:58:38,855] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 96.91 | bwd_microstep: 348.23 | bwd_inner_microstep: 343.18 | bwd_allreduce_microstep: 5.01 | step_microstep: 39.21\n",
            "[2024-11-01 22:58:38,856] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 96.89 | bwd: 348.22 | bwd_inner: 343.17 | bwd_allreduce: 5.01 | step: 39.22\n",
            "[2024-11-01 22:58:39,364] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.04 | msg size: 134.33 MB | algbw (Gbps): 52439.78 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:39,373] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:39,380] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:39,383] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:39,401] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.06 | msg size: 134.25 MB | algbw (Gbps): 17738.32 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:39,401] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.14 | msg size: 80.0 KB | algbw (Gbps): 4.84 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:39,402] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.71 | optimizer_gradients: 5.90 | optimizer_step: 11.88\n",
            "[2024-11-01 22:58:39,403] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 97.32 | bwd_microstep: 344.95 | bwd_inner_microstep: 339.99 | bwd_allreduce_microstep: 4.92 | step_microstep: 36.12\n",
            "[2024-11-01 22:58:39,403] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 97.29 | bwd: 344.94 | bwd_inner: 339.98 | bwd_allreduce: 4.92 | step: 36.12\n",
            "[2024-11-01 22:58:39,913] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.10 | msg size: 134.33 MB | algbw (Gbps): 23585.61 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:39,924] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.24 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:39,933] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:39,937] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:39,955] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.10 | msg size: 134.25 MB | algbw (Gbps): 11758.38 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:39,956] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.20 | msg size: 80.0 KB | algbw (Gbps): 3.28 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:39,957] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.06 | optimizer_gradients: 5.97 | optimizer_step: 11.94\n",
            "[2024-11-01 22:58:39,958] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 96.26 | bwd_microstep: 347.96 | bwd_inner_microstep: 342.03 | bwd_allreduce_microstep: 5.86 | step_microstep: 42.83\n",
            "[2024-11-01 22:58:39,958] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 96.24 | bwd: 347.94 | bwd_inner: 342.02 | bwd_allreduce: 5.86 | step: 42.82\n",
            "[2024-11-01 22:58:40,475] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 31107.17 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:40,486] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:40,493] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:40,497] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:40,515] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 13747.20 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:40,516] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.19 | msg size: 80.0 KB | algbw (Gbps): 3.50 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:40,517] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.88 | optimizer_gradients: 5.92 | optimizer_step: 11.89\n",
            "[2024-11-01 22:58:40,518] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 98.76 | bwd_microstep: 349.00 | bwd_inner_microstep: 343.14 | bwd_allreduce_microstep: 5.80 | step_microstep: 40.18\n",
            "[2024-11-01 22:58:40,518] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 98.74 | bwd: 348.97 | bwd_inner: 343.12 | bwd_allreduce: 5.80 | step: 40.19\n",
            "[2024-11-01 22:58:41,032] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 30984.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:41,041] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:41,049] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:41,052] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:41,071] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 13386.39 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:41,071] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.17 | msg size: 80.0 KB | algbw (Gbps): 3.95 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:41,073] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.90 | optimizer_gradients: 5.95 | optimizer_step: 11.90\n",
            "[2024-11-01 22:58:41,073] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 96.93 | bwd_microstep: 347.86 | bwd_inner_microstep: 341.92 | bwd_allreduce_microstep: 5.88 | step_microstep: 39.11\n",
            "[2024-11-01 22:58:41,073] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 96.91 | bwd: 347.83 | bwd_inner: 341.90 | bwd_allreduce: 5.88 | step: 39.10\n",
            "[2024-11-01 22:58:41,592] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.10 | msg size: 134.33 MB | algbw (Gbps): 23343.26 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:41,602] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.24 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:41,610] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:41,615] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:41,633] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.10 | msg size: 134.25 MB | algbw (Gbps): 11035.69 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:41,634] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.25 | msg size: 80.0 KB | algbw (Gbps): 2.64 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:41,635] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.06 | optimizer_gradients: 5.93 | optimizer_step: 11.96\n",
            "[2024-11-01 22:58:41,636] [INFO] [logging.py:96:log_dist] [Rank 0] step=50, skipped=0, lr=[0.0005571396837256637, 0.0005571396837256637], mom=[[0.9, 0.95], [0.9, 0.95]]\n",
            "[2024-11-01 22:58:41,636] [INFO] [timer.py:260:stop] epoch=0/micro_step=50/global_step=50, RunningAvgSamplesPerSec=7.3498843668711995, CurrSamplesPerSec=7.185900277589677, MemAllocated=0.93GB, MaxMemAllocated=3.31GB\n",
            "[2024-11-01 22:58:41,637] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 98.41 | bwd_microstep: 351.48 | bwd_inner_microstep: 345.42 | bwd_allreduce_microstep: 5.99 | step_microstep: 42.10\n",
            "[2024-11-01 22:58:41,637] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 98.38 | bwd: 351.45 | bwd_inner: 345.40 | bwd_allreduce: 5.99 | step: 42.11\n",
            " samples/sec: 7.228 | iteration       50/     100 | elapsed time per iteration (ms): 553.4 | learning rate: 5.571E-04 | approx flops per GPU: 6.0TFLOPS | lm_loss: 3.223305E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
            "time (ms) | forward: 164.25 | backward: 347.84 | backward-backward: 347.81 | backward-allreduce: 0.00 | optimizer: 39.64 | batch generator: 2.46\n",
            "-------------------------------------------------------------------------------------------------------\n",
            " validation results at iteration 50 | lm_loss value: 3.174141E+00 | lm_loss_ppl value: 2.390628E+01 | \n",
            "-------------------------------------------------------------------------------------------------------\n",
            "[2024-11-01 22:58:43,853] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.09 | msg size: 134.33 MB | algbw (Gbps): 25242.52 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:43,864] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:43,872] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:43,877] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:43,896] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.46 | msg size: 134.25 MB | algbw (Gbps): 2453.49 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:43,896] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.18 | msg size: 80.0 KB | algbw (Gbps): 3.73 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:43,898] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.43 | optimizer_gradients: 5.94 | optimizer_step: 11.91\n",
            "[2024-11-01 22:58:43,899] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1102.28 | bwd_microstep: 356.94 | bwd_inner_microstep: 350.61 | bwd_allreduce_microstep: 6.24 | step_microstep: 43.18\n",
            "[2024-11-01 22:58:43,900] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 1101.83 | bwd: 356.94 | bwd_inner: 350.59 | bwd_allreduce: 6.24 | step: 43.18\n",
            "[2024-11-01 22:58:44,415] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 29150.09 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:44,424] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:44,432] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:44,436] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:44,455] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.12 | msg size: 134.25 MB | algbw (Gbps): 9655.10 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:44,455] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.20 | msg size: 80.0 KB | algbw (Gbps): 3.30 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:44,456] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.97 | optimizer_gradients: 5.93 | optimizer_step: 11.97\n",
            "[2024-11-01 22:58:44,457] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 95.69 | bwd_microstep: 349.01 | bwd_inner_microstep: 343.16 | bwd_allreduce_microstep: 5.79 | step_microstep: 39.78\n",
            "[2024-11-01 22:58:44,457] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 95.66 | bwd: 348.99 | bwd_inner: 343.13 | bwd_allreduce: 5.79 | step: 39.79\n",
            "[2024-11-01 22:58:44,981] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 27564.24 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:44,990] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:44,998] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.24 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:45,003] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:45,022] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.62 | msg size: 134.25 MB | algbw (Gbps): 1808.84 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:45,023] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.21 | msg size: 80.0 KB | algbw (Gbps): 3.16 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:45,024] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.65 | optimizer_gradients: 5.96 | optimizer_step: 11.96\n",
            "[2024-11-01 22:58:45,025] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 96.58 | bwd_microstep: 357.42 | bwd_inner_microstep: 351.42 | bwd_allreduce_microstep: 5.93 | step_microstep: 41.55\n",
            "[2024-11-01 22:58:45,025] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 96.56 | bwd: 357.40 | bwd_inner: 351.40 | bwd_allreduce: 5.94 | step: 41.56\n",
            "[2024-11-01 22:58:45,542] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 27488.92 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:45,551] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:45,559] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:45,563] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:45,582] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 14452.91 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:45,582] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.17 | msg size: 80.0 KB | algbw (Gbps): 3.76 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:45,584] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.91 | optimizer_gradients: 5.95 | optimizer_step: 11.88\n",
            "[2024-11-01 22:58:45,584] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 97.10 | bwd_microstep: 348.45 | bwd_inner_microstep: 342.64 | bwd_allreduce_microstep: 5.75 | step_microstep: 39.85\n",
            "[2024-11-01 22:58:45,584] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 97.07 | bwd: 348.42 | bwd_inner: 342.62 | bwd_allreduce: 5.75 | step: 39.86\n",
            "[2024-11-01 22:58:46,105] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 32365.18 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:46,115] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:46,123] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:46,127] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:46,145] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 13205.57 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:46,146] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.17 | msg size: 80.0 KB | algbw (Gbps): 3.84 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:46,147] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.93 | optimizer_gradients: 5.95 | optimizer_step: 11.89\n",
            "[2024-11-01 22:58:46,148] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 97.88 | bwd_microstep: 353.64 | bwd_inner_microstep: 347.74 | bwd_allreduce_microstep: 5.82 | step_microstep: 39.92\n",
            "[2024-11-01 22:58:46,148] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 97.85 | bwd: 353.62 | bwd_inner: 347.73 | bwd_allreduce: 5.82 | step: 39.94\n",
            "[2024-11-01 22:58:46,668] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 32756.57 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:46,678] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:46,686] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:46,690] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:46,708] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 12811.37 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:46,709] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.17 | msg size: 80.0 KB | algbw (Gbps): 3.76 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:46,710] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.93 | optimizer_gradients: 5.91 | optimizer_step: 11.94\n",
            "[2024-11-01 22:58:46,710] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 101.29 | bwd_microstep: 350.90 | bwd_inner_microstep: 345.10 | bwd_allreduce_microstep: 5.74 | step_microstep: 39.94\n",
            "[2024-11-01 22:58:46,711] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 101.27 | bwd: 350.88 | bwd_inner: 345.09 | bwd_allreduce: 5.74 | step: 39.94\n",
            "[2024-11-01 22:58:47,233] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.09 | msg size: 134.33 MB | algbw (Gbps): 24360.65 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:47,243] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:47,252] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:47,256] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:47,275] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 11962.21 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:47,275] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.23 | msg size: 80.0 KB | algbw (Gbps): 2.90 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:47,277] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.06 | optimizer_gradients: 5.95 | optimizer_step: 11.95\n",
            "[2024-11-01 22:58:47,277] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 97.25 | bwd_microstep: 355.44 | bwd_inner_microstep: 349.48 | bwd_allreduce_microstep: 5.89 | step_microstep: 41.78\n",
            "[2024-11-01 22:58:47,278] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 97.23 | bwd: 355.41 | bwd_inner: 349.46 | bwd_allreduce: 5.89 | step: 41.79\n",
            "[2024-11-01 22:58:47,795] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.05 | msg size: 134.33 MB | algbw (Gbps): 43934.26 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:47,803] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:47,810] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:47,813] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:47,831] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 14294.41 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:47,832] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.18 | msg size: 80.0 KB | algbw (Gbps): 3.67 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:47,833] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.77 | optimizer_gradients: 5.90 | optimizer_step: 11.86\n",
            "[2024-11-01 22:58:47,833] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 99.93 | bwd_microstep: 348.79 | bwd_inner_microstep: 343.73 | bwd_allreduce_microstep: 4.99 | step_microstep: 36.33\n",
            "[2024-11-01 22:58:47,833] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 99.89 | bwd: 348.76 | bwd_inner: 343.71 | bwd_allreduce: 4.99 | step: 36.33\n",
            "[2024-11-01 22:58:48,349] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.05 | msg size: 134.33 MB | algbw (Gbps): 50018.91 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:48,357] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:48,365] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:48,368] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:48,386] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 16173.18 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:48,386] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.15 | msg size: 80.0 KB | algbw (Gbps): 4.38 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:48,387] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.85 | optimizer_gradients: 5.91 | optimizer_step: 11.90\n",
            "[2024-11-01 22:58:48,388] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 97.64 | bwd_microstep: 351.08 | bwd_inner_microstep: 345.87 | bwd_allreduce_microstep: 5.16 | step_microstep: 36.48\n",
            "[2024-11-01 22:58:48,388] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 97.61 | bwd: 351.06 | bwd_inner: 345.86 | bwd_allreduce: 5.16 | step: 36.48\n",
            "[2024-11-01 22:58:48,901] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.05 | msg size: 134.33 MB | algbw (Gbps): 41771.43 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:48,909] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:48,917] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:48,920] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:48,938] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 17108.81 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:48,938] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.13 | msg size: 80.0 KB | algbw (Gbps): 4.95 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:48,939] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.70 | optimizer_gradients: 5.87 | optimizer_step: 11.88\n",
            "[2024-11-01 22:58:48,939] [INFO] [logging.py:96:log_dist] [Rank 0] step=60, skipped=0, lr=[0.0004163858311022763, 0.0004163858311022763], mom=[[0.9, 0.95], [0.9, 0.95]]\n",
            "[2024-11-01 22:58:48,940] [INFO] [timer.py:260:stop] epoch=0/micro_step=60/global_step=60, RunningAvgSamplesPerSec=7.325831002908293, CurrSamplesPerSec=7.301355805628112, MemAllocated=0.93GB, MaxMemAllocated=3.31GB\n",
            "[2024-11-01 22:58:48,940] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 98.09 | bwd_microstep: 347.90 | bwd_inner_microstep: 342.90 | bwd_allreduce_microstep: 4.95 | step_microstep: 37.28\n",
            "[2024-11-01 22:58:48,940] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 98.06 | bwd: 347.89 | bwd_inner: 342.89 | bwd_allreduce: 4.95 | step: 37.28\n",
            " samples/sec: 5.477 | iteration       60/     100 | elapsed time per iteration (ms): 730.3 | learning rate: 4.164E-04 | approx flops per GPU: 4.6TFLOPS | lm_loss: 3.151922E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
            "time (ms) | forward: 166.54 | backward: 352.23 | backward-backward: 352.18 | backward-allreduce: 0.00 | optimizer: 40.35 | batch generator: 7.41\n",
            "[2024-11-01 22:58:49,456] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.09 | msg size: 134.33 MB | algbw (Gbps): 23962.78 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:49,464] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:49,472] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:49,475] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:49,493] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 15234.99 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:49,493] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.16 | msg size: 80.0 KB | algbw (Gbps): 4.11 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:49,494] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.76 | optimizer_gradients: 5.90 | optimizer_step: 11.87\n",
            "[2024-11-01 22:58:49,495] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 98.27 | bwd_microstep: 350.08 | bwd_inner_microstep: 344.81 | bwd_allreduce_microstep: 5.22 | step_microstep: 36.85\n",
            "[2024-11-01 22:58:49,495] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 98.24 | bwd: 350.07 | bwd_inner: 344.80 | bwd_allreduce: 5.22 | step: 36.85\n",
            "[2024-11-01 22:58:50,011] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.05 | msg size: 134.33 MB | algbw (Gbps): 50054.46 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:50,019] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:50,026] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:50,029] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:50,047] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 15739.19 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:50,048] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.16 | msg size: 80.0 KB | algbw (Gbps): 4.05 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:50,049] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.72 | optimizer_gradients: 5.89 | optimizer_step: 11.88\n",
            "[2024-11-01 22:58:50,049] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 97.07 | bwd_microstep: 351.67 | bwd_inner_microstep: 346.62 | bwd_allreduce_microstep: 5.01 | step_microstep: 36.34\n",
            "[2024-11-01 22:58:50,049] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 97.05 | bwd: 351.66 | bwd_inner: 346.61 | bwd_allreduce: 5.01 | step: 36.34\n",
            "[2024-11-01 22:58:50,562] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.05 | msg size: 134.33 MB | algbw (Gbps): 47876.70 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:50,570] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:50,577] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:50,580] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:50,599] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 14578.64 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:50,599] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.14 | msg size: 80.0 KB | algbw (Gbps): 4.66 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:50,600] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.74 | optimizer_gradients: 5.89 | optimizer_step: 11.94\n",
            "[2024-11-01 22:58:50,600] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 96.72 | bwd_microstep: 350.34 | bwd_inner_microstep: 345.30 | bwd_allreduce_microstep: 5.00 | step_microstep: 36.41\n",
            "[2024-11-01 22:58:50,600] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 96.71 | bwd: 350.32 | bwd_inner: 345.29 | bwd_allreduce: 5.00 | step: 36.42\n",
            "[2024-11-01 22:58:51,118] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.04 | msg size: 134.33 MB | algbw (Gbps): 53032.10 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:51,126] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:51,134] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.24 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:51,139] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:51,157] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 14843.03 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:51,158] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.14 | msg size: 80.0 KB | algbw (Gbps): 4.72 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:51,158] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.72 | optimizer_gradients: 5.93 | optimizer_step: 11.87\n",
            "[2024-11-01 22:58:51,159] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 99.40 | bwd_microstep: 351.14 | bwd_inner_microstep: 345.92 | bwd_allreduce_microstep: 5.18 | step_microstep: 39.03\n",
            "[2024-11-01 22:58:51,159] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 99.37 | bwd: 351.13 | bwd_inner: 345.91 | bwd_allreduce: 5.18 | step: 39.03\n",
            "[2024-11-01 22:58:51,676] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.05 | msg size: 134.33 MB | algbw (Gbps): 45850.67 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:51,684] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:51,692] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:51,695] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:51,713] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 15327.89 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:51,713] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.14 | msg size: 80.0 KB | algbw (Gbps): 4.77 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:51,714] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.73 | optimizer_gradients: 5.88 | optimizer_step: 11.93\n",
            "[2024-11-01 22:58:51,715] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 98.43 | bwd_microstep: 351.80 | bwd_inner_microstep: 346.78 | bwd_allreduce_microstep: 4.97 | step_microstep: 36.55\n",
            "[2024-11-01 22:58:51,715] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 98.40 | bwd: 351.78 | bwd_inner: 346.77 | bwd_allreduce: 4.98 | step: 36.56\n",
            "[2024-11-01 22:58:52,231] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 27510.40 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:52,240] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:52,247] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:52,250] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:52,268] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 16663.27 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:52,269] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.14 | msg size: 80.0 KB | algbw (Gbps): 4.58 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:52,270] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 5.91 | optimizer_step: 11.87\n",
            "[2024-11-01 22:58:52,270] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 97.10 | bwd_microstep: 352.42 | bwd_inner_microstep: 347.23 | bwd_allreduce_microstep: 5.15 | step_microstep: 37.12\n",
            "[2024-11-01 22:58:52,270] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 97.07 | bwd: 352.41 | bwd_inner: 347.22 | bwd_allreduce: 5.15 | step: 37.12\n",
            "[2024-11-01 22:58:52,790] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.06 | msg size: 134.33 MB | algbw (Gbps): 37401.29 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:52,798] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:52,806] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:52,809] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:52,827] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.10 | msg size: 134.25 MB | algbw (Gbps): 11415.13 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:52,828] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.22 | msg size: 80.0 KB | algbw (Gbps): 3.01 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:52,829] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.99 | optimizer_gradients: 5.90 | optimizer_step: 11.93\n",
            "[2024-11-01 22:58:52,830] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 98.41 | bwd_microstep: 353.70 | bwd_inner_microstep: 348.25 | bwd_allreduce_microstep: 5.37 | step_microstep: 38.13\n",
            "[2024-11-01 22:58:52,830] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 98.39 | bwd: 353.65 | bwd_inner: 348.23 | bwd_allreduce: 5.37 | step: 38.14\n",
            "[2024-11-01 22:58:53,349] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.05 | msg size: 134.33 MB | algbw (Gbps): 48403.18 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:53,357] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:53,364] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:53,368] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:53,386] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.05 | msg size: 134.25 MB | algbw (Gbps): 23524.62 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:53,386] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.17 | msg size: 80.0 KB | algbw (Gbps): 3.86 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:53,387] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.77 | optimizer_gradients: 5.92 | optimizer_step: 11.87\n",
            "[2024-11-01 22:58:53,387] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 99.56 | bwd_microstep: 351.79 | bwd_inner_microstep: 346.67 | bwd_allreduce_microstep: 5.05 | step_microstep: 36.31\n",
            "[2024-11-01 22:58:53,388] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 99.54 | bwd: 351.76 | bwd_inner: 346.66 | bwd_allreduce: 5.05 | step: 36.31\n",
            "[2024-11-01 22:58:53,906] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.04 | msg size: 134.33 MB | algbw (Gbps): 55020.80 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:53,916] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:53,923] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:53,926] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:53,944] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 13092.57 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:53,945] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.14 | msg size: 80.0 KB | algbw (Gbps): 4.72 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:53,946] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.82 | optimizer_gradients: 5.90 | optimizer_step: 11.89\n",
            "[2024-11-01 22:58:53,946] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 98.10 | bwd_microstep: 353.08 | bwd_inner_microstep: 348.01 | bwd_allreduce_microstep: 5.02 | step_microstep: 38.16\n",
            "[2024-11-01 22:58:53,947] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 98.07 | bwd: 353.06 | bwd_inner: 348.00 | bwd_allreduce: 5.02 | step: 38.16\n",
            "[2024-11-01 22:58:54,462] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.05 | msg size: 134.33 MB | algbw (Gbps): 48138.50 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:54,471] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:54,478] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:54,481] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:54,499] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 15058.98 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:54,500] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.16 | msg size: 80.0 KB | algbw (Gbps): 4.20 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:54,501] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.82 | optimizer_gradients: 5.89 | optimizer_step: 11.89\n",
            "[2024-11-01 22:58:54,501] [INFO] [logging.py:96:log_dist] [Rank 0] step=70, skipped=0, lr=[0.0002889743906929609, 0.0002889743906929609], mom=[[0.9, 0.95], [0.9, 0.95]]\n",
            "[2024-11-01 22:58:54,501] [INFO] [timer.py:260:stop] epoch=0/micro_step=70/global_step=70, RunningAvgSamplesPerSec=7.3134558827234315, CurrSamplesPerSec=7.256386723193409, MemAllocated=0.93GB, MaxMemAllocated=3.31GB\n",
            "[2024-11-01 22:58:54,502] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 97.86 | bwd_microstep: 351.08 | bwd_inner_microstep: 345.96 | bwd_allreduce_microstep: 5.07 | step_microstep: 37.18\n",
            "[2024-11-01 22:58:54,502] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 97.85 | bwd: 351.07 | bwd_inner: 345.95 | bwd_allreduce: 5.08 | step: 37.18\n",
            " samples/sec: 7.192 | iteration       70/     100 | elapsed time per iteration (ms): 556.2 | learning rate: 2.890E-04 | approx flops per GPU: 6.0TFLOPS | lm_loss: 3.165251E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
            "time (ms) | forward: 164.97 | backward: 351.95 | backward-backward: 351.91 | backward-allreduce: 0.00 | optimizer: 37.72 | batch generator: 1.61\n",
            "[2024-11-01 22:58:55,020] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.05 | msg size: 134.33 MB | algbw (Gbps): 44016.64 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:55,029] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:55,036] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:55,039] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:55,057] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 14905.90 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:55,058] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.19 | msg size: 80.0 KB | algbw (Gbps): 3.38 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:55,059] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.90 | optimizer_gradients: 5.90 | optimizer_step: 11.88\n",
            "[2024-11-01 22:58:55,059] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 98.75 | bwd_microstep: 352.63 | bwd_inner_microstep: 347.61 | bwd_allreduce_microstep: 4.98 | step_microstep: 36.94\n",
            "[2024-11-01 22:58:55,060] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 98.72 | bwd: 352.62 | bwd_inner: 347.60 | bwd_allreduce: 4.98 | step: 36.94\n",
            "[2024-11-01 22:58:55,577] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.05 | msg size: 134.33 MB | algbw (Gbps): 45554.09 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:55,585] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:55,592] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:55,595] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:55,614] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 16195.50 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:55,614] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.14 | msg size: 80.0 KB | algbw (Gbps): 4.76 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:55,615] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.80 | optimizer_gradients: 5.92 | optimizer_step: 11.85\n",
            "[2024-11-01 22:58:55,615] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 97.56 | bwd_microstep: 353.02 | bwd_inner_microstep: 347.98 | bwd_allreduce_microstep: 4.99 | step_microstep: 36.43\n",
            "[2024-11-01 22:58:55,615] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 97.55 | bwd: 353.01 | bwd_inner: 347.97 | bwd_allreduce: 4.99 | step: 36.43\n",
            "[2024-11-01 22:58:56,139] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 28283.78 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:56,148] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:56,155] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:56,158] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:56,176] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.06 | msg size: 134.25 MB | algbw (Gbps): 18829.77 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:56,176] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.13 | msg size: 80.0 KB | algbw (Gbps): 4.86 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:56,177] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.70 | optimizer_gradients: 5.91 | optimizer_step: 11.87\n",
            "[2024-11-01 22:58:56,178] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 100.77 | bwd_microstep: 356.22 | bwd_inner_microstep: 351.09 | bwd_allreduce_microstep: 5.06 | step_microstep: 36.41\n",
            "[2024-11-01 22:58:56,178] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 100.75 | bwd: 356.19 | bwd_inner: 351.08 | bwd_allreduce: 5.06 | step: 36.41\n",
            "[2024-11-01 22:58:56,694] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.05 | msg size: 134.33 MB | algbw (Gbps): 41672.56 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:56,703] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:56,710] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:56,713] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:56,731] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 16300.53 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:56,731] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.14 | msg size: 80.0 KB | algbw (Gbps): 4.84 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:56,732] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.70 | optimizer_gradients: 5.88 | optimizer_step: 11.85\n",
            "[2024-11-01 22:58:56,733] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 97.68 | bwd_microstep: 351.21 | bwd_inner_microstep: 346.18 | bwd_allreduce_microstep: 4.99 | step_microstep: 36.32\n",
            "[2024-11-01 22:58:56,733] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 97.65 | bwd: 351.20 | bwd_inner: 346.17 | bwd_allreduce: 4.99 | step: 36.33\n",
            "[2024-11-01 22:58:57,252] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 34388.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:57,261] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:57,268] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:57,271] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:57,289] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 13029.56 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:57,290] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.21 | msg size: 80.0 KB | algbw (Gbps): 3.05 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:57,291] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.97 | optimizer_gradients: 5.91 | optimizer_step: 11.87\n",
            "[2024-11-01 22:58:57,292] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 98.52 | bwd_microstep: 354.39 | bwd_inner_microstep: 349.29 | bwd_allreduce_microstep: 5.06 | step_microstep: 37.54\n",
            "[2024-11-01 22:58:57,292] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 98.49 | bwd: 354.38 | bwd_inner: 349.28 | bwd_allreduce: 5.06 | step: 37.56\n",
            "[2024-11-01 22:58:57,827] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 134.33 MB | algbw (Gbps): 12953.21 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:57,838] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.33 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:57,846] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:57,851] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:57,869] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.10 | msg size: 134.25 MB | algbw (Gbps): 11032.24 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:57,870] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.19 | msg size: 80.0 KB | algbw (Gbps): 3.39 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:57,871] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.04 | optimizer_gradients: 5.97 | optimizer_step: 11.97\n",
            "[2024-11-01 22:58:57,872] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 100.30 | bwd_microstep: 366.03 | bwd_inner_microstep: 357.82 | bwd_allreduce_microstep: 8.02 | step_microstep: 41.88\n",
            "[2024-11-01 22:58:57,872] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 100.27 | bwd: 366.03 | bwd_inner: 357.84 | bwd_allreduce: 8.01 | step: 41.89\n",
            "[2024-11-01 22:58:58,398] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 30500.92 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:58,410] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.28 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:58,418] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:58,422] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:58,440] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.10 | msg size: 134.25 MB | algbw (Gbps): 11222.20 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:58,441] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.17 | msg size: 80.0 KB | algbw (Gbps): 3.86 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:58,442] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.95 | optimizer_gradients: 5.94 | optimizer_step: 11.95\n",
            "[2024-11-01 22:58:58,443] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 100.38 | bwd_microstep: 356.58 | bwd_inner_microstep: 350.59 | bwd_allreduce_microstep: 5.93 | step_microstep: 42.24\n",
            "[2024-11-01 22:58:58,443] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 100.35 | bwd: 356.57 | bwd_inner: 350.58 | bwd_allreduce: 5.93 | step: 42.25\n",
            "[2024-11-01 22:58:58,963] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.11 | msg size: 134.33 MB | algbw (Gbps): 20319.28 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:58,974] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.25 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:58,982] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:58,987] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:59,005] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.10 | msg size: 134.25 MB | algbw (Gbps): 11129.93 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:59,006] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.19 | msg size: 80.0 KB | algbw (Gbps): 3.45 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:59,007] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.01 | optimizer_gradients: 5.93 | optimizer_step: 11.95\n",
            "[2024-11-01 22:58:59,008] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 98.74 | bwd_microstep: 351.47 | bwd_inner_microstep: 345.40 | bwd_allreduce_microstep: 5.98 | step_microstep: 42.44\n",
            "[2024-11-01 22:58:59,008] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 98.72 | bwd: 351.47 | bwd_inner: 345.39 | bwd_allreduce: 5.98 | step: 42.44\n",
            "[2024-11-01 22:58:59,531] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.09 | msg size: 134.33 MB | algbw (Gbps): 24259.95 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:59,541] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.24 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:59,549] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:59,554] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:59,572] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 12732.57 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:59,573] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.18 | msg size: 80.0 KB | algbw (Gbps): 3.71 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:58:59,574] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.94 | optimizer_gradients: 5.93 | optimizer_step: 11.93\n",
            "[2024-11-01 22:58:59,574] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 100.74 | bwd_microstep: 354.89 | bwd_inner_microstep: 348.91 | bwd_allreduce_microstep: 5.91 | step_microstep: 40.99\n",
            "[2024-11-01 22:58:59,575] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 100.71 | bwd: 354.89 | bwd_inner: 348.89 | bwd_allreduce: 5.92 | step: 40.99\n",
            "[2024-11-01 22:59:00,103] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.09 | msg size: 134.33 MB | algbw (Gbps): 24453.69 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:00,113] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.24 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:00,121] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:00,126] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:00,145] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 12148.03 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:00,146] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.18 | msg size: 80.0 KB | algbw (Gbps): 3.64 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:00,147] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.96 | optimizer_gradients: 5.96 | optimizer_step: 11.91\n",
            "[2024-11-01 22:59:00,147] [INFO] [logging.py:96:log_dist] [Rank 0] step=80, skipped=0, lr=[0.0001876283841110236, 0.0001876283841110236], mom=[[0.9, 0.95], [0.9, 0.95]]\n",
            "[2024-11-01 22:59:00,148] [INFO] [timer.py:260:stop] epoch=0/micro_step=80/global_step=80, RunningAvgSamplesPerSec=7.2918424046063715, CurrSamplesPerSec=7.082358960417481, MemAllocated=0.93GB, MaxMemAllocated=3.31GB\n",
            "[2024-11-01 22:59:00,148] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 99.98 | bwd_microstep: 356.44 | bwd_inner_microstep: 350.59 | bwd_allreduce_microstep: 5.78 | step_microstep: 43.14\n",
            "[2024-11-01 22:59:00,149] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 99.95 | bwd: 356.42 | bwd_inner: 350.57 | bwd_allreduce: 5.78 | step: 43.13\n",
            " samples/sec: 7.083 | iteration       80/     100 | elapsed time per iteration (ms): 564.7 | learning rate: 1.876E-04 | approx flops per GPU: 5.9TFLOPS | lm_loss: 3.016550E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
            "time (ms) | forward: 167.33 | backward: 355.56 | backward-backward: 355.51 | backward-allreduce: 0.00 | optimizer: 40.04 | batch generator: 2.51\n",
            "[2024-11-01 22:59:00,683] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 27318.32 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:00,692] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:00,700] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:00,705] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:00,723] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 12600.37 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:00,724] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.18 | msg size: 80.0 KB | algbw (Gbps): 3.72 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:00,725] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.92 | optimizer_gradients: 5.95 | optimizer_step: 11.89\n",
            "[2024-11-01 22:59:00,725] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 98.50 | bwd_microstep: 364.24 | bwd_inner_microstep: 358.25 | bwd_allreduce_microstep: 5.92 | step_microstep: 40.59\n",
            "[2024-11-01 22:59:00,726] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 98.48 | bwd: 364.22 | bwd_inner: 358.23 | bwd_allreduce: 5.92 | step: 40.60\n",
            "[2024-11-01 22:59:01,250] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.09 | msg size: 134.33 MB | algbw (Gbps): 26386.89 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:01,260] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:01,268] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:01,274] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:01,292] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 12223.98 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:01,292] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.18 | msg size: 80.0 KB | algbw (Gbps): 3.72 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:01,294] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.92 | optimizer_gradients: 5.92 | optimizer_step: 11.91\n",
            "[2024-11-01 22:59:01,294] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 100.56 | bwd_microstep: 354.17 | bwd_inner_microstep: 348.29 | bwd_allreduce_microstep: 5.81 | step_microstep: 41.86\n",
            "[2024-11-01 22:59:01,295] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 100.53 | bwd: 354.17 | bwd_inner: 348.27 | bwd_allreduce: 5.81 | step: 41.87\n",
            "[2024-11-01 22:59:01,824] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.27 | msg size: 134.33 MB | algbw (Gbps): 8357.26 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:01,834] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.25 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:01,842] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:01,846] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:01,865] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 13839.10 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:01,865] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.18 | msg size: 80.0 KB | algbw (Gbps): 3.56 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:01,867] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.97 | optimizer_gradients: 5.96 | optimizer_step: 11.92\n",
            "[2024-11-01 22:59:01,867] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 101.53 | bwd_microstep: 357.18 | bwd_inner_microstep: 351.19 | bwd_allreduce_microstep: 5.93 | step_microstep: 41.08\n",
            "[2024-11-01 22:59:01,867] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 101.51 | bwd: 357.17 | bwd_inner: 351.17 | bwd_allreduce: 5.93 | step: 41.09\n",
            "[2024-11-01 22:59:02,394] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 32409.86 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:02,403] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:02,411] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:02,415] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.26 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:02,434] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 13442.64 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:02,434] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.17 | msg size: 80.0 KB | algbw (Gbps): 3.81 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:02,436] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.91 | optimizer_gradients: 5.92 | optimizer_step: 11.92\n",
            "[2024-11-01 22:59:02,436] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 101.94 | bwd_microstep: 352.82 | bwd_inner_microstep: 346.99 | bwd_allreduce_microstep: 5.76 | step_microstep: 40.17\n",
            "[2024-11-01 22:59:02,436] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 101.91 | bwd: 352.79 | bwd_inner: 346.97 | bwd_allreduce: 5.76 | step: 40.18\n",
            "[2024-11-01 22:59:02,972] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 28994.08 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:02,981] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:02,990] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:02,994] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:03,013] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 13265.30 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:03,013] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.18 | msg size: 80.0 KB | algbw (Gbps): 3.71 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:03,015] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.94 | optimizer_gradients: 5.93 | optimizer_step: 11.90\n",
            "[2024-11-01 22:59:03,015] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 102.26 | bwd_microstep: 362.68 | bwd_inner_microstep: 356.68 | bwd_allreduce_microstep: 5.94 | step_microstep: 41.07\n",
            "[2024-11-01 22:59:03,015] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 102.24 | bwd: 362.66 | bwd_inner: 356.66 | bwd_allreduce: 5.94 | step: 41.07\n",
            "[2024-11-01 22:59:03,543] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 30408.73 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:03,553] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:03,561] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:03,565] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:03,583] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 12296.59 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:03,584] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.17 | msg size: 80.0 KB | algbw (Gbps): 3.78 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:03,585] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.94 | optimizer_gradients: 5.92 | optimizer_step: 11.86\n",
            "[2024-11-01 22:59:03,586] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 99.24 | bwd_microstep: 354.96 | bwd_inner_microstep: 349.10 | bwd_allreduce_microstep: 5.79 | step_microstep: 40.31\n",
            "[2024-11-01 22:59:03,586] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 99.21 | bwd: 354.93 | bwd_inner: 349.08 | bwd_allreduce: 5.79 | step: 40.31\n",
            "[2024-11-01 22:59:04,123] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 28409.29 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:04,133] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.25 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:04,141] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:04,145] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:04,164] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.10 | msg size: 134.25 MB | algbw (Gbps): 11297.86 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:04,164] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.19 | msg size: 80.0 KB | algbw (Gbps): 3.40 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:04,166] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.22 | optimizer_gradients: 5.94 | optimizer_step: 11.87\n",
            "[2024-11-01 22:59:04,166] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 106.33 | bwd_microstep: 360.74 | bwd_inner_microstep: 354.68 | bwd_allreduce_microstep: 5.99 | step_microstep: 41.04\n",
            "[2024-11-01 22:59:04,167] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 106.31 | bwd: 360.72 | bwd_inner: 354.66 | bwd_allreduce: 5.99 | step: 41.04\n",
            "[2024-11-01 22:59:04,695] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.09 | msg size: 134.33 MB | algbw (Gbps): 23905.85 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:04,709] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.33 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:04,719] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:04,724] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:04,742] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 11954.09 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:04,743] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.19 | msg size: 80.0 KB | algbw (Gbps): 3.38 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:04,744] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.24 | optimizer_gradients: 5.95 | optimizer_step: 11.97\n",
            "[2024-11-01 22:59:04,745] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 100.01 | bwd_microstep: 359.46 | bwd_inner_microstep: 352.95 | bwd_allreduce_microstep: 6.45 | step_microstep: 46.55\n",
            "[2024-11-01 22:59:04,745] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 99.98 | bwd: 359.43 | bwd_inner: 352.93 | bwd_allreduce: 6.45 | step: 46.56\n",
            "[2024-11-01 22:59:05,278] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.10 | msg size: 134.33 MB | algbw (Gbps): 21864.83 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:05,289] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.25 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:05,298] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:05,303] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:05,321] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 11954.09 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:05,322] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.23 | msg size: 80.0 KB | algbw (Gbps): 2.86 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:05,324] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.03 | optimizer_gradients: 5.93 | optimizer_step: 11.91\n",
            "[2024-11-01 22:59:05,324] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 100.65 | bwd_microstep: 362.07 | bwd_inner_microstep: 355.80 | bwd_allreduce_microstep: 6.18 | step_microstep: 43.39\n",
            "[2024-11-01 22:59:05,324] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 100.63 | bwd: 362.07 | bwd_inner: 355.78 | bwd_allreduce: 6.18 | step: 43.40\n",
            "[2024-11-01 22:59:05,850] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.09 | msg size: 134.33 MB | algbw (Gbps): 25287.84 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:05,860] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:05,868] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.24 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:05,872] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:05,890] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 13092.57 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:05,891] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.21 | msg size: 80.0 KB | algbw (Gbps): 3.08 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:05,892] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.87 | optimizer_gradients: 5.90 | optimizer_step: 11.88\n",
            "[2024-11-01 22:59:05,892] [INFO] [logging.py:96:log_dist] [Rank 0] step=90, skipped=0, lr=[0.00012246799701657457, 0.00012246799701657457], mom=[[0.9, 0.95], [0.9, 0.95]]\n",
            "[2024-11-01 22:59:05,893] [INFO] [timer.py:260:stop] epoch=0/micro_step=90/global_step=90, RunningAvgSamplesPerSec=7.263891262387981, CurrSamplesPerSec=7.130550682062371, MemAllocated=0.93GB, MaxMemAllocated=3.31GB\n",
            "[2024-11-01 22:59:05,893] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 99.22 | bwd_microstep: 356.40 | bwd_inner_microstep: 350.50 | bwd_allreduce_microstep: 5.81 | step_microstep: 40.76\n",
            "[2024-11-01 22:59:05,893] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 99.19 | bwd: 356.36 | bwd_inner: 350.47 | bwd_allreduce: 5.81 | step: 40.76\n",
            " samples/sec: 6.963 | iteration       90/     100 | elapsed time per iteration (ms): 574.4 | learning rate: 1.225E-04 | approx flops per GPU: 5.8TFLOPS | lm_loss: 2.838070E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
            "time (ms) | forward: 170.66 | backward: 359.25 | backward-backward: 359.20 | backward-allreduce: 0.00 | optimizer: 42.36 | batch generator: 4.27\n",
            "[2024-11-01 22:59:06,416] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.06 | msg size: 134.33 MB | algbw (Gbps): 39082.48 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:06,424] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:06,432] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:06,435] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:06,453] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 17125.47 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:06,454] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.17 | msg size: 80.0 KB | algbw (Gbps): 3.90 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:06,455] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.77 | optimizer_gradients: 5.89 | optimizer_step: 11.85\n",
            "[2024-11-01 22:59:06,455] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 99.53 | bwd_microstep: 355.39 | bwd_inner_microstep: 350.12 | bwd_allreduce_microstep: 5.23 | step_microstep: 36.88\n",
            "[2024-11-01 22:59:06,455] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 99.50 | bwd: 355.38 | bwd_inner: 350.11 | bwd_allreduce: 5.23 | step: 36.88\n",
            "[2024-11-01 22:59:06,982] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.04 | msg size: 134.33 MB | algbw (Gbps): 51144.97 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:06,989] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:06,997] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:07,000] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:07,019] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 15117.20 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:07,019] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.14 | msg size: 80.0 KB | algbw (Gbps): 4.62 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:07,020] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.80 | optimizer_gradients: 5.89 | optimizer_step: 11.86\n",
            "[2024-11-01 22:59:07,020] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 101.31 | bwd_microstep: 358.11 | bwd_inner_microstep: 352.78 | bwd_allreduce_microstep: 5.29 | step_microstep: 36.73\n",
            "[2024-11-01 22:59:07,020] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 101.29 | bwd: 358.10 | bwd_inner: 352.77 | bwd_allreduce: 5.29 | step: 36.73\n",
            "[2024-11-01 22:59:07,547] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 28170.65 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:07,555] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:07,563] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:07,566] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:07,584] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 15551.41 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:07,584] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.14 | msg size: 80.0 KB | algbw (Gbps): 4.68 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:07,585] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.75 | optimizer_gradients: 5.89 | optimizer_step: 11.88\n",
            "[2024-11-01 22:59:07,586] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 100.68 | bwd_microstep: 358.74 | bwd_inner_microstep: 353.60 | bwd_allreduce_microstep: 5.09 | step_microstep: 36.55\n",
            "[2024-11-01 22:59:07,586] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 100.66 | bwd: 358.72 | bwd_inner: 353.59 | bwd_allreduce: 5.09 | step: 36.55\n",
            "[2024-11-01 22:59:08,114] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 31595.61 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:08,122] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:08,130] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:08,133] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:08,151] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 16308.08 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:08,151] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.13 | msg size: 80.0 KB | algbw (Gbps): 4.90 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:08,152] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.72 | optimizer_gradients: 5.90 | optimizer_step: 11.86\n",
            "[2024-11-01 22:59:08,152] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 100.33 | bwd_microstep: 360.68 | bwd_inner_microstep: 355.63 | bwd_allreduce_microstep: 5.00 | step_microstep: 36.04\n",
            "[2024-11-01 22:59:08,153] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 100.28 | bwd: 360.66 | bwd_inner: 355.62 | bwd_allreduce: 5.00 | step: 36.05\n",
            "[2024-11-01 22:59:08,681] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 30527.36 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:08,689] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:08,697] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:08,700] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:08,718] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 14799.34 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:08,719] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.15 | msg size: 80.0 KB | algbw (Gbps): 4.51 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:08,719] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.76 | optimizer_gradients: 5.90 | optimizer_step: 11.88\n",
            "[2024-11-01 22:59:08,720] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 101.45 | bwd_microstep: 359.19 | bwd_inner_microstep: 354.00 | bwd_allreduce_microstep: 5.14 | step_microstep: 36.51\n",
            "[2024-11-01 22:59:08,720] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 101.43 | bwd: 359.17 | bwd_inner: 353.99 | bwd_allreduce: 5.14 | step: 36.51\n",
            "[2024-11-01 22:59:09,248] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.09 | msg size: 134.33 MB | algbw (Gbps): 24003.62 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:09,256] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:09,264] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:09,267] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:09,285] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.06 | msg size: 134.25 MB | algbw (Gbps): 18377.46 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:09,285] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.15 | msg size: 80.0 KB | algbw (Gbps): 4.27 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:09,286] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.76 | optimizer_gradients: 5.93 | optimizer_step: 11.87\n",
            "[2024-11-01 22:59:09,287] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 101.67 | bwd_microstep: 358.72 | bwd_inner_microstep: 353.52 | bwd_allreduce_microstep: 5.15 | step_microstep: 36.65\n",
            "[2024-11-01 22:59:09,287] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 101.63 | bwd: 358.70 | bwd_inner: 353.51 | bwd_allreduce: 5.15 | step: 36.65\n",
            "[2024-11-01 22:59:09,816] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 27265.44 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:09,828] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.24 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:09,837] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.24 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:09,842] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:09,860] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 15347.94 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:09,861] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.17 | msg size: 80.0 KB | algbw (Gbps): 3.90 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:09,862] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 5.94 | optimizer_step: 11.91\n",
            "[2024-11-01 22:59:09,862] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 100.33 | bwd_microstep: 361.10 | bwd_inner_microstep: 355.90 | bwd_allreduce_microstep: 5.15 | step_microstep: 44.41\n",
            "[2024-11-01 22:59:09,862] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 100.31 | bwd: 361.08 | bwd_inner: 355.89 | bwd_allreduce: 5.15 | step: 44.41\n",
            "[2024-11-01 22:59:10,384] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 32365.18 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:10,392] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:10,400] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:10,403] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:10,421] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 13747.20 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:10,421] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.15 | msg size: 80.0 KB | algbw (Gbps): 4.51 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:10,422] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.75 | optimizer_gradients: 5.89 | optimizer_step: 11.87\n",
            "[2024-11-01 22:59:10,423] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 99.51 | bwd_microstep: 355.36 | bwd_inner_microstep: 350.22 | bwd_allreduce_microstep: 5.09 | step_microstep: 36.69\n",
            "[2024-11-01 22:59:10,423] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 99.49 | bwd: 355.34 | bwd_inner: 350.21 | bwd_allreduce: 5.09 | step: 36.69\n",
            "[2024-11-01 22:59:10,953] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 32217.12 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:10,961] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:10,968] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:10,971] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:10,989] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.04 | msg size: 134.25 MB | algbw (Gbps): 27886.56 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:10,990] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.13 | msg size: 80.0 KB | algbw (Gbps): 4.96 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:10,991] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.69 | optimizer_gradients: 5.90 | optimizer_step: 11.86\n",
            "[2024-11-01 22:59:10,991] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 99.65 | bwd_microstep: 362.24 | bwd_inner_microstep: 357.04 | bwd_allreduce_microstep: 5.15 | step_microstep: 36.54\n",
            "[2024-11-01 22:59:10,991] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 99.63 | bwd: 362.23 | bwd_inner: 357.03 | bwd_allreduce: 5.15 | step: 36.54\n",
            "[2024-11-01 22:59:11,515] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.06 | msg size: 134.33 MB | algbw (Gbps): 37381.43 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:11,523] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:11,531] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:11,533] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.13 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:11,551] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 15676.09 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:11,552] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.17 | msg size: 80.0 KB | algbw (Gbps): 3.80 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:11,553] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.75 | optimizer_gradients: 5.90 | optimizer_step: 11.88\n",
            "[2024-11-01 22:59:11,553] [INFO] [logging.py:96:log_dist] [Rank 0] step=100, skipped=0, lr=[0.0001, 0.0001], mom=[[0.9, 0.95], [0.9, 0.95]]\n",
            "[2024-11-01 22:59:11,553] [INFO] [timer.py:260:stop] epoch=0/micro_step=100/global_step=100, RunningAvgSamplesPerSec=7.248630746560788, CurrSamplesPerSec=7.1635297895161125, MemAllocated=0.93GB, MaxMemAllocated=3.31GB\n",
            "[2024-11-01 22:59:11,554] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 99.72 | bwd_microstep: 356.21 | bwd_inner_microstep: 351.04 | bwd_allreduce_microstep: 5.12 | step_microstep: 36.82\n",
            "[2024-11-01 22:59:11,554] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 99.70 | bwd: 356.19 | bwd_inner: 351.03 | bwd_allreduce: 5.12 | step: 36.82\n",
            " samples/sec: 7.067 | iteration      100/     100 | elapsed time per iteration (ms): 566.0 | learning rate: 1.000E-04 | approx flops per GPU: 5.9TFLOPS | lm_loss: 2.784878E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
            "time (ms) | forward: 167.74 | backward: 358.82 | backward-backward: 358.79 | backward-allreduce: 0.00 | optimizer: 37.91 | batch generator: 1.69\n",
            "--------------------------------------------------------------------------------------------------------\n",
            " validation results at iteration 100 | lm_loss value: 2.736050E+00 | lm_loss_ppl value: 1.542593E+01 | \n",
            "--------------------------------------------------------------------------------------------------------\n",
            "---------------------------------------------------------------------------------------------------------------------------\n",
            " validation results at the end of training for val data | lm_loss value: 2.810510E+00 | lm_loss_ppl value: 1.661839E+01 | \n",
            "---------------------------------------------------------------------------------------------------------------------------\n",
            "[2024-11-01 22:59:14,976] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: barrier | time (ms): 0.30 | msg size: 0B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:14,976] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step100 is about to be saved!\n",
            "[2024-11-01 22:59:14,977] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 20.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:14,977] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 20.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1898: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
            "  warnings.warn(\n",
            "[2024-11-01 22:59:15,030] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: checkpoints/global_step100/mp_rank_00_model_states.pt\n",
            "[2024-11-01 22:59:15,030] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/global_step100/mp_rank_00_model_states.pt...\n",
            "[2024-11-01 22:59:15,396] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/global_step100/mp_rank_00_model_states.pt.\n",
            "[2024-11-01 22:59:15,398] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: barrier | time (ms): 0.37 | msg size: 0B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-01 22:59:15,399] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/global_step100/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
            "[2024-11-01 22:59:24,154] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/global_step100/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
            "[2024-11-01 22:59:24,157] [INFO] [engine.py:3426:_save_zero_checkpoint] zero checkpoint saved checkpoints/global_step100/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
            "[2024-11-01 22:59:24,157] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!\n",
            "[2024-11-01 22:59:24,158] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: barrier | time (ms): 0.44 | msg size: 0B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "Evaluating iter 10/10\n",
            "----------------------------------------------------------------------------------------------------------------------\n",
            " test results at the end of training for test data | lm_loss value: 2.808052E+00 | lm_loss_ppl value: 1.657759E+01 | \n",
            "----------------------------------------------------------------------------------------------------------------------\n",
            "[2024-11-01 22:59:29,303] [INFO] [launch.py:347:main] Process 28820 exits successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "M3Wp-zQC-EXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./deepy.py generate.py -d /content/GPT-NeoX-Colab/configs CC19M.yml cc_setup.yml text_generation.yml"
      ],
      "metadata": {
        "id": "S0XIQLE4bm8Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f22a91c-6a7a-4157-aa83-a2afd82d3680"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-11-01 23:03:32,056] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "NeoXArgs.from_ymls() ['configs/19M.yml', 'configs/local_setup.yml', 'configs/text_generation.yml']\n",
            "INFO:root:NeoXArgs.calculate_derived() Total number of GPUs determined to be: 1\n",
            "-------------------- arguments --------------------\n",
            "  attention_config ................ ['global', 'global', 'global', 'global', 'global', 'global']updated\n",
            "  batch_size ...................... 4...........................updated\n",
            "  checkpoint_activations .......... True........................updated\n",
            "  checkpoint_factor ............... 1000........................updated\n",
            "  config_files .................... {'19M.yml': '{\\n  \"pipe_parallel_size\": 0,\\n  \"model_parallel_size\": 1,\\n\\n  # model settings\\n  \"num_layers\": 6,\\n  \"hidden_size\": 512,\\n  \"num_attention_heads\": 8,\\n  \"seq_length\": 2048,\\n  \"max_position_embeddings\": 2048,\\n  \"pos_emb\": \"rotary\",\\n  \"no_weight_tying\": true,\\n  \"gpt_j_residual\": false,\\n  \"output_layer_parallelism\": \"column\",\\n\\n  \"scaled_upper_triang_masked_softmax_fusion\": false,\\n  \"bias_gelu_fusion\": false,\\n  \"rope_fusion\": false,\\n  \"layernorm_fusion\": false,\\n\\n  # init methods\\n  \"init_method\": \"small_init\",\\n  \"output_layer_init_method\": \"wang_init\",\\n\\n  \"optimizer\": {\\n    \"type\": \"Adam\",\\n    \"params\": {\\n      \"lr\": 0.001,\\n      \"betas\": [0.9, 0.95],\\n      \"eps\": 1.0e-8,\\n    }\\n  },\\n  \"min_lr\": 0.0001,\\n\\n  # for all zero_optimization options, see https://www.deepspeed.ai/docs/config-json/#zero-optimizations-for-fp16-training\\n  \"zero_optimization\": {\\n    \"stage\": 1,\\n    \"allgather_partitions\": True,\\n    \"allgather_bucket_size\": 500000000,\\n    \"overlap_comm\": True,\\n    \"reduce_scatter\": True,\\n    \"reduce_bucket_size\": 500000000,\\n    \"contiguous_gradients\": True,\\n  },\\n\\n  \"train_micro_batch_size_per_gpu\": 4, #32,\\n  \"gradient_accumulation_steps\": 1,\\n  \"data_impl\": \"mmap\",\\n  \"num_workers\": 1,\\n\\n  # activation checkpointing\\n  \"checkpoint_activations\": true,\\n  \"checkpoint_num_layers\": 1,\\n  \"partition_activations\": true,\\n  \"synchronize_each_layer\": true,\\n\\n  # regularization\\n  \"gradient_clipping\": 1.0,\\n  \"weight_decay\": 0.1,\\n  \"hidden_dropout\": 0,\\n  \"attention_dropout\": 0,\\n\\n  # precision settings\\n  \"fp16\": {\\n    \"fp16\": true,\\n    \"enabled\": true,\\n    \"loss_scale\": 0,\\n    \"loss_scale_window\": 1000,\\n    \"initial_scale_power\": 12,\\n    \"hysteresis\": 2,\\n    \"min_loss_scale\": 1,\\n  },\\n\\n  \"train_iters\": 100,\\n  \"lr_decay_iters\": 100,\\n  \"distributed_backend\": \"nccl\",\\n  \"lr_decay_style\": \"cosine\",\\n  \"warmup\": 0.01,\\n  \"checkpoint_factor\": 1000,\\n  \"eval_interval\": 50,\\n  \"eval_iters\": 10,\\n\\n  \"log_interval\": 10,\\n  \"steps_per_print\": 10,\\n  \"wall_clock_breakdown\": true,\\n\\n  # additional deepspeed args not specified above\\n  \"deepspeed_extra_args\": {\\n    \"comms_logger\": {\\n        \"enabled\": true,\\n        \"verbose\": true,\\n        \"prof_all\": true,\\n        \"debug\": false\\n    },\\n  }\\n\\n}\\n', 'local_setup.yml': '# Suggested data paths when using GPT-NeoX locally\\n{\\n  \"data_path\": \"processed_data/py150_text_document\",\\n\\n  # or for weighted datasets:\\n  # \"train-data-paths\": [\"data/enwik8/enwik8_text_document\", \"data/enwik8/enwik8_text_document\"],\\n  # \"test-data-paths\": [\"data/enwik8/enwik8_text_document\", \"data/enwik8/enwik8_text_document\"],\\n  # \"valid-data-paths\": [\"data/enwik8/enwik8_text_document\", \"data/enwik8/enwik8_text_document\"],\\n  # \"train-data-weights\": [1., 2.],\\n  # \"test-data-weights\": [2., 1.],\\n  # \"valid-data-weights\": [0.5, 0.4],\\n\\n  # If weight_by_num_documents is True, Builds dataset weights from a multinomial distribution over groups of data according to the number of documents in each group.\\n  # WARNING: setting this to True will override any user provided weights\\n  # \"weight_by_num_documents\": false,\\n  # \"weighted_sampler_alpha\": 0.3,\\n\\n  \"vocab_file\": \"data/gpt2-vocab.json\",\\n  \"merge_file\": \"data/gpt2-merges.txt\",\\n\\n  \"save\": \"checkpoints\",\\n  \"load\": \"checkpoints\",\\n  \"checkpoint_validation_with_forward_pass\": False,\\n\\n  \"tensorboard_dir\": \"tensorboard\",\\n  \"log_dir\": \"logs\",\\n}\\n', 'text_generation.yml': '# Parameters used for text generation\\n# Make sure `load` is specified somewhere else\\n{\\n  # Text gen type: `input-file`, `unconditional` or `interactive`\\n  \"text_gen_type\": \"unconditional\",\\n\\n  # Params for all\\n  \"maximum_tokens\": 102,\\n  \"prompt_end\": \"\\\\n\",\\n  \"temperature\": 1.0,\\n  \"top_p\": 0.0,\\n  \"top_k\": 0,\\n  \"recompute\": false,\\n\\n  # `unconditional`: samples\\n  \"num_samples\": 10,\\n\\n  # input/output file\\n  \"sample_input_file\": \"sample_input.txt\",\\n  \"sample_output_file\": \"sample_output.txt\",\\n}\\n'}updated\n",
            "  data_impl ....................... mmap........................updated\n",
            "  data_path ....................... processed_data/py150_text_documentupdated\n",
            "  deepspeed_extra_args ............ {'comms_logger': {'enabled': True, 'verbose': True, 'prof_all': True, 'debug': False}}updated\n",
            "  dynamic_loss_scale .............. True........................updated\n",
            "  eval_interval ................... 50..........................updated\n",
            "  eval_iters ...................... 10..........................updated\n",
            "  fp16 ............................ {'fp16': True, 'enabled': True, 'loss_scale': 0, 'loss_scale_window': 1000, 'initial_scale_power': 12, 'hysteresis': 2, 'min_loss_scale': 1}updated\n",
            "  global_num_gpus ................. 1...........................updated\n",
            "  hidden_size ..................... 512.........................updated\n",
            "  init_method ..................... small_init..................updated\n",
            "  load ............................ checkpoints.................updated\n",
            "  log_dir ......................... logs........................updated\n",
            "  log_interval .................... 10..........................updated\n",
            "  lr .............................. 0.001.......................updated\n",
            "  lr_decay_iters .................. 100.........................updated\n",
            "  lr_decay_style .................. cosine......................updated\n",
            "  max_position_embeddings ......... 2048........................updated\n",
            "  maximum_tokens .................. 102.........................updated\n",
            "  merge_file ...................... data/gpt2-merges.txt........updated\n",
            "  min_lr .......................... 0.0001......................updated\n",
            "  no_weight_tying ................. True........................updated\n",
            "  num_attention_heads ............. 8...........................updated\n",
            "  num_layers ...................... 6...........................updated\n",
            "  num_samples ..................... 10..........................updated\n",
            "  num_workers ..................... 1...........................updated\n",
            "  optimizer ....................... {'type': 'Adam', 'params': {'lr': 0.001, 'betas': [0.9, 0.95], 'eps': 1e-08}}updated\n",
            "  optimizer_type .................. Adam........................updated\n",
            "  output_layer_init_method ........ wang_init...................updated\n",
            "  partition_activations ........... True........................updated\n",
            "  pos_emb ......................... rotary......................updated\n",
            "  precision ....................... fp16........................updated\n",
            "  sample_input_file ............... sample_input.txt............updated\n",
            "  sample_output_file .............. sample_output.txt...........updated\n",
            "  save ............................ checkpoints.................updated\n",
            "  seq_length ...................... 2048........................updated\n",
            "  sparsity_config ................. {}..........................updated\n",
            "  synchronize_each_layer .......... True........................updated\n",
            "  temperature ..................... 1.0.........................updated\n",
            "  tensorboard_dir ................. tensorboard.................updated\n",
            "  text_gen_type ................... unconditional...............updated\n",
            "  train_batch_size ................ 4...........................updated\n",
            "  train_iters ..................... 100.........................updated\n",
            "  train_micro_batch_size_per_gpu .. 4...........................updated\n",
            "  user_script ..................... generate.py.................updated\n",
            "  vocab_file ...................... data/gpt2-vocab.json........updated\n",
            "  wall_clock_breakdown ............ True........................updated\n",
            "  zero_allgather_bucket_size ...... 500000000...................updated\n",
            "  zero_contiguous_gradients ....... True........................updated\n",
            "  zero_optimization ............... {'stage': 1, 'allgather_partitions': True, 'allgather_bucket_size': 500000000, 'overlap_comm': True, 'reduce_scatter': True, 'reduce_bucket_size': 500000000, 'contiguous_gradients': True}updated\n",
            "  zero_reduce_bucket_size ......... 500000000...................updated\n",
            "  zero_reduce_scatter ............. True........................updated\n",
            "  zero_stage ...................... 1...........................updated\n",
            "  account ......................... None........................default\n",
            "  activation ...................... gelu........................default\n",
            "  activation_checkpointing ........ None........................default\n",
            "  adlr_autoresume ................. False.......................default\n",
            "  adlr_autoresume_interval ........ 1000........................default\n",
            "  allow_chopped ................... True........................default\n",
            "  amp ............................. None........................default\n",
            "  apply_query_key_layer_scaling ... False.......................default\n",
            "  attention_dropout ............... 0...........................default\n",
            "  attention_softmax_in_fp32 ....... False.......................default\n",
            "  autotuning ...................... None........................default\n",
            "  autotuning_run .................. None........................default\n",
            "  base_shapes_file ................ None........................default\n",
            "  bf16 ............................ None........................default\n",
            "  bias_dropout_fusion ............. False.......................default\n",
            "  bias_gelu_fusion ................ False.......................default\n",
            "  char_level_ppl .................. False.......................default\n",
            "  checkpoint ...................... None........................default\n",
            "  checkpoint_in_cpu ............... False.......................default\n",
            "  checkpoint_num_layers ........... 1...........................default\n",
            "  checkpoint_scale ................ linear......................default\n",
            "  checkpoint_validation_with_forward_pass  False................default\n",
            "  clip_grad ....................... 1.0.........................default\n",
            "  comet_experiment ................ None........................default\n",
            "  comet_experiment_name ........... None........................default\n",
            "  comet_others .................... None........................default\n",
            "  comet_project ................... None........................default\n",
            "  comet_tags ...................... None........................default\n",
            "  comet_workspace ................. None........................default\n",
            "  comment ......................... None........................default\n",
            "  comms_logger .................... None........................default\n",
            "  communication_data_type ......... None........................default\n",
            "  compression_training ............ None........................default\n",
            "  contiguous_checkpointing ........ False.......................default\n",
            "  coord_check ..................... False.......................default\n",
            "  create_moe_param_group .......... True........................default\n",
            "  csv_monitor ..................... None........................default\n",
            "  curriculum_learning ............. None........................default\n",
            "  curriculum_seqlen ............... 0...........................default\n",
            "  data_efficiency ................. None........................default\n",
            "  data_types ...................... None........................default\n",
            "  dataset_impl .................... gpt2........................default\n",
            "  deepscale ....................... False.......................default\n",
            "  deepscale_config ................ None........................default\n",
            "  deepspeed ....................... True........................default\n",
            "  deepspeed_activation_checkpointing  True......................default\n",
            "  deepspeed_mpi ................... False.......................default\n",
            "  deepspeed_slurm ................. False.......................default\n",
            "  detect_nvlink_pairs ............. False.......................default\n",
            "  dim_att ......................... None........................default\n",
            "  distributed_backend ............. nccl........................default\n",
            "  do_test ......................... None........................default\n",
            "  do_train ........................ None........................default\n",
            "  do_valid ........................ None........................default\n",
            "  dpo_beta ........................ 0.1.........................default\n",
            "  dpo_fp32 ........................ True........................default\n",
            "  dpo_reference_free .............. False.......................default\n",
            "  dump_state ...................... False.......................default\n",
            "  elasticity ...................... None........................default\n",
            "  enable_expert_tensor_parallelism  False.......................default\n",
            "  eod_mask_loss ................... False.......................default\n",
            "  eval_results_prefix ............. ............................default\n",
            "  eval_tasks ...................... None........................default\n",
            "  exclude ......................... None........................default\n",
            "  exit_interval ................... None........................default\n",
            "  expansion_factor ................ None........................default\n",
            "  expert_interval ................. 2...........................default\n",
            "  extra_save_iters ................ None........................default\n",
            "  ffn_dim ......................... None........................default\n",
            "  finetune ........................ False.......................default\n",
            "  flops_profiler .................. None........................default\n",
            "  force_multi ..................... False.......................default\n",
            "  fp16_lm_cross_entropy ........... False.......................default\n",
            "  fp32_allreduce .................. False.......................default\n",
            "  git_hash ........................ 59a5236d....................default\n",
            "  gmlp_attn_dim ................... 64..........................default\n",
            "  gpt_j_residual .................. False.......................default\n",
            "  gpt_j_tied ...................... False.......................default\n",
            "  gradient_accumulation_steps ..... 1...........................default\n",
            "  gradient_clipping ............... 1.0.........................default\n",
            "  gradient_noise_scale_cpu_offload  False.......................default\n",
            "  gradient_noise_scale_n_batches .. 5...........................default\n",
            "  gradient_predivide_factor ....... 1.0.........................default\n",
            "  head_size ....................... None........................default\n",
            "  hidden_dropout .................. 0...........................default\n",
            "  hostfile ........................ None........................default\n",
            "  hysteresis ...................... 2...........................default\n",
            "  include ......................... None........................default\n",
            "  init_method_std ................. 0.02........................default\n",
            "  intermediate_size ............... None........................default\n",
            "  is_pipe_parallel ................ False.......................default\n",
            "  iteration ....................... None........................default\n",
            "  keep_last_n_checkpoints ......... None........................default\n",
            "  kto_beta ........................ 0.1.........................default\n",
            "  kto_desirable_weight ............ 1.0.........................default\n",
            "  kto_fp32 ........................ True........................default\n",
            "  kto_undesirable_weight .......... 1.0.........................default\n",
            "  launcher ........................ pdsh........................default\n",
            "  layernorm_epsilon ............... 1e-05.......................default\n",
            "  layernorm_fusion ................ False.......................default\n",
            "  lazy_mpu_init ................... False.......................default\n",
            "  local_rank ...................... None........................default\n",
            "  log_grad_norm ................... False.......................default\n",
            "  log_grad_pct_zeros .............. False.......................default\n",
            "  log_gradient_noise_scale ........ False.......................default\n",
            "  log_optimizer_states ............ False.......................default\n",
            "  log_param_norm .................. False.......................default\n",
            "  loss_scale ...................... None........................default\n",
            "  loss_scale_window ............... 1000.0......................default\n",
            "  lr_decay_fraction ............... None........................default\n",
            "  make_vocab_size_divisible_by .... 128.........................default\n",
            "  mamba_causal_conv_fusion ........ False.......................default\n",
            "  mamba_inner_func_fusion ......... False.......................default\n",
            "  mamba_selective_fp32_params ..... True........................default\n",
            "  mamba_selective_scan_fusion ..... False.......................default\n",
            "  mamba_use_bias_in_conv .......... True........................default\n",
            "  mamba_use_bias_in_linears ....... False.......................default\n",
            "  master_addr ..................... None........................default\n",
            "  master_port ..................... 29500.......................default\n",
            "  memory_profiling ................ False.......................default\n",
            "  memory_profiling_path ........... None........................default\n",
            "  min_scale ....................... 1.0.........................default\n",
            "  mlp_multiple_of ................. 1...........................default\n",
            "  mmap_warmup ..................... False.......................default\n",
            "  model_parallel_size ............. 1...........................default\n",
            "  moe_eval_capacity_factor ........ 1.0.........................default\n",
            "  moe_expert_parallel_size ........ 1...........................default\n",
            "  moe_glu ......................... False.......................default\n",
            "  moe_jitter_eps .................. None........................default\n",
            "  moe_lbl_in_fp32 ................. False.......................default\n",
            "  moe_loss_coeff .................. 0.1.........................default\n",
            "  moe_min_capacity ................ 4...........................default\n",
            "  moe_num_experts ................. 1...........................default\n",
            "  moe_token_dropping .............. False.......................default\n",
            "  moe_top_k ....................... 1...........................default\n",
            "  moe_train_capacity_factor ....... 1.0.........................default\n",
            "  moe_type ........................ megablocks..................default\n",
            "  moe_use_residual ................ True........................default\n",
            "  mup_attn_temp ................... 1.0.........................default\n",
            "  mup_embedding_mult .............. 1.0.........................default\n",
            "  mup_init_scale .................. 1.0.........................default\n",
            "  mup_output_temp ................. 1.0.........................default\n",
            "  mup_rp_embedding_mult ........... 1.0.........................default\n",
            "  mup_width_scale ................. 2...........................default\n",
            "  neg_test_data_paths ............. None........................default\n",
            "  neg_test_label_data_paths ....... None........................default\n",
            "  neg_train_data_paths ............ None........................default\n",
            "  neg_train_label_data_paths ...... None........................default\n",
            "  neg_valid_data_paths ............ None........................default\n",
            "  neg_valid_label_data_paths ...... None........................default\n",
            "  no_load_optim ................... False.......................default\n",
            "  no_load_rng ..................... False.......................default\n",
            "  no_save_optim ................... False.......................default\n",
            "  no_save_rng ..................... False.......................default\n",
            "  no_ssh_check .................... False.......................default\n",
            "  norm ............................ layernorm...................default\n",
            "  num_gpus ........................ None........................default\n",
            "  num_kv_heads .................... None........................default\n",
            "  num_nodes ....................... -1..........................default\n",
            "  num_unique_layers ............... None........................default\n",
            "  onnx_safe ....................... False.......................default\n",
            "  opt_pos_emb_offset .............. 0...........................default\n",
            "  output_layer_parallelism ........ column......................default\n",
            "  override_lr_scheduler ........... False.......................default\n",
            "  pack_impl ....................... packed......................default\n",
            "  padded_vocab_size ............... None........................default\n",
            "  param_sharing_style ............. grouped.....................default\n",
            "  pipe_parallel_size .............. 0...........................default\n",
            "  pipe_partition_method ........... type:transformer|mlp........default\n",
            "  pos_test_data_paths ............. None........................default\n",
            "  pos_test_label_data_paths ....... None........................default\n",
            "  pos_train_data_paths ............ None........................default\n",
            "  pos_train_label_data_paths ...... None........................default\n",
            "  pos_valid_data_paths ............ None........................default\n",
            "  pos_valid_label_data_paths ...... None........................default\n",
            "  precompute_model_name ........... None........................default\n",
            "  prescale_gradients .............. False.......................default\n",
            "  profile ......................... False.......................default\n",
            "  profile_backward ................ False.......................default\n",
            "  profile_step_start .............. 10..........................default\n",
            "  profile_step_stop ............... 12..........................default\n",
            "  prompt_end ...................... \n",
            "...........................default\n",
            "  rank ............................ None........................default\n",
            "  recompute ....................... False.......................default\n",
            "  return_logits ................... False.......................default\n",
            "  rms_norm_epsilon ................ 1e-08.......................default\n",
            "  rmsnorm_fusion .................. False.......................default\n",
            "  rope_fusion ..................... False.......................default\n",
            "  rotary_emb_base ................. 10000.......................default\n",
            "  rotary_pct ...................... 1.0.........................default\n",
            "  rotary_save_freqs_buffer ........ False.......................default\n",
            "  rpe_max_distance ................ 128.........................default\n",
            "  rpe_num_buckets ................. 32..........................default\n",
            "  s3_chunk_size ................... 104857600...................default\n",
            "  s3_path ......................... None........................default\n",
            "  save_base_shapes ................ False.......................default\n",
            "  scaled_masked_softmax_fusion .... False.......................default\n",
            "  scaled_upper_triang_masked_softmax_fusion  False..............default\n",
            "  scalenorm_epsilon ............... 1e-08.......................default\n",
            "  scheduler ....................... None........................default\n",
            "  seed ............................ 1234........................default\n",
            "  sequence_parallel ............... False.......................default\n",
            "  short_seq_prob .................. 0.1.........................default\n",
            "  sliding_window_width ............ None........................default\n",
            "  soft_prompt_tuning .............. None........................default\n",
            "  sparse_attention ................ None........................default\n",
            "  sparse_gradients ................ False.......................default\n",
            "  split ........................... 969, 30, 1..................default\n",
            "  steps_per_print ................. 10..........................default\n",
            "  tensorboard ..................... None........................default\n",
            "  test_data_paths ................. None........................default\n",
            "  test_data_weights ............... None........................default\n",
            "  test_label_data_paths ........... None........................default\n",
            "  test_reward_data_paths .......... None........................default\n",
            "  tokenizer_type .................. GPT2BPETokenizer............default\n",
            "  top_k ........................... 0...........................default\n",
            "  top_p ........................... 0.0.........................default\n",
            "  train_data_paths ................ None........................default\n",
            "  train_data_weights .............. None........................default\n",
            "  train_epochs .................... None........................default\n",
            "  train_impl ...................... normal......................default\n",
            "  train_label_data_paths .......... None........................default\n",
            "  train_reward_data_paths ......... None........................default\n",
            "  use_bias_in_attn_linear ......... True........................default\n",
            "  use_bias_in_mlp ................. True........................default\n",
            "  use_bias_in_norms ............... True........................default\n",
            "  use_bnb_optimizer ............... False.......................default\n",
            "  use_checkpoint_lr_scheduler ..... False.......................default\n",
            "  use_comet ....................... None........................default\n",
            "  use_cpu_initialization .......... False.......................default\n",
            "  use_flashattn_swiglu ............ False.......................default\n",
            "  use_mup ......................... False.......................default\n",
            "  use_qk_layernorm ................ False.......................default\n",
            "  use_shared_fs ................... True........................default\n",
            "  use_tutel ....................... False.......................default\n",
            "  use_wandb ....................... None........................default\n",
            "  valid_data_paths ................ None........................default\n",
            "  valid_data_weights .............. None........................default\n",
            "  valid_label_data_paths .......... None........................default\n",
            "  valid_reward_data_paths ......... None........................default\n",
            "  wandb ........................... None........................default\n",
            "  wandb_group ..................... None........................default\n",
            "  wandb_host ...................... https://api.wandb.ai........default\n",
            "  wandb_init_all_ranks ............ False.......................default\n",
            "  wandb_project ................... neox........................default\n",
            "  wandb_team ...................... None........................default\n",
            "  warmup .......................... 0.01........................default\n",
            "  weight_by_num_documents ......... False.......................default\n",
            "  weight_decay .................... 0.1.........................default\n",
            "  weighted_sampler_alpha .......... 1.0.........................default\n",
            "  world_size ...................... None........................default\n",
            "  z_loss .......................... 0.0.........................default\n",
            "---------------- end of arguments ----------------\n",
            "NeoXArgs.configure_distributed_args() using world size: 1 and model-parallel size: 1 \n",
            "[2024-11-01 23:03:34,907] [WARNING] [runner.py:217:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
            "[2024-11-01 23:03:34,908] [INFO] [runner.py:586:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None generate.py --deepspeed_config eyJ0cmFpbl9iYXRjaF9zaXplIjogNCwgInRyYWluX21pY3JvX2JhdGNoX3NpemVfcGVyX2dwdSI6IDQsICJvcHRpbWl6ZXIiOiB7InR5cGUiOiAiQWRhbSIsICJwYXJhbXMiOiB7ImxyIjogMC4wMDEsICJiZXRhcyI6IFswLjksIDAuOTVdLCAiZXBzIjogMWUtMDh9fSwgImZwMTYiOiB7ImZwMTYiOiB0cnVlLCAiZW5hYmxlZCI6IHRydWUsICJsb3NzX3NjYWxlIjogMCwgImxvc3Nfc2NhbGVfd2luZG93IjogMTAwMCwgImluaXRpYWxfc2NhbGVfcG93ZXIiOiAxMiwgImh5c3RlcmVzaXMiOiAyLCAibWluX2xvc3Nfc2NhbGUiOiAxfSwgInplcm9fb3B0aW1pemF0aW9uIjogeyJzdGFnZSI6IDEsICJhbGxnYXRoZXJfcGFydGl0aW9ucyI6IHRydWUsICJhbGxnYXRoZXJfYnVja2V0X3NpemUiOiA1MDAwMDAwMDAsICJvdmVybGFwX2NvbW0iOiB0cnVlLCAicmVkdWNlX3NjYXR0ZXIiOiB0cnVlLCAicmVkdWNlX2J1Y2tldF9zaXplIjogNTAwMDAwMDAwLCAiY29udGlndW91c19ncmFkaWVudHMiOiB0cnVlfSwgIndhbGxfY2xvY2tfYnJlYWtkb3duIjogdHJ1ZSwgImNvbW1zX2xvZ2dlciI6IHsiZW5hYmxlZCI6IHRydWUsICJ2ZXJib3NlIjogdHJ1ZSwgInByb2ZfYWxsIjogdHJ1ZSwgImRlYnVnIjogZmFsc2V9fQ== --megatron_config {"train_batch_size": 4, "train_micro_batch_size_per_gpu": 4, "optimizer": {"type": "Adam", "params": {"lr": 0.001, "betas": [0.9, 0.95], "eps": 1e-08}}, "fp16": {"fp16": true, "enabled": true, "loss_scale": 0, "loss_scale_window": 1000, "initial_scale_power": 12, "hysteresis": 2, "min_loss_scale": 1}, "zero_optimization": {"stage": 1, "allgather_partitions": true, "allgather_bucket_size": 500000000, "overlap_comm": true, "reduce_scatter": true, "reduce_bucket_size": 500000000, "contiguous_gradients": true}, "wall_clock_breakdown": true, "deepspeed_extra_args": {"comms_logger": {"enabled": true, "verbose": true, "prof_all": true, "debug": false}}, "precision": "fp16", "num_layers": 6, "hidden_size": 512, "num_attention_heads": 8, "seq_length": 2048, "max_position_embeddings": 2048, "pos_emb": "rotary", "no_weight_tying": true, "attention_config": ["global", "global", "global", "global", "global", "global"], "sparsity_config": {}, "init_method": "small_init", "output_layer_init_method": "wang_init", "lr_decay_style": "cosine", "lr_decay_iters": 100, "min_lr": 0.0001, "optimizer_type": "Adam", "zero_stage": 1, "zero_reduce_scatter": true, "zero_contiguous_gradients": true, "zero_reduce_bucket_size": 500000000, "zero_allgather_bucket_size": 500000000, "lr": 0.001, "data_path": "processed_data/py150_text_document", "data_impl": "mmap", "save": "checkpoints", "config_files": {"19M.yml": "{\n  \"pipe_parallel_size\": 0,\n  \"model_parallel_size\": 1,\n\n  # model settings\n  \"num_layers\": 6,\n  \"hidden_size\": 512,\n  \"num_attention_heads\": 8,\n  \"seq_length\": 2048,\n  \"max_position_embeddings\": 2048,\n  \"pos_emb\": \"rotary\",\n  \"no_weight_tying\": true,\n  \"gpt_j_residual\": false,\n  \"output_layer_parallelism\": \"column\",\n\n  \"scaled_upper_triang_masked_softmax_fusion\": false,\n  \"bias_gelu_fusion\": false,\n  \"rope_fusion\": false,\n  \"layernorm_fusion\": false,\n\n  # init methods\n  \"init_method\": \"small_init\",\n  \"output_layer_init_method\": \"wang_init\",\n\n  \"optimizer\": {\n    \"type\": \"Adam\",\n    \"params\": {\n      \"lr\": 0.001,\n      \"betas\": [0.9, 0.95],\n      \"eps\": 1.0e-8,\n    }\n  },\n  \"min_lr\": 0.0001,\n\n  # for all zero_optimization options, see https://www.deepspeed.ai/docs/config-json/#zero-optimizations-for-fp16-training\n  \"zero_optimization\": {\n    \"stage\": 1,\n    \"allgather_partitions\": True,\n    \"allgather_bucket_size\": 500000000,\n    \"overlap_comm\": True,\n    \"reduce_scatter\": True,\n    \"reduce_bucket_size\": 500000000,\n    \"contiguous_gradients\": True,\n  },\n\n  \"train_micro_batch_size_per_gpu\": 4, #32,\n  \"gradient_accumulation_steps\": 1,\n  \"data_impl\": \"mmap\",\n  \"num_workers\": 1,\n\n  # activation checkpointing\n  \"checkpoint_activations\": true,\n  \"checkpoint_num_layers\": 1,\n  \"partition_activations\": true,\n  \"synchronize_each_layer\": true,\n\n  # regularization\n  \"gradient_clipping\": 1.0,\n  \"weight_decay\": 0.1,\n  \"hidden_dropout\": 0,\n  \"attention_dropout\": 0,\n\n  # precision settings\n  \"fp16\": {\n    \"fp16\": true,\n    \"enabled\": true,\n    \"loss_scale\": 0,\n    \"loss_scale_window\": 1000,\n    \"initial_scale_power\": 12,\n    \"hysteresis\": 2,\n    \"min_loss_scale\": 1,\n  },\n\n  \"train_iters\": 100,\n  \"lr_decay_iters\": 100,\n  \"distributed_backend\": \"nccl\",\n  \"lr_decay_style\": \"cosine\",\n  \"warmup\": 0.01,\n  \"checkpoint_factor\": 1000,\n  \"eval_interval\": 50,\n  \"eval_iters\": 10,\n\n  \"log_interval\": 10,\n  \"steps_per_print\": 10,\n  \"wall_clock_breakdown\": true,\n\n  # additional deepspeed args not specified above\n  \"deepspeed_extra_args\": {\n    \"comms_logger\": {\n        \"enabled\": true,\n        \"verbose\": true,\n        \"prof_all\": true,\n        \"debug\": false\n    },\n  }\n\n}\n", "local_setup.yml": "# Suggested data paths when using GPT-NeoX locally\n{\n  \"data_path\": \"processed_data/py150_text_document\",\n\n  # or for weighted datasets:\n  # \"train-data-paths\": [\"data/enwik8/enwik8_text_document\", \"data/enwik8/enwik8_text_document\"],\n  # \"test-data-paths\": [\"data/enwik8/enwik8_text_document\", \"data/enwik8/enwik8_text_document\"],\n  # \"valid-data-paths\": [\"data/enwik8/enwik8_text_document\", \"data/enwik8/enwik8_text_document\"],\n  # \"train-data-weights\": [1., 2.],\n  # \"test-data-weights\": [2., 1.],\n  # \"valid-data-weights\": [0.5, 0.4],\n\n  # If weight_by_num_documents is True, Builds dataset weights from a multinomial distribution over groups of data according to the number of documents in each group.\n  # WARNING: setting this to True will override any user provided weights\n  # \"weight_by_num_documents\": false,\n  # \"weighted_sampler_alpha\": 0.3,\n\n  \"vocab_file\": \"data/gpt2-vocab.json\",\n  \"merge_file\": \"data/gpt2-merges.txt\",\n\n  \"save\": \"checkpoints\",\n  \"load\": \"checkpoints\",\n  \"checkpoint_validation_with_forward_pass\": False,\n\n  \"tensorboard_dir\": \"tensorboard\",\n  \"log_dir\": \"logs\",\n}\n", "text_generation.yml": "# Parameters used for text generation\n# Make sure `load` is specified somewhere else\n{\n  # Text gen type: `input-file`, `unconditional` or `interactive`\n  \"text_gen_type\": \"unconditional\",\n\n  # Params for all\n  \"maximum_tokens\": 102,\n  \"prompt_end\": \"\\n\",\n  \"temperature\": 1.0,\n  \"top_p\": 0.0,\n  \"top_k\": 0,\n  \"recompute\": false,\n\n  # `unconditional`: samples\n  \"num_samples\": 10,\n\n  # input/output file\n  \"sample_input_file\": \"sample_input.txt\",\n  \"sample_output_file\": \"sample_output.txt\",\n}\n"}, "load": "checkpoints", "checkpoint_factor": 1000, "batch_size": 4, "train_iters": 100, "eval_iters": 10, "eval_interval": 50, "vocab_file": "data/gpt2-vocab.json", "merge_file": "data/gpt2-merges.txt", "num_workers": 1, "checkpoint_activations": true, "synchronize_each_layer": true, "partition_activations": true, "dynamic_loss_scale": true, "world_size": 1, "log_dir": "logs", "tensorboard_dir": "tensorboard", "log_interval": 10, "text_gen_type": "unconditional", "temperature": 1.0, "maximum_tokens": 102, "sample_input_file": "sample_input.txt", "sample_output_file": "sample_output.txt", "num_samples": 10, "local_rank": 0, "rank": 0, "user_script": "generate.py", "global_num_gpus": 1}\n",
            "[2024-11-01 23:03:36,523] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2024-11-01 23:03:39,794] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.19.3-1+cuda12.2\n",
            "[2024-11-01 23:03:39,794] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.19.3-1\n",
            "[2024-11-01 23:03:39,794] [INFO] [launch.py:138:main] 0 NCCL_VERSION=2.19.3-1\n",
            "[2024-11-01 23:03:39,794] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n",
            "[2024-11-01 23:03:39,794] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.19.3-1+cuda12.2\n",
            "[2024-11-01 23:03:39,794] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n",
            "[2024-11-01 23:03:39,794] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.19.3-1\n",
            "[2024-11-01 23:03:39,794] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0]}\n",
            "[2024-11-01 23:03:39,794] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0\n",
            "[2024-11-01 23:03:39,794] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
            "[2024-11-01 23:03:39,794] [INFO] [launch.py:163:main] dist_world_size=1\n",
            "[2024-11-01 23:03:39,794] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0\n",
            "[2024-11-01 23:03:42,242] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba\n",
            "For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3\n",
            "For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer\n",
            "NeoXArgs.configure_distributed_args() using world size: 1 and model-parallel size: 1 \n",
            "> building GPT2BPETokenizer tokenizer ...\n",
            " > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)\n",
            "> initializing torch distributed ...\n",
            "[2024-11-01 23:03:45,601] [INFO] [comm.py:637:init_distributed] cdb=None\n",
            "[2024-11-01 23:03:45,602] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
            "> initializing model parallel with size 1\n",
            "MPU DP: [0]\n",
            "MPU PP: [0]\n",
            "MPU MP: [0]\n",
            "> setting random seeds to 1234 ...\n",
            "[2024-11-01 23:03:45,608] [INFO] [checkpointing.py:227:model_parallel_cuda_manual_seed] > initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234\n",
            "make: Entering directory '/content/gpt-neox/megatron/data'\n",
            "make: Nothing to be done for 'default'.\n",
            "make: Leaving directory '/content/gpt-neox/megatron/data'\n",
            "building GPT2 model ...\n",
            "SEED_LAYERS=False BASE_SEED=1234 SEED_FN=None\n",
            "Using topology: {ProcessCoord(pipe=0, data=0, model=0): 0}\n",
            "[2024-11-01 23:03:45,638] [INFO] [module.py:375:_partition_layers] Partitioning pipeline stages with method type:transformer|mlp\n",
            "stage=0 layers=11\n",
            "     0: EmbeddingPipe\n",
            "     1: _pre_transformer_block\n",
            "     2: ParallelTransformerLayerPipe\n",
            "     3: ParallelTransformerLayerPipe\n",
            "     4: ParallelTransformerLayerPipe\n",
            "     5: ParallelTransformerLayerPipe\n",
            "     6: ParallelTransformerLayerPipe\n",
            "     7: ParallelTransformerLayerPipe\n",
            "     8: _post_transformer_block\n",
            "     9: NormPipe\n",
            "    10: ParallelLinearPipe\n",
            "  loss: partial\n",
            "Configuring Optimizer type: adam with params: {'lr': 0.0}\n",
            "WARNING: APEX not installed - defaulting to deepspeed's fused adam\n",
            "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py310_cu121/fused_adam/build.ninja...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n",
            "Building extension module fused_adam...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "ninja: no work to do.\n",
            "Loading extension module fused_adam...\n",
            "Time to load fused_adam op: 0.10203361511230469 seconds\n",
            "/usr/local/lib/python3.10/dist-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n",
            "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
            "> learning rate decay style: cosine\n",
            "DeepSpeed is enabled.\n",
            "[2024-11-01 23:03:46,482] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.12.4+02e2ebf, git-hash=02e2ebf, git-branch=HEAD\n",
            "[2024-11-01 23:03:46,827] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 338.62 | msg size: 49.12 MB | algbw (Gbps): 1.22 | busbw (Gbps): 1.22\n",
            "[2024-11-01 23:03:46,828] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.25 | msg size: 1.0 KB | algbw (Gbps): 0.03 | busbw (Gbps): 0.03\n",
            "[2024-11-01 23:03:46,829] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.21 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 23:03:46,829] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.22 | msg size: 1.5 MB | algbw (Gbps): 57.58 | busbw (Gbps): 57.58\n",
            "[2024-11-01 23:03:46,830] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.24 | msg size: 3.0 KB | algbw (Gbps): 0.10 | busbw (Gbps): 0.10\n",
            "[2024-11-01 23:03:46,831] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.21 | msg size: 512.0 KB | algbw (Gbps): 20.37 | busbw (Gbps): 20.37\n",
            "[2024-11-01 23:03:46,831] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.16 | msg size: 1.0 KB | algbw (Gbps): 0.05 | busbw (Gbps): 0.05\n",
            "[2024-11-01 23:03:46,832] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.15 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-01 23:03:46,832] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.17 | msg size: 1.0 KB | algbw (Gbps): 0.05 | busbw (Gbps): 0.05\n",
            "[2024-11-01 23:03:46,833] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.15 | msg size: 2.0 MB | algbw (Gbps): 115.20 | busbw (Gbps): 115.20\n",
            "[2024-11-01 23:03:46,833] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 4.0 KB | algbw (Gbps): 0.23 | busbw (Gbps): 0.23\n",
            "[2024-11-01 23:03:46,834] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 2.0 MB | algbw (Gbps): 118.22 | busbw (Gbps): 118.22\n",
            "[2024-11-01 23:03:46,834] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.15 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-01 23:03:46,835] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-01 23:03:46,835] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.15 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-01 23:03:46,836] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 1.5 MB | algbw (Gbps): 90.23 | busbw (Gbps): 90.23\n",
            "[2024-11-01 23:03:46,836] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.15 | msg size: 3.0 KB | algbw (Gbps): 0.17 | busbw (Gbps): 0.17\n",
            "[2024-11-01 23:03:46,837] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 512.0 KB | algbw (Gbps): 31.01 | busbw (Gbps): 31.01\n",
            "[2024-11-01 23:03:46,837] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-01 23:03:46,838] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.32 | msg size: 1.0 KB | algbw (Gbps): 0.03 | busbw (Gbps): 0.03\n",
            "[2024-11-01 23:03:46,839] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.20 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 23:03:46,839] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.19 | msg size: 2.0 MB | algbw (Gbps): 87.18 | busbw (Gbps): 87.18\n",
            "[2024-11-01 23:03:46,840] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.15 | msg size: 4.0 KB | algbw (Gbps): 0.22 | busbw (Gbps): 0.22\n",
            "[2024-11-01 23:03:46,840] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.16 | msg size: 2.0 MB | algbw (Gbps): 107.59 | busbw (Gbps): 107.59\n",
            "[2024-11-01 23:03:46,841] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-01 23:03:46,841] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-01 23:03:46,841] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.13 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-01 23:03:46,842] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.16 | msg size: 1.5 MB | algbw (Gbps): 77.57 | busbw (Gbps): 77.57\n",
            "[2024-11-01 23:03:46,842] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.13 | msg size: 3.0 KB | algbw (Gbps): 0.18 | busbw (Gbps): 0.18\n",
            "[2024-11-01 23:03:46,843] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.16 | msg size: 512.0 KB | algbw (Gbps): 25.92 | busbw (Gbps): 25.92\n",
            "[2024-11-01 23:03:46,843] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-01 23:03:46,844] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.13 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-01 23:03:46,844] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-01 23:03:46,845] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.15 | msg size: 2.0 MB | algbw (Gbps): 113.68 | busbw (Gbps): 113.68\n",
            "[2024-11-01 23:03:46,845] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 4.0 KB | algbw (Gbps): 0.24 | busbw (Gbps): 0.24\n",
            "[2024-11-01 23:03:46,846] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.13 | msg size: 2.0 MB | algbw (Gbps): 124.33 | busbw (Gbps): 124.33\n",
            "[2024-11-01 23:03:46,846] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-01 23:03:46,847] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-01 23:03:46,847] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.22 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 23:03:46,848] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.20 | msg size: 1.5 MB | algbw (Gbps): 63.22 | busbw (Gbps): 63.22\n",
            "[2024-11-01 23:03:46,848] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.20 | msg size: 3.0 KB | algbw (Gbps): 0.12 | busbw (Gbps): 0.12\n",
            "[2024-11-01 23:03:46,849] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.20 | msg size: 512.0 KB | algbw (Gbps): 21.48 | busbw (Gbps): 21.48\n",
            "[2024-11-01 23:03:46,849] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-01 23:03:46,850] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.19 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-01 23:03:46,850] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-01 23:03:46,851] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 2.0 MB | algbw (Gbps): 123.92 | busbw (Gbps): 123.92\n",
            "[2024-11-01 23:03:46,851] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 4.0 KB | algbw (Gbps): 0.24 | busbw (Gbps): 0.24\n",
            "[2024-11-01 23:03:46,852] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.13 | msg size: 2.0 MB | algbw (Gbps): 124.98 | busbw (Gbps): 124.98\n",
            "[2024-11-01 23:03:46,852] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.16 | msg size: 1.0 KB | algbw (Gbps): 0.05 | busbw (Gbps): 0.05\n",
            "[2024-11-01 23:03:46,853] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-01 23:03:46,853] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.16 | msg size: 1.0 KB | algbw (Gbps): 0.05 | busbw (Gbps): 0.05\n",
            "[2024-11-01 23:03:46,854] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.15 | msg size: 1.5 MB | algbw (Gbps): 86.08 | busbw (Gbps): 86.08\n",
            "[2024-11-01 23:03:46,854] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 3.0 KB | algbw (Gbps): 0.17 | busbw (Gbps): 0.17\n",
            "[2024-11-01 23:03:46,855] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.13 | msg size: 512.0 KB | algbw (Gbps): 31.48 | busbw (Gbps): 31.48\n",
            "[2024-11-01 23:03:46,855] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.15 | msg size: 1.0 KB | algbw (Gbps): 0.05 | busbw (Gbps): 0.05\n",
            "[2024-11-01 23:03:46,855] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-01 23:03:46,856] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.15 | msg size: 1.0 KB | algbw (Gbps): 0.05 | busbw (Gbps): 0.05\n",
            "[2024-11-01 23:03:46,856] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.13 | msg size: 2.0 MB | algbw (Gbps): 124.30 | busbw (Gbps): 124.30\n",
            "[2024-11-01 23:03:46,857] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.13 | msg size: 4.0 KB | algbw (Gbps): 0.24 | busbw (Gbps): 0.24\n",
            "[2024-11-01 23:03:46,857] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 2.0 MB | algbw (Gbps): 120.08 | busbw (Gbps): 120.08\n",
            "[2024-11-01 23:03:46,858] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.13 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-01 23:03:46,858] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.15 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-01 23:03:46,859] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.13 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-01 23:03:46,859] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 1.5 MB | algbw (Gbps): 89.04 | busbw (Gbps): 89.04\n",
            "[2024-11-01 23:03:46,859] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 3.0 KB | algbw (Gbps): 0.18 | busbw (Gbps): 0.18\n",
            "[2024-11-01 23:03:46,860] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.17 | msg size: 512.0 KB | algbw (Gbps): 24.01 | busbw (Gbps): 24.01\n",
            "[2024-11-01 23:03:46,860] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.13 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-01 23:03:46,861] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.13 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-01 23:03:46,861] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-01 23:03:46,862] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 2.0 MB | algbw (Gbps): 124.09 | busbw (Gbps): 124.09\n",
            "[2024-11-01 23:03:46,862] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 4.0 KB | algbw (Gbps): 0.24 | busbw (Gbps): 0.24\n",
            "[2024-11-01 23:03:46,863] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 2.0 MB | algbw (Gbps): 124.12 | busbw (Gbps): 124.12\n",
            "[2024-11-01 23:03:46,863] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.15 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-01 23:03:46,864] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-01 23:03:46,864] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-01 23:03:46,864] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 49.12 MB | algbw (Gbps): 3048.01 | busbw (Gbps): 3048.01\n",
            "[2024-11-01 23:03:46,865] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
            "[2024-11-01 23:03:46,865] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
            "[2024-11-01 23:03:46,865] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
            "[2024-11-01 23:03:46,866] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam\n",
            "[2024-11-01 23:03:46,866] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>\n",
            "[2024-11-01 23:03:46,866] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 1 optimizer\n",
            "[2024-11-01 23:03:46,866] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 500000000\n",
            "[2024-11-01 23:03:46,866] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 500000000\n",
            "[2024-11-01 23:03:46,866] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
            "[2024-11-01 23:03:46,866] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
            "[2024-11-01 23:03:47,140] [INFO] [utils.py:802:see_memory_usage] Before initializing optimizer states\n",
            "[2024-11-01 23:03:47,141] [INFO] [utils.py:803:see_memory_usage] MA 0.23 GB         Max_MA 0.28 GB         CA 0.31 GB         Max_CA 0 GB \n",
            "[2024-11-01 23:03:47,141] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 4.54 GB, percent = 35.9%\n",
            "[2024-11-01 23:03:47,335] [INFO] [utils.py:802:see_memory_usage] After initializing optimizer states\n",
            "[2024-11-01 23:03:47,336] [INFO] [utils.py:803:see_memory_usage] MA 0.42 GB         Max_MA 0.52 GB         CA 0.6 GB         Max_CA 1 GB \n",
            "[2024-11-01 23:03:47,336] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 4.54 GB, percent = 35.9%\n",
            "[2024-11-01 23:03:47,336] [INFO] [stage_1_and_2.py:517:__init__] optimizer state initialized\n",
            "[2024-11-01 23:03:47,521] [INFO] [utils.py:802:see_memory_usage] After initializing ZeRO optimizer\n",
            "[2024-11-01 23:03:47,522] [INFO] [utils.py:803:see_memory_usage] MA 0.42 GB         Max_MA 0.42 GB         CA 0.6 GB         Max_CA 1 GB \n",
            "[2024-11-01 23:03:47,522] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 4.55 GB, percent = 35.9%\n",
            "[2024-11-01 23:03:47,523] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam\n",
            "[2024-11-01 23:03:47,523] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
            "[2024-11-01 23:03:47,523] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <megatron.learning_rates.AnnealingLR object at 0x1362590f1030>\n",
            "[2024-11-01 23:03:47,523] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0], mom=[(0.9, 0.999)]\n",
            "[2024-11-01 23:03:47,523] [INFO] [config.py:979:print] DeepSpeedEngine configuration:\n",
            "[2024-11-01 23:03:47,524] [INFO] [config.py:983:print]   activation_checkpointing_config  {\n",
            "    \"partition_activations\": false, \n",
            "    \"contiguous_memory_optimization\": false, \n",
            "    \"cpu_checkpointing\": false, \n",
            "    \"number_checkpoints\": null, \n",
            "    \"synchronize_checkpoint_boundary\": false, \n",
            "    \"profile\": false\n",
            "}\n",
            "[2024-11-01 23:03:47,524] [INFO] [config.py:983:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
            "[2024-11-01 23:03:47,524] [INFO] [config.py:983:print]   amp_enabled .................. False\n",
            "[2024-11-01 23:03:47,524] [INFO] [config.py:983:print]   amp_params ................... False\n",
            "[2024-11-01 23:03:47,525] [INFO] [config.py:983:print]   autotuning_config ............ {\n",
            "    \"enabled\": false, \n",
            "    \"start_step\": null, \n",
            "    \"end_step\": null, \n",
            "    \"metric_path\": null, \n",
            "    \"arg_mappings\": null, \n",
            "    \"metric\": \"throughput\", \n",
            "    \"model_info\": null, \n",
            "    \"results_dir\": \"autotuning_results\", \n",
            "    \"exps_dir\": \"autotuning_exps\", \n",
            "    \"overwrite\": true, \n",
            "    \"fast\": true, \n",
            "    \"start_profile_step\": 3, \n",
            "    \"end_profile_step\": 5, \n",
            "    \"tuner_type\": \"gridsearch\", \n",
            "    \"tuner_early_stopping\": 5, \n",
            "    \"tuner_num_trials\": 50, \n",
            "    \"model_info_path\": null, \n",
            "    \"mp_size\": 1, \n",
            "    \"max_train_batch_size\": null, \n",
            "    \"min_train_batch_size\": 1, \n",
            "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
            "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
            "    \"num_tuning_micro_batch_sizes\": 3\n",
            "}\n",
            "[2024-11-01 23:03:47,525] [INFO] [config.py:983:print]   bfloat16_enabled ............. False\n",
            "[2024-11-01 23:03:47,525] [INFO] [config.py:983:print]   checkpoint_parallel_write_pipeline  False\n",
            "[2024-11-01 23:03:47,525] [INFO] [config.py:983:print]   checkpoint_tag_validation_enabled  True\n",
            "[2024-11-01 23:03:47,525] [INFO] [config.py:983:print]   checkpoint_tag_validation_fail  False\n",
            "[2024-11-01 23:03:47,525] [INFO] [config.py:983:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x136258d98a30>\n",
            "[2024-11-01 23:03:47,525] [INFO] [config.py:983:print]   communication_data_type ...... None\n",
            "[2024-11-01 23:03:47,525] [INFO] [config.py:983:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
            "[2024-11-01 23:03:47,525] [INFO] [config.py:983:print]   curriculum_enabled_legacy .... False\n",
            "[2024-11-01 23:03:47,525] [INFO] [config.py:983:print]   curriculum_params_legacy ..... False\n",
            "[2024-11-01 23:03:47,525] [INFO] [config.py:983:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
            "[2024-11-01 23:03:47,525] [INFO] [config.py:983:print]   data_efficiency_enabled ...... False\n",
            "[2024-11-01 23:03:47,525] [INFO] [config.py:983:print]   dataloader_drop_last ......... False\n",
            "[2024-11-01 23:03:47,525] [INFO] [config.py:983:print]   disable_allgather ............ False\n",
            "[2024-11-01 23:03:47,525] [INFO] [config.py:983:print]   dump_state ................... False\n",
            "[2024-11-01 23:03:47,525] [INFO] [config.py:983:print]   dynamic_loss_scale_args ...... {'init_scale': 4096, 'scale_window': 1000, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}\n",
            "[2024-11-01 23:03:47,525] [INFO] [config.py:983:print]   eigenvalue_enabled ........... False\n",
            "[2024-11-01 23:03:47,525] [INFO] [config.py:983:print]   eigenvalue_gas_boundary_resolution  1\n",
            "[2024-11-01 23:03:47,525] [INFO] [config.py:983:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
            "[2024-11-01 23:03:47,525] [INFO] [config.py:983:print]   eigenvalue_layer_num ......... 0\n",
            "[2024-11-01 23:03:47,525] [INFO] [config.py:983:print]   eigenvalue_max_iter .......... 100\n",
            "[2024-11-01 23:03:47,526] [INFO] [config.py:983:print]   eigenvalue_stability ......... 1e-06\n",
            "[2024-11-01 23:03:47,526] [INFO] [config.py:983:print]   eigenvalue_tol ............... 0.01\n",
            "[2024-11-01 23:03:47,526] [INFO] [config.py:983:print]   eigenvalue_verbose ........... False\n",
            "[2024-11-01 23:03:47,526] [INFO] [config.py:983:print]   elasticity_enabled ........... False\n",
            "[2024-11-01 23:03:47,526] [INFO] [config.py:983:print]   flops_profiler_config ........ {\n",
            "    \"enabled\": false, \n",
            "    \"recompute_fwd_factor\": 0.0, \n",
            "    \"profile_step\": 1, \n",
            "    \"module_depth\": -1, \n",
            "    \"top_modules\": 1, \n",
            "    \"detailed\": true, \n",
            "    \"output_file\": null\n",
            "}\n",
            "[2024-11-01 23:03:47,526] [INFO] [config.py:983:print]   fp16_auto_cast ............... False\n",
            "[2024-11-01 23:03:47,526] [INFO] [config.py:983:print]   fp16_enabled ................. True\n",
            "[2024-11-01 23:03:47,526] [INFO] [config.py:983:print]   fp16_master_weights_and_gradients  False\n",
            "[2024-11-01 23:03:47,526] [INFO] [config.py:983:print]   global_rank .................. 0\n",
            "[2024-11-01 23:03:47,526] [INFO] [config.py:983:print]   grad_accum_dtype ............. None\n",
            "[2024-11-01 23:03:47,526] [INFO] [config.py:983:print]   gradient_accumulation_steps .. 1\n",
            "[2024-11-01 23:03:47,526] [INFO] [config.py:983:print]   gradient_clipping ............ 0.0\n",
            "[2024-11-01 23:03:47,526] [INFO] [config.py:983:print]   gradient_predivide_factor .... 1.0\n",
            "[2024-11-01 23:03:47,526] [INFO] [config.py:983:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
            "[2024-11-01 23:03:47,526] [INFO] [config.py:983:print]   initial_dynamic_scale ........ 4096\n",
            "[2024-11-01 23:03:47,526] [INFO] [config.py:983:print]   load_universal_checkpoint .... False\n",
            "[2024-11-01 23:03:47,526] [INFO] [config.py:983:print]   loss_scale ................... 0\n",
            "[2024-11-01 23:03:47,526] [INFO] [config.py:983:print]   memory_breakdown ............. False\n",
            "[2024-11-01 23:03:47,526] [INFO] [config.py:983:print]   mics_hierarchial_params_gather  False\n",
            "[2024-11-01 23:03:47,526] [INFO] [config.py:983:print]   mics_shard_size .............. -1\n",
            "[2024-11-01 23:03:47,527] [INFO] [config.py:983:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
            "[2024-11-01 23:03:47,527] [INFO] [config.py:983:print]   nebula_config ................ {\n",
            "    \"enabled\": false, \n",
            "    \"persistent_storage_path\": null, \n",
            "    \"persistent_time_interval\": 100, \n",
            "    \"num_of_version_in_retention\": 2, \n",
            "    \"enable_nebula_load\": true, \n",
            "    \"load_path\": null\n",
            "}\n",
            "[2024-11-01 23:03:47,527] [INFO] [config.py:983:print]   optimizer_legacy_fusion ...... False\n",
            "[2024-11-01 23:03:47,527] [INFO] [config.py:983:print]   optimizer_name ............... None\n",
            "[2024-11-01 23:03:47,527] [INFO] [config.py:983:print]   optimizer_params ............. None\n",
            "[2024-11-01 23:03:47,527] [INFO] [config.py:983:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
            "[2024-11-01 23:03:47,527] [INFO] [config.py:983:print]   pld_enabled .................. False\n",
            "[2024-11-01 23:03:47,527] [INFO] [config.py:983:print]   pld_params ................... False\n",
            "[2024-11-01 23:03:47,527] [INFO] [config.py:983:print]   prescale_gradients ........... False\n",
            "[2024-11-01 23:03:47,527] [INFO] [config.py:983:print]   scheduler_name ............... None\n",
            "[2024-11-01 23:03:47,527] [INFO] [config.py:983:print]   scheduler_params ............. None\n",
            "[2024-11-01 23:03:47,527] [INFO] [config.py:983:print]   seq_parallel_communication_data_type  torch.float32\n",
            "[2024-11-01 23:03:47,527] [INFO] [config.py:983:print]   sparse_attention ............. None\n",
            "[2024-11-01 23:03:47,527] [INFO] [config.py:983:print]   sparse_gradients_enabled ..... False\n",
            "[2024-11-01 23:03:47,527] [INFO] [config.py:983:print]   steps_per_print .............. 10\n",
            "[2024-11-01 23:03:47,527] [INFO] [config.py:983:print]   train_batch_size ............. 4\n",
            "[2024-11-01 23:03:47,527] [INFO] [config.py:983:print]   train_micro_batch_size_per_gpu  4\n",
            "[2024-11-01 23:03:47,527] [INFO] [config.py:983:print]   use_data_before_expert_parallel_  False\n",
            "[2024-11-01 23:03:47,527] [INFO] [config.py:983:print]   use_node_local_storage ....... False\n",
            "[2024-11-01 23:03:47,527] [INFO] [config.py:983:print]   wall_clock_breakdown ......... True\n",
            "[2024-11-01 23:03:47,527] [INFO] [config.py:983:print]   weight_quantization_config ... None\n",
            "[2024-11-01 23:03:47,527] [INFO] [config.py:983:print]   world_size ................... 1\n",
            "[2024-11-01 23:03:47,527] [INFO] [config.py:983:print]   zero_allow_untested_optimizer  False\n",
            "[2024-11-01 23:03:47,528] [INFO] [config.py:983:print]   zero_config .................. stage=1 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
            "[2024-11-01 23:03:47,528] [INFO] [config.py:983:print]   zero_enabled ................. True\n",
            "[2024-11-01 23:03:47,528] [INFO] [config.py:983:print]   zero_force_ds_cpu_optimizer .. True\n",
            "[2024-11-01 23:03:47,528] [INFO] [config.py:983:print]   zero_optimization_stage ...... 1\n",
            "[2024-11-01 23:03:47,528] [INFO] [config.py:969:print_user_config]   json = {\n",
            "    \"train_batch_size\": 4, \n",
            "    \"train_micro_batch_size_per_gpu\": 4, \n",
            "    \"optimizer\": {\n",
            "        \"params\": {\n",
            "            \"lr\": 0.0\n",
            "        }\n",
            "    }, \n",
            "    \"fp16\": {\n",
            "        \"fp16\": true, \n",
            "        \"enabled\": true, \n",
            "        \"loss_scale\": 0, \n",
            "        \"loss_scale_window\": 1000, \n",
            "        \"initial_scale_power\": 12, \n",
            "        \"hysteresis\": 2, \n",
            "        \"min_loss_scale\": 1\n",
            "    }, \n",
            "    \"zero_optimization\": {\n",
            "        \"stage\": 1, \n",
            "        \"allgather_partitions\": true, \n",
            "        \"allgather_bucket_size\": 5.000000e+08, \n",
            "        \"overlap_comm\": true, \n",
            "        \"reduce_scatter\": true, \n",
            "        \"reduce_bucket_size\": 5.000000e+08, \n",
            "        \"contiguous_gradients\": true\n",
            "    }, \n",
            "    \"wall_clock_breakdown\": true, \n",
            "    \"comms_logger\": {\n",
            "        \"enabled\": true, \n",
            "        \"verbose\": true, \n",
            "        \"prof_all\": true, \n",
            "        \"debug\": false\n",
            "    }\n",
            "}\n",
            " > number of parameters on model parallel rank 0: 70426624\n",
            " > total params: 70,426,624\n",
            "[2024-11-01 23:03:47,586] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from checkpoints/global_step100/mp_rank_00_model_states.pt...\n",
            "[2024-11-01 23:03:48,105] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from checkpoints/global_step100/mp_rank_00_model_states.pt.\n",
            "[2024-11-01 23:03:48,113] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from checkpoints/global_step100/mp_rank_00_model_states.pt...\n",
            "[2024-11-01 23:03:48,194] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from checkpoints/global_step100/mp_rank_00_model_states.pt.\n",
            " > validated currently set args with arguments in the checkpoint ...\n",
            "  successfully loaded checkpoints/global_step100/mp_rank_00_model_states.pt\n",
            "Loading checkpoint and starting from iteration 100\n",
            "Finished loading model\n",
            "Generating samples unconditionally and saving results to sample_output.txt\n",
            "generate_samples_unconditional() generating...\n",
            "[rank0]: Traceback (most recent call last):\n",
            "[rank0]:   File \"/content/gpt-neox/generate.py\", line 96, in <module>\n",
            "[rank0]:     main()\n",
            "[rank0]:   File \"/content/gpt-neox/generate.py\", line 45, in main\n",
            "[rank0]:     generate_samples_unconditional(\n",
            "[rank0]:   File \"/content/gpt-neox/megatron/text_generation_utils.py\", line 692, in generate_samples_unconditional\n",
            "[rank0]:     generated_texts = generate_samples_from_prompt(\n",
            "[rank0]:   File \"/content/gpt-neox/megatron/text_generation_utils.py\", line 492, in generate_samples_from_prompt\n",
            "[rank0]:     for (\n",
            "[rank0]:   File \"/content/gpt-neox/megatron/text_generation_utils.py\", line 331, in stream_tokens\n",
            "[rank0]:     logits[:, -1].view(batch_size, -1).contiguous()\n",
            "[rank0]: TypeError: tuple indices must be integers or slices, not tuple\n",
            "[2024-11-01 23:03:51,808] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 30393\n",
            "[2024-11-01 23:03:51,808] [ERROR] [launch.py:321:sigkill_handler] ['/usr/bin/python3', '-u', 'generate.py', '--local_rank=0', '--deepspeed_config', 'eyJ0cmFpbl9iYXRjaF9zaXplIjogNCwgInRyYWluX21pY3JvX2JhdGNoX3NpemVfcGVyX2dwdSI6IDQsICJvcHRpbWl6ZXIiOiB7InR5cGUiOiAiQWRhbSIsICJwYXJhbXMiOiB7ImxyIjogMC4wMDEsICJiZXRhcyI6IFswLjksIDAuOTVdLCAiZXBzIjogMWUtMDh9fSwgImZwMTYiOiB7ImZwMTYiOiB0cnVlLCAiZW5hYmxlZCI6IHRydWUsICJsb3NzX3NjYWxlIjogMCwgImxvc3Nfc2NhbGVfd2luZG93IjogMTAwMCwgImluaXRpYWxfc2NhbGVfcG93ZXIiOiAxMiwgImh5c3RlcmVzaXMiOiAyLCAibWluX2xvc3Nfc2NhbGUiOiAxfSwgInplcm9fb3B0aW1pemF0aW9uIjogeyJzdGFnZSI6IDEsICJhbGxnYXRoZXJfcGFydGl0aW9ucyI6IHRydWUsICJhbGxnYXRoZXJfYnVja2V0X3NpemUiOiA1MDAwMDAwMDAsICJvdmVybGFwX2NvbW0iOiB0cnVlLCAicmVkdWNlX3NjYXR0ZXIiOiB0cnVlLCAicmVkdWNlX2J1Y2tldF9zaXplIjogNTAwMDAwMDAwLCAiY29udGlndW91c19ncmFkaWVudHMiOiB0cnVlfSwgIndhbGxfY2xvY2tfYnJlYWtkb3duIjogdHJ1ZSwgImNvbW1zX2xvZ2dlciI6IHsiZW5hYmxlZCI6IHRydWUsICJ2ZXJib3NlIjogdHJ1ZSwgInByb2ZfYWxsIjogdHJ1ZSwgImRlYnVnIjogZmFsc2V9fQ==', '--megatron_config', '{"train_batch_size": 4, "train_micro_batch_size_per_gpu": 4, "optimizer": {"type": "Adam", "params": {"lr": 0.001, "betas": [0.9, 0.95], "eps": 1e-08}}, "fp16": {"fp16": true, "enabled": true, "loss_scale": 0, "loss_scale_window": 1000, "initial_scale_power": 12, "hysteresis": 2, "min_loss_scale": 1}, "zero_optimization": {"stage": 1, "allgather_partitions": true, "allgather_bucket_size": 500000000, "overlap_comm": true, "reduce_scatter": true, "reduce_bucket_size": 500000000, "contiguous_gradients": true}, "wall_clock_breakdown": true, "deepspeed_extra_args": {"comms_logger": {"enabled": true, "verbose": true, "prof_all": true, "debug": false}}, "precision": "fp16", "num_layers": 6, "hidden_size": 512, "num_attention_heads": 8, "seq_length": 2048, "max_position_embeddings": 2048, "pos_emb": "rotary", "no_weight_tying": true, "attention_config": ["global", "global", "global", "global", "global", "global"], "sparsity_config": {}, "init_method": "small_init", "output_layer_init_method": "wang_init", "lr_decay_style": "cosine", "lr_decay_iters": 100, "min_lr": 0.0001, "optimizer_type": "Adam", "zero_stage": 1, "zero_reduce_scatter": true, "zero_contiguous_gradients": true, "zero_reduce_bucket_size": 500000000, "zero_allgather_bucket_size": 500000000, "lr": 0.001, "data_path": "processed_data/py150_text_document", "data_impl": "mmap", "save": "checkpoints", "config_files": {"19M.yml": "{\n  \"pipe_parallel_size\": 0,\n  \"model_parallel_size\": 1,\n\n  # model settings\n  \"num_layers\": 6,\n  \"hidden_size\": 512,\n  \"num_attention_heads\": 8,\n  \"seq_length\": 2048,\n  \"max_position_embeddings\": 2048,\n  \"pos_emb\": \"rotary\",\n  \"no_weight_tying\": true,\n  \"gpt_j_residual\": false,\n  \"output_layer_parallelism\": \"column\",\n\n  \"scaled_upper_triang_masked_softmax_fusion\": false,\n  \"bias_gelu_fusion\": false,\n  \"rope_fusion\": false,\n  \"layernorm_fusion\": false,\n\n  # init methods\n  \"init_method\": \"small_init\",\n  \"output_layer_init_method\": \"wang_init\",\n\n  \"optimizer\": {\n    \"type\": \"Adam\",\n    \"params\": {\n      \"lr\": 0.001,\n      \"betas\": [0.9, 0.95],\n      \"eps\": 1.0e-8,\n    }\n  },\n  \"min_lr\": 0.0001,\n\n  # for all zero_optimization options, see https://www.deepspeed.ai/docs/config-json/#zero-optimizations-for-fp16-training\n  \"zero_optimization\": {\n    \"stage\": 1,\n    \"allgather_partitions\": True,\n    \"allgather_bucket_size\": 500000000,\n    \"overlap_comm\": True,\n    \"reduce_scatter\": True,\n    \"reduce_bucket_size\": 500000000,\n    \"contiguous_gradients\": True,\n  },\n\n  \"train_micro_batch_size_per_gpu\": 4, #32,\n  \"gradient_accumulation_steps\": 1,\n  \"data_impl\": \"mmap\",\n  \"num_workers\": 1,\n\n  # activation checkpointing\n  \"checkpoint_activations\": true,\n  \"checkpoint_num_layers\": 1,\n  \"partition_activations\": true,\n  \"synchronize_each_layer\": true,\n\n  # regularization\n  \"gradient_clipping\": 1.0,\n  \"weight_decay\": 0.1,\n  \"hidden_dropout\": 0,\n  \"attention_dropout\": 0,\n\n  # precision settings\n  \"fp16\": {\n    \"fp16\": true,\n    \"enabled\": true,\n    \"loss_scale\": 0,\n    \"loss_scale_window\": 1000,\n    \"initial_scale_power\": 12,\n    \"hysteresis\": 2,\n    \"min_loss_scale\": 1,\n  },\n\n  \"train_iters\": 100,\n  \"lr_decay_iters\": 100,\n  \"distributed_backend\": \"nccl\",\n  \"lr_decay_style\": \"cosine\",\n  \"warmup\": 0.01,\n  \"checkpoint_factor\": 1000,\n  \"eval_interval\": 50,\n  \"eval_iters\": 10,\n\n  \"log_interval\": 10,\n  \"steps_per_print\": 10,\n  \"wall_clock_breakdown\": true,\n\n  # additional deepspeed args not specified above\n  \"deepspeed_extra_args\": {\n    \"comms_logger\": {\n        \"enabled\": true,\n        \"verbose\": true,\n        \"prof_all\": true,\n        \"debug\": false\n    },\n  }\n\n}\n", "local_setup.yml": "# Suggested data paths when using GPT-NeoX locally\n{\n  \"data_path\": \"processed_data/py150_text_document\",\n\n  # or for weighted datasets:\n  # \"train-data-paths\": [\"data/enwik8/enwik8_text_document\", \"data/enwik8/enwik8_text_document\"],\n  # \"test-data-paths\": [\"data/enwik8/enwik8_text_document\", \"data/enwik8/enwik8_text_document\"],\n  # \"valid-data-paths\": [\"data/enwik8/enwik8_text_document\", \"data/enwik8/enwik8_text_document\"],\n  # \"train-data-weights\": [1., 2.],\n  # \"test-data-weights\": [2., 1.],\n  # \"valid-data-weights\": [0.5, 0.4],\n\n  # If weight_by_num_documents is True, Builds dataset weights from a multinomial distribution over groups of data according to the number of documents in each group.\n  # WARNING: setting this to True will override any user provided weights\n  # \"weight_by_num_documents\": false,\n  # \"weighted_sampler_alpha\": 0.3,\n\n  \"vocab_file\": \"data/gpt2-vocab.json\",\n  \"merge_file\": \"data/gpt2-merges.txt\",\n\n  \"save\": \"checkpoints\",\n  \"load\": \"checkpoints\",\n  \"checkpoint_validation_with_forward_pass\": False,\n\n  \"tensorboard_dir\": \"tensorboard\",\n  \"log_dir\": \"logs\",\n}\n", "text_generation.yml": "# Parameters used for text generation\n# Make sure `load` is specified somewhere else\n{\n  # Text gen type: `input-file`, `unconditional` or `interactive`\n  \"text_gen_type\": \"unconditional\",\n\n  # Params for all\n  \"maximum_tokens\": 102,\n  \"prompt_end\": \"\\n\",\n  \"temperature\": 1.0,\n  \"top_p\": 0.0,\n  \"top_k\": 0,\n  \"recompute\": false,\n\n  # `unconditional`: samples\n  \"num_samples\": 10,\n\n  # input/output file\n  \"sample_input_file\": \"sample_input.txt\",\n  \"sample_output_file\": \"sample_output.txt\",\n}\n"}, "load": "checkpoints", "checkpoint_factor": 1000, "batch_size": 4, "train_iters": 100, "eval_iters": 10, "eval_interval": 50, "vocab_file": "data/gpt2-vocab.json", "merge_file": "data/gpt2-merges.txt", "num_workers": 1, "checkpoint_activations": true, "synchronize_each_layer": true, "partition_activations": true, "dynamic_loss_scale": true, "world_size": 1, "log_dir": "logs", "tensorboard_dir": "tensorboard", "log_interval": 10, "text_gen_type": "unconditional", "temperature": 1.0, "maximum_tokens": 102, "sample_input_file": "sample_input.txt", "sample_output_file": "sample_output.txt", "num_samples": 10, "local_rank": 0, "rank": 0, "user_script": "generate.py", "global_num_gpus": 1}'] exits with return code = 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorboard.backend.event_processing import event_accumulator\n",
        "import os\n",
        "import numpy as np\n",
        "# Path to the latest log file\n",
        "log_dir = \"tensorboard\"\n",
        "log_files = [os.path.join(log_dir, d) for d in os.listdir(log_dir)]\n",
        "latest_log_dir = max(log_files, key=os.path.getmtime)\n",
        "\n",
        "# Initialize EventAccumulator to load scalar data\n",
        "ea = event_accumulator.EventAccumulator(latest_log_dir)\n",
        "ea.Reload()  # Load all logs\n",
        "\n",
        "# List all scalar keys available in the logs\n",
        "scalar_keys = ea.Tags()['scalars']\n",
        "print(\"Available scalar keys:\", scalar_keys)\n",
        "\n",
        "# Extract training and validation losses\n",
        "train_loss = ea.Scalars('train/lm_loss')  # Adjust for actual name if necessary\n",
        "val_loss = ea.Scalars('validation/lm_loss')  # Adjust for actual name if necessary\n",
        "\n",
        "# Convert to lists for plotting\n",
        "train_loss_values = [x.value for x in train_loss]\n",
        "val_loss_values = [x.value for x in val_loss]\n",
        "\n",
        "# Find the lengths of both arrays\n",
        "len_train = len(train_loss_values)\n",
        "len_val = len(val_loss_values)\n",
        "\n",
        "iterations = None\n",
        "# Interpolate the shorter array\n",
        "if len_train != len_val:\n",
        "    if len_train > len_val:\n",
        "        # Interpolate validation loss to match the training loss length\n",
        "        iterations = np.linspace(1, len_train, len_train)\n",
        "        val_iterations = np.linspace(1, len_train, len_val)\n",
        "        val_loss_values = np.interp(iterations, val_iterations, val_loss_values)\n",
        "    else:\n",
        "        # Interpolate training loss to match the validation loss length\n",
        "        iterations = np.linspace(1, len_val, len_val)\n",
        "        train_iterations = np.linspace(1, len_val, len_train)\n",
        "        train_loss_values = np.interp(iterations, train_iterations, train_loss_values)\n",
        "else:\n",
        "    iterations = range(1, len_train + 1)\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(iterations, train_loss_values, label='Training Loss')\n",
        "plt.plot(iterations, val_loss_values, label='Validation Loss')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "id": "rYKP6ya8Iqej",
        "outputId": "9ebe0784-00e3-4faa-8d4d-4f30b6389841"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available scalar keys: ['timers/forward', 'timers/backward', 'timers/backward-backward', 'timers/backward-allreduce', 'timers/optimizer', 'timers/batch generator', 'train/learning_rate', 'train/lm_loss', 'train/loss_scale', 'runtime/samples_per_sec', 'runtime/iteration_time', 'runtime/flops_per_sec_per_gpu', 'validation/lm_loss', 'validation/lm_loss_ppl', 'test/lm_loss', 'test/lm_loss_ppl']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HuggingFace Inference"
      ],
      "metadata": {
        "id": "RNB4sSsS-RN3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert Our Model to HuggingFace Format"
      ],
      "metadata": {
        "id": "5IOlAoGw-jZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the path to the checkpoints directory\n",
        "checkpoints_dir = \"/content/gpt-neox/checkpoints\"\n",
        "\n",
        "# Read the 'latest' file to get the latest checkpoint name\n",
        "with open(os.path.join(checkpoints_dir, \"latest\"), \"r\") as f:\n",
        "    latest_checkpoint_name = f.read().strip()\n",
        "\n",
        "# Construct the full path to the latest checkpoint directory\n",
        "latest_checkpoint_path = os.path.join(checkpoints_dir, latest_checkpoint_name)\n",
        "print(\"Path to the latest checkpoint:\", latest_checkpoint_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfKL-k5k-DQj",
        "outputId": "7958cff8-2fa9-42bb-8a1a-2a288a261749"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to the latest checkpoint: /content/gpt-neox/checkpoints/global_step100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./tools/ckpts/convert_neox_to_hf.py --input_dir {latest_checkpoint_path} --config_file /content/GPT-NeoX-Colab/configs/CC19M.yml --output_dir hf_model/save/location --precision auto --architecture neox"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPbSUBro-25L",
        "outputId": "faea9cac-5a68-4f83-ca55-8a93d563805b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-11-01 23:27:25,261] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "Detected 'pipe-parallel-size' of 0, assuming model is saved as Sequential...\n",
            "> building GPT2BPETokenizer tokenizer ...\n",
            " > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)\n",
            "Auto-detecting precision to save model into...\n",
            "Saving weights in fp16 precision...\n",
            "['sequential.0.word_embeddings.weight', 'sequential.2.input_layernorm.weight', 'sequential.2.input_layernorm.bias', 'sequential.2.attention.query_key_value.weight', 'sequential.2.attention.query_key_value.bias', 'sequential.2.attention.dense.weight', 'sequential.2.attention.dense.bias', 'sequential.2.post_attention_layernorm.weight', 'sequential.2.post_attention_layernorm.bias', 'sequential.2.mlp.linear1.weight', 'sequential.2.mlp.linear1.bias', 'sequential.2.mlp.linear2.weight', 'sequential.2.mlp.linear2.bias', 'sequential.3.input_layernorm.weight', 'sequential.3.input_layernorm.bias', 'sequential.3.attention.query_key_value.weight', 'sequential.3.attention.query_key_value.bias', 'sequential.3.attention.dense.weight', 'sequential.3.attention.dense.bias', 'sequential.3.post_attention_layernorm.weight', 'sequential.3.post_attention_layernorm.bias', 'sequential.3.mlp.linear1.weight', 'sequential.3.mlp.linear1.bias', 'sequential.3.mlp.linear2.weight', 'sequential.3.mlp.linear2.bias', 'sequential.4.input_layernorm.weight', 'sequential.4.input_layernorm.bias', 'sequential.4.attention.query_key_value.weight', 'sequential.4.attention.query_key_value.bias', 'sequential.4.attention.dense.weight', 'sequential.4.attention.dense.bias', 'sequential.4.post_attention_layernorm.weight', 'sequential.4.post_attention_layernorm.bias', 'sequential.4.mlp.linear1.weight', 'sequential.4.mlp.linear1.bias', 'sequential.4.mlp.linear2.weight', 'sequential.4.mlp.linear2.bias', 'sequential.5.input_layernorm.weight', 'sequential.5.input_layernorm.bias', 'sequential.5.attention.query_key_value.weight', 'sequential.5.attention.query_key_value.bias', 'sequential.5.attention.dense.weight', 'sequential.5.attention.dense.bias', 'sequential.5.post_attention_layernorm.weight', 'sequential.5.post_attention_layernorm.bias', 'sequential.5.mlp.linear1.weight', 'sequential.5.mlp.linear1.bias', 'sequential.5.mlp.linear2.weight', 'sequential.5.mlp.linear2.bias', 'sequential.6.input_layernorm.weight', 'sequential.6.input_layernorm.bias', 'sequential.6.attention.query_key_value.weight', 'sequential.6.attention.query_key_value.bias', 'sequential.6.attention.dense.weight', 'sequential.6.attention.dense.bias', 'sequential.6.post_attention_layernorm.weight', 'sequential.6.post_attention_layernorm.bias', 'sequential.6.mlp.linear1.weight', 'sequential.6.mlp.linear1.bias', 'sequential.6.mlp.linear2.weight', 'sequential.6.mlp.linear2.bias', 'sequential.7.input_layernorm.weight', 'sequential.7.input_layernorm.bias', 'sequential.7.attention.query_key_value.weight', 'sequential.7.attention.query_key_value.bias', 'sequential.7.attention.dense.weight', 'sequential.7.attention.dense.bias', 'sequential.7.post_attention_layernorm.weight', 'sequential.7.post_attention_layernorm.bias', 'sequential.7.mlp.linear1.weight', 'sequential.7.mlp.linear1.bias', 'sequential.7.mlp.linear2.weight', 'sequential.7.mlp.linear2.bias', 'sequential.9.norm.weight', 'sequential.9.norm.bias', 'sequential.10.final_linear.weight']\n",
            "Detected MLP naming convention: new\n",
            "100% 6/6 [00:00<00:00, 135.74it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code Completion"
      ],
      "metadata": {
        "id": "GVuBSMByImpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPTNeoXForCausalLM\n",
        "import torch\n",
        "\n",
        "# Move to model directory\n",
        "%cd /content/gpt-neox\n",
        "\n",
        "# Assuming CharLevelTokenizer is properly imported and instantiated\n",
        "from megatron.tokenizer.tokenizer import _GPT2BPETokenizer\n",
        "tokenizer = _GPT2BPETokenizer(vocab_file=\"data/gpt2-vocab.json\", merge_file=\"data/gpt2-merges.txt\")\n",
        "\n",
        "# Load your model\n",
        "model_path = \"/content/gpt-neox/hf_model/save/location\"\n",
        "model = GPTNeoXForCausalLM.from_pretrained(model_path)\n",
        "\n",
        "# Define a simple char-level tokenizer if not provided\n",
        "def char_level_tokenize(text):\n",
        "    return tokenizer.tokenize(text)\n",
        "\n",
        "def char_level_detokenize(tokens):\n",
        "    return tokenizer.detokenize(tokens)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Prompt the user for input\n",
        "#input_text = input(\"Enter your prompt: \")\n",
        "input_text = \"<s> import os\"\n",
        "\n",
        "# Tokenize and prepare input\n",
        "input_ids = torch.tensor([char_level_tokenize(input_text)], dtype=torch.long)\n",
        "attention_mask = torch.ones_like(input_ids)  # Create an attention mask for non-padded input\n",
        "\n",
        "# Generate text with specified pad_token_id and attention_mask\n",
        "with torch.no_grad():\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        max_length=200,          # Adjust this for desired output length\n",
        "        temperature=0.7,        # Controls creativity\n",
        "        top_k=50,               # Controls diversity\n",
        "        top_p=0.9,              # Nucleus sampling\n",
        "        num_return_sequences=1, # Number of sequences to return\n",
        "        pad_token_id=model.config.eos_token_id,  # Set pad_token_id explicitly\n",
        "        do_sample=True           # Enable sampling mode to use temperature and top_p\n",
        "    )\n",
        "\n",
        "# Decode and print the generated text\n",
        "generated_text = char_level_detokenize(output[0].tolist())\n",
        "print(\"Generated text:\", generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztr-ItKf_G1M",
        "outputId": "0d2cd2b1-0be6-4a18-de2c-2e56d360afc3"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gpt-neox\n",
            "Generated text: <s> import os._id ( ), ) ) ), (, )., <EOL> self. data. _ = True, <EOL>. set_d ( self ) ) ) <EOL> self. __ ( ) <EOL> self. _1 = _ [ '<STR_LIT>' ) <EOL> ) <EOL> self. _1 ( \"<STR_LIT:1>' ) <EOL> def set_config ( ) <EOL> class_name ( self ) ) <EOL> self. _name, '<STR_LIT>', <EOL> return [ '<STR_LIT>', '<STR_LIT>', <EOL> return ( self. assert_name, self, '<STR_LIT:1>', <EOL> ) <EOL> import os. _1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BKMXxIklEFhL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}