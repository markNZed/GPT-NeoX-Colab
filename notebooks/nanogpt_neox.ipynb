{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMdhzMqpvb/eAjCFk+IlSZw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Installing Python3.8"],"metadata":{"id":"UFHX4BjTqtKW"}},{"cell_type":"code","source":["!python --version"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JB43Ced8qGox","executionInfo":{"status":"ok","timestamp":1730059702584,"user_tz":-300,"elapsed":685,"user":{"displayName":"Syed Anwar","userId":"02441741431658012689"}},"outputId":"38d30906-7fc5-4c9e-b988-9f75ff5ffba6"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.10.12\n"]}]},{"cell_type":"code","source":["!apt-get update -y\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HwFvOxFTqQAf","executionInfo":{"status":"ok","timestamp":1730046040984,"user_tz":-300,"elapsed":6285,"user":{"displayName":"Syed Anwar","userId":"02441741431658012689"}},"outputId":"a485ce2d-9aee-4622-8ea8-8506c7f6b3fb"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n","Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n","Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n","Ign:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n","Get:6 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n","Get:7 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n","Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n","Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,071 kB]\n","Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n","Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,601 kB]\n","Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,425 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,654 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,450 kB]\n","Fetched 16.6 MB in 3s (5,378 kB/s)\n","Reading package lists... Done\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"]}]},{"cell_type":"code","source":["!apt-get install python3.8 python3.8-distutils"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QTB2_MQRqg3b","executionInfo":{"status":"ok","timestamp":1730046055437,"user_tz":-300,"elapsed":12678,"user":{"displayName":"Syed Anwar","userId":"02441741431658012689"}},"outputId":"cba1c96e-8794-43af-b912-b527a361f97a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  libpython3.8-minimal libpython3.8-stdlib mailcap mime-support python3.8-lib2to3 python3.8-minimal\n","Suggested packages:\n","  python3.8-venv binfmt-support\n","The following NEW packages will be installed:\n","  libpython3.8-minimal libpython3.8-stdlib mailcap mime-support python3.8 python3.8-distutils\n","  python3.8-lib2to3 python3.8-minimal\n","0 upgraded, 8 newly installed, 0 to remove and 50 not upgraded.\n","Need to get 5,422 kB of archives.\n","After this operation, 20.2 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 mailcap all 3.70+nmu1ubuntu1 [23.8 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 mime-support all 3.66 [3,696 B]\n","Get:3 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-minimal amd64 3.8.20-1+jammy1 [796 kB]\n","Get:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-minimal amd64 3.8.20-1+jammy1 [2,023 kB]\n","Get:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-stdlib amd64 3.8.20-1+jammy1 [1,817 kB]\n","Get:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8 amd64 3.8.20-1+jammy1 [440 kB]\n","Get:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-lib2to3 all 3.8.20-1+jammy1 [126 kB]\n","Get:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-distutils all 3.8.20-1+jammy1 [193 kB]\n","Fetched 5,422 kB in 1s (3,938 kB/s)\n","Selecting previously unselected package libpython3.8-minimal:amd64.\n","(Reading database ... 123622 files and directories currently installed.)\n","Preparing to unpack .../0-libpython3.8-minimal_3.8.20-1+jammy1_amd64.deb ...\n","Unpacking libpython3.8-minimal:amd64 (3.8.20-1+jammy1) ...\n","Selecting previously unselected package python3.8-minimal.\n","Preparing to unpack .../1-python3.8-minimal_3.8.20-1+jammy1_amd64.deb ...\n","Unpacking python3.8-minimal (3.8.20-1+jammy1) ...\n","Selecting previously unselected package mailcap.\n","Preparing to unpack .../2-mailcap_3.70+nmu1ubuntu1_all.deb ...\n","Unpacking mailcap (3.70+nmu1ubuntu1) ...\n","Selecting previously unselected package mime-support.\n","Preparing to unpack .../3-mime-support_3.66_all.deb ...\n","Unpacking mime-support (3.66) ...\n","Selecting previously unselected package libpython3.8-stdlib:amd64.\n","Preparing to unpack .../4-libpython3.8-stdlib_3.8.20-1+jammy1_amd64.deb ...\n","Unpacking libpython3.8-stdlib:amd64 (3.8.20-1+jammy1) ...\n","Selecting previously unselected package python3.8.\n","Preparing to unpack .../5-python3.8_3.8.20-1+jammy1_amd64.deb ...\n","Unpacking python3.8 (3.8.20-1+jammy1) ...\n","Selecting previously unselected package python3.8-lib2to3.\n","Preparing to unpack .../6-python3.8-lib2to3_3.8.20-1+jammy1_all.deb ...\n","Unpacking python3.8-lib2to3 (3.8.20-1+jammy1) ...\n","Selecting previously unselected package python3.8-distutils.\n","Preparing to unpack .../7-python3.8-distutils_3.8.20-1+jammy1_all.deb ...\n","Unpacking python3.8-distutils (3.8.20-1+jammy1) ...\n","Setting up libpython3.8-minimal:amd64 (3.8.20-1+jammy1) ...\n","Setting up python3.8-lib2to3 (3.8.20-1+jammy1) ...\n","Setting up python3.8-minimal (3.8.20-1+jammy1) ...\n","Setting up python3.8-distutils (3.8.20-1+jammy1) ...\n","Setting up mailcap (3.70+nmu1ubuntu1) ...\n","Setting up mime-support (3.66) ...\n","Setting up libpython3.8-stdlib:amd64 (3.8.20-1+jammy1) ...\n","Setting up python3.8 (3.8.20-1+jammy1) ...\n","Processing triggers for man-db (2.10.2-1) ...\n"]}]},{"cell_type":"code","source":["!update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H7NdtOHbqp5U","executionInfo":{"status":"ok","timestamp":1730046055438,"user_tz":-300,"elapsed":13,"user":{"displayName":"Syed Anwar","userId":"02441741431658012689"}},"outputId":"79e3a2aa-2ff3-4aab-9e99-31f4c8f5211b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["update-alternatives: using /usr/bin/python3.8 to provide /usr/bin/python3 (python3) in auto mode\n"]}]},{"cell_type":"code","source":["!update-alternatives --config python3\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oIHdFB3Vq5UK","executionInfo":{"status":"ok","timestamp":1730046055958,"user_tz":-300,"elapsed":524,"user":{"displayName":"Syed Anwar","userId":"02441741431658012689"}},"outputId":"849cecb5-f357-4eba-d3b4-491fb44d98c5"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["There is only one alternative in link group python3 (providing /usr/bin/python3): /usr/bin/python3.8\n","Nothing to configure.\n"]}]},{"cell_type":"code","source":["!apt-get install python3-pip\n","!python3 -m pip install --upgrade pip --user"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OHaN6PD-q_TY","executionInfo":{"status":"ok","timestamp":1730046072844,"user_tz":-300,"elapsed":16899,"user":{"displayName":"Syed Anwar","userId":"02441741431658012689"}},"outputId":"142e62c0-4a99-473d-b278-c2c0192e48cd"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  python3-setuptools python3-wheel\n","Suggested packages:\n","  python-setuptools-doc\n","The following NEW packages will be installed:\n","  python3-pip python3-setuptools python3-wheel\n","0 upgraded, 3 newly installed, 0 to remove and 50 not upgraded.\n","Need to get 1,677 kB of archives.\n","After this operation, 8,968 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-setuptools all 59.6.0-1.2ubuntu0.22.04.2 [340 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-wheel all 0.37.1-2ubuntu0.22.04.1 [32.0 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip all 22.0.2+dfsg-1ubuntu0.4 [1,305 kB]\n","Fetched 1,677 kB in 1s (1,637 kB/s)\n","Selecting previously unselected package python3-setuptools.\n","(Reading database ... 124412 files and directories currently installed.)\n","Preparing to unpack .../python3-setuptools_59.6.0-1.2ubuntu0.22.04.2_all.deb ...\n","Unpacking python3-setuptools (59.6.0-1.2ubuntu0.22.04.2) ...\n","Selecting previously unselected package python3-wheel.\n","Preparing to unpack .../python3-wheel_0.37.1-2ubuntu0.22.04.1_all.deb ...\n","Unpacking python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n","Selecting previously unselected package python3-pip.\n","Preparing to unpack .../python3-pip_22.0.2+dfsg-1ubuntu0.4_all.deb ...\n","Unpacking python3-pip (22.0.2+dfsg-1ubuntu0.4) ...\n","Setting up python3-setuptools (59.6.0-1.2ubuntu0.22.04.2) ...\n","Setting up python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n","Setting up python3-pip (22.0.2+dfsg-1ubuntu0.4) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Requirement already satisfied: pip in /usr/lib/python3/dist-packages (22.0.2)\n","Collecting pip\n","  Downloading pip-24.3-py3-none-any.whl (1.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pip\n","\u001b[33m  WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH.\n","  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n","\u001b[0mSuccessfully installed pip-24.3\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"markdown","source":["# Cloning GPT-NeoX Repo"],"metadata":{"id":"74e27VRVq07s"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FjLEIFCR6d8m","executionInfo":{"status":"ok","timestamp":1730059724252,"user_tz":-300,"elapsed":6301,"user":{"displayName":"Syed Anwar","userId":"02441741431658012689"}},"outputId":"885312c0-8b3d-430e-eb92-a0e89341e443"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'gpt-neox'...\n","remote: Enumerating objects: 19481, done.\u001b[K\n","remote: Counting objects: 100% (1684/1684), done.\u001b[K\n","remote: Compressing objects: 100% (816/816), done.\u001b[K\n","remote: Total 19481 (delta 1243), reused 1188 (delta 860), pack-reused 17797 (from 1)\u001b[K\n","Receiving objects: 100% (19481/19481), 113.65 MiB | 29.52 MiB/s, done.\n","Resolving deltas: 100% (14102/14102), done.\n"]}],"source":["!git clone https://github.com/EleutherAI/gpt-neox"]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IkJjiX0csfeQ","executionInfo":{"status":"ok","timestamp":1730059725608,"user_tz":-300,"elapsed":727,"user":{"displayName":"Syed Anwar","userId":"02441741431658012689"}},"outputId":"78fcff7c-2bf3-439a-cbc6-e8f084060769"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["gpt-neox  sample_data\n"]}]},{"cell_type":"markdown","source":["# Installing Dependencies"],"metadata":{"id":"5OBHMRDRap0G"}},{"cell_type":"code","source":["%cd gpt-neox/requirements\n","!pip install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8T7JsHvusiyy","executionInfo":{"status":"ok","timestamp":1730059960195,"user_tz":-300,"elapsed":232540,"user":{"displayName":"Syed Anwar","userId":"02441741431658012689"}},"outputId":"ecd26df1-2c17-403b-e344-2808869d8fdf"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gpt-neox/requirements\n","Collecting deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed (from -r requirements.txt (line 1))\n","  Cloning https://github.com/EleutherAI/DeeperSpeed.git (to revision 02e2ebf7dee6aaab3d89094ed470a4609763c742) to /tmp/pip-install-ih7op72v/deepspeed_2fc2eb3a3b494791b00491a95cfc09ad\n","  Running command git clone --filter=blob:none --quiet https://github.com/EleutherAI/DeeperSpeed.git /tmp/pip-install-ih7op72v/deepspeed_2fc2eb3a3b494791b00491a95cfc09ad\n","  Running command git rev-parse -q --verify 'sha^02e2ebf7dee6aaab3d89094ed470a4609763c742'\n","  Running command git fetch -q https://github.com/EleutherAI/DeeperSpeed.git 02e2ebf7dee6aaab3d89094ed470a4609763c742\n","  Running command git checkout -q 02e2ebf7dee6aaab3d89094ed470a4609763c742\n","  Resolved https://github.com/EleutherAI/DeeperSpeed.git to commit 02e2ebf7dee6aaab3d89094ed470a4609763c742\n","  Running command git submodule update --init --recursive -q\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting lm_dataformat@ git+https://github.com/EleutherAI/lm_dataformat.git@4eec05349977071bf67fc072290b95e31c8dd836 (from -r requirements.txt (line 5))\n","  Cloning https://github.com/EleutherAI/lm_dataformat.git (to revision 4eec05349977071bf67fc072290b95e31c8dd836) to /tmp/pip-install-ih7op72v/lm-dataformat_141c77493ff84e59841ec56f3efc6075\n","  Running command git clone --filter=blob:none --quiet https://github.com/EleutherAI/lm_dataformat.git /tmp/pip-install-ih7op72v/lm-dataformat_141c77493ff84e59841ec56f3efc6075\n","  Running command git rev-parse -q --verify 'sha^4eec05349977071bf67fc072290b95e31c8dd836'\n","  Running command git fetch -q https://github.com/EleutherAI/lm_dataformat.git 4eec05349977071bf67fc072290b95e31c8dd836\n","  Resolved https://github.com/EleutherAI/lm_dataformat.git to commit 4eec05349977071bf67fc072290b95e31c8dd836\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting ftfy>=6.0.1 (from -r requirements.txt (line 2))\n","  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n","Requirement already satisfied: huggingface_hub>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.24.7)\n","Requirement already satisfied: jinja2==3.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (3.1.4)\n","Collecting lm_eval<=0.4.1,>=0.4.0 (from -r requirements.txt (line 6))\n","  Downloading lm_eval-0.4.1-py3-none-any.whl.metadata (27 kB)\n","Collecting mpi4py>=3.0.3 (from -r requirements.txt (line 7))\n","  Downloading mpi4py-4.0.1.tar.gz (466 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m466.2/466.2 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (1.26.4)\n","Collecting pybind11>=2.6.2 (from -r requirements.txt (line 9))\n","  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (2024.9.11)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (0.2.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (1.16.0)\n","Collecting tiktoken>=0.1.2 (from -r requirements.txt (line 13))\n","  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: tokenizers>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (0.19.1)\n","Collecting transformers==4.38.0 (from -r requirements.txt (line 15))\n","  Downloading transformers-4.38.0-py3-none-any.whl.metadata (131 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.1/131.1 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2==3.1.4->-r requirements.txt (line 4)) (3.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0->-r requirements.txt (line 15)) (3.16.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0->-r requirements.txt (line 15)) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0->-r requirements.txt (line 15)) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0->-r requirements.txt (line 15)) (2.32.3)\n","Collecting tokenizers>=0.12.1 (from -r requirements.txt (line 14))\n","  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0->-r requirements.txt (line 15)) (0.4.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0->-r requirements.txt (line 15)) (4.66.5)\n","Collecting hjson (from deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r requirements.txt (line 1))\n","  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n","Collecting ninja (from deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r requirements.txt (line 1))\n","  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r requirements.txt (line 1)) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r requirements.txt (line 1)) (9.0.0)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r requirements.txt (line 1)) (2.9.2)\n","Collecting pynvml (from deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r requirements.txt (line 1))\n","  Downloading pynvml-11.5.3-py3-none-any.whl.metadata (8.8 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r requirements.txt (line 1)) (2.5.0+cu121)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy>=6.0.1->-r requirements.txt (line 2)) (0.2.13)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.11.0->-r requirements.txt (line 3)) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.11.0->-r requirements.txt (line 3)) (4.12.2)\n","Collecting zstandard (from lm_dataformat@ git+https://github.com/EleutherAI/lm_dataformat.git@4eec05349977071bf67fc072290b95e31c8dd836->-r requirements.txt (line 5))\n","  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n","Collecting jsonlines (from lm_dataformat@ git+https://github.com/EleutherAI/lm_dataformat.git@4eec05349977071bf67fc072290b95e31c8dd836->-r requirements.txt (line 5))\n","  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n","Collecting ujson (from lm_dataformat@ git+https://github.com/EleutherAI/lm_dataformat.git@4eec05349977071bf67fc072290b95e31c8dd836->-r requirements.txt (line 5))\n","  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n","Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6)) (0.34.2)\n","Collecting evaluate (from lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6))\n","  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n","Collecting datasets>=2.14.0 (from lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6))\n","  Downloading datasets-3.0.2-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6)) (2.10.1)\n","Collecting peft>=0.2.0 (from lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6))\n","  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\n","Collecting pytablewriter (from lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6))\n","  Downloading pytablewriter-1.2.0-py3-none-any.whl.metadata (37 kB)\n","Collecting rouge-score>=0.0.4 (from lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6))\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting sacrebleu>=1.5.0 (from lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6))\n","  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6)) (1.5.2)\n","Collecting sqlitedict (from lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6))\n","  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting tqdm-multiprocess (from lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6))\n","  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6)) (16.1.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6))\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6)) (2.2.2)\n","Collecting xxhash (from datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6))\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6))\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6)) (3.10.10)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.0->-r requirements.txt (line 15)) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.0->-r requirements.txt (line 15)) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.0->-r requirements.txt (line 15)) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.0->-r requirements.txt (line 15)) (2024.8.30)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6)) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6)) (3.8.1)\n","Collecting portalocker (from sacrebleu>=1.5.0->lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6))\n","  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6)) (0.9.0)\n","Collecting colorama (from sacrebleu>=1.5.0->lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6))\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6)) (4.9.4)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6)) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6)) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6)) (3.5.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r requirements.txt (line 1)) (3.4.2)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r requirements.txt (line 1)) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r requirements.txt (line 1)) (1.3.0)\n","Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->lm_dataformat@ git+https://github.com/EleutherAI/lm_dataformat.git@4eec05349977071bf67fc072290b95e31c8dd836->-r requirements.txt (line 5)) (24.2.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r requirements.txt (line 1)) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r requirements.txt (line 1)) (2.23.4)\n","Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6)) (75.1.0)\n","Collecting DataProperty<2,>=1.0.1 (from pytablewriter->lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6))\n","  Downloading DataProperty-1.0.1-py3-none-any.whl.metadata (11 kB)\n","Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6))\n","  Downloading mbstrdecoder-1.1.3-py3-none-any.whl.metadata (4.0 kB)\n","Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6))\n","  Downloading pathvalidate-3.2.1-py3-none-any.whl.metadata (12 kB)\n","Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6))\n","  Downloading tabledata-1.3.3-py3-none-any.whl.metadata (3.7 kB)\n","Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6))\n","  Downloading tcolorpy-0.1.6-py3-none-any.whl.metadata (6.4 kB)\n","Collecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6))\n","  Downloading typepy-1.3.2-py3-none-any.whl.metadata (9.3 kB)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6)) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6)) (1.3.1)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6)) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6)) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6)) (1.16.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6)) (4.0.3)\n","Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6)) (5.2.0)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6)) (2.8.2)\n","Requirement already satisfied: pytz>=2018.9 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6)) (2024.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score>=0.0.4->lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6)) (8.1.7)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6)) (2024.2)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r requirements.txt (line 6)) (0.2.0)\n","Downloading transformers-4.38.0-py3-none-any.whl (8.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lm_eval-0.4.1-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-3.0.2-py3-none-any.whl (472 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.7/472.7 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading peft-0.13.2-py3-none-any.whl (320 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading hjson-3.1.0-py3-none-any.whl (54 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n","Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pynvml-11.5.3-py3-none-any.whl (53 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pytablewriter-1.2.0-py3-none-any.whl (111 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n","Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading DataProperty-1.0.1-py3-none-any.whl (27 kB)\n","Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mbstrdecoder-1.1.3-py3-none-any.whl (7.8 kB)\n","Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pathvalidate-3.2.1-py3-none-any.whl (23 kB)\n","Downloading tabledata-1.3.3-py3-none-any.whl (11 kB)\n","Downloading tcolorpy-0.1.6-py3-none-any.whl (8.1 kB)\n","Downloading typepy-1.3.2-py3-none-any.whl (31 kB)\n","Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n","Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: deepspeed, lm_dataformat, mpi4py, rouge-score, sqlitedict\n","  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for deepspeed: filename=deepspeed-0.12.4+02e2ebf-py3-none-any.whl size=1286069 sha256=bb93f677e68236b1c1c0cf2c0d763cbba0fbe52458038cebdcc87ba5dc51aba4\n","  Stored in directory: /root/.cache/pip/wheels/ff/a3/16/4d52efba511c9490fb634597e2b4b6023819175fccfb7e4453\n","  Building wheel for lm_dataformat (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for lm_dataformat: filename=lm_dataformat-0.0.20-py3-none-any.whl size=5833 sha256=28d04488081a3007d1afb2b0666518ae2e43f9741bd6c5be61542034f86f82e9\n","  Stored in directory: /root/.cache/pip/wheels/a8/5d/39/858622f394e968f5055c63d6023137b79341dfe415baf84098\n","  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mpi4py: filename=mpi4py-4.0.1-cp310-cp310-linux_x86_64.whl size=4266352 sha256=ee8e1d285eeb07c5270eb4ef4f88f2e6b408f479beecd9b2d6c37eeecae6af8c\n","  Stored in directory: /root/.cache/pip/wheels/3c/ca/13/13218a83854023ccec184e3af482f0f038b434aa32c19afee8\n","  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=7bda1763286a83914ee2cbc0da432a4d1b869ae52acdd201daef5f98db9c98e2\n","  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n","  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16864 sha256=d24b37b32aeaf3f73f2e6a38eea7c6a677f9528b5976a1a512b5903f41b46a06\n","  Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n","Successfully built deepspeed lm_dataformat mpi4py rouge-score sqlitedict\n","Installing collected packages: sqlitedict, ninja, hjson, zstandard, xxhash, ujson, tcolorpy, pynvml, pybind11, portalocker, pathvalidate, mpi4py, mbstrdecoder, jsonlines, ftfy, dill, colorama, typepy, tqdm-multiprocess, tiktoken, sacrebleu, rouge-score, multiprocess, lm_dataformat, tokenizers, deepspeed, transformers, DataProperty, tabledata, peft, datasets, pytablewriter, evaluate, lm_eval\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.19.1\n","    Uninstalling tokenizers-0.19.1:\n","      Successfully uninstalled tokenizers-0.19.1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.44.2\n","    Uninstalling transformers-4.44.2:\n","      Successfully uninstalled transformers-4.44.2\n","Successfully installed DataProperty-1.0.1 colorama-0.4.6 datasets-3.0.2 deepspeed-0.12.4+02e2ebf dill-0.3.8 evaluate-0.4.3 ftfy-6.3.1 hjson-3.1.0 jsonlines-4.0.0 lm_dataformat-0.0.20 lm_eval-0.4.1 mbstrdecoder-1.1.3 mpi4py-4.0.1 multiprocess-0.70.16 ninja-1.11.1.1 pathvalidate-3.2.1 peft-0.13.2 portalocker-2.10.1 pybind11-2.13.6 pynvml-11.5.3 pytablewriter-1.2.0 rouge-score-0.1.2 sacrebleu-2.4.3 sqlitedict-2.1.0 tabledata-1.3.3 tcolorpy-0.1.6 tiktoken-0.8.0 tokenizers-0.15.2 tqdm-multiprocess-0.0.11 transformers-4.38.0 typepy-1.3.2 ujson-5.10.0 xxhash-3.5.0 zstandard-0.23.0\n"]}]},{"cell_type":"code","source":["!pip install lm_dataformat@git+https://github.com/EleutherAI/lm_dataformat.git@4eec05349977071bf67fc072290b95e31c8dd836\n","!pip install lm_eval>=0.4.0,<=0.4.1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cAFqQamUuCr6","executionInfo":{"status":"ok","timestamp":1730058251734,"user_tz":-300,"elapsed":3779,"user":{"displayName":"Syed Anwar","userId":"02441741431658012689"}},"outputId":"26284f11-e650-42eb-cad9-71bc3623ed88"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting lm_dataformat@ git+https://github.com/EleutherAI/lm_dataformat.git@4eec05349977071bf67fc072290b95e31c8dd836\n","  Using cached lm_dataformat-0.0.20-py3-none-any.whl\n","Requirement already satisfied: zstandard in /usr/local/lib/python3.10/dist-packages (from lm_dataformat@ git+https://github.com/EleutherAI/lm_dataformat.git@4eec05349977071bf67fc072290b95e31c8dd836) (0.23.0)\n","Requirement already satisfied: jsonlines in /usr/local/lib/python3.10/dist-packages (from lm_dataformat@ git+https://github.com/EleutherAI/lm_dataformat.git@4eec05349977071bf67fc072290b95e31c8dd836) (4.0.0)\n","Requirement already satisfied: ujson in /usr/local/lib/python3.10/dist-packages (from lm_dataformat@ git+https://github.com/EleutherAI/lm_dataformat.git@4eec05349977071bf67fc072290b95e31c8dd836) (5.10.0)\n","Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->lm_dataformat@ git+https://github.com/EleutherAI/lm_dataformat.git@4eec05349977071bf67fc072290b95e31c8dd836) (24.2.0)\n","/bin/bash: line 1: =0.4.1: No such file or directory\n"]}]},{"cell_type":"code","source":["!pip install torch==1.11.0\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0IzTTkQCuIaC","executionInfo":{"status":"ok","timestamp":1730060209881,"user_tz":-300,"elapsed":82269,"user":{"displayName":"Syed Anwar","userId":"02441741431658012689"}},"outputId":"ba0581f7-dfe7-44d6-8584-4baaddbc74cc"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch==1.11.0\n","  Downloading torch-1.11.0-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.11.0) (4.12.2)\n","Downloading torch-1.11.0-cp310-cp310-manylinux1_x86_64.whl (750.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.5.0+cu121\n","    Uninstalling torch-2.5.0+cu121:\n","      Successfully uninstalled torch-2.5.0+cu121\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","peft 0.13.2 requires torch>=1.13.0, but you have torch 1.11.0 which is incompatible.\n","torchaudio 2.5.0+cu121 requires torch==2.5.0, but you have torch 1.11.0 which is incompatible.\n","torchvision 0.20.0+cu121 requires torch==2.5.0, but you have torch 1.11.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torch-1.11.0\n"]}]},{"cell_type":"code","source":["%cd ..\n","!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FY2Bx-43tysn","executionInfo":{"status":"ok","timestamp":1730060220513,"user_tz":-300,"elapsed":513,"user":{"displayName":"Syed Anwar","userId":"02441741431658012689"}},"outputId":"278c2413-3d23-48ce-d784-1e2f69833424"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gpt-neox\n","CITATION.cff\t\t      docker-compose.yml  images\t prepare_data.py  tools\n","configs\t\t\t      Dockerfile\t  LICENSE\t README.md\t  train.py\n","CONTRIBUTING.md\t\t      eval.py\t\t  MANIFEST.in\t README-MUP.md\n","deepy.py\t\t      eval_tasks\t  megatron\t requirements\n","docker-compose-dockerhub.yml  generate.py\t  post-training  tests\n"]}]},{"cell_type":"markdown","source":["# Preparing Custom Dataset"],"metadata":{"id":"2jzX5ohGax6p"}},{"cell_type":"code","source":["%cd gpt-neox\n","!python prepare_data.py -d ./data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fa8lgCHo9ma4","executionInfo":{"status":"ok","timestamp":1730060387445,"user_tz":-300,"elapsed":162353,"user":{"displayName":"Syed Anwar","userId":"02441741431658012689"}},"outputId":"43d3d667-d2b7-43ae-ad00-7c6cefa535e0"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: 'gpt-neox'\n","/content/gpt-neox\n","--2024-10-27 20:17:04--  https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json\n","Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.138.112, 16.15.176.115, 16.15.217.143, ...\n","Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.138.112|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1042301 (1018K) [application/json]\n","Saving to: ‘./data//gpt2-vocab.json’\n","\n","./data//gpt2-vocab. 100%[===================>]   1018K  2.76MB/s    in 0.4s    \n","\n","2024-10-27 20:17:04 (2.76 MB/s) - ‘./data//gpt2-vocab.json’ saved [1042301/1042301]\n","\n","--2024-10-27 20:17:04--  https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt\n","Resolving s3.amazonaws.com (s3.amazonaws.com)... 16.15.185.223, 16.182.74.128, 52.216.32.8, ...\n","Connecting to s3.amazonaws.com (s3.amazonaws.com)|16.15.185.223|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 456318 (446K) [text/plain]\n","Saving to: ‘./data/gpt2-merges.txt’\n","\n","./data/gpt2-merges. 100%[===================>] 445.62K   615KB/s    in 0.7s    \n","\n","2024-10-27 20:17:05 (615 KB/s) - ‘./data/gpt2-merges.txt’ saved [456318/456318]\n","\n","--2024-10-27 20:17:05--  http://mattmahoney.net/dc/enwik8.zip\n","Resolving mattmahoney.net (mattmahoney.net)... 34.198.1.81\n","Connecting to mattmahoney.net (mattmahoney.net)|34.198.1.81|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 36445475 (35M) [application/zip]\n","Saving to: ‘./data/enwik8/enwik8.zip’\n","\n","./data/enwik8/enwik 100%[===================>]  34.76M  31.5MB/s    in 1.1s    \n","\n","2024-10-27 20:17:07 (31.5 MB/s) - ‘./data/enwik8/enwik8.zip’ saved [36445475/36445475]\n","\n","/content/gpt-neox/megatron/neox_arguments/arguments.py:1101: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n","  assert (\n","/content/gpt-neox/megatron/neox_arguments/arguments.py:1110: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n","  assert (\n","[2024-10-27 20:17:08,305] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n","> building GPT2BPETokenizer tokenizer ...\n"," > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)\n","Vocab size: 50257\n","Output prefix: ./data/enwik8/enwik8\n","> building GPT2BPETokenizer tokenizer ...\n"," > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)\n","0it [02:30, ?it/s]\n"]}]},{"cell_type":"code","source":["%cd ..\n","!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UBFmdVUTCy7y","executionInfo":{"status":"ok","timestamp":1730060580489,"user_tz":-300,"elapsed":643,"user":{"displayName":"Syed Anwar","userId":"02441741431658012689"}},"outputId":"e9c2179c-cc4e-49f3-940b-bbdce56ca563"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","gpt-neox  sample_data\n"]}]},{"cell_type":"markdown","source":["# Downloading TinyShakespear Dataset"],"metadata":{"id":"VZzye-15a5aO"}},{"cell_type":"code","source":["!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9YuQGevPCGSc","executionInfo":{"status":"ok","timestamp":1730060621277,"user_tz":-300,"elapsed":471,"user":{"displayName":"Syed Anwar","userId":"02441741431658012689"}},"outputId":"6152d6e8-dcd6-41f8-e9d8-b1777aa6a13f"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-10-27 20:23:40--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1115394 (1.1M) [text/plain]\n","Saving to: ‘input.txt’\n","\n","input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.03s   \n","\n","2024-10-27 20:23:40 (30.5 MB/s) - ‘input.txt’ saved [1115394/1115394]\n","\n"]}]},{"cell_type":"markdown","source":["# Tokenizing Dataset"],"metadata":{"id":"x57thNaLa-yN"}},{"cell_type":"code","source":["!ls\n","%cd data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Lwt-51Vp3af","executionInfo":{"status":"ok","timestamp":1730060730181,"user_tz":-300,"elapsed":525,"user":{"displayName":"Syed Anwar","userId":"02441741431658012689"}},"outputId":"c8443c5c-ad41-4a1a-9608-2115cc4ffcbe"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["CITATION.cff\t docker-compose-dockerhub.yml  generate.py  post-training    tests\n","configs\t\t docker-compose.yml\t       images\t    prepare_data.py  tools\n","CONTRIBUTING.md  Dockerfile\t\t       LICENSE\t    README.md\t     train.py\n","data\t\t eval.py\t\t       MANIFEST.in  README-MUP.md\n","deepy.py\t eval_tasks\t\t       megatron     requirements\n","/content/gpt-neox/data\n"]}]},{"cell_type":"code","source":["import json\n","\n","# Load the Tiny Shakespeare text file\n","with open(\"/content/input.txt\", \"r\") as f:\n","    text = f.read()\n","\n","# Create a list with one document in JSONL format\n","data = [{\"text\": text}]\n","\n","# Save as JSONL\n","with open(\"tinyshakespeare.jsonl\", \"w\") as f:\n","    for entry in data:\n","        f.write(json.dumps(entry) + \"\\n\")\n"],"metadata":{"id":"N-hmZjCc-WnV","executionInfo":{"status":"ok","timestamp":1730060734281,"user_tz":-300,"elapsed":610,"user":{"displayName":"Syed Anwar","userId":"02441741431658012689"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["%ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kAGBJz0JEPRk","executionInfo":{"status":"ok","timestamp":1730060746059,"user_tz":-300,"elapsed":554,"user":{"displayName":"Syed Anwar","userId":"02441741431658012689"}},"outputId":"8d407dfd-0201-4007-8616-21e7f3cd6115"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: 'gpt-neox/data'\n","/content/gpt-neox/data\n","\u001b[0m\u001b[01;34menwik8\u001b[0m/  gpt2-merges.txt  gpt2-vocab.json  tinyshakespeare.jsonl\n"]}]},{"cell_type":"code","source":["%cd .."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nXmXdS8gjHCF","executionInfo":{"status":"ok","timestamp":1730060752404,"user_tz":-300,"elapsed":461,"user":{"displayName":"Syed Anwar","userId":"02441741431658012689"}},"outputId":"17e4ee81-cf5c-47e8-aec0-df3559fb70f2"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gpt-neox\n"]}]},{"cell_type":"code","source":["!python tools/datasets/preprocess_data.py \\\n","    --input ./data/tinyshakespeare.jsonl \\\n","    --output-prefix ./data/tinyshakespeare \\\n","    --vocab-file ./data/gpt2-vocab.json \\\n","    --merge-file ./data/gpt2-merges.txt \\\n","    --dataset-impl mmap \\\n","    --tokenizer-type GPT2BPETokenizer \\\n","    --append-eod\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JyD8RujkEUsr","executionInfo":{"status":"ok","timestamp":1730060761559,"user_tz":-300,"elapsed":7226,"user":{"displayName":"Syed Anwar","userId":"02441741431658012689"}},"outputId":"f10b9c58-84e0-4ce3-8fa7-b0be152907a5"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["[2024-10-27 20:25:54,902] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n","> building GPT2BPETokenizer tokenizer ...\n"," > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)\n","Vocab size: 50257\n","Output prefix: ./data/tinyshakespeare\n","> building GPT2BPETokenizer tokenizer ...\n"," > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)\n","0it [00:02, ?it/s]\n"]}]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jqiRltVdGPly","executionInfo":{"status":"ok","timestamp":1730060766172,"user_tz":-300,"elapsed":468,"user":{"displayName":"Syed Anwar","userId":"02441741431658012689"}},"outputId":"e5743b8e-526a-48d8-eae1-610d17ebdec0"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["CITATION.cff\t docker-compose-dockerhub.yml  generate.py  post-training    tests\n","configs\t\t docker-compose.yml\t       images\t    prepare_data.py  tools\n","CONTRIBUTING.md  Dockerfile\t\t       LICENSE\t    README.md\t     train.py\n","data\t\t eval.py\t\t       MANIFEST.in  README-MUP.md\n","deepy.py\t eval_tasks\t\t       megatron     requirements\n"]}]},{"cell_type":"code","source":["!python ./deepy.py train.py -d configs 125M.yml local_setup.yml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0mfqqEw_lnbh","outputId":"79126b38-63ee-424e-8966-ae2369d7100a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[2024-10-27 20:26:09,767] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n","NeoXArgs.from_ymls() ['configs/125M.yml', 'configs/local_setup.yml']\n","[2024-10-27 20:26:13,531] [WARNING] [runner.py:217:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n","INFO:root:NeoXArgs.calculate_derived() Total number of GPUs determined to be: 1\n","-------------------- arguments --------------------\n","  attention_config ................ ['global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global']updated\n","  batch_size ...................... 4...........................updated\n","  checkpoint_activations .......... True........................updated\n","  checkpoint_factor ............... 10000.......................updated\n","  config_files .................... {'125M.yml': '# GPT-2 pretraining setup\\n{\\n   # parallelism settings ( you will want to change these based on your cluster setup, ideally scheduling pipeline stages\\n   # across the node boundaries )\\n   \"pipe_parallel_size\": 1,\\n   \"model_parallel_size\": 1,\\n\\n   # model settings\\n   \"num_layers\": 12,\\n   \"hidden_size\": 768,\\n   \"num_attention_heads\": 12,\\n   \"seq_length\": 2048,\\n   \"max_position_embeddings\": 2048,\\n   \"norm\": \"layernorm\",\\n   \"pos_emb\": \"rotary\",\\n   \"no_weight_tying\": true,\\n   \"gpt_j_residual\": false,\\n   \"output_layer_parallelism\": \"column\",\\n\\n   # these should provide some speedup but takes a while to build, set to true if desired\\n   \"scaled_upper_triang_masked_softmax_fusion\": false,\\n   \"bias_gelu_fusion\": false,\\n   \"rope_fusion\": false,\\n   \"layernorm_fusion\": false,\\n\\n   # init methods\\n   \"init_method\": \"small_init\",\\n   \"output_layer_init_method\": \"wang_init\",\\n\\n\\n   # optimizer settings\\n   \"optimizer\": {\\n     \"type\": \"Adam\",\\n     \"params\": {\\n       \"lr\": 0.0006,\\n       \"betas\": [0.9, 0.95],\\n       \"eps\": 1.0e-8,\\n     }\\n   },\\n   \"min_lr\": 0.00006,\\n\\n   # for all zero_optimization options, see https://www.deepspeed.ai/docs/config-json/#zero-optimizations-for-fp16-training\\n   \"zero_optimization\": {\\n    \"stage\": 1,\\n    \"allgather_partitions\": True,\\n    \"allgather_bucket_size\": 500000000,\\n    \"overlap_comm\": True,\\n    \"reduce_scatter\": True,\\n    \"reduce_bucket_size\": 500000000,\\n    \"contiguous_gradients\": True,\\n  },\\n\\n   # batch / data settings\\n   \"train_micro_batch_size_per_gpu\": 4,\\n   \"data_impl\": \"mmap\",\\n\\n   # activation checkpointing\\n   \"checkpoint_activations\": true,\\n   \"checkpoint_num_layers\": 1,\\n   \"partition_activations\": true,\\n   \"synchronize_each_layer\": true,\\n\\n   # regularization\\n   \"gradient_clipping\": 1.0,\\n   \"weight_decay\": 0.1,\\n   \"hidden_dropout\": 0.0,\\n   \"attention_dropout\": 0.0,\\n\\n   # precision settings\\n   \"fp16\": {\\n     \"enabled\": true,\\n     \"loss_scale\": 0,\\n     \"loss_scale_window\": 1000,\\n     \"hysteresis\": 2,\\n     \"min_loss_scale\": 1\\n   },\\n\\n   # misc. training settings\\n   \"train_iters\": 320000,\\n   \"lr_decay_iters\": 320000,\\n   \"distributed_backend\": \"nccl\",\\n   \"lr_decay_style\": \"cosine\",\\n   \"warmup\": 0.01,\\n   \"checkpoint_factor\": 10000,\\n   \"eval_interval\": 1000,\\n   \"eval_iters\": 10,\\n\\n   # logging\\n   \"log_interval\": 100,\\n   \"steps_per_print\": 10,\\n   \"keep_last_n_checkpoints\": 4,\\n   \"wall_clock_breakdown\": true,\\n\\n  #  networking\\n  \"hostfile\": \"/mock_path\"\\n}\\n', 'local_setup.yml': '# Suggested data paths when using GPT-NeoX locally\\n{\\n  \"data_path\": \"data/enwik8/enwik8_text_document\",\\n\\n  # or for weighted datasets:\\n  # \"train-data-paths\": [\"data/enwik8/enwik8_text_document\", \"data/enwik8/enwik8_text_document\"],\\n  # \"test-data-paths\": [\"data/enwik8/enwik8_text_document\", \"data/enwik8/enwik8_text_document\"],\\n  # \"valid-data-paths\": [\"data/enwik8/enwik8_text_document\", \"data/enwik8/enwik8_text_document\"],\\n  # \"train-data-weights\": [1., 2.],\\n  # \"test-data-weights\": [2., 1.],\\n  # \"valid-data-weights\": [0.5, 0.4],\\n\\n  # If weight_by_num_documents is True, Builds dataset weights from a multinomial distribution over groups of data according to the number of documents in each group.\\n  # WARNING: setting this to True will override any user provided weights\\n  # \"weight_by_num_documents\": false,\\n  # \"weighted_sampler_alpha\": 0.3,\\n\\n  \"vocab_file\": \"data/gpt2-vocab.json\",\\n  \"merge_file\": \"data/gpt2-merges.txt\",\\n\\n  \"save\": \"checkpoints\",\\n  \"load\": \"checkpoints\",\\n  \"checkpoint_validation_with_forward_pass\": False,\\n\\n  \"tensorboard_dir\": \"tensorboard\",\\n  \"log_dir\": \"logs\",\\n}\\n'}updated\n","  data_impl ....................... mmap........................updated\n","  data_path ....................... data/enwik8/enwik8_text_documentupdated\n","  dynamic_loss_scale .............. True........................updated\n","  eval_iters ...................... 10..........................updated\n","  fp16 ............................ {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 1000, 'hysteresis': 2, 'min_loss_scale': 1}updated\n","  global_num_gpus ................. 1...........................updated\n","  hidden_size ..................... 768.........................updated\n","  hostfile ........................ /mock_path..................updated\n","  init_method ..................... small_init..................updated\n","  is_pipe_parallel ................ True........................updated\n","  keep_last_n_checkpoints ......... 4...........................updated\n","  load ............................ checkpoints.................updated\n","  log_dir ......................... logs........................updated\n","  lr .............................. 0.0006......................updated\n","  lr_decay_iters .................. 320000......................updated\n","  lr_decay_style .................. cosine......................updated\n","  max_position_embeddings ......... 2048........................updated\n","  merge_file ...................... data/gpt2-merges.txt........updated\n","  min_lr .......................... 6e-05.......................updated\n","  no_weight_tying ................. True........................updated\n","  num_attention_heads ............. 12..........................updated\n","  num_layers ...................... 12..........................updated\n","  optimizer ....................... {'type': 'Adam', 'params': {'lr': 0.0006, 'betas': [0.9, 0.95], 'eps': 1e-08}}updated\n","  optimizer_type .................. Adam........................updated\n","  output_layer_init_method ........ wang_init...................updated\n","  partition_activations ........... True........................updated\n","  pipe_parallel_size .............. 1...........................updated\n","  pos_emb ......................... rotary......................updated\n","  precision ....................... fp16........................updated\n","  save ............................ checkpoints.................updated\n","  seq_length ...................... 2048........................updated\n","  sparsity_config ................. {}..........................updated\n","  synchronize_each_layer .......... True........................updated\n","  tensorboard_dir ................. tensorboard.................updated\n","  text_gen_type ................... unconditional...............updated\n","  train_batch_size ................ 4...........................updated\n","  train_iters ..................... 320000......................updated\n","  train_micro_batch_size_per_gpu .. 4...........................updated\n","  user_script ..................... train.py....................updated\n","  vocab_file ...................... data/gpt2-vocab.json........updated\n","  wall_clock_breakdown ............ True........................updated\n","  zero_allgather_bucket_size ...... 500000000...................updated\n","  zero_contiguous_gradients ....... True........................updated\n","  zero_optimization ............... {'stage': 1, 'allgather_partitions': True, 'allgather_bucket_size': 500000000, 'overlap_comm': True, 'reduce_scatter': True, 'reduce_bucket_size': 500000000, 'contiguous_gradients': True}updated\n","  zero_reduce_bucket_size ......... 500000000...................updated\n","  zero_reduce_scatter ............. True........................updated\n","  zero_stage ...................... 1...........................updated\n","  account ......................... None........................default\n","  activation ...................... gelu........................default\n","  activation_checkpointing ........ None........................default\n","  adlr_autoresume ................. False.......................default\n","  adlr_autoresume_interval ........ 1000........................default\n","  allow_chopped ................... True........................default\n","  amp ............................. None........................default\n","  apply_query_key_layer_scaling ... False.......................default\n","  attention_dropout ............... 0.0.........................default\n","  attention_softmax_in_fp32 ....... False.......................default\n","  autotuning ...................... None........................default\n","  autotuning_run .................. None........................default\n","  base_shapes_file ................ None........................default\n","  bf16 ............................ None........................default\n","  bias_dropout_fusion ............. False.......................default\n","  bias_gelu_fusion ................ False.......................default\n","  char_level_ppl .................. False.......................default\n","  checkpoint ...................... None........................default\n","  checkpoint_in_cpu ............... False.......................default\n","  checkpoint_num_layers ........... 1...........................default\n","  checkpoint_scale ................ linear......................default\n","  checkpoint_validation_with_forward_pass  False................default\n","  clip_grad ....................... 1.0.........................default\n","  comet_experiment ................ None........................default\n","  comet_experiment_name ........... None........................default\n","  comet_others .................... None........................default\n","  comet_project ................... None........................default\n","  comet_tags ...................... None........................default\n","  comet_workspace ................. None........................default\n","  comment ......................... None........................default\n","  comms_logger .................... None........................default\n","  communication_data_type ......... None........................default\n","  compression_training ............ None........................default\n","  contiguous_checkpointing ........ False.......................default\n","  coord_check ..................... False.......................default\n","  create_moe_param_group .......... True........................default\n","  csv_monitor ..................... None........................default\n","  curriculum_learning ............. None........................default\n","  curriculum_seqlen ............... 0...........................default\n","  data_efficiency ................. None........................default\n","  data_types ...................... None........................default\n","  dataset_impl .................... gpt2........................default\n","  deepscale ....................... False.......................default\n","  deepscale_config ................ None........................default\n","  deepspeed ....................... True........................default\n","  deepspeed_activation_checkpointing  True......................default\n","  deepspeed_extra_args ............ None........................default\n","  deepspeed_mpi ................... False.......................default\n","  deepspeed_slurm ................. False.......................default\n","  detect_nvlink_pairs ............. False.......................default\n","  dim_att ......................... None........................default\n","  distributed_backend ............. nccl........................default\n","  do_test ......................... None........................default\n","  do_train ........................ None........................default\n","  do_valid ........................ None........................default\n","  dpo_beta ........................ 0.1.........................default\n","  dpo_fp32 ........................ True........................default\n","  dpo_reference_free .............. False.......................default\n","  dump_state ...................... False.......................default\n","  elasticity ...................... None........................default\n","  enable_expert_tensor_parallelism  False.......................default\n","  eod_mask_loss ................... False.......................default\n","  eval_interval ................... 1000........................default\n","  eval_results_prefix ............. ............................default\n","  eval_tasks ...................... None........................default\n","  exclude ......................... None........................default\n","  exit_interval ................... None........................default\n","  expansion_factor ................ None........................default\n","  expert_interval ................. 2...........................default\n","  extra_save_iters ................ None........................default\n","  ffn_dim ......................... None........................default\n","  finetune ........................ False.......................default\n","  flops_profiler .................. None........................default\n","  force_multi ..................... False.......................default\n","  fp16_lm_cross_entropy ........... False.......................default\n","  fp32_allreduce .................. False.......................default\n","  git_hash ........................ 59a5236d....................default\n","  gmlp_attn_dim ................... 64..........................default\n","  gpt_j_residual .................. False.......................default\n","  gpt_j_tied ...................... False.......................default\n","  gradient_accumulation_steps ..... 1...........................default\n","  gradient_clipping ............... 1.0.........................default\n","  gradient_noise_scale_cpu_offload  False.......................default\n","  gradient_noise_scale_n_batches .. 5...........................default\n","  gradient_predivide_factor ....... 1.0.........................default\n","  head_size ....................... None........................default\n","  hidden_dropout .................. 0.0.........................default\n","  hysteresis ...................... 2...........................default\n","  include ......................... None........................default\n","  init_method_std ................. 0.02........................default\n","  intermediate_size ............... None........................default\n","  iteration ....................... None........................default\n","  kto_beta ........................ 0.1.........................default\n","  kto_desirable_weight ............ 1.0.........................default\n","  kto_fp32 ........................ True........................default\n","  kto_undesirable_weight .......... 1.0.........................default\n","  launcher ........................ pdsh........................default\n","  layernorm_epsilon ............... 1e-05.......................default\n","  layernorm_fusion ................ False.......................default\n","  lazy_mpu_init ................... False.......................default\n","  local_rank ...................... None........................default\n","  log_grad_norm ................... False.......................default\n","  log_grad_pct_zeros .............. False.......................default\n","  log_gradient_noise_scale ........ False.......................default\n","  log_interval .................... 100.........................default\n","  log_optimizer_states ............ False.......................default\n","  log_param_norm .................. False.......................default\n","  loss_scale ...................... None........................default\n","  loss_scale_window ............... 1000.0......................default\n","  lr_decay_fraction ............... None........................default\n","  make_vocab_size_divisible_by .... 128.........................default\n","  mamba_causal_conv_fusion ........ False.......................default\n","  mamba_inner_func_fusion ......... False.......................default\n","  mamba_selective_fp32_params ..... True........................default\n","  mamba_selective_scan_fusion ..... False.......................default\n","  mamba_use_bias_in_conv .......... True........................default\n","  mamba_use_bias_in_linears ....... False.......................default\n","  master_addr ..................... None........................default\n","  master_port ..................... 29500.......................default\n","  maximum_tokens .................. 64..........................default\n","  memory_profiling ................ False.......................default\n","  memory_profiling_path ........... None........................default\n","  min_scale ....................... 1.0.........................default\n","  mlp_multiple_of ................. 1...........................default\n","  mmap_warmup ..................... False.......................default\n","  model_parallel_size ............. 1...........................default\n","  moe_eval_capacity_factor ........ 1.0.........................default\n","  moe_expert_parallel_size ........ 1...........................default\n","  moe_glu ......................... False.......................default\n","  moe_jitter_eps .................. None........................default\n","  moe_lbl_in_fp32 ................. False.......................default\n","  moe_loss_coeff .................. 0.1.........................default\n","  moe_min_capacity ................ 4...........................default\n","  moe_num_experts ................. 1...........................default\n","  moe_token_dropping .............. False.......................default\n","  moe_top_k ....................... 1...........................default\n","  moe_train_capacity_factor ....... 1.0.........................default\n","  moe_type ........................ megablocks..................default\n","  moe_use_residual ................ True........................default\n","  mup_attn_temp ................... 1.0.........................default\n","  mup_embedding_mult .............. 1.0.........................default\n","  mup_init_scale .................. 1.0.........................default\n","  mup_output_temp ................. 1.0.........................default\n","  mup_rp_embedding_mult ........... 1.0.........................default\n","  mup_width_scale ................. 2...........................default\n","  neg_test_data_paths ............. None........................default\n","  neg_test_label_data_paths ....... None........................default\n","  neg_train_data_paths ............ None........................default\n","  neg_train_label_data_paths ...... None........................default\n","  neg_valid_data_paths ............ None........................default\n","  neg_valid_label_data_paths ...... None........................default\n","  no_load_optim ................... False.......................default\n","  no_load_rng ..................... False.......................default\n","  no_save_optim ................... False.......................default\n","  no_save_rng ..................... False.......................default\n","  no_ssh_check .................... False.......................default\n","  norm ............................ layernorm...................default\n","  num_gpus ........................ None........................default\n","  num_kv_heads .................... None........................default\n","  num_nodes ....................... -1..........................default\n","  num_samples ..................... 1...........................default\n","  num_unique_layers ............... None........................default\n","  num_workers ..................... 2...........................default\n","  onnx_safe ....................... False.......................default\n","  opt_pos_emb_offset .............. 0...........................default\n","  output_layer_parallelism ........ column......................default\n","  override_lr_scheduler ........... False.......................default\n","  pack_impl ....................... packed......................default\n","  padded_vocab_size ............... None........................default\n","  param_sharing_style ............. grouped.....................default\n","  pipe_partition_method ........... type:transformer|mlp........default\n","  pos_test_data_paths ............. None........................default\n","  pos_test_label_data_paths ....... None........................default\n","  pos_train_data_paths ............ None........................default\n","  pos_train_label_data_paths ...... None........................default\n","  pos_valid_data_paths ............ None........................default\n","  pos_valid_label_data_paths ...... None........................default\n","  precompute_model_name ........... None........................default\n","  prescale_gradients .............. False.......................default\n","  profile ......................... False.......................default\n","  profile_backward ................ False.......................default\n","  profile_step_start .............. 10..........................default\n","  profile_step_stop ............... 12..........................default\n","  prompt_end ...................... \n","...........................default\n","  rank ............................ None........................default\n","  recompute ....................... False.......................default\n","  return_logits ................... False.......................default\n","  rms_norm_epsilon ................ 1e-08.......................default\n","  rmsnorm_fusion .................. False.......................default\n","  rope_fusion ..................... False.......................default\n","  rotary_emb_base ................. 10000.......................default\n","  rotary_pct ...................... 1.0.........................default\n","  rotary_save_freqs_buffer ........ False.......................default\n","  rpe_max_distance ................ 128.........................default\n","  rpe_num_buckets ................. 32..........................default\n","  s3_chunk_size ................... 104857600...................default\n","  s3_path ......................... None........................default\n","  sample_input_file ............... None........................default\n","  sample_output_file .............. samples.txt.................default\n","  save_base_shapes ................ False.......................default\n","  scaled_masked_softmax_fusion .... False.......................default\n","  scaled_upper_triang_masked_softmax_fusion  False..............default\n","  scalenorm_epsilon ............... 1e-08.......................default\n","  scheduler ....................... None........................default\n","  seed ............................ 1234........................default\n","  sequence_parallel ............... False.......................default\n","  short_seq_prob .................. 0.1.........................default\n","  sliding_window_width ............ None........................default\n","  soft_prompt_tuning .............. None........................default\n","  sparse_attention ................ None........................default\n","  sparse_gradients ................ False.......................default\n","  split ........................... 969, 30, 1..................default\n","  steps_per_print ................. 10..........................default\n","  temperature ..................... 0.0.........................default\n","  tensorboard ..................... None........................default\n","  test_data_paths ................. None........................default\n","  test_data_weights ............... None........................default\n","  test_label_data_paths ........... None........................default\n","  test_reward_data_paths .......... None........................default\n","  tokenizer_type .................. GPT2BPETokenizer............default\n","  top_k ........................... 0...........................default\n","  top_p ........................... 0.0.........................default\n","  train_data_paths ................ None........................default\n","  train_data_weights .............. None........................default\n","  train_epochs .................... None........................default\n","  train_impl ...................... normal......................default\n","  train_label_data_paths .......... None........................default\n","  train_reward_data_paths ......... None........................default\n","  use_bias_in_attn_linear ......... True........................default\n","  use_bias_in_mlp ................. True........................default\n","  use_bias_in_norms ............... True........................default\n","  use_bnb_optimizer ............... False.......................default\n","  use_checkpoint_lr_scheduler ..... False.......................default\n","  use_comet ....................... None........................default\n","  use_cpu_initialization .......... False.......................default\n","  use_flashattn_swiglu ............ False.......................default\n","  use_mup ......................... False.......................default\n","  use_qk_layernorm ................ False.......................default\n","  use_shared_fs ................... True........................default\n","  use_tutel ....................... False.......................default\n","  use_wandb ....................... None........................default\n","  valid_data_paths ................ None........................default\n","  valid_data_weights .............. None........................default\n","  valid_label_data_paths .......... None........................default\n","  valid_reward_data_paths ......... None........................default\n","  wandb ........................... None........................default\n","  wandb_group ..................... None........................default\n","  wandb_host ...................... https://api.wandb.ai........default\n","  wandb_init_all_ranks ............ False.......................default\n","  wandb_project ................... neox........................default\n","  wandb_team ...................... None........................default\n","  warmup .......................... 0.01........................default\n","  weight_by_num_documents ......... False.......................default\n","  weight_decay .................... 0.1.........................default\n","  weighted_sampler_alpha .......... 1.0.........................default\n","  world_size ...................... None........................default\n","  z_loss .......................... 0.0.........................default\n","---------------- end of arguments ----------------\n","NeoXArgs.configure_distributed_args() using world size: 1 and model-parallel size: 1 \n","[2024-10-27 20:26:13,558] [WARNING] [runner.py:217:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n","[2024-10-27 20:26:13,559] [INFO] [runner.py:586:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None train.py --deepspeed_config eyJ0cmFpbl9iYXRjaF9zaXplIjogNCwgInRyYWluX21pY3JvX2JhdGNoX3NpemVfcGVyX2dwdSI6IDQsICJvcHRpbWl6ZXIiOiB7InR5cGUiOiAiQWRhbSIsICJwYXJhbXMiOiB7ImxyIjogMC4wMDA2LCAiYmV0YXMiOiBbMC45LCAwLjk1XSwgImVwcyI6IDFlLTA4fX0sICJmcDE2IjogeyJlbmFibGVkIjogdHJ1ZSwgImxvc3Nfc2NhbGUiOiAwLCAibG9zc19zY2FsZV93aW5kb3ciOiAxMDAwLCAiaHlzdGVyZXNpcyI6IDIsICJtaW5fbG9zc19zY2FsZSI6IDF9LCAiemVyb19vcHRpbWl6YXRpb24iOiB7InN0YWdlIjogMSwgImFsbGdhdGhlcl9wYXJ0aXRpb25zIjogdHJ1ZSwgImFsbGdhdGhlcl9idWNrZXRfc2l6ZSI6IDUwMDAwMDAwMCwgIm92ZXJsYXBfY29tbSI6IHRydWUsICJyZWR1Y2Vfc2NhdHRlciI6IHRydWUsICJyZWR1Y2VfYnVja2V0X3NpemUiOiA1MDAwMDAwMDAsICJjb250aWd1b3VzX2dyYWRpZW50cyI6IHRydWV9LCAid2FsbF9jbG9ja19icmVha2Rvd24iOiB0cnVlfQ== --megatron_config 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\n","[2024-10-27 20:26:14,563] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n","[2024-10-27 20:26:17,163] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.19.3-1+cuda12.2\n","[2024-10-27 20:26:17,163] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.19.3-1\n","[2024-10-27 20:26:17,163] [INFO] [launch.py:138:main] 0 NCCL_VERSION=2.19.3-1\n","[2024-10-27 20:26:17,163] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n","[2024-10-27 20:26:17,163] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.19.3-1+cuda12.2\n","[2024-10-27 20:26:17,163] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n","[2024-10-27 20:26:17,163] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.19.3-1\n","[2024-10-27 20:26:17,163] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0]}\n","[2024-10-27 20:26:17,163] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0\n","[2024-10-27 20:26:17,163] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n","[2024-10-27 20:26:17,163] [INFO] [launch.py:163:main] dist_world_size=1\n","[2024-10-27 20:26:17,163] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0\n","[2024-10-27 20:26:17,963] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n","Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba\n","For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3\n","For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer\n","NeoXArgs.configure_distributed_args() using world size: 1 and model-parallel size: 1 \n","> building GPT2BPETokenizer tokenizer ...\n"," > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)\n","> setting up tensorboard ...\n","2024-10-27 20:26:23.443969: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-10-27 20:26:23.705979: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-10-27 20:26:23.778612: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-10-27 20:26:26.159566: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","> initializing torch distributed ...\n","[2024-10-27 20:26:27,373] [INFO] [comm.py:637:init_distributed] cdb=None\n","[2024-10-27 20:26:27,373] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n","> initializing model parallel with size 1\n","MPU DP: [0]\n","MPU PP: [0]\n","MPU MP: [0]\n","> setting random seeds to 1234 ...\n","[2024-10-27 20:26:27,377] [INFO] [checkpointing.py:227:model_parallel_cuda_manual_seed] > initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234\n","make: Entering directory '/content/gpt-neox/megatron/data'\n","g++ -O3 -Wall -shared -std=c++11 -fPIC -fdiagnostics-color -I/usr/include/python3.10 -I/usr/local/lib/python3.10/dist-packages/pybind11/include helpers.cpp -o helpers.cpython-310-x86_64-linux-gnu.so\n","make: Leaving directory '/content/gpt-neox/megatron/data'\n","> building train, validation, and test datasets ...\n","    reading sizes...\n","    reading pointers...\n","    reading document index...\n","    creating numpy buffer of mmap...\n","    creating memory view of numpy buffer...\n"," > dataset split:\n","    train:\n","     document indices in [0, 1) total of 1 documents\n","    validation:\n","     document indices in [1, 1) total of 0 documents\n","    test:\n","     document indices in [1, 1) total of 0 documents\n"," > WARNING: could not find index map files, building the indices on rank 0 ...\n"," > elapsed time to build and save doc-idx mapping (seconds): 0.000408\n","    using:\n","     number of documents:       1\n","     number of epochs:          91\n","     sequence length:           2048\n","     total number of samples:   1289177\n"," > elapsed time to build and save sample-idx mapping (seconds): 0.022305\n"," > elapsed time to build and save shuffle-idx mapping (seconds): 0.042419\n"," > loading doc-idx mapping from data/enwik8/enwik8_text_document_train_indexmap_1280000ns_2048sl_1234s_packedpi_ac_doc_idx.npy\n"," > loading sample-idx mapping from data/enwik8/enwik8_text_document_train_indexmap_1280000ns_2048sl_1234s_packedpi_ac_sample_idx.npy\n"," > loading shuffle-idx mapping from data/enwik8/enwik8_text_document_train_indexmap_1280000ns_2048sl_1234s_packedpi_ac_shuffle_idx.npy\n","    loaded indexed file in 0.002 seconds\n","    total number of samples: 1289178\n","    total number of epochs: 91\n","building GPT2 model ...\n","SEED_LAYERS=False BASE_SEED=1234 SEED_FN=None\n","Using topology: {ProcessCoord(pipe=0, data=0, model=0): 0}\n","[2024-10-27 20:26:38,970] [INFO] [module.py:375:_partition_layers] Partitioning pipeline stages with method type:transformer|mlp\n","stage=0 layers=17\n","     0: EmbeddingPipe\n","     1: _pre_transformer_block\n","     2: ParallelTransformerLayerPipe\n","     3: ParallelTransformerLayerPipe\n","     4: ParallelTransformerLayerPipe\n","     5: ParallelTransformerLayerPipe\n","     6: ParallelTransformerLayerPipe\n","     7: ParallelTransformerLayerPipe\n","     8: ParallelTransformerLayerPipe\n","     9: ParallelTransformerLayerPipe\n","    10: ParallelTransformerLayerPipe\n","    11: ParallelTransformerLayerPipe\n","    12: ParallelTransformerLayerPipe\n","    13: ParallelTransformerLayerPipe\n","    14: _post_transformer_block\n","    15: NormPipe\n","    16: ParallelLinearPipe\n","  loss: partial\n","Configuring Optimizer type: Adam with params: {'lr': 0.0006, 'betas': [0.9, 0.95], 'eps': 1e-08}\n","WARNING: APEX not installed - defaulting to deepspeed's fused adam\n","Using /root/.cache/torch_extensions/py310_cu102 as PyTorch extensions root...\n","Creating extension directory /root/.cache/torch_extensions/py310_cu102/fused_adam...\n","Detected CUDA files, patching ldflags\n","Emitting ninja build file /root/.cache/torch_extensions/py310_cu102/fused_adam/build.ninja...\n","Building extension module fused_adam...\n","Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n","[1/3] c++ -MMD -MF fused_adam_frontend.o.d -DTORCH_EXTENSION_NAME=fused_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/usr/local/lib/python3.10/dist-packages/deepspeed/ops/csrc/includes -I/usr/local/lib/python3.10/dist-packages/deepspeed/ops/csrc/adam -isystem /usr/local/lib/python3.10/dist-packages/torch/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.10/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++17 -g -Wno-reorder -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -c /usr/local/lib/python3.10/dist-packages/deepspeed/ops/csrc/adam/fused_adam_frontend.cpp -o fused_adam_frontend.o \n","[2/3] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=fused_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/usr/local/lib/python3.10/dist-packages/deepspeed/ops/csrc/includes -I/usr/local/lib/python3.10/dist-packages/deepspeed/ops/csrc/adam -isystem /usr/local/lib/python3.10/dist-packages/torch/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.10/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -lineinfo --use_fast_math -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_75,code=compute_75 -std=c++14 -c /usr/local/lib/python3.10/dist-packages/deepspeed/ops/csrc/adam/multi_tensor_adam.cu -o multi_tensor_adam.cuda.o \n","[3/3] c++ fused_adam_frontend.o multi_tensor_adam.cuda.o -shared -L/usr/local/lib/python3.10/dist-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o fused_adam.so\n","Loading extension module fused_adam...\n","Time to load fused_adam op: 43.9732027053833 seconds\n","> learning rate decay style: cosine\n","DeepSpeed is enabled.\n","[2024-10-27 20:27:23,008] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.12.4+02e2ebf, git-hash=02e2ebf, git-branch=HEAD\n","[2024-10-27 20:27:23,053] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n","[2024-10-27 20:27:23,054] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n","[2024-10-27 20:27:23,054] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n","[2024-10-27 20:27:23,057] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam\n","[2024-10-27 20:27:23,057] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>\n","[2024-10-27 20:27:23,057] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 1 optimizer\n","[2024-10-27 20:27:23,058] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 500000000\n","[2024-10-27 20:27:23,058] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 500000000\n","[2024-10-27 20:27:23,058] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n","[2024-10-27 20:27:23,058] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n","[2024-10-27 20:27:23,921] [INFO] [utils.py:802:see_memory_usage] Before initializing optimizer states\n","[2024-10-27 20:27:23,922] [INFO] [utils.py:803:see_memory_usage] MA 0.91 GB         Max_MA 0.91 GB         CA 0.91 GB         Max_CA 1 GB \n","[2024-10-27 20:27:23,922] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 4.53 GB, percent = 35.7%\n","[2024-10-27 20:27:24,134] [INFO] [utils.py:802:see_memory_usage] After initializing optimizer states\n","[2024-10-27 20:27:24,135] [INFO] [utils.py:803:see_memory_usage] MA 2.12 GB         Max_MA 2.72 GB         CA 2.73 GB         Max_CA 3 GB \n","[2024-10-27 20:27:24,135] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 4.53 GB, percent = 35.7%\n","[2024-10-27 20:27:24,135] [INFO] [stage_1_and_2.py:517:__init__] optimizer state initialized\n","[2024-10-27 20:27:24,344] [INFO] [utils.py:802:see_memory_usage] After initializing ZeRO optimizer\n","[2024-10-27 20:27:24,345] [INFO] [utils.py:803:see_memory_usage] MA 2.12 GB         Max_MA 2.12 GB         CA 2.73 GB         Max_CA 3 GB \n","[2024-10-27 20:27:24,345] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 4.53 GB, percent = 35.7%\n","[2024-10-27 20:27:24,348] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam\n","[2024-10-27 20:27:24,349] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n","[2024-10-27 20:27:24,349] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <megatron.learning_rates.AnnealingLR object at 0x11463924a230>\n","[2024-10-27 20:27:24,349] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[[0.9, 0.95], [0.9, 0.95]]\n","[2024-10-27 20:27:24,349] [INFO] [config.py:979:print] DeepSpeedEngine configuration:\n","[2024-10-27 20:27:24,350] [INFO] [config.py:983:print]   activation_checkpointing_config  {\n","    \"partition_activations\": false, \n","    \"contiguous_memory_optimization\": false, \n","    \"cpu_checkpointing\": false, \n","    \"number_checkpoints\": null, \n","    \"synchronize_checkpoint_boundary\": false, \n","    \"profile\": false\n","}\n","[2024-10-27 20:27:24,350] [INFO] [config.py:983:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n","[2024-10-27 20:27:24,350] [INFO] [config.py:983:print]   amp_enabled .................. False\n","[2024-10-27 20:27:24,350] [INFO] [config.py:983:print]   amp_params ................... False\n","[2024-10-27 20:27:24,350] [INFO] [config.py:983:print]   autotuning_config ............ {\n","    \"enabled\": false, \n","    \"start_step\": null, \n","    \"end_step\": null, \n","    \"metric_path\": null, \n","    \"arg_mappings\": null, \n","    \"metric\": \"throughput\", \n","    \"model_info\": null, \n","    \"results_dir\": \"autotuning_results\", \n","    \"exps_dir\": \"autotuning_exps\", \n","    \"overwrite\": true, \n","    \"fast\": true, \n","    \"start_profile_step\": 3, \n","    \"end_profile_step\": 5, \n","    \"tuner_type\": \"gridsearch\", \n","    \"tuner_early_stopping\": 5, \n","    \"tuner_num_trials\": 50, \n","    \"model_info_path\": null, \n","    \"mp_size\": 1, \n","    \"max_train_batch_size\": null, \n","    \"min_train_batch_size\": 1, \n","    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n","    \"min_train_micro_batch_size_per_gpu\": 1, \n","    \"num_tuning_micro_batch_sizes\": 3\n","}\n","[2024-10-27 20:27:24,350] [INFO] [config.py:983:print]   bfloat16_enabled ............. False\n","[2024-10-27 20:27:24,350] [INFO] [config.py:983:print]   checkpoint_parallel_write_pipeline  False\n","[2024-10-27 20:27:24,350] [INFO] [config.py:983:print]   checkpoint_tag_validation_enabled  True\n","[2024-10-27 20:27:24,350] [INFO] [config.py:983:print]   checkpoint_tag_validation_fail  False\n","[2024-10-27 20:27:24,350] [INFO] [config.py:983:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x1146392a9bd0>\n","[2024-10-27 20:27:24,351] [INFO] [config.py:983:print]   communication_data_type ...... None\n","[2024-10-27 20:27:24,351] [INFO] [config.py:983:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n","[2024-10-27 20:27:24,351] [INFO] [config.py:983:print]   curriculum_enabled_legacy .... False\n","[2024-10-27 20:27:24,351] [INFO] [config.py:983:print]   curriculum_params_legacy ..... False\n","[2024-10-27 20:27:24,351] [INFO] [config.py:983:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n","[2024-10-27 20:27:24,351] [INFO] [config.py:983:print]   data_efficiency_enabled ...... False\n","[2024-10-27 20:27:24,351] [INFO] [config.py:983:print]   dataloader_drop_last ......... False\n","[2024-10-27 20:27:24,351] [INFO] [config.py:983:print]   disable_allgather ............ False\n","[2024-10-27 20:27:24,351] [INFO] [config.py:983:print]   dump_state ................... False\n","[2024-10-27 20:27:24,351] [INFO] [config.py:983:print]   dynamic_loss_scale_args ...... {'init_scale': 65536, 'scale_window': 1000, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}\n","[2024-10-27 20:27:24,351] [INFO] [config.py:983:print]   eigenvalue_enabled ........... False\n","[2024-10-27 20:27:24,351] [INFO] [config.py:983:print]   eigenvalue_gas_boundary_resolution  1\n","[2024-10-27 20:27:24,351] [INFO] [config.py:983:print]   eigenvalue_layer_name ........ bert.encoder.layer\n","[2024-10-27 20:27:24,351] [INFO] [config.py:983:print]   eigenvalue_layer_num ......... 0\n","[2024-10-27 20:27:24,351] [INFO] [config.py:983:print]   eigenvalue_max_iter .......... 100\n","[2024-10-27 20:27:24,351] [INFO] [config.py:983:print]   eigenvalue_stability ......... 1e-06\n","[2024-10-27 20:27:24,351] [INFO] [config.py:983:print]   eigenvalue_tol ............... 0.01\n","[2024-10-27 20:27:24,351] [INFO] [config.py:983:print]   eigenvalue_verbose ........... False\n","[2024-10-27 20:27:24,351] [INFO] [config.py:983:print]   elasticity_enabled ........... False\n","[2024-10-27 20:27:24,351] [INFO] [config.py:983:print]   flops_profiler_config ........ {\n","    \"enabled\": false, \n","    \"recompute_fwd_factor\": 0.0, \n","    \"profile_step\": 1, \n","    \"module_depth\": -1, \n","    \"top_modules\": 1, \n","    \"detailed\": true, \n","    \"output_file\": null\n","}\n","[2024-10-27 20:27:24,351] [INFO] [config.py:983:print]   fp16_auto_cast ............... False\n","[2024-10-27 20:27:24,351] [INFO] [config.py:983:print]   fp16_enabled ................. True\n","[2024-10-27 20:27:24,351] [INFO] [config.py:983:print]   fp16_master_weights_and_gradients  False\n","[2024-10-27 20:27:24,351] [INFO] [config.py:983:print]   global_rank .................. 0\n","[2024-10-27 20:27:24,351] [INFO] [config.py:983:print]   grad_accum_dtype ............. None\n","[2024-10-27 20:27:24,352] [INFO] [config.py:983:print]   gradient_accumulation_steps .. 1\n","[2024-10-27 20:27:24,352] [INFO] [config.py:983:print]   gradient_clipping ............ 0.0\n","[2024-10-27 20:27:24,352] [INFO] [config.py:983:print]   gradient_predivide_factor .... 1.0\n","[2024-10-27 20:27:24,352] [INFO] [config.py:983:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n","[2024-10-27 20:27:24,352] [INFO] [config.py:983:print]   initial_dynamic_scale ........ 65536\n","[2024-10-27 20:27:24,352] [INFO] [config.py:983:print]   load_universal_checkpoint .... False\n","[2024-10-27 20:27:24,352] [INFO] [config.py:983:print]   loss_scale ................... 0\n","[2024-10-27 20:27:24,352] [INFO] [config.py:983:print]   memory_breakdown ............. False\n","[2024-10-27 20:27:24,352] [INFO] [config.py:983:print]   mics_hierarchial_params_gather  False\n","[2024-10-27 20:27:24,352] [INFO] [config.py:983:print]   mics_shard_size .............. -1\n","[2024-10-27 20:27:24,352] [INFO] [config.py:983:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n","[2024-10-27 20:27:24,352] [INFO] [config.py:983:print]   nebula_config ................ {\n","    \"enabled\": false, \n","    \"persistent_storage_path\": null, \n","    \"persistent_time_interval\": 100, \n","    \"num_of_version_in_retention\": 2, \n","    \"enable_nebula_load\": true, \n","    \"load_path\": null\n","}\n","[2024-10-27 20:27:24,352] [INFO] [config.py:983:print]   optimizer_legacy_fusion ...... False\n","[2024-10-27 20:27:24,352] [INFO] [config.py:983:print]   optimizer_name ............... adam\n","[2024-10-27 20:27:24,352] [INFO] [config.py:983:print]   optimizer_params ............. {'lr': 0.0006, 'betas': [0.9, 0.95], 'eps': 1e-08}\n","[2024-10-27 20:27:24,352] [INFO] [config.py:983:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n","[2024-10-27 20:27:24,352] [INFO] [config.py:983:print]   pld_enabled .................. False\n","[2024-10-27 20:27:24,353] [INFO] [config.py:983:print]   pld_params ................... False\n","[2024-10-27 20:27:24,353] [INFO] [config.py:983:print]   prescale_gradients ........... False\n","[2024-10-27 20:27:24,353] [INFO] [config.py:983:print]   scheduler_name ............... None\n","[2024-10-27 20:27:24,353] [INFO] [config.py:983:print]   scheduler_params ............. None\n","[2024-10-27 20:27:24,353] [INFO] [config.py:983:print]   seq_parallel_communication_data_type  torch.float32\n","[2024-10-27 20:27:24,353] [INFO] [config.py:983:print]   sparse_attention ............. None\n","[2024-10-27 20:27:24,353] [INFO] [config.py:983:print]   sparse_gradients_enabled ..... False\n","[2024-10-27 20:27:24,353] [INFO] [config.py:983:print]   steps_per_print .............. 10\n","[2024-10-27 20:27:24,353] [INFO] [config.py:983:print]   train_batch_size ............. 4\n","[2024-10-27 20:27:24,353] [INFO] [config.py:983:print]   train_micro_batch_size_per_gpu  4\n","[2024-10-27 20:27:24,353] [INFO] [config.py:983:print]   use_data_before_expert_parallel_  False\n","[2024-10-27 20:27:24,353] [INFO] [config.py:983:print]   use_node_local_storage ....... False\n","[2024-10-27 20:27:24,353] [INFO] [config.py:983:print]   wall_clock_breakdown ......... True\n","[2024-10-27 20:27:24,353] [INFO] [config.py:983:print]   weight_quantization_config ... None\n","[2024-10-27 20:27:24,353] [INFO] [config.py:983:print]   world_size ................... 1\n","[2024-10-27 20:27:24,353] [INFO] [config.py:983:print]   zero_allow_untested_optimizer  False\n","[2024-10-27 20:27:24,353] [INFO] [config.py:983:print]   zero_config .................. stage=1 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n","[2024-10-27 20:27:24,353] [INFO] [config.py:983:print]   zero_enabled ................. True\n","[2024-10-27 20:27:24,353] [INFO] [config.py:983:print]   zero_force_ds_cpu_optimizer .. True\n","[2024-10-27 20:27:24,353] [INFO] [config.py:983:print]   zero_optimization_stage ...... 1\n","[2024-10-27 20:27:24,354] [INFO] [config.py:969:print_user_config]   json = {\n","    \"train_batch_size\": 4, \n","    \"train_micro_batch_size_per_gpu\": 4, \n","    \"optimizer\": {\n","        \"type\": \"Adam\", \n","        \"params\": {\n","            \"lr\": 0.0006, \n","            \"betas\": [0.9, 0.95], \n","            \"eps\": 1e-08\n","        }\n","    }, \n","    \"fp16\": {\n","        \"enabled\": true, \n","        \"loss_scale\": 0, \n","        \"loss_scale_window\": 1000, \n","        \"hysteresis\": 2, \n","        \"min_loss_scale\": 1\n","    }, \n","    \"zero_optimization\": {\n","        \"stage\": 1, \n","        \"allgather_partitions\": true, \n","        \"allgather_bucket_size\": 5.000000e+08, \n","        \"overlap_comm\": true, \n","        \"reduce_scatter\": true, \n","        \"reduce_bucket_size\": 5.000000e+08, \n","        \"contiguous_gradients\": true\n","    }, \n","    \"wall_clock_breakdown\": true\n","}\n","[2024-10-27 20:27:24,354] [INFO] [engine.py:99:__init__] CONFIG: micro_batches=1 micro_batch_size=4\n","[2024-10-27 20:27:24,354] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False\n","[2024-10-27 20:27:24,389] [INFO] [engine.py:158:__init__] RANK=0 STAGE=0 LAYERS=17 [0, 17) STAGE_PARAMS=162322944 (162.323M) TOTAL_PARAMS=162322944 (162.323M) UNIQUE_PARAMS=162322944 (162.323M)\n"," > number of parameters on model parallel rank 0: 162322944\n"," > total params: 162,322,944\n","[2024-10-27 20:27:24,393] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at checkpoints/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.\n","Unable to load checkpoint.\n","Loading checkpoint and starting from iteration 0\n","setting training data start iteration to 0\n","done with setups ...\n","time (ms) | train/valid/test data loaders: 4428.44 | model and optimizer: 45426.30 | train/valid/test data iterators: 108.30\n","training ...\n","[2024-10-27 20:27:24,574] [INFO] [checkpointing.py:540:forward] Activation Checkpointing Information\n","[2024-10-27 20:27:24,574] [INFO] [checkpointing.py:541:forward] ----Partition Activations True, CPU CHECKPOINTING False\n","[2024-10-27 20:27:24,574] [INFO] [checkpointing.py:542:forward] ----contiguous Memory Checkpointing False with 12 total layers\n","[2024-10-27 20:27:24,574] [INFO] [checkpointing.py:544:forward] ----Synchronization True\n","[2024-10-27 20:27:24,575] [INFO] [checkpointing.py:545:forward] ----Profiling time in checkpointing False\n","[2024-10-27 20:27:27,778] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.00 | optimizer_gradients: 13.65 | optimizer_step: 27.73\n","[2024-10-27 20:27:29,289] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.00 | optimizer_gradients: 13.63 | optimizer_step: 27.73\n","[2024-10-27 20:27:30,784] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.00 | optimizer_gradients: 13.53 | optimizer_step: 27.65\n","[2024-10-27 20:27:32,281] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.00 | optimizer_gradients: 13.57 | optimizer_step: 27.69\n","[2024-10-27 20:27:33,778] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.00 | optimizer_gradients: 13.60 | optimizer_step: 27.67\n","[2024-10-27 20:27:35,275] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.00 | optimizer_gradients: 13.57 | optimizer_step: 27.72\n","[2024-10-27 20:27:36,778] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.00 | optimizer_gradients: 13.57 | optimizer_step: 27.73\n","[2024-10-27 20:27:38,279] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.00 | optimizer_gradients: 13.59 | optimizer_step: 27.70\n","[2024-10-27 20:27:39,792] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.00 | optimizer_gradients: 13.59 | optimizer_step: 27.69\n","[2024-10-27 20:27:41,312] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.00 | optimizer_gradients: 13.63 | optimizer_step: 27.73\n","[2024-10-27 20:27:41,312] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=0, lr=[1.8749999999999998e-06, 1.8749999999999998e-06], mom=[[0.9, 0.95], [0.9, 0.95]]\n","[2024-10-27 20:27:41,314] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 78.62 | fwd_microstep: 4748.00 | bwd_microstep: 10442.84 | bwd_inner_microstep: 10441.77 | bwd_allreduce_microstep: 0.21 | step_microstep: 753.48\n","[2024-10-27 20:27:41,315] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 4747.60 | bwd: 10442.69 | bwd_inner: 10441.58 | bwd_allreduce: 0.25 | step: 753.70\n","steps: 10 loss: 10.8347 iter time (s): 1.679 samples/sec: 2.382\n","[2024-10-27 20:27:41,316] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms)\n","[2024-10-27 20:27:42,839] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.00 | optimizer_gradients: 13.63 | optimizer_step: 27.67\n","[2024-10-27 20:27:44,374] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.00 | optimizer_gradients: 13.95 | optimizer_step: 27.73\n","[2024-10-27 20:27:45,898] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.00 | optimizer_gradients: 13.53 | optimizer_step: 27.65\n","[2024-10-27 20:27:47,415] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.00 | optimizer_gradients: 13.51 | optimizer_step: 27.64\n","[2024-10-27 20:27:48,938] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.00 | optimizer_gradients: 13.52 | optimizer_step: 27.62\n","[2024-10-27 20:27:50,457] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.00 | optimizer_gradients: 13.55 | optimizer_step: 27.66\n","[2024-10-27 20:27:51,994] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.00 | optimizer_gradients: 13.53 | optimizer_step: 27.60\n","[2024-10-27 20:27:53,521] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.00 | optimizer_gradients: 13.57 | optimizer_step: 27.68\n","[2024-10-27 20:27:55,051] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.00 | optimizer_gradients: 13.51 | optimizer_step: 27.61\n","[2024-10-27 20:27:56,589] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.00 | optimizer_gradients: 13.59 | optimizer_step: 27.73\n","[2024-10-27 20:27:56,589] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=0, lr=[3.7499999999999997e-06, 3.7499999999999997e-06], mom=[[0.9, 0.95], [0.9, 0.95]]\n","[2024-10-27 20:27:56,591] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | batch_input: 26.80 | fwd_microstep: 3208.29 | bwd_microstep: 10490.90 | bwd_inner_microstep: 10490.13 | bwd_allreduce_microstep: 0.09 | step_microstep: 759.47\n","[2024-10-27 20:27:56,592] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 3208.03 | bwd: 10490.71 | bwd_inner: 10489.95 | bwd_allreduce: 0.11 | step: 759.69\n","steps: 20 loss: 10.1767 iter time (s): 1.526 samples/sec: 2.622\n","[2024-10-27 20:27:56,593] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"TZm3BCHQlqku"},"execution_count":null,"outputs":[]}]}