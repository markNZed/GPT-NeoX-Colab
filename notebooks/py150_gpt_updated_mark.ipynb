{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7d339573e3bb4d268f64b3657a4f19a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b54e5b61ded4d09822640e6f7e46107",
              "IPY_MODEL_53a62faff75d450e811186209b6f69ab",
              "IPY_MODEL_e9e8cd831e2f4011aa22b162787a381b"
            ],
            "layout": "IPY_MODEL_743a890fc61749259bc6dbd3c1f94f86"
          }
        },
        "0b54e5b61ded4d09822640e6f7e46107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42cd3223cac443358872eee3c5f537ee",
            "placeholder": "​",
            "style": "IPY_MODEL_c1069ed6b01d47ba85601bf24f40fad5",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "53a62faff75d450e811186209b6f69ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96d11c2cf9544b4cb36ddd46f71d45c7",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_42522aebd7bc4be587cb74bf0a26f95c",
            "value": 26
          }
        },
        "e9e8cd831e2f4011aa22b162787a381b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2404181a0e36474498273059f85a785b",
            "placeholder": "​",
            "style": "IPY_MODEL_59ea7f5b4fdf4ddba5fa8be002affbf4",
            "value": " 26.0/26.0 [00:00&lt;00:00, 1.61kB/s]"
          }
        },
        "743a890fc61749259bc6dbd3c1f94f86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42cd3223cac443358872eee3c5f537ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1069ed6b01d47ba85601bf24f40fad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96d11c2cf9544b4cb36ddd46f71d45c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42522aebd7bc4be587cb74bf0a26f95c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2404181a0e36474498273059f85a785b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59ea7f5b4fdf4ddba5fa8be002affbf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dff53ad09a39473eb4cc4a9051376cf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1cece3836854eeca3a156f9cd4d3d75",
              "IPY_MODEL_f3a4c2a4ddcb4c49890731309ea8114f",
              "IPY_MODEL_0b782f51c7164017a78aaf7a99f27311"
            ],
            "layout": "IPY_MODEL_ef92b995424740f49671cc49e2cb0a83"
          }
        },
        "a1cece3836854eeca3a156f9cd4d3d75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9990d8bd135f496daf9781b188503983",
            "placeholder": "​",
            "style": "IPY_MODEL_5de9030e43e24af6889188860ee34770",
            "value": "vocab.json: 100%"
          }
        },
        "f3a4c2a4ddcb4c49890731309ea8114f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e6481655a2343ab95fc55d3df1bedf6",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a68e459e08804258979a87b4fe8e857d",
            "value": 1042301
          }
        },
        "0b782f51c7164017a78aaf7a99f27311": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe38365787914258952deebdeedb2466",
            "placeholder": "​",
            "style": "IPY_MODEL_d1f1c77426514243aa2c7d2003202011",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 3.81MB/s]"
          }
        },
        "ef92b995424740f49671cc49e2cb0a83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9990d8bd135f496daf9781b188503983": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5de9030e43e24af6889188860ee34770": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e6481655a2343ab95fc55d3df1bedf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a68e459e08804258979a87b4fe8e857d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe38365787914258952deebdeedb2466": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1f1c77426514243aa2c7d2003202011": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1cf9aaaf8797439298e7719174dee870": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_937cd34e7447410f91236829a0d8d748",
              "IPY_MODEL_8d7b998358a04d8584dba4d97f769d03",
              "IPY_MODEL_76c39bfe2a4d41c2ae63c38213fc1047"
            ],
            "layout": "IPY_MODEL_0fe91eb02a2446b09c0dcd2d6b34ad19"
          }
        },
        "937cd34e7447410f91236829a0d8d748": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2a0d521b03b4aaab7a5da5da96322f3",
            "placeholder": "​",
            "style": "IPY_MODEL_983eb9124e454a12bd3f99cbbe9c4902",
            "value": "merges.txt: 100%"
          }
        },
        "8d7b998358a04d8584dba4d97f769d03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d26976f64094f7ebb4c803cb8e4255b",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62cf1059e6684256bd6c87e186fa6654",
            "value": 456318
          }
        },
        "76c39bfe2a4d41c2ae63c38213fc1047": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81fd6ab99a9647a5b30695f5c8614551",
            "placeholder": "​",
            "style": "IPY_MODEL_09f97e6566214b1591a7877dea3f5ca8",
            "value": " 456k/456k [00:00&lt;00:00, 3.52MB/s]"
          }
        },
        "0fe91eb02a2446b09c0dcd2d6b34ad19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2a0d521b03b4aaab7a5da5da96322f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "983eb9124e454a12bd3f99cbbe9c4902": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d26976f64094f7ebb4c803cb8e4255b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62cf1059e6684256bd6c87e186fa6654": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "81fd6ab99a9647a5b30695f5c8614551": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09f97e6566214b1591a7877dea3f5ca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb12959b6d7445f097932f5218c6794d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85620201b3164381a622022ca24f521d",
              "IPY_MODEL_22c23eec60504f638e2cefc28af657ad",
              "IPY_MODEL_c2de5cd484b3438cafb6b247603295b8"
            ],
            "layout": "IPY_MODEL_e8a4c17206e2441cb85bb4bdae60ca39"
          }
        },
        "85620201b3164381a622022ca24f521d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dade3d93bb9b4a98b8103e5dc555d3cf",
            "placeholder": "​",
            "style": "IPY_MODEL_9fb29d5ed2c4482e8011f50ee3a9f999",
            "value": "tokenizer.json: 100%"
          }
        },
        "22c23eec60504f638e2cefc28af657ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_778d9faad7014b0988201e838a98cef2",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ac6b5a4f76847a784e975302de97957",
            "value": 1355256
          }
        },
        "c2de5cd484b3438cafb6b247603295b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d9f5156d7ab410ebb99b82a2cbbfa01",
            "placeholder": "​",
            "style": "IPY_MODEL_30567ea02bbd4c69a37cf65a87ce55ba",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 4.10MB/s]"
          }
        },
        "e8a4c17206e2441cb85bb4bdae60ca39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dade3d93bb9b4a98b8103e5dc555d3cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fb29d5ed2c4482e8011f50ee3a9f999": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "778d9faad7014b0988201e838a98cef2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ac6b5a4f76847a784e975302de97957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d9f5156d7ab410ebb99b82a2cbbfa01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30567ea02bbd4c69a37cf65a87ce55ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31467005d1fe4b3aa30df5ccca7caef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82028479d102409c843092cbe0b84225",
              "IPY_MODEL_cc0cfd79739044b58d5c600f39ae4202",
              "IPY_MODEL_97787c990ad54964a6e855f8c56db086"
            ],
            "layout": "IPY_MODEL_d486405f78a3409590437c0f9a23c261"
          }
        },
        "82028479d102409c843092cbe0b84225": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c0b710da583491b86bbb86eb79f2d18",
            "placeholder": "​",
            "style": "IPY_MODEL_7665ed11d1d14eb69a2651b2d547b864",
            "value": "config.json: 100%"
          }
        },
        "cc0cfd79739044b58d5c600f39ae4202": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7aae498c75ca4200bdad80fcce411246",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43248401b800496896a35f3f99fe3ce1",
            "value": 665
          }
        },
        "97787c990ad54964a6e855f8c56db086": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ff6cc68f3684533a055be07572de8ae",
            "placeholder": "​",
            "style": "IPY_MODEL_0d280ce820634d7e91b322a3cef88e4f",
            "value": " 665/665 [00:00&lt;00:00, 27.9kB/s]"
          }
        },
        "d486405f78a3409590437c0f9a23c261": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c0b710da583491b86bbb86eb79f2d18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7665ed11d1d14eb69a2651b2d547b864": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7aae498c75ca4200bdad80fcce411246": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43248401b800496896a35f3f99fe3ce1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ff6cc68f3684533a055be07572de8ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d280ce820634d7e91b322a3cef88e4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Clone CodeXGLUE Repo"
      ],
      "metadata": {
        "id": "OpgI19mPrtvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!git clone https://github.com/microsoft/CodeXGLUE.git\n",
        "!git clone -b GPT-NeoX-Colab git@github.com:markNZed/CodeXGLUE.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOySwjeyktsH",
        "outputId": "affba2c6-abdf-46ee-9e0c-1eb3ce3e4d71"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CodeXGLUE'...\n",
            "remote: Enumerating objects: 3373, done.\u001b[K\n",
            "remote: Counting objects: 100% (3372/3372), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1534/1534), done.\u001b[K\n",
            "remote: Total 3373 (delta 1748), reused 3326 (delta 1733), pack-reused 1 (from 1)\u001b[K\n",
            "Receiving objects: 100% (3373/3373), 213.15 MiB | 9.83 MiB/s, done.\n",
            "Resolving deltas: 100% (1748/1748), done.\n",
            "Updating files: 100% (400/400), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git lfs install\n",
        "!git clone https://github.com/markNZed/GPT-NeoX-Colab.git\n",
        "%cd /content/GPT-NeoX-Colab/data\n",
        "!tar -xf py150_preprocessed.tar.gz\n",
        "!mkdir -p /content/CodeXGLUE/Code-Code/CodeCompletion-token/dataset/py150/token_completion\n",
        "!cp py150_preprocessed/* /content/CodeXGLUE/Code-Code/CodeCompletion-token/dataset/py150/token_completion\n",
        "%cd /content"
      ],
      "metadata": {
        "id": "1m7so6NvF6J5",
        "outputId": "a7545104-acf3-4b8c-a58a-9fedd89a860e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Git LFS initialized.\n",
            "fatal: destination path 'GPT-NeoX-Colab' already exists and is not an empty directory.\n",
            "/content/GPT-NeoX-Colab/data\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading and Preprocessing Dataset"
      ],
      "metadata": {
        "id": "-UV1kBtFXkKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the file path you want to check for existence\n",
        "file_path = \"/content/CodeXGLUE/Code-Code/CodeCompletion-token/dataset/py150/token_completion\"  # Replace with the actual file name you want to check\n",
        "\n",
        "# Check if the file exists\n",
        "if not os.path.exists(file_path):\n",
        "    # Change directory\n",
        "    %cd /content/CodeXGLUE/Code-Code/CodeCompletion-token/dataset/py150\n",
        "    # Run the shell script to download and extract\n",
        "    !bash /content/CodeXGLUE/Code-Code/CodeCompletion-token/dataset/py150/download_and_extract.sh\n",
        "    # Run the preprocessing Python script\n",
        "    !python preprocess.py --base_dir=py150_files --output_dir=token_completion\n",
        "else:\n",
        "    print(\"File already exists, skipping download and preprocessing.\")\n"
      ],
      "metadata": {
        "id": "fn0Wy7g7lGGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cloning GPT-NeoX Repo"
      ],
      "metadata": {
        "id": "Y_0FMSSnXzW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/EleutherAI/gpt-neox.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OguN3qpTQAQs",
        "outputId": "1908b6a4-7bc9-408d-e994-2402cc8e7bd8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'gpt-neox'...\n",
            "remote: Enumerating objects: 19496, done.\u001b[K\n",
            "remote: Counting objects: 100% (1699/1699), done.\u001b[K\n",
            "remote: Compressing objects: 100% (822/822), done.\u001b[K\n",
            "remote: Total 19496 (delta 1252), reused 1206 (delta 869), pack-reused 17797 (from 1)\u001b[K\n",
            "Receiving objects: 100% (19496/19496), 113.65 MiB | 27.83 MiB/s, done.\n",
            "Resolving deltas: 100% (14109/14109), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/markNZed/GPT-NeoX-Colab.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4IqZlX9QNxx",
        "outputId": "61f86718-c0ac-4749-a89f-aac1bed83b79"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'GPT-NeoX-Colab' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Dependencies"
      ],
      "metadata": {
        "id": "NWTuy456X7Yl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "%cd /content/gpt-neox\n",
        "# Could not redirect to /dev/null in the standard Colab notebook (maybe no output for a particular time?)\n",
        "# Currently deepspeed from GTP-NeoX is not compatible with logging in torch >= 2.4\n",
        "!pip install torch==2.3 torchaudio==2.3.0 torchvision==0.18.0 transformers==4.41.0 sentence-transformers==2.2.2\n",
        "!pip install -r ./requirements/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QH7iL-O-Qq3A",
        "outputId": "d3b4693a-64b4-424d-9621-10a1ef8f2c23"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gpt-neox\n",
            "Collecting torch==2.3\n",
            "  Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting torchaudio==2.3.0\n",
            "  Downloading torchaudio-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting torchvision==0.18.0\n",
            "  Downloading torchvision-0.18.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting transformers==4.41.0\n",
            "  Downloading transformers-4.41.0-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentence-transformers==2.2.2\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.3.0 (from torch==2.3)\n",
            "  Downloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.18.0) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.18.0) (10.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.0) (0.24.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.0) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.0) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.0) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.0) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.0) (4.66.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (1.13.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (0.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3) (12.6.77)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3) (3.0.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers==2.2.2) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers==2.2.2) (1.4.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.41.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.41.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.41.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.41.0) (2024.8.30)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers==2.2.2) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3) (1.3.0)\n",
            "Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.3.0-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.18.0-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.41.0-py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m104.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125924 sha256=5262c341cd181066615c66756b709377d4cd9a4b3b29d282f717bb163c26b214\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, transformers, torchvision, torchaudio, sentence-transformers\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.3.3\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.3.3:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.3.3\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.5.1.17\n",
            "    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.0+cu121\n",
            "    Uninstalling torch-2.5.0+cu121:\n",
            "      Successfully uninstalled torch-2.5.0+cu121\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.44.2\n",
            "    Uninstalling transformers-4.44.2:\n",
            "      Successfully uninstalled transformers-4.44.2\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.0+cu121\n",
            "    Uninstalling torchvision-0.20.0+cu121:\n",
            "      Successfully uninstalled torchvision-0.20.0+cu121\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.5.0+cu121\n",
            "    Uninstalling torchaudio-2.5.0+cu121:\n",
            "      Successfully uninstalled torchaudio-2.5.0+cu121\n",
            "  Attempting uninstall: sentence-transformers\n",
            "    Found existing installation: sentence-transformers 3.2.1\n",
            "    Uninstalling sentence-transformers-3.2.1:\n",
            "      Successfully uninstalled sentence-transformers-3.2.1\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 sentence-transformers-2.2.2 torch-2.3.0 torchaudio-2.3.0 torchvision-0.18.0 transformers-4.41.0 triton-2.3.0\n",
            "Collecting deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed (from -r ./requirements/requirements.txt (line 1))\n",
            "  Cloning https://github.com/EleutherAI/DeeperSpeed.git (to revision 02e2ebf7dee6aaab3d89094ed470a4609763c742) to /tmp/pip-install-gsm6m1u_/deepspeed_98be2daf5b60452faa373807575c37ee\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/EleutherAI/DeeperSpeed.git /tmp/pip-install-gsm6m1u_/deepspeed_98be2daf5b60452faa373807575c37ee\n",
            "  Running command git rev-parse -q --verify 'sha^02e2ebf7dee6aaab3d89094ed470a4609763c742'\n",
            "  Running command git fetch -q https://github.com/EleutherAI/DeeperSpeed.git 02e2ebf7dee6aaab3d89094ed470a4609763c742\n",
            "  Running command git checkout -q 02e2ebf7dee6aaab3d89094ed470a4609763c742\n",
            "  Resolved https://github.com/EleutherAI/DeeperSpeed.git to commit 02e2ebf7dee6aaab3d89094ed470a4609763c742\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lm_dataformat@ git+https://github.com/EleutherAI/lm_dataformat.git@4eec05349977071bf67fc072290b95e31c8dd836 (from -r ./requirements/requirements.txt (line 5))\n",
            "  Cloning https://github.com/EleutherAI/lm_dataformat.git (to revision 4eec05349977071bf67fc072290b95e31c8dd836) to /tmp/pip-install-gsm6m1u_/lm-dataformat_406b0b9013e1436d9b285b0a09dbbc96\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/EleutherAI/lm_dataformat.git /tmp/pip-install-gsm6m1u_/lm-dataformat_406b0b9013e1436d9b285b0a09dbbc96\n",
            "  Running command git rev-parse -q --verify 'sha^4eec05349977071bf67fc072290b95e31c8dd836'\n",
            "  Running command git fetch -q https://github.com/EleutherAI/lm_dataformat.git 4eec05349977071bf67fc072290b95e31c8dd836\n",
            "  Resolved https://github.com/EleutherAI/lm_dataformat.git to commit 4eec05349977071bf67fc072290b95e31c8dd836\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy>=6.0.1 (from -r ./requirements/requirements.txt (line 2))\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: huggingface_hub>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements/requirements.txt (line 3)) (0.24.7)\n",
            "Requirement already satisfied: jinja2==3.1.4 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements/requirements.txt (line 4)) (3.1.4)\n",
            "Collecting lm_eval<=0.4.1,>=0.4.0 (from -r ./requirements/requirements.txt (line 6))\n",
            "  Downloading lm_eval-0.4.1-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting mpi4py>=3.0.3 (from -r ./requirements/requirements.txt (line 7))\n",
            "  Downloading mpi4py-4.0.1.tar.gz (466 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m466.2/466.2 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements/requirements.txt (line 8)) (1.26.4)\n",
            "Collecting pybind11>=2.6.2 (from -r ./requirements/requirements.txt (line 9))\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from -r ./requirements/requirements.txt (line 10)) (2024.9.11)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from -r ./requirements/requirements.txt (line 11)) (0.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from -r ./requirements/requirements.txt (line 12)) (1.16.0)\n",
            "Collecting tiktoken>=0.1.2 (from -r ./requirements/requirements.txt (line 13))\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: tokenizers>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements/requirements.txt (line 14)) (0.19.1)\n",
            "Collecting transformers==4.38.0 (from -r ./requirements/requirements.txt (line 15))\n",
            "  Downloading transformers-4.38.0-py3-none-any.whl.metadata (131 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.1/131.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2==3.1.4->-r ./requirements/requirements.txt (line 4)) (3.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0->-r ./requirements/requirements.txt (line 15)) (3.16.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0->-r ./requirements/requirements.txt (line 15)) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0->-r ./requirements/requirements.txt (line 15)) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0->-r ./requirements/requirements.txt (line 15)) (2.32.3)\n",
            "Collecting tokenizers>=0.12.1 (from -r ./requirements/requirements.txt (line 14))\n",
            "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0->-r ./requirements/requirements.txt (line 15)) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0->-r ./requirements/requirements.txt (line 15)) (4.66.6)\n",
            "Collecting hjson (from deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1))\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting ninja (from deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1))\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (9.0.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (2.9.2)\n",
            "Collecting pynvml (from deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1))\n",
            "  Downloading pynvml-11.5.3-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy>=6.0.1->-r ./requirements/requirements.txt (line 2)) (0.2.13)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.11.0->-r ./requirements/requirements.txt (line 3)) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.11.0->-r ./requirements/requirements.txt (line 3)) (4.12.2)\n",
            "Collecting zstandard (from lm_dataformat@ git+https://github.com/EleutherAI/lm_dataformat.git@4eec05349977071bf67fc072290b95e31c8dd836->-r ./requirements/requirements.txt (line 5))\n",
            "  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting jsonlines (from lm_dataformat@ git+https://github.com/EleutherAI/lm_dataformat.git@4eec05349977071bf67fc072290b95e31c8dd836->-r ./requirements/requirements.txt (line 5))\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting ujson (from lm_dataformat@ git+https://github.com/EleutherAI/lm_dataformat.git@4eec05349977071bf67fc072290b95e31c8dd836->-r ./requirements/requirements.txt (line 5))\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (0.34.2)\n",
            "Collecting evaluate (from lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6))\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting datasets>=2.14.0 (from lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6))\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (2.10.1)\n",
            "Requirement already satisfied: peft>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (0.13.2)\n",
            "Collecting pytablewriter (from lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6))\n",
            "  Downloading pytablewriter-1.2.0-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting rouge-score>=0.0.4 (from lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6))\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacrebleu>=1.5.0 (from lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6))\n",
            "  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (1.5.2)\n",
            "Collecting sqlitedict (from lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6))\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tqdm-multiprocess (from lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6))\n",
            "  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (2.2.2)\n",
            "Collecting xxhash (from datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6))\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6))\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface_hub>=0.11.0->-r ./requirements/requirements.txt (line 3))\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (3.10.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.0->-r ./requirements/requirements.txt (line 15)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.0->-r ./requirements/requirements.txt (line 15)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.0->-r ./requirements/requirements.txt (line 15)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.0->-r ./requirements/requirements.txt (line 15)) (2024.8.30)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (3.8.1)\n",
            "Collecting portalocker (from sacrebleu>=1.5.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6))\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (0.9.0)\n",
            "Collecting colorama (from sacrebleu>=1.5.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (5.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (3.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->lm_dataformat@ git+https://github.com/EleutherAI/lm_dataformat.git@4eec05349977071bf67fc072290b95e31c8dd836->-r ./requirements/requirements.txt (line 5)) (24.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (2.23.4)\n",
            "Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (75.1.0)\n",
            "Collecting DataProperty<2,>=1.0.1 (from pytablewriter->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6))\n",
            "  Downloading DataProperty-1.0.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6))\n",
            "  Downloading mbstrdecoder-1.1.3-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6))\n",
            "  Downloading pathvalidate-3.2.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6))\n",
            "  Downloading tabledata-1.3.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6))\n",
            "  Downloading tcolorpy-0.1.6-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6))\n",
            "  Downloading typepy-1.3.2-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (4.0.3)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (5.2.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.9 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (2024.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score>=0.0.4->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (8.1.7)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (2024.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deepspeed@ git+https://github.com/EleutherAI/DeeperSpeed.git@02e2ebf7dee6aaab3d89094ed470a4609763c742#egg=deepspeed->-r ./requirements/requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.14.0->lm_eval<=0.4.1,>=0.4.0->-r ./requirements/requirements.txt (line 6)) (0.2.0)\n",
            "Downloading transformers-4.38.0-py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m101.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lm_eval-0.4.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynvml-11.5.3-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytablewriter-1.2.0-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n",
            "Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m107.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading DataProperty-1.0.1-py3-none-any.whl (27 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mbstrdecoder-1.1.3-py3-none-any.whl (7.8 kB)\n",
            "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pathvalidate-3.2.1-py3-none-any.whl (23 kB)\n",
            "Downloading tabledata-1.3.3-py3-none-any.whl (11 kB)\n",
            "Downloading tcolorpy-0.1.6-py3-none-any.whl (8.1 kB)\n",
            "Downloading typepy-1.3.2-py3-none-any.whl (31 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: deepspeed, lm_dataformat, mpi4py, rouge-score, sqlitedict\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.12.4+02e2ebf-py3-none-any.whl size=1286063 sha256=91d453d4f761b39988ac7a8edec73bb4bde3fafe1c7ff7b5fba6e7828ae55b2a\n",
            "  Stored in directory: /root/.cache/pip/wheels/ff/a3/16/4d52efba511c9490fb634597e2b4b6023819175fccfb7e4453\n",
            "  Building wheel for lm_dataformat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lm_dataformat: filename=lm_dataformat-0.0.20-py3-none-any.whl size=5833 sha256=213bfac6662a9834a8e175dc1d117fc8a5f229777f7a0b015b69933ec4d3005e\n",
            "  Stored in directory: /root/.cache/pip/wheels/a8/5d/39/858622f394e968f5055c63d6023137b79341dfe415baf84098\n",
            "  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-4.0.1-cp310-cp310-linux_x86_64.whl size=4266348 sha256=54a3a467e5514ed57ac1a63eea6fbe567921310b4e90ec3745740047a8f2ab06\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/ca/13/13218a83854023ccec184e3af482f0f038b434aa32c19afee8\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=1755adff773de54dd57fe063c3c43a846c6ed81a14ab757a6b0f8a11b55a35f4\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16864 sha256=9804cf36f74a05b70e26802f391496a600ba95921913a540e5b1f1ace2f3f361\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n",
            "Successfully built deepspeed lm_dataformat mpi4py rouge-score sqlitedict\n",
            "Installing collected packages: sqlitedict, ninja, hjson, zstandard, xxhash, ujson, tcolorpy, pynvml, pybind11, portalocker, pathvalidate, mpi4py, mbstrdecoder, jsonlines, ftfy, fsspec, dill, colorama, typepy, tqdm-multiprocess, tiktoken, sacrebleu, rouge-score, multiprocess, lm_dataformat, tokenizers, transformers, deepspeed, DataProperty, tabledata, datasets, pytablewriter, evaluate, lm_eval\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.41.0\n",
            "    Uninstalling transformers-4.41.0:\n",
            "      Successfully uninstalled transformers-4.41.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed DataProperty-1.0.1 colorama-0.4.6 datasets-3.1.0 deepspeed-0.12.4+02e2ebf dill-0.3.8 evaluate-0.4.3 fsspec-2024.9.0 ftfy-6.3.1 hjson-3.1.0 jsonlines-4.0.0 lm_dataformat-0.0.20 lm_eval-0.4.1 mbstrdecoder-1.1.3 mpi4py-4.0.1 multiprocess-0.70.16 ninja-1.11.1.1 pathvalidate-3.2.1 portalocker-2.10.1 pybind11-2.13.6 pynvml-11.5.3 pytablewriter-1.2.0 rouge-score-0.1.2 sacrebleu-2.4.3 sqlitedict-2.1.0 tabledata-1.3.3 tcolorpy-0.1.6 tiktoken-0.8.0 tokenizers-0.15.2 tqdm-multiprocess-0.0.11 transformers-4.38.0 typepy-1.3.2 ujson-5.10.0 xxhash-3.5.0 zstandard-0.23.0\n",
            "CPU times: user 3.24 s, sys: 499 ms, total: 3.74 s\n",
            "Wall time: 7min 35s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing Custom Dataset\n"
      ],
      "metadata": {
        "id": "VwrfbvLpYXAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gpt-neox\n",
        "!!mkdir -p data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDlSqS1iyU8k",
        "outputId": "785154d8-90a7-4a04-b993-5a22861cb230"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gpt-neox\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Generate a list of dictionaries\n",
        "lines = []\n",
        "with open(\"/content/CodeXGLUE/Code-Code/CodeCompletion-token/dataset/py150/token_completion/train.txt\", encoding=\"utf8\") as f:\n",
        "    for line in f.read().splitlines():\n",
        "        if line:\n",
        "            lines.append({\"text\": line})\n",
        "\n",
        "# Convert to a list of JSON strings\n",
        "json_lines = [json.dumps(l) for l in lines]\n",
        "\n",
        "# Join lines and save to .jsonl file\n",
        "json_data = '\\n'.join(json_lines)\n",
        "with open('/content/gpt-neox/data/py95K_train.jsonl', 'w') as f:\n",
        "    f.write(json_data)"
      ],
      "metadata": {
        "id": "StUBNuLhHUPm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Byte-Pair Encoding Tokenizer"
      ],
      "metadata": {
        "id": "AZ7f8hTqipgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd data\n",
        "!wget https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json\n",
        "!wget https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmOgA5alzT2A",
        "outputId": "5263f8a6-328e-4eb3-8812-98ad5b6653ff"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gpt-neox/data\n",
            "--2024-11-04 12:30:40--  https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 16.15.178.136, 52.217.173.120, 52.217.117.152, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|16.15.178.136|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1042301 (1018K) [application/json]\n",
            "Saving to: ‘gpt2-vocab.json’\n",
            "\n",
            "gpt2-vocab.json     100%[===================>]   1018K  2.71MB/s    in 0.4s    \n",
            "\n",
            "2024-11-04 12:30:41 (2.71 MB/s) - ‘gpt2-vocab.json’ saved [1042301/1042301]\n",
            "\n",
            "--2024-11-04 12:30:41--  https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 16.15.178.136, 52.217.173.120, 52.217.117.152, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|16.15.178.136|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 456318 (446K) [text/plain]\n",
            "Saving to: ‘gpt2-merges.txt’\n",
            "\n",
            "gpt2-merges.txt     100%[===================>] 445.62K  1.80MB/s    in 0.2s    \n",
            "\n",
            "2024-11-04 12:30:41 (1.80 MB/s) - ‘gpt2-merges.txt’ saved [456318/456318]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/GPT-NeoX-Colab/data\n",
        "!tar -xf py150_processed.tar.gz\n",
        "!mkdir -p /content/gpt-neox/processed_data\n",
        "!cp py150_processed/* /content/gpt-neox/processed_data\n",
        "%cd /content"
      ],
      "metadata": {
        "id": "oHwG3CzJOfpy",
        "outputId": "52ebba48-08a2-4b8d-c125-83bdb0a2b238",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/GPT-NeoX-Colab/data\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import os\n",
        "\n",
        "# Define the file path you want to check for existence\n",
        "file_path = \"/content/gpt-neox/processed_data\"\n",
        "\n",
        "# Check if the file exists\n",
        "if not os.path.exists(file_path):\n",
        "  %cd /content/gpt-neox\n",
        "  !mkdir -p processed_data\n",
        "  !python tools/datasets/preprocess_data.py \\\n",
        "    --input ./data/py95K_train.jsonl \\\n",
        "    --vocab ./data/gpt2-vocab.json \\\n",
        "    --merge-file ./data/gpt2-merges.txt \\\n",
        "    --output-prefix ./processed_data/py150 \\\n",
        "    --tokenizer-type GPT2BPETokenizer \\\n",
        "    --dataset-impl mmap \\\n",
        "    --append-eod\n",
        "else:\n",
        "    print(\"File already exists, skipping download and preprocessing.\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Xh49c3aQ1WW",
        "outputId": "898590d5-33e5-43ce-c237-e38d4b5366f0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gpt-neox\n",
            "/content/gpt-neox/megatron/neox_arguments/arguments.py:1101: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
            "  assert (\n",
            "/content/gpt-neox/megatron/neox_arguments/arguments.py:1110: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
            "  assert (\n",
            "[2024-11-04 12:30:45,124] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "> building GPT2BPETokenizer tokenizer ...\n",
            " > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)\n",
            "Vocab size: 50257\n",
            "Output prefix: ./processed_data/py150\n",
            "> building GPT2BPETokenizer tokenizer ...\n",
            " > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)\n",
            "Processed 95000 documents (118.87 docs/s, 0.53 MB/s).: : 95000it [13:19, 118.86it/s]\n",
            "CPU times: user 5.73 s, sys: 715 ms, total: 6.45 s\n",
            "Wall time: 13min 40s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokens count in Dataset"
      ],
      "metadata": {
        "id": "v2bv8UUYqRBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer\n",
        "\n",
        "# Initialize the GPT-2 tokenizer (BPE-based)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Path to your text file\n",
        "file_path = \"/content/CodeXGLUE/Code-Code/CodeCompletion-token/dataset/py150/token_completion/train.txt\"\n",
        "\n",
        "# Initialize a token counter\n",
        "total_token_count = 0\n",
        "\n",
        "# Open the file and read line by line to count tokens\n",
        "#with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "#    for line in file:\n",
        "#        tokens = tokenizer.encode(line)\n",
        "#        total_token_count += len(tokens)\n",
        "        #print(total_token_count)\n",
        "\n",
        "print(f\"Total token count: {total_token_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710,
          "referenced_widgets": [
            "7d339573e3bb4d268f64b3657a4f19a8",
            "0b54e5b61ded4d09822640e6f7e46107",
            "53a62faff75d450e811186209b6f69ab",
            "e9e8cd831e2f4011aa22b162787a381b",
            "743a890fc61749259bc6dbd3c1f94f86",
            "42cd3223cac443358872eee3c5f537ee",
            "c1069ed6b01d47ba85601bf24f40fad5",
            "96d11c2cf9544b4cb36ddd46f71d45c7",
            "42522aebd7bc4be587cb74bf0a26f95c",
            "2404181a0e36474498273059f85a785b",
            "59ea7f5b4fdf4ddba5fa8be002affbf4",
            "dff53ad09a39473eb4cc4a9051376cf8",
            "a1cece3836854eeca3a156f9cd4d3d75",
            "f3a4c2a4ddcb4c49890731309ea8114f",
            "0b782f51c7164017a78aaf7a99f27311",
            "ef92b995424740f49671cc49e2cb0a83",
            "9990d8bd135f496daf9781b188503983",
            "5de9030e43e24af6889188860ee34770",
            "3e6481655a2343ab95fc55d3df1bedf6",
            "a68e459e08804258979a87b4fe8e857d",
            "fe38365787914258952deebdeedb2466",
            "d1f1c77426514243aa2c7d2003202011",
            "1cf9aaaf8797439298e7719174dee870",
            "937cd34e7447410f91236829a0d8d748",
            "8d7b998358a04d8584dba4d97f769d03",
            "76c39bfe2a4d41c2ae63c38213fc1047",
            "0fe91eb02a2446b09c0dcd2d6b34ad19",
            "e2a0d521b03b4aaab7a5da5da96322f3",
            "983eb9124e454a12bd3f99cbbe9c4902",
            "4d26976f64094f7ebb4c803cb8e4255b",
            "62cf1059e6684256bd6c87e186fa6654",
            "81fd6ab99a9647a5b30695f5c8614551",
            "09f97e6566214b1591a7877dea3f5ca8",
            "bb12959b6d7445f097932f5218c6794d",
            "85620201b3164381a622022ca24f521d",
            "22c23eec60504f638e2cefc28af657ad",
            "c2de5cd484b3438cafb6b247603295b8",
            "e8a4c17206e2441cb85bb4bdae60ca39",
            "dade3d93bb9b4a98b8103e5dc555d3cf",
            "9fb29d5ed2c4482e8011f50ee3a9f999",
            "778d9faad7014b0988201e838a98cef2",
            "2ac6b5a4f76847a784e975302de97957",
            "6d9f5156d7ab410ebb99b82a2cbbfa01",
            "30567ea02bbd4c69a37cf65a87ce55ba",
            "31467005d1fe4b3aa30df5ccca7caef6",
            "82028479d102409c843092cbe0b84225",
            "cc0cfd79739044b58d5c600f39ae4202",
            "97787c990ad54964a6e855f8c56db086",
            "d486405f78a3409590437c0f9a23c261",
            "7c0b710da583491b86bbb86eb79f2d18",
            "7665ed11d1d14eb69a2651b2d547b864",
            "7aae498c75ca4200bdad80fcce411246",
            "43248401b800496896a35f3f99fe3ce1",
            "1ff6cc68f3684533a055be07572de8ae",
            "0d280ce820634d7e91b322a3cef88e4f"
          ]
        },
        "id": "YJzBk_-2etia",
        "outputId": "505c483f-1fad-4997-810a-15652bf39e8b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d339573e3bb4d268f64b3657a4f19a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dff53ad09a39473eb4cc4a9051376cf8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1cf9aaaf8797439298e7719174dee870"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb12959b6d7445f097932f5218c6794d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31467005d1fe4b3aa30df5ccca7caef6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3814 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-e7d06b11b084>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mtotal_token_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#print(total_token_count)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, return_tensors, **kwargs)\u001b[0m\n\u001b[1;32m   2598\u001b[0m                 method).\n\u001b[1;32m   2599\u001b[0m         \"\"\"\n\u001b[0;32m-> 2600\u001b[0;31m         encoded_inputs = self.encode_plus(\n\u001b[0m\u001b[1;32m   2601\u001b[0m             \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2602\u001b[0m             \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3006\u001b[0m         )\n\u001b[1;32m   3007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3008\u001b[0;31m         return self._encode_plus(\n\u001b[0m\u001b[1;32m   3009\u001b[0m             \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3010\u001b[0m             \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    717\u001b[0m             )\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m         \u001b[0mfirst_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m         \u001b[0msecond_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mget_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m                 \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0mno_split_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_added_tokens_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# don't split on any of the added tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;31m# \"This is something<special_token_1>  else\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens_trie\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;31m# [\"This is something\", \"<special_token_1>\", \"  else\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;31m# Either clearing the full start (we found a real match)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0;31m# Or clearing only the partial matches that didn't work.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m                 \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "miolaIFSa8sS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "a_t7Dpd3Wn0Y"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "%cd /content/gpt-neox\n",
        "!python ./deepy.py train.py --conf_dir /content/GPT-NeoX-Colab/configs CC19M.yml cc_setup.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQknkkSEbMXa",
        "outputId": "34427ea2-9c7d-4882-8acc-d88ae4065fd5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gpt-neox\n",
            "[2024-11-04 12:57:18,269] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "NeoXArgs.from_ymls() ['/content/GPT-NeoX-Colab/configs/CC19M.yml', '/content/GPT-NeoX-Colab/configs/cc_setup.yml']\n",
            "INFO:root:NeoXArgs.calculate_derived() Total number of GPUs determined to be: 1\n",
            "-------------------- arguments --------------------\n",
            "  attention_config ................ ['global', 'global', 'global', 'global', 'global', 'global']updated\n",
            "  batch_size ...................... 4...........................updated\n",
            "  checkpoint_activations .......... True........................updated\n",
            "  checkpoint_factor ............... 1000........................updated\n",
            "  config_files .................... {'CC19M.yml': '{\\n  \"pipe_parallel_size\": 0,\\n  \"model_parallel_size\": 1,\\n  \"tokenizer_type\": \"GPT2BPETokenizer\",\\n  \"vocab_file\": \"data/gpt2-vocab.json\",\\n  \"merge_file\": \"data/gpt2-merges.txt\",\\n  \"save\": \"checkpoints\",\\n  \"load\": \"checkpoints\",\\n  \"checkpoint_validation_with_forward_pass\": False,\\n\\n\\n  # model settings\\n  \"num_layers\": 6,\\n  \"hidden_size\": 512,\\n  \"num_attention_heads\": 8,\\n  \"seq_length\": 2048,\\n  \"max_position_embeddings\": 2048,\\n  \"pos_emb\": \"rotary\",\\n  \"no_weight_tying\": true,\\n  \"gpt_j_residual\": false,\\n  \"output_layer_parallelism\": \"column\",\\n\\n  \"scaled_upper_triang_masked_softmax_fusion\": false,\\n  \"bias_gelu_fusion\": false,\\n  \"rope_fusion\": false,\\n  \"layernorm_fusion\": false,\\n\\n  # init methods\\n  \"init_method\": \"small_init\",\\n  \"output_layer_init_method\": \"wang_init\",\\n\\n  \"optimizer\": {\\n    \"type\": \"Adam\",\\n    \"params\": {\\n      \"lr\": 0.001,\\n      \"betas\": [0.9, 0.95],\\n      \"eps\": 1.0e-8,\\n    }\\n  },\\n  \"min_lr\": 0.0001,\\n\\n  # for all zero_optimization options, see https://www.deepspeed.ai/docs/config-json/#zero-optimizations-for-fp16-training\\n  \"zero_optimization\": {\\n    \"stage\": 1,\\n    \"allgather_partitions\": True,\\n    \"allgather_bucket_size\": 500000000,\\n    \"overlap_comm\": True,\\n    \"reduce_scatter\": True,\\n    \"reduce_bucket_size\": 500000000,\\n    \"contiguous_gradients\": True,\\n  },\\n\\n  \"train_micro_batch_size_per_gpu\": 4, #32,\\n  \"gradient_accumulation_steps\": 1,\\n  \"data_impl\": \"mmap\",\\n  \"num_workers\": 1,\\n\\n  # activation checkpointing\\n  \"checkpoint_activations\": true,\\n  \"checkpoint_num_layers\": 1,\\n  \"partition_activations\": true,\\n  \"synchronize_each_layer\": true,\\n\\n  # regularization\\n  \"gradient_clipping\": 1.0,\\n  \"weight_decay\": 0.1,\\n  \"hidden_dropout\": 0,\\n  \"attention_dropout\": 0,\\n\\n  # precision settings\\n  \"fp16\": {\\n    \"fp16\": true,\\n    \"enabled\": true,\\n    \"loss_scale\": 0,\\n    \"loss_scale_window\": 1000,\\n    \"initial_scale_power\": 12,\\n    \"hysteresis\": 2,\\n    \"min_loss_scale\": 1,\\n  },\\n\\n  \"train_iters\": 100,\\n  \"lr_decay_iters\": 100,\\n  \"distributed_backend\": \"nccl\",\\n  \"lr_decay_style\": \"cosine\",\\n  \"warmup\": 0.01,\\n  \"checkpoint_factor\": 1000,\\n  \"eval_interval\": 50,\\n  \"eval_iters\": 10,\\n\\n  \"log_interval\": 10,\\n  \"steps_per_print\": 10,\\n  \"wall_clock_breakdown\": true,\\n\\n  # additional deepspeed args not specified above\\n  \"deepspeed_extra_args\": {\\n    \"comms_logger\": {\\n        \"enabled\": true,\\n        \"verbose\": true,\\n        \"prof_all\": true,\\n        \"debug\": false\\n    },\\n  }\\n\\n}\\n', 'cc_setup.yml': '# Suggested data paths when using GPT-NeoX locally\\n{\\n  \"data_path\": \"processed_data/py150_text_document\",\\n\\n  # or for weighted datasets:\\n  # \"train-data-paths\": [\"data/enwik8/enwik8_text_document\", \"data/enwik8/enwik8_text_document\"],\\n  # \"test-data-paths\": [\"data/enwik8/enwik8_text_document\", \"data/enwik8/enwik8_text_document\"],\\n  # \"valid-data-paths\": [\"data/enwik8/enwik8_text_document\", \"data/enwik8/enwik8_text_document\"],\\n  # \"train-data-weights\": [1., 2.],\\n  # \"test-data-weights\": [2., 1.],\\n  # \"valid-data-weights\": [0.5, 0.4],\\n\\n  # If weight_by_num_documents is True, Builds dataset weights from a multinomial distribution over groups of data according to the number of documents in each group.\\n  # WARNING: setting this to True will override any user provided weights\\n  # \"weight_by_num_documents\": false,\\n  # \"weighted_sampler_alpha\": 0.3,\\n\\n#  \"vocab_file\": \"data/gpt2-vocab.json\",\\n#  \"merge_file\": \"data/gpt2-merges.txt\",\\n\\n  \"tensorboard_dir\": \"tensorboard\",\\n  \"log_dir\": \"logs\",\\n}\\n'}updated\n",
            "  data_impl ....................... mmap........................updated\n",
            "  data_path ....................... processed_data/py150_text_documentupdated\n",
            "  deepspeed_extra_args ............ {'comms_logger': {'enabled': True, 'verbose': True, 'prof_all': True, 'debug': False}}updated\n",
            "  dynamic_loss_scale .............. True........................updated\n",
            "  eval_interval ................... 50..........................updated\n",
            "  eval_iters ...................... 10..........................updated\n",
            "  fp16 ............................ {'fp16': True, 'enabled': True, 'loss_scale': 0, 'loss_scale_window': 1000, 'initial_scale_power': 12, 'hysteresis': 2, 'min_loss_scale': 1}updated\n",
            "  global_num_gpus ................. 1...........................updated\n",
            "  hidden_size ..................... 512.........................updated\n",
            "  init_method ..................... small_init..................updated\n",
            "  load ............................ checkpoints.................updated\n",
            "  log_dir ......................... logs........................updated\n",
            "  log_interval .................... 10..........................updated\n",
            "  lr .............................. 0.001.......................updated\n",
            "  lr_decay_iters .................. 100.........................updated\n",
            "  lr_decay_style .................. cosine......................updated\n",
            "  max_position_embeddings ......... 2048........................updated\n",
            "  merge_file ...................... data/gpt2-merges.txt........updated\n",
            "  min_lr .......................... 0.0001......................updated\n",
            "  no_weight_tying ................. True........................updated\n",
            "  num_attention_heads ............. 8...........................updated\n",
            "  num_layers ...................... 6...........................updated\n",
            "  num_workers ..................... 1...........................updated\n",
            "  optimizer ....................... {'type': 'Adam', 'params': {'lr': 0.001, 'betas': [0.9, 0.95], 'eps': 1e-08}}updated\n",
            "  optimizer_type .................. Adam........................updated\n",
            "  output_layer_init_method ........ wang_init...................updated\n",
            "  partition_activations ........... True........................updated\n",
            "  pos_emb ......................... rotary......................updated\n",
            "  precision ....................... fp16........................updated\n",
            "  save ............................ checkpoints.................updated\n",
            "  seq_length ...................... 2048........................updated\n",
            "  sparsity_config ................. {}..........................updated\n",
            "  synchronize_each_layer .......... True........................updated\n",
            "  tensorboard_dir ................. tensorboard.................updated\n",
            "  text_gen_type ................... unconditional...............updated\n",
            "  train_batch_size ................ 4...........................updated\n",
            "  train_iters ..................... 100.........................updated\n",
            "  train_micro_batch_size_per_gpu .. 4...........................updated\n",
            "  user_script ..................... train.py....................updated\n",
            "  vocab_file ...................... data/gpt2-vocab.json........updated\n",
            "  wall_clock_breakdown ............ True........................updated\n",
            "  zero_allgather_bucket_size ...... 500000000...................updated\n",
            "  zero_contiguous_gradients ....... True........................updated\n",
            "  zero_optimization ............... {'stage': 1, 'allgather_partitions': True, 'allgather_bucket_size': 500000000, 'overlap_comm': True, 'reduce_scatter': True, 'reduce_bucket_size': 500000000, 'contiguous_gradients': True}updated\n",
            "  zero_reduce_bucket_size ......... 500000000...................updated\n",
            "  zero_reduce_scatter ............. True........................updated\n",
            "  zero_stage ...................... 1...........................updated\n",
            "  account ......................... None........................default\n",
            "  activation ...................... gelu........................default\n",
            "  activation_checkpointing ........ None........................default\n",
            "  adlr_autoresume ................. False.......................default\n",
            "  adlr_autoresume_interval ........ 1000........................default\n",
            "  allow_chopped ................... True........................default\n",
            "  amp ............................. None........................default\n",
            "  apply_query_key_layer_scaling ... False.......................default\n",
            "  attention_dropout ............... 0...........................default\n",
            "  attention_softmax_in_fp32 ....... False.......................default\n",
            "  autotuning ...................... None........................default\n",
            "  autotuning_run .................. None........................default\n",
            "  base_shapes_file ................ None........................default\n",
            "  bf16 ............................ None........................default\n",
            "  bias_dropout_fusion ............. False.......................default\n",
            "  bias_gelu_fusion ................ False.......................default\n",
            "  char_level_ppl .................. False.......................default\n",
            "  checkpoint ...................... None........................default\n",
            "  checkpoint_in_cpu ............... False.......................default\n",
            "  checkpoint_num_layers ........... 1...........................default\n",
            "  checkpoint_scale ................ linear......................default\n",
            "  checkpoint_validation_with_forward_pass  False................default\n",
            "  clip_grad ....................... 1.0.........................default\n",
            "  comet_experiment ................ None........................default\n",
            "  comet_experiment_name ........... None........................default\n",
            "  comet_others .................... None........................default\n",
            "  comet_project ................... None........................default\n",
            "  comet_tags ...................... None........................default\n",
            "  comet_workspace ................. None........................default\n",
            "  comment ......................... None........................default\n",
            "  comms_logger .................... None........................default\n",
            "  communication_data_type ......... None........................default\n",
            "  compression_training ............ None........................default\n",
            "  contiguous_checkpointing ........ False.......................default\n",
            "  coord_check ..................... False.......................default\n",
            "  create_moe_param_group .......... True........................default\n",
            "  csv_monitor ..................... None........................default\n",
            "  curriculum_learning ............. None........................default\n",
            "  curriculum_seqlen ............... 0...........................default\n",
            "  data_efficiency ................. None........................default\n",
            "  data_types ...................... None........................default\n",
            "  dataset_impl .................... gpt2........................default\n",
            "  deepscale ....................... False.......................default\n",
            "  deepscale_config ................ None........................default\n",
            "  deepspeed ....................... True........................default\n",
            "  deepspeed_activation_checkpointing  True......................default\n",
            "  deepspeed_mpi ................... False.......................default\n",
            "  deepspeed_slurm ................. False.......................default\n",
            "  detect_nvlink_pairs ............. False.......................default\n",
            "  dim_att ......................... None........................default\n",
            "  distributed_backend ............. nccl........................default\n",
            "  do_test ......................... None........................default\n",
            "  do_train ........................ None........................default\n",
            "  do_valid ........................ None........................default\n",
            "  dpo_beta ........................ 0.1.........................default\n",
            "  dpo_fp32 ........................ True........................default\n",
            "  dpo_reference_free .............. False.......................default\n",
            "  dump_state ...................... False.......................default\n",
            "  elasticity ...................... None........................default\n",
            "  enable_expert_tensor_parallelism  False.......................default\n",
            "  eod_mask_loss ................... False.......................default\n",
            "  eval_results_prefix ............. ............................default\n",
            "  eval_tasks ...................... None........................default\n",
            "  exclude ......................... None........................default\n",
            "  exit_interval ................... None........................default\n",
            "  expansion_factor ................ None........................default\n",
            "  expert_interval ................. 2...........................default\n",
            "  extra_save_iters ................ None........................default\n",
            "  ffn_dim ......................... None........................default\n",
            "  finetune ........................ False.......................default\n",
            "  flops_profiler .................. None........................default\n",
            "  force_multi ..................... False.......................default\n",
            "  fp16_lm_cross_entropy ........... False.......................default\n",
            "  fp32_allreduce .................. False.......................default\n",
            "  git_hash ........................ 59a5236d....................default\n",
            "  gmlp_attn_dim ................... 64..........................default\n",
            "  gpt_j_residual .................. False.......................default\n",
            "  gpt_j_tied ...................... False.......................default\n",
            "  gradient_accumulation_steps ..... 1...........................default\n",
            "  gradient_clipping ............... 1.0.........................default\n",
            "  gradient_noise_scale_cpu_offload  False.......................default\n",
            "  gradient_noise_scale_n_batches .. 5...........................default\n",
            "  gradient_predivide_factor ....... 1.0.........................default\n",
            "  head_size ....................... None........................default\n",
            "  hidden_dropout .................. 0...........................default\n",
            "  hostfile ........................ None........................default\n",
            "  hysteresis ...................... 2...........................default\n",
            "  include ......................... None........................default\n",
            "  init_method_std ................. 0.02........................default\n",
            "  intermediate_size ............... None........................default\n",
            "  is_pipe_parallel ................ False.......................default\n",
            "  iteration ....................... None........................default\n",
            "  keep_last_n_checkpoints ......... None........................default\n",
            "  kto_beta ........................ 0.1.........................default\n",
            "  kto_desirable_weight ............ 1.0.........................default\n",
            "  kto_fp32 ........................ True........................default\n",
            "  kto_undesirable_weight .......... 1.0.........................default\n",
            "  launcher ........................ pdsh........................default\n",
            "  layernorm_epsilon ............... 1e-05.......................default\n",
            "  layernorm_fusion ................ False.......................default\n",
            "  lazy_mpu_init ................... False.......................default\n",
            "  local_rank ...................... None........................default\n",
            "  log_grad_norm ................... False.......................default\n",
            "  log_grad_pct_zeros .............. False.......................default\n",
            "  log_gradient_noise_scale ........ False.......................default\n",
            "  log_optimizer_states ............ False.......................default\n",
            "  log_param_norm .................. False.......................default\n",
            "  loss_scale ...................... None........................default\n",
            "  loss_scale_window ............... 1000.0......................default\n",
            "  lr_decay_fraction ............... None........................default\n",
            "  make_vocab_size_divisible_by .... 128.........................default\n",
            "  mamba_causal_conv_fusion ........ False.......................default\n",
            "  mamba_inner_func_fusion ......... False.......................default\n",
            "  mamba_selective_fp32_params ..... True........................default\n",
            "  mamba_selective_scan_fusion ..... False.......................default\n",
            "  mamba_use_bias_in_conv .......... True........................default\n",
            "  mamba_use_bias_in_linears ....... False.......................default\n",
            "  master_addr ..................... None........................default\n",
            "  master_port ..................... 29500.......................default\n",
            "  maximum_tokens .................. 64..........................default\n",
            "  memory_profiling ................ False.......................default\n",
            "  memory_profiling_path ........... None........................default\n",
            "  min_scale ....................... 1.0.........................default\n",
            "  mlp_multiple_of ................. 1...........................default\n",
            "  mmap_warmup ..................... False.......................default\n",
            "  model_parallel_size ............. 1...........................default\n",
            "  moe_eval_capacity_factor ........ 1.0.........................default\n",
            "  moe_expert_parallel_size ........ 1...........................default\n",
            "  moe_glu ......................... False.......................default\n",
            "  moe_jitter_eps .................. None........................default\n",
            "  moe_lbl_in_fp32 ................. False.......................default\n",
            "  moe_loss_coeff .................. 0.1.........................default\n",
            "  moe_min_capacity ................ 4...........................default\n",
            "  moe_num_experts ................. 1...........................default\n",
            "  moe_token_dropping .............. False.......................default\n",
            "  moe_top_k ....................... 1...........................default\n",
            "  moe_train_capacity_factor ....... 1.0.........................default\n",
            "  moe_type ........................ megablocks..................default\n",
            "  moe_use_residual ................ True........................default\n",
            "  mup_attn_temp ................... 1.0.........................default\n",
            "  mup_embedding_mult .............. 1.0.........................default\n",
            "  mup_init_scale .................. 1.0.........................default\n",
            "  mup_output_temp ................. 1.0.........................default\n",
            "  mup_rp_embedding_mult ........... 1.0.........................default\n",
            "  mup_width_scale ................. 2...........................default\n",
            "  neg_test_data_paths ............. None........................default\n",
            "  neg_test_label_data_paths ....... None........................default\n",
            "  neg_train_data_paths ............ None........................default\n",
            "  neg_train_label_data_paths ...... None........................default\n",
            "  neg_valid_data_paths ............ None........................default\n",
            "  neg_valid_label_data_paths ...... None........................default\n",
            "  no_load_optim ................... False.......................default\n",
            "  no_load_rng ..................... False.......................default\n",
            "  no_save_optim ................... False.......................default\n",
            "  no_save_rng ..................... False.......................default\n",
            "  no_ssh_check .................... False.......................default\n",
            "  norm ............................ layernorm...................default\n",
            "  num_gpus ........................ None........................default\n",
            "  num_kv_heads .................... None........................default\n",
            "  num_nodes ....................... -1..........................default\n",
            "  num_samples ..................... 1...........................default\n",
            "  num_unique_layers ............... None........................default\n",
            "  onnx_safe ....................... False.......................default\n",
            "  opt_pos_emb_offset .............. 0...........................default\n",
            "  output_layer_parallelism ........ column......................default\n",
            "  override_lr_scheduler ........... False.......................default\n",
            "  pack_impl ....................... packed......................default\n",
            "  padded_vocab_size ............... None........................default\n",
            "  param_sharing_style ............. grouped.....................default\n",
            "  pipe_parallel_size .............. 0...........................default\n",
            "  pipe_partition_method ........... type:transformer|mlp........default\n",
            "  pos_test_data_paths ............. None........................default\n",
            "  pos_test_label_data_paths ....... None........................default\n",
            "  pos_train_data_paths ............ None........................default\n",
            "  pos_train_label_data_paths ...... None........................default\n",
            "  pos_valid_data_paths ............ None........................default\n",
            "  pos_valid_label_data_paths ...... None........................default\n",
            "  precompute_model_name ........... None........................default\n",
            "  prescale_gradients .............. False.......................default\n",
            "  profile ......................... False.......................default\n",
            "  profile_backward ................ False.......................default\n",
            "  profile_step_start .............. 10..........................default\n",
            "  profile_step_stop ............... 12..........................default\n",
            "  prompt_end ...................... \n",
            "...........................default\n",
            "  rank ............................ None........................default\n",
            "  recompute ....................... False.......................default\n",
            "  return_logits ................... False.......................default\n",
            "  rms_norm_epsilon ................ 1e-08.......................default\n",
            "  rmsnorm_fusion .................. False.......................default\n",
            "  rope_fusion ..................... False.......................default\n",
            "  rotary_emb_base ................. 10000.......................default\n",
            "  rotary_pct ...................... 1.0.........................default\n",
            "  rotary_save_freqs_buffer ........ False.......................default\n",
            "  rpe_max_distance ................ 128.........................default\n",
            "  rpe_num_buckets ................. 32..........................default\n",
            "  s3_chunk_size ................... 104857600...................default\n",
            "  s3_path ......................... None........................default\n",
            "  sample_input_file ............... None........................default\n",
            "  sample_output_file .............. samples.txt.................default\n",
            "  save_base_shapes ................ False.......................default\n",
            "  scaled_masked_softmax_fusion .... False.......................default\n",
            "  scaled_upper_triang_masked_softmax_fusion  False..............default\n",
            "  scalenorm_epsilon ............... 1e-08.......................default\n",
            "  scheduler ....................... None........................default\n",
            "  seed ............................ 1234........................default\n",
            "  sequence_parallel ............... False.......................default\n",
            "  short_seq_prob .................. 0.1.........................default\n",
            "  sliding_window_width ............ None........................default\n",
            "  soft_prompt_tuning .............. None........................default\n",
            "  sparse_attention ................ None........................default\n",
            "  sparse_gradients ................ False.......................default\n",
            "  split ........................... 969, 30, 1..................default\n",
            "  steps_per_print ................. 10..........................default\n",
            "  temperature ..................... 0.0.........................default\n",
            "  tensorboard ..................... None........................default\n",
            "  test_data_paths ................. None........................default\n",
            "  test_data_weights ............... None........................default\n",
            "  test_label_data_paths ........... None........................default\n",
            "  test_reward_data_paths .......... None........................default\n",
            "  tokenizer_type .................. GPT2BPETokenizer............default\n",
            "  top_k ........................... 0...........................default\n",
            "  top_p ........................... 0.0.........................default\n",
            "  train_data_paths ................ None........................default\n",
            "  train_data_weights .............. None........................default\n",
            "  train_epochs .................... None........................default\n",
            "  train_impl ...................... normal......................default\n",
            "  train_label_data_paths .......... None........................default\n",
            "  train_reward_data_paths ......... None........................default\n",
            "  use_bias_in_attn_linear ......... True........................default\n",
            "  use_bias_in_mlp ................. True........................default\n",
            "  use_bias_in_norms ............... True........................default\n",
            "  use_bnb_optimizer ............... False.......................default\n",
            "  use_checkpoint_lr_scheduler ..... False.......................default\n",
            "  use_comet ....................... None........................default\n",
            "  use_cpu_initialization .......... False.......................default\n",
            "  use_flashattn_swiglu ............ False.......................default\n",
            "  use_mup ......................... False.......................default\n",
            "  use_qk_layernorm ................ False.......................default\n",
            "  use_shared_fs ................... True........................default\n",
            "  use_tutel ....................... False.......................default\n",
            "  use_wandb ....................... None........................default\n",
            "  valid_data_paths ................ None........................default\n",
            "  valid_data_weights .............. None........................default\n",
            "  valid_label_data_paths .......... None........................default\n",
            "  valid_reward_data_paths ......... None........................default\n",
            "  wandb ........................... None........................default\n",
            "  wandb_group ..................... None........................default\n",
            "  wandb_host ...................... https://api.wandb.ai........default\n",
            "  wandb_init_all_ranks ............ False.......................default\n",
            "  wandb_project ................... neox........................default\n",
            "  wandb_team ...................... None........................default\n",
            "  warmup .......................... 0.01........................default\n",
            "  weight_by_num_documents ......... False.......................default\n",
            "  weight_decay .................... 0.1.........................default\n",
            "  weighted_sampler_alpha .......... 1.0.........................default\n",
            "  world_size ...................... None........................default\n",
            "  z_loss .......................... 0.0.........................default\n",
            "---------------- end of arguments ----------------\n",
            "NeoXArgs.configure_distributed_args() using world size: 1 and model-parallel size: 1 \n",
            "[2024-11-04 12:57:21,088] [WARNING] [runner.py:217:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
            "[2024-11-04 12:57:21,089] [INFO] [runner.py:586:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None train.py --deepspeed_config eyJ0cmFpbl9iYXRjaF9zaXplIjogNCwgInRyYWluX21pY3JvX2JhdGNoX3NpemVfcGVyX2dwdSI6IDQsICJvcHRpbWl6ZXIiOiB7InR5cGUiOiAiQWRhbSIsICJwYXJhbXMiOiB7ImxyIjogMC4wMDEsICJiZXRhcyI6IFswLjksIDAuOTVdLCAiZXBzIjogMWUtMDh9fSwgImZwMTYiOiB7ImZwMTYiOiB0cnVlLCAiZW5hYmxlZCI6IHRydWUsICJsb3NzX3NjYWxlIjogMCwgImxvc3Nfc2NhbGVfd2luZG93IjogMTAwMCwgImluaXRpYWxfc2NhbGVfcG93ZXIiOiAxMiwgImh5c3RlcmVzaXMiOiAyLCAibWluX2xvc3Nfc2NhbGUiOiAxfSwgInplcm9fb3B0aW1pemF0aW9uIjogeyJzdGFnZSI6IDEsICJhbGxnYXRoZXJfcGFydGl0aW9ucyI6IHRydWUsICJhbGxnYXRoZXJfYnVja2V0X3NpemUiOiA1MDAwMDAwMDAsICJvdmVybGFwX2NvbW0iOiB0cnVlLCAicmVkdWNlX3NjYXR0ZXIiOiB0cnVlLCAicmVkdWNlX2J1Y2tldF9zaXplIjogNTAwMDAwMDAwLCAiY29udGlndW91c19ncmFkaWVudHMiOiB0cnVlfSwgIndhbGxfY2xvY2tfYnJlYWtkb3duIjogdHJ1ZSwgImNvbW1zX2xvZ2dlciI6IHsiZW5hYmxlZCI6IHRydWUsICJ2ZXJib3NlIjogdHJ1ZSwgInByb2ZfYWxsIjogdHJ1ZSwgImRlYnVnIjogZmFsc2V9fQ== --megatron_config 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\n",
            "[2024-11-04 12:57:22,631] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2024-11-04 12:57:24,855] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.19.3-1+cuda12.2\n",
            "[2024-11-04 12:57:24,855] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.19.3-1\n",
            "[2024-11-04 12:57:24,855] [INFO] [launch.py:138:main] 0 NCCL_VERSION=2.19.3-1\n",
            "[2024-11-04 12:57:24,855] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n",
            "[2024-11-04 12:57:24,855] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.19.3-1+cuda12.2\n",
            "[2024-11-04 12:57:24,855] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n",
            "[2024-11-04 12:57:24,855] [INFO] [launch.py:138:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.19.3-1\n",
            "[2024-11-04 12:57:24,855] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0]}\n",
            "[2024-11-04 12:57:24,855] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0\n",
            "[2024-11-04 12:57:24,855] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
            "[2024-11-04 12:57:24,855] [INFO] [launch.py:163:main] dist_world_size=1\n",
            "[2024-11-04 12:57:24,855] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0\n",
            "[2024-11-04 12:57:26,518] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba\n",
            "For s3 checkpointing, please install boto3 either using requirements/requirements-s3.txt or https://github.com/boto/boto3\n",
            "For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer\n",
            "NeoXArgs.configure_distributed_args() using world size: 1 and model-parallel size: 1 \n",
            "> building GPT2BPETokenizer tokenizer ...\n",
            " > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)\n",
            "2024-11-04 12:57:32.946185: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-04 12:57:33.174578: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-04 12:57:33.241832: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-04 12:57:35.234378: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "> setting up tensorboard ...\n",
            "> initializing torch distributed ...\n",
            "[2024-11-04 12:57:36,373] [INFO] [comm.py:637:init_distributed] cdb=None\n",
            "[2024-11-04 12:57:36,373] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
            "> initializing model parallel with size 1\n",
            "MPU DP: [0]\n",
            "MPU PP: [0]\n",
            "MPU MP: [0]\n",
            "> setting random seeds to 1234 ...\n",
            "[2024-11-04 12:57:36,387] [INFO] [checkpointing.py:227:model_parallel_cuda_manual_seed] > initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234\n",
            "make: Entering directory '/content/gpt-neox/megatron/data'\n",
            "g++ -O3 -Wall -shared -std=c++11 -fPIC -fdiagnostics-color -I/usr/include/python3.10 -I/usr/local/lib/python3.10/dist-packages/pybind11/include helpers.cpp -o helpers.cpython-310-x86_64-linux-gnu.so\n",
            "make: Leaving directory '/content/gpt-neox/megatron/data'\n",
            "> building train, validation, and test datasets ...\n",
            "    reading sizes...\n",
            "    reading pointers...\n",
            "    reading document index...\n",
            "    creating numpy buffer of mmap...\n",
            "    creating memory view of numpy buffer...\n",
            " > dataset split:\n",
            "    train:\n",
            "     document indices in [0, 92055) total of 92055 documents\n",
            "    validation:\n",
            "     document indices in [92055, 94905) total of 2850 documents\n",
            "    test:\n",
            "     document indices in [94905, 95000) total of 95 documents\n",
            " > WARNING: could not find index map files, building the indices on rank 0 ...\n",
            " > elapsed time to build and save doc-idx mapping (seconds): 0.009505\n",
            "    using:\n",
            "     number of documents:       92055\n",
            "     number of epochs:          1\n",
            "     sequence length:           2048\n",
            "     total number of samples:   86774\n",
            " > elapsed time to build and save sample-idx mapping (seconds): 0.003994\n",
            " > elapsed time to build and save shuffle-idx mapping (seconds): 0.003448\n",
            "/content/gpt-neox/megatron/data/gpt2_dataset.py:373: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n",
            "  counts = torch.cuda.LongTensor([1])\n",
            " > loading doc-idx mapping from processed_data/py150_text_document_train_indexmap_400ns_2048sl_1234s_packedpi_ac_doc_idx.npy\n",
            " > loading sample-idx mapping from processed_data/py150_text_document_train_indexmap_400ns_2048sl_1234s_packedpi_ac_sample_idx.npy\n",
            " > loading shuffle-idx mapping from processed_data/py150_text_document_train_indexmap_400ns_2048sl_1234s_packedpi_ac_shuffle_idx.npy\n",
            "    loaded indexed file in 0.001 seconds\n",
            "    total number of samples: 86775\n",
            "    total number of epochs: 1\n",
            " > WARNING: could not find index map files, building the indices on rank 0 ...\n",
            " > elapsed time to build and save doc-idx mapping (seconds): 0.000459\n",
            "    using:\n",
            "     number of documents:       2850\n",
            "     number of epochs:          1\n",
            "     sequence length:           2048\n",
            "     total number of samples:   2370\n",
            " > elapsed time to build and save sample-idx mapping (seconds): 0.000290\n",
            " > elapsed time to build and save shuffle-idx mapping (seconds): 0.000305\n",
            " > loading doc-idx mapping from processed_data/py150_text_document_valid_indexmap_120ns_2048sl_1234s_packedpi_ac_doc_idx.npy\n",
            " > loading sample-idx mapping from processed_data/py150_text_document_valid_indexmap_120ns_2048sl_1234s_packedpi_ac_sample_idx.npy\n",
            " > loading shuffle-idx mapping from processed_data/py150_text_document_valid_indexmap_120ns_2048sl_1234s_packedpi_ac_shuffle_idx.npy\n",
            "    loaded indexed file in 0.001 seconds\n",
            "    total number of samples: 2371\n",
            "    total number of epochs: 1\n",
            " > WARNING: could not find index map files, building the indices on rank 0 ...\n",
            " > elapsed time to build and save doc-idx mapping (seconds): 0.000298\n",
            "    using:\n",
            "     number of documents:       95\n",
            "     number of epochs:          1\n",
            "     sequence length:           2048\n",
            "     total number of samples:   67\n",
            " > elapsed time to build and save sample-idx mapping (seconds): 0.000272\n",
            " > elapsed time to build and save shuffle-idx mapping (seconds): 0.000183\n",
            " > loading doc-idx mapping from processed_data/py150_text_document_test_indexmap_40ns_2048sl_1234s_packedpi_ac_doc_idx.npy\n",
            " > loading sample-idx mapping from processed_data/py150_text_document_test_indexmap_40ns_2048sl_1234s_packedpi_ac_sample_idx.npy\n",
            " > loading shuffle-idx mapping from processed_data/py150_text_document_test_indexmap_40ns_2048sl_1234s_packedpi_ac_shuffle_idx.npy\n",
            "    loaded indexed file in 0.009 seconds\n",
            "    total number of samples: 68\n",
            "    total number of epochs: 1\n",
            "building GPT2 model ...\n",
            "SEED_LAYERS=False BASE_SEED=1234 SEED_FN=None\n",
            "Using topology: {ProcessCoord(pipe=0, data=0, model=0): 0}\n",
            "[2024-11-04 12:57:45,323] [INFO] [module.py:375:_partition_layers] Partitioning pipeline stages with method type:transformer|mlp\n",
            "stage=0 layers=11\n",
            "     0: EmbeddingPipe\n",
            "     1: _pre_transformer_block\n",
            "     2: ParallelTransformerLayerPipe\n",
            "     3: ParallelTransformerLayerPipe\n",
            "     4: ParallelTransformerLayerPipe\n",
            "     5: ParallelTransformerLayerPipe\n",
            "     6: ParallelTransformerLayerPipe\n",
            "     7: ParallelTransformerLayerPipe\n",
            "     8: _post_transformer_block\n",
            "     9: NormPipe\n",
            "    10: ParallelLinearPipe\n",
            "  loss: partial\n",
            "Configuring Optimizer type: Adam with params: {'lr': 0.001, 'betas': [0.9, 0.95], 'eps': 1e-08}\n",
            "WARNING: APEX not installed - defaulting to deepspeed's fused adam\n",
            "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
            "Creating extension directory /root/.cache/torch_extensions/py310_cu121/fused_adam...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py310_cu121/fused_adam/build.ninja...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n",
            "Building extension module fused_adam...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "[1/3] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output multi_tensor_adam.cuda.o.d -DTORCH_EXTENSION_NAME=fused_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/usr/local/lib/python3.10/dist-packages/deepspeed/ops/csrc/includes -I/usr/local/lib/python3.10/dist-packages/deepspeed/ops/csrc/adam -isystem /usr/local/lib/python3.10/dist-packages/torch/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.10/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -lineinfo --use_fast_math -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_75,code=compute_75 -std=c++17 -c /usr/local/lib/python3.10/dist-packages/deepspeed/ops/csrc/adam/multi_tensor_adam.cu -o multi_tensor_adam.cuda.o \n",
            "[2/3] c++ -MMD -MF fused_adam_frontend.o.d -DTORCH_EXTENSION_NAME=fused_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/usr/local/lib/python3.10/dist-packages/deepspeed/ops/csrc/includes -I/usr/local/lib/python3.10/dist-packages/deepspeed/ops/csrc/adam -isystem /usr/local/lib/python3.10/dist-packages/torch/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.10/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -std=c++17 -g -Wno-reorder -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -c /usr/local/lib/python3.10/dist-packages/deepspeed/ops/csrc/adam/fused_adam_frontend.cpp -o fused_adam_frontend.o \n",
            "[3/3] c++ fused_adam_frontend.o multi_tensor_adam.cuda.o -shared -L/usr/local/lib/python3.10/dist-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o fused_adam.so\n",
            "Loading extension module fused_adam...\n",
            "Time to load fused_adam op: 58.43455123901367 seconds\n",
            "> learning rate decay style: cosine\n",
            "DeepSpeed is enabled.\n",
            "[2024-11-04 12:58:44,841] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.12.4+02e2ebf, git-hash=02e2ebf, git-branch=HEAD\n",
            "[2024-11-04 12:58:44,852] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 3.57 | msg size: 49.12 MB | algbw (Gbps): 115.56 | busbw (Gbps): 115.56\n",
            "[2024-11-04 12:58:44,852] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.18 | msg size: 1.0 KB | algbw (Gbps): 0.05 | busbw (Gbps): 0.05\n",
            "[2024-11-04 12:58:44,853] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.18 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-04 12:58:44,853] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.15 | msg size: 1.5 MB | algbw (Gbps): 84.16 | busbw (Gbps): 84.16\n",
            "[2024-11-04 12:58:44,854] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.16 | msg size: 3.0 KB | algbw (Gbps): 0.16 | busbw (Gbps): 0.16\n",
            "[2024-11-04 12:58:44,854] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.16 | msg size: 512.0 KB | algbw (Gbps): 26.77 | busbw (Gbps): 26.77\n",
            "[2024-11-04 12:58:44,855] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.15 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-04 12:58:44,855] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.16 | msg size: 1.0 KB | algbw (Gbps): 0.05 | busbw (Gbps): 0.05\n",
            "[2024-11-04 12:58:44,856] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-04 12:58:44,856] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.15 | msg size: 2.0 MB | algbw (Gbps): 108.71 | busbw (Gbps): 108.71\n",
            "[2024-11-04 12:58:44,857] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.19 | msg size: 4.0 KB | algbw (Gbps): 0.18 | busbw (Gbps): 0.18\n",
            "[2024-11-04 12:58:44,857] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.22 | msg size: 2.0 MB | algbw (Gbps): 77.67 | busbw (Gbps): 77.67\n",
            "[2024-11-04 12:58:44,858] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.24 | msg size: 1.0 KB | algbw (Gbps): 0.03 | busbw (Gbps): 0.03\n",
            "[2024-11-04 12:58:44,858] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.15 | msg size: 1.0 KB | algbw (Gbps): 0.05 | busbw (Gbps): 0.05\n",
            "[2024-11-04 12:58:44,859] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.16 | msg size: 1.0 KB | algbw (Gbps): 0.05 | busbw (Gbps): 0.05\n",
            "[2024-11-04 12:58:44,859] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.15 | msg size: 1.5 MB | algbw (Gbps): 84.95 | busbw (Gbps): 84.95\n",
            "[2024-11-04 12:58:44,860] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.20 | msg size: 3.0 KB | algbw (Gbps): 0.12 | busbw (Gbps): 0.12\n",
            "[2024-11-04 12:58:44,860] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.15 | msg size: 512.0 KB | algbw (Gbps): 28.44 | busbw (Gbps): 28.44\n",
            "[2024-11-04 12:58:44,861] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.15 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-04 12:58:44,861] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.16 | msg size: 1.0 KB | algbw (Gbps): 0.05 | busbw (Gbps): 0.05\n",
            "[2024-11-04 12:58:44,862] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-04 12:58:44,862] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.16 | msg size: 2.0 MB | algbw (Gbps): 105.79 | busbw (Gbps): 105.79\n",
            "[2024-11-04 12:58:44,862] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 4.0 KB | algbw (Gbps): 0.23 | busbw (Gbps): 0.23\n",
            "[2024-11-04 12:58:44,863] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.15 | msg size: 2.0 MB | algbw (Gbps): 113.78 | busbw (Gbps): 113.78\n",
            "[2024-11-04 12:58:44,863] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.15 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-04 12:58:44,864] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.15 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-04 12:58:44,864] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-04 12:58:44,865] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.19 | msg size: 1.5 MB | algbw (Gbps): 65.05 | busbw (Gbps): 65.05\n",
            "[2024-11-04 12:58:44,865] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.15 | msg size: 3.0 KB | algbw (Gbps): 0.17 | busbw (Gbps): 0.17\n",
            "[2024-11-04 12:58:44,866] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.17 | msg size: 512.0 KB | algbw (Gbps): 25.28 | busbw (Gbps): 25.28\n",
            "[2024-11-04 12:58:44,866] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.15 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-04 12:58:44,867] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.16 | msg size: 1.0 KB | algbw (Gbps): 0.05 | busbw (Gbps): 0.05\n",
            "[2024-11-04 12:58:44,867] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-04 12:58:44,868] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 2.0 MB | algbw (Gbps): 119.05 | busbw (Gbps): 119.05\n",
            "[2024-11-04 12:58:44,868] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.16 | msg size: 4.0 KB | algbw (Gbps): 0.20 | busbw (Gbps): 0.20\n",
            "[2024-11-04 12:58:44,869] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 2.0 MB | algbw (Gbps): 118.14 | busbw (Gbps): 118.14\n",
            "[2024-11-04 12:58:44,869] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.16 | msg size: 1.0 KB | algbw (Gbps): 0.05 | busbw (Gbps): 0.05\n",
            "[2024-11-04 12:58:44,869] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-04 12:58:44,870] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.15 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-04 12:58:44,870] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 1.5 MB | algbw (Gbps): 87.75 | busbw (Gbps): 87.75\n",
            "[2024-11-04 12:58:44,871] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.18 | msg size: 3.0 KB | algbw (Gbps): 0.14 | busbw (Gbps): 0.14\n",
            "[2024-11-04 12:58:44,871] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 512.0 KB | algbw (Gbps): 29.18 | busbw (Gbps): 29.18\n",
            "[2024-11-04 12:58:44,872] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.18 | msg size: 1.0 KB | algbw (Gbps): 0.05 | busbw (Gbps): 0.05\n",
            "[2024-11-04 12:58:44,872] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.15 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-04 12:58:44,873] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.19 | msg size: 1.0 KB | algbw (Gbps): 0.04 | busbw (Gbps): 0.04\n",
            "[2024-11-04 12:58:44,873] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.15 | msg size: 2.0 MB | algbw (Gbps): 111.22 | busbw (Gbps): 111.22\n",
            "[2024-11-04 12:58:44,874] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 4.0 KB | algbw (Gbps): 0.23 | busbw (Gbps): 0.23\n",
            "[2024-11-04 12:58:44,874] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.15 | msg size: 2.0 MB | algbw (Gbps): 108.80 | busbw (Gbps): 108.80\n",
            "[2024-11-04 12:58:44,875] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-04 12:58:44,875] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.16 | msg size: 1.0 KB | algbw (Gbps): 0.05 | busbw (Gbps): 0.05\n",
            "[2024-11-04 12:58:44,875] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-04 12:58:44,876] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.15 | msg size: 1.5 MB | algbw (Gbps): 86.46 | busbw (Gbps): 86.46\n",
            "[2024-11-04 12:58:44,876] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 3.0 KB | algbw (Gbps): 0.17 | busbw (Gbps): 0.17\n",
            "[2024-11-04 12:58:44,877] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 512.0 KB | algbw (Gbps): 29.25 | busbw (Gbps): 29.25\n",
            "[2024-11-04 12:58:44,877] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-04 12:58:44,878] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.18 | msg size: 1.0 KB | algbw (Gbps): 0.05 | busbw (Gbps): 0.05\n",
            "[2024-11-04 12:58:44,878] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-04 12:58:44,879] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.16 | msg size: 2.0 MB | algbw (Gbps): 105.85 | busbw (Gbps): 105.85\n",
            "[2024-11-04 12:58:44,879] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.15 | msg size: 4.0 KB | algbw (Gbps): 0.22 | busbw (Gbps): 0.22\n",
            "[2024-11-04 12:58:44,880] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 2.0 MB | algbw (Gbps): 117.26 | busbw (Gbps): 117.26\n",
            "[2024-11-04 12:58:44,880] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.16 | msg size: 1.0 KB | algbw (Gbps): 0.05 | busbw (Gbps): 0.05\n",
            "[2024-11-04 12:58:44,881] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.15 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-04 12:58:44,881] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-04 12:58:44,881] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 1.5 MB | algbw (Gbps): 88.01 | busbw (Gbps): 88.01\n",
            "[2024-11-04 12:58:44,882] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.15 | msg size: 3.0 KB | algbw (Gbps): 0.17 | busbw (Gbps): 0.17\n",
            "[2024-11-04 12:58:44,882] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 512.0 KB | algbw (Gbps): 29.38 | busbw (Gbps): 29.38\n",
            "[2024-11-04 12:58:44,883] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.16 | msg size: 1.0 KB | algbw (Gbps): 0.05 | busbw (Gbps): 0.05\n",
            "[2024-11-04 12:58:44,883] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.15 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-04 12:58:44,884] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.18 | msg size: 1.0 KB | algbw (Gbps): 0.05 | busbw (Gbps): 0.05\n",
            "[2024-11-04 12:58:44,884] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.15 | msg size: 2.0 MB | algbw (Gbps): 114.87 | busbw (Gbps): 114.87\n",
            "[2024-11-04 12:58:44,885] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.17 | msg size: 4.0 KB | algbw (Gbps): 0.19 | busbw (Gbps): 0.19\n",
            "[2024-11-04 12:58:44,885] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 2.0 MB | algbw (Gbps): 116.92 | busbw (Gbps): 116.92\n",
            "[2024-11-04 12:58:44,886] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-04 12:58:44,886] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.16 | msg size: 1.0 KB | algbw (Gbps): 0.05 | busbw (Gbps): 0.05\n",
            "[2024-11-04 12:58:44,887] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.14 | msg size: 1.0 KB | algbw (Gbps): 0.06 | busbw (Gbps): 0.06\n",
            "[2024-11-04 12:58:44,887] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: broadcast | time (ms): 0.16 | msg size: 49.12 MB | algbw (Gbps): 2578.66 | busbw (Gbps): 2578.66\n",
            "[2024-11-04 12:58:44,887] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
            "[2024-11-04 12:58:44,888] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
            "[2024-11-04 12:58:44,888] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
            "[2024-11-04 12:58:44,889] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam\n",
            "[2024-11-04 12:58:44,889] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>\n",
            "[2024-11-04 12:58:44,889] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 1 optimizer\n",
            "[2024-11-04 12:58:44,889] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 500000000\n",
            "[2024-11-04 12:58:44,889] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 500000000\n",
            "[2024-11-04 12:58:44,889] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
            "[2024-11-04 12:58:44,889] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
            "[2024-11-04 12:58:45,507] [INFO] [utils.py:802:see_memory_usage] Before initializing optimizer states\n",
            "[2024-11-04 12:58:45,507] [INFO] [utils.py:803:see_memory_usage] MA 0.39 GB         Max_MA 0.39 GB         CA 0.4 GB         Max_CA 0 GB \n",
            "[2024-11-04 12:58:45,508] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 5.0 GB, percent = 39.5%\n",
            "[2024-11-04 12:58:45,803] [INFO] [utils.py:802:see_memory_usage] After initializing optimizer states\n",
            "[2024-11-04 12:58:45,804] [INFO] [utils.py:803:see_memory_usage] MA 0.92 GB         Max_MA 1.18 GB         CA 1.19 GB         Max_CA 1 GB \n",
            "[2024-11-04 12:58:45,805] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 5.0 GB, percent = 39.5%\n",
            "[2024-11-04 12:58:45,805] [INFO] [stage_1_and_2.py:517:__init__] optimizer state initialized\n",
            "[2024-11-04 12:58:46,098] [INFO] [utils.py:802:see_memory_usage] After initializing ZeRO optimizer\n",
            "[2024-11-04 12:58:46,098] [INFO] [utils.py:803:see_memory_usage] MA 0.92 GB         Max_MA 0.92 GB         CA 1.19 GB         Max_CA 1 GB \n",
            "[2024-11-04 12:58:46,099] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 5.0 GB, percent = 39.5%\n",
            "[2024-11-04 12:58:46,101] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam\n",
            "[2024-11-04 12:58:46,101] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
            "[2024-11-04 12:58:46,102] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <megatron.learning_rates.AnnealingLR object at 0x7ec4a3a47d60>\n",
            "[2024-11-04 12:58:46,102] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[[0.9, 0.95], [0.9, 0.95]]\n",
            "[2024-11-04 12:58:46,102] [INFO] [config.py:979:print] DeepSpeedEngine configuration:\n",
            "[2024-11-04 12:58:46,103] [INFO] [config.py:983:print]   activation_checkpointing_config  {\n",
            "    \"partition_activations\": false, \n",
            "    \"contiguous_memory_optimization\": false, \n",
            "    \"cpu_checkpointing\": false, \n",
            "    \"number_checkpoints\": null, \n",
            "    \"synchronize_checkpoint_boundary\": false, \n",
            "    \"profile\": false\n",
            "}\n",
            "[2024-11-04 12:58:46,103] [INFO] [config.py:983:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
            "[2024-11-04 12:58:46,103] [INFO] [config.py:983:print]   amp_enabled .................. False\n",
            "[2024-11-04 12:58:46,103] [INFO] [config.py:983:print]   amp_params ................... False\n",
            "[2024-11-04 12:58:46,104] [INFO] [config.py:983:print]   autotuning_config ............ {\n",
            "    \"enabled\": false, \n",
            "    \"start_step\": null, \n",
            "    \"end_step\": null, \n",
            "    \"metric_path\": null, \n",
            "    \"arg_mappings\": null, \n",
            "    \"metric\": \"throughput\", \n",
            "    \"model_info\": null, \n",
            "    \"results_dir\": \"autotuning_results\", \n",
            "    \"exps_dir\": \"autotuning_exps\", \n",
            "    \"overwrite\": true, \n",
            "    \"fast\": true, \n",
            "    \"start_profile_step\": 3, \n",
            "    \"end_profile_step\": 5, \n",
            "    \"tuner_type\": \"gridsearch\", \n",
            "    \"tuner_early_stopping\": 5, \n",
            "    \"tuner_num_trials\": 50, \n",
            "    \"model_info_path\": null, \n",
            "    \"mp_size\": 1, \n",
            "    \"max_train_batch_size\": null, \n",
            "    \"min_train_batch_size\": 1, \n",
            "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
            "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
            "    \"num_tuning_micro_batch_sizes\": 3\n",
            "}\n",
            "[2024-11-04 12:58:46,104] [INFO] [config.py:983:print]   bfloat16_enabled ............. False\n",
            "[2024-11-04 12:58:46,104] [INFO] [config.py:983:print]   checkpoint_parallel_write_pipeline  False\n",
            "[2024-11-04 12:58:46,104] [INFO] [config.py:983:print]   checkpoint_tag_validation_enabled  True\n",
            "[2024-11-04 12:58:46,104] [INFO] [config.py:983:print]   checkpoint_tag_validation_fail  False\n",
            "[2024-11-04 12:58:46,104] [INFO] [config.py:983:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7ec4d2fc1930>\n",
            "[2024-11-04 12:58:46,104] [INFO] [config.py:983:print]   communication_data_type ...... None\n",
            "[2024-11-04 12:58:46,104] [INFO] [config.py:983:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
            "[2024-11-04 12:58:46,104] [INFO] [config.py:983:print]   curriculum_enabled_legacy .... False\n",
            "[2024-11-04 12:58:46,104] [INFO] [config.py:983:print]   curriculum_params_legacy ..... False\n",
            "[2024-11-04 12:58:46,104] [INFO] [config.py:983:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
            "[2024-11-04 12:58:46,104] [INFO] [config.py:983:print]   data_efficiency_enabled ...... False\n",
            "[2024-11-04 12:58:46,105] [INFO] [config.py:983:print]   dataloader_drop_last ......... False\n",
            "[2024-11-04 12:58:46,105] [INFO] [config.py:983:print]   disable_allgather ............ False\n",
            "[2024-11-04 12:58:46,105] [INFO] [config.py:983:print]   dump_state ................... False\n",
            "[2024-11-04 12:58:46,105] [INFO] [config.py:983:print]   dynamic_loss_scale_args ...... {'init_scale': 4096, 'scale_window': 1000, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}\n",
            "[2024-11-04 12:58:46,105] [INFO] [config.py:983:print]   eigenvalue_enabled ........... False\n",
            "[2024-11-04 12:58:46,105] [INFO] [config.py:983:print]   eigenvalue_gas_boundary_resolution  1\n",
            "[2024-11-04 12:58:46,105] [INFO] [config.py:983:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
            "[2024-11-04 12:58:46,105] [INFO] [config.py:983:print]   eigenvalue_layer_num ......... 0\n",
            "[2024-11-04 12:58:46,105] [INFO] [config.py:983:print]   eigenvalue_max_iter .......... 100\n",
            "[2024-11-04 12:58:46,105] [INFO] [config.py:983:print]   eigenvalue_stability ......... 1e-06\n",
            "[2024-11-04 12:58:46,105] [INFO] [config.py:983:print]   eigenvalue_tol ............... 0.01\n",
            "[2024-11-04 12:58:46,105] [INFO] [config.py:983:print]   eigenvalue_verbose ........... False\n",
            "[2024-11-04 12:58:46,105] [INFO] [config.py:983:print]   elasticity_enabled ........... False\n",
            "[2024-11-04 12:58:46,105] [INFO] [config.py:983:print]   flops_profiler_config ........ {\n",
            "    \"enabled\": false, \n",
            "    \"recompute_fwd_factor\": 0.0, \n",
            "    \"profile_step\": 1, \n",
            "    \"module_depth\": -1, \n",
            "    \"top_modules\": 1, \n",
            "    \"detailed\": true, \n",
            "    \"output_file\": null\n",
            "}\n",
            "[2024-11-04 12:58:46,105] [INFO] [config.py:983:print]   fp16_auto_cast ............... False\n",
            "[2024-11-04 12:58:46,105] [INFO] [config.py:983:print]   fp16_enabled ................. True\n",
            "[2024-11-04 12:58:46,105] [INFO] [config.py:983:print]   fp16_master_weights_and_gradients  False\n",
            "[2024-11-04 12:58:46,105] [INFO] [config.py:983:print]   global_rank .................. 0\n",
            "[2024-11-04 12:58:46,105] [INFO] [config.py:983:print]   grad_accum_dtype ............. None\n",
            "[2024-11-04 12:58:46,105] [INFO] [config.py:983:print]   gradient_accumulation_steps .. 1\n",
            "[2024-11-04 12:58:46,105] [INFO] [config.py:983:print]   gradient_clipping ............ 0.0\n",
            "[2024-11-04 12:58:46,105] [INFO] [config.py:983:print]   gradient_predivide_factor .... 1.0\n",
            "[2024-11-04 12:58:46,106] [INFO] [config.py:983:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
            "[2024-11-04 12:58:46,106] [INFO] [config.py:983:print]   initial_dynamic_scale ........ 4096\n",
            "[2024-11-04 12:58:46,106] [INFO] [config.py:983:print]   load_universal_checkpoint .... False\n",
            "[2024-11-04 12:58:46,106] [INFO] [config.py:983:print]   loss_scale ................... 0\n",
            "[2024-11-04 12:58:46,106] [INFO] [config.py:983:print]   memory_breakdown ............. False\n",
            "[2024-11-04 12:58:46,106] [INFO] [config.py:983:print]   mics_hierarchial_params_gather  False\n",
            "[2024-11-04 12:58:46,106] [INFO] [config.py:983:print]   mics_shard_size .............. -1\n",
            "[2024-11-04 12:58:46,106] [INFO] [config.py:983:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
            "[2024-11-04 12:58:46,106] [INFO] [config.py:983:print]   nebula_config ................ {\n",
            "    \"enabled\": false, \n",
            "    \"persistent_storage_path\": null, \n",
            "    \"persistent_time_interval\": 100, \n",
            "    \"num_of_version_in_retention\": 2, \n",
            "    \"enable_nebula_load\": true, \n",
            "    \"load_path\": null\n",
            "}\n",
            "[2024-11-04 12:58:46,106] [INFO] [config.py:983:print]   optimizer_legacy_fusion ...... False\n",
            "[2024-11-04 12:58:46,106] [INFO] [config.py:983:print]   optimizer_name ............... adam\n",
            "[2024-11-04 12:58:46,106] [INFO] [config.py:983:print]   optimizer_params ............. {'lr': 0.001, 'betas': [0.9, 0.95], 'eps': 1e-08}\n",
            "[2024-11-04 12:58:46,106] [INFO] [config.py:983:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
            "[2024-11-04 12:58:46,106] [INFO] [config.py:983:print]   pld_enabled .................. False\n",
            "[2024-11-04 12:58:46,106] [INFO] [config.py:983:print]   pld_params ................... False\n",
            "[2024-11-04 12:58:46,107] [INFO] [config.py:983:print]   prescale_gradients ........... False\n",
            "[2024-11-04 12:58:46,107] [INFO] [config.py:983:print]   scheduler_name ............... None\n",
            "[2024-11-04 12:58:46,107] [INFO] [config.py:983:print]   scheduler_params ............. None\n",
            "[2024-11-04 12:58:46,107] [INFO] [config.py:983:print]   seq_parallel_communication_data_type  torch.float32\n",
            "[2024-11-04 12:58:46,107] [INFO] [config.py:983:print]   sparse_attention ............. None\n",
            "[2024-11-04 12:58:46,107] [INFO] [config.py:983:print]   sparse_gradients_enabled ..... False\n",
            "[2024-11-04 12:58:46,107] [INFO] [config.py:983:print]   steps_per_print .............. 10\n",
            "[2024-11-04 12:58:46,107] [INFO] [config.py:983:print]   train_batch_size ............. 4\n",
            "[2024-11-04 12:58:46,107] [INFO] [config.py:983:print]   train_micro_batch_size_per_gpu  4\n",
            "[2024-11-04 12:58:46,107] [INFO] [config.py:983:print]   use_data_before_expert_parallel_  False\n",
            "[2024-11-04 12:58:46,107] [INFO] [config.py:983:print]   use_node_local_storage ....... False\n",
            "[2024-11-04 12:58:46,107] [INFO] [config.py:983:print]   wall_clock_breakdown ......... True\n",
            "[2024-11-04 12:58:46,107] [INFO] [config.py:983:print]   weight_quantization_config ... None\n",
            "[2024-11-04 12:58:46,107] [INFO] [config.py:983:print]   world_size ................... 1\n",
            "[2024-11-04 12:58:46,107] [INFO] [config.py:983:print]   zero_allow_untested_optimizer  False\n",
            "[2024-11-04 12:58:46,107] [INFO] [config.py:983:print]   zero_config .................. stage=1 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
            "[2024-11-04 12:58:46,107] [INFO] [config.py:983:print]   zero_enabled ................. True\n",
            "[2024-11-04 12:58:46,107] [INFO] [config.py:983:print]   zero_force_ds_cpu_optimizer .. True\n",
            "[2024-11-04 12:58:46,107] [INFO] [config.py:983:print]   zero_optimization_stage ...... 1\n",
            "[2024-11-04 12:58:46,108] [INFO] [config.py:969:print_user_config]   json = {\n",
            "    \"train_batch_size\": 4, \n",
            "    \"train_micro_batch_size_per_gpu\": 4, \n",
            "    \"optimizer\": {\n",
            "        \"type\": \"Adam\", \n",
            "        \"params\": {\n",
            "            \"lr\": 0.001, \n",
            "            \"betas\": [0.9, 0.95], \n",
            "            \"eps\": 1e-08\n",
            "        }\n",
            "    }, \n",
            "    \"fp16\": {\n",
            "        \"fp16\": true, \n",
            "        \"enabled\": true, \n",
            "        \"loss_scale\": 0, \n",
            "        \"loss_scale_window\": 1000, \n",
            "        \"initial_scale_power\": 12, \n",
            "        \"hysteresis\": 2, \n",
            "        \"min_loss_scale\": 1\n",
            "    }, \n",
            "    \"zero_optimization\": {\n",
            "        \"stage\": 1, \n",
            "        \"allgather_partitions\": true, \n",
            "        \"allgather_bucket_size\": 5.000000e+08, \n",
            "        \"overlap_comm\": true, \n",
            "        \"reduce_scatter\": true, \n",
            "        \"reduce_bucket_size\": 5.000000e+08, \n",
            "        \"contiguous_gradients\": true\n",
            "    }, \n",
            "    \"wall_clock_breakdown\": true, \n",
            "    \"comms_logger\": {\n",
            "        \"enabled\": true, \n",
            "        \"verbose\": true, \n",
            "        \"prof_all\": true, \n",
            "        \"debug\": false\n",
            "    }\n",
            "}\n",
            " > number of parameters on model parallel rank 0: 70426624\n",
            " > total params: 70,426,624\n",
            "[2024-11-04 12:58:46,164] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at checkpoints/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.\n",
            "Unable to load checkpoint.\n",
            "Loading checkpoint and starting from iteration 0\n",
            "setting training data start iteration to 0\n",
            "setting validation data start iteration to 0\n",
            "done with setups ...\n",
            "time (ms) | train/valid/test data loaders: 807.15 | model and optimizer: 60844.59 | train/valid/test data iterators: 102.14\n",
            "training ...\n",
            "[2024-11-04 12:58:46,853] [INFO] [checkpointing.py:540:forward] Activation Checkpointing Information\n",
            "[2024-11-04 12:58:46,853] [INFO] [checkpointing.py:541:forward] ----Partition Activations True, CPU CHECKPOINTING False\n",
            "[2024-11-04 12:58:46,853] [INFO] [checkpointing.py:542:forward] ----contiguous Memory Checkpointing False with 6 total layers\n",
            "[2024-11-04 12:58:46,854] [INFO] [checkpointing.py:544:forward] ----Synchronization True\n",
            "[2024-11-04 12:58:46,854] [INFO] [checkpointing.py:545:forward] ----Profiling time in checkpointing False\n",
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "[2024-11-04 12:58:49,162] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 134.33 MB | algbw (Gbps): 14653.90 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:49,172] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.31 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:49,253] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.37 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:49,259] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.37 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:49,278] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.10 | msg size: 134.25 MB | algbw (Gbps): 10956.67 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:49,278] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.27 | msg size: 80.0 KB | algbw (Gbps): 2.41 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:49,280] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.26 | optimizer_gradients: 6.11 | optimizer_step: 12.11\n",
            "[2024-11-04 12:58:49,281] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1702.54 | bwd_microstep: 720.19 | bwd_inner_microstep: 712.66 | bwd_allreduce_microstep: 7.29 | step_microstep: 115.74\n",
            "[2024-11-04 12:58:49,281] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 1702.51 | bwd: 720.14 | bwd_inner: 712.70 | bwd_allreduce: 7.26 | step: 115.75\n",
            "[2024-11-04 12:58:49,781] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 26839.42 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:49,792] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.31 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:49,801] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:49,805] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:49,824] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 12219.73 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:49,824] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.20 | msg size: 80.0 KB | algbw (Gbps): 3.30 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:49,826] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.99 | optimizer_gradients: 6.01 | optimizer_step: 12.04\n",
            "[2024-11-04 12:58:49,829] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 93.97 | bwd_microstep: 337.72 | bwd_inner_microstep: 330.64 | bwd_allreduce_microstep: 6.86 | step_microstep: 44.88\n",
            "[2024-11-04 12:58:49,829] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 93.94 | bwd: 337.69 | bwd_inner: 330.66 | bwd_allreduce: 6.87 | step: 44.89\n",
            "[2024-11-04 12:58:50,330] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.09 | msg size: 134.33 MB | algbw (Gbps): 24044.60 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:50,340] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.25 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:50,348] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.25 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:50,352] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:50,372] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 1.51 | msg size: 134.25 MB | algbw (Gbps): 748.04 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:50,373] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.24 | msg size: 80.0 KB | algbw (Gbps): 2.70 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:50,374] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 2.53 | optimizer_gradients: 6.00 | optimizer_step: 12.01\n",
            "[2024-11-04 12:58:50,375] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 91.76 | bwd_microstep: 338.29 | bwd_inner_microstep: 332.09 | bwd_allreduce_microstep: 6.12 | step_microstep: 42.62\n",
            "[2024-11-04 12:58:50,375] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 91.74 | bwd: 338.30 | bwd_inner: 332.07 | bwd_allreduce: 6.10 | step: 42.63\n",
            "[2024-11-04 12:58:50,873] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 30226.02 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:50,883] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.30 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:50,891] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:50,895] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:50,914] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.10 | msg size: 134.25 MB | algbw (Gbps): 11699.74 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:50,915] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.23 | msg size: 80.0 KB | algbw (Gbps): 2.83 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:50,916] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.04 | optimizer_gradients: 6.01 | optimizer_step: 12.02\n",
            "[2024-11-04 12:58:50,917] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 91.18 | bwd_microstep: 335.07 | bwd_inner_microstep: 328.88 | bwd_allreduce_microstep: 6.10 | step_microstep: 41.19\n",
            "[2024-11-04 12:58:50,917] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 91.15 | bwd: 335.05 | bwd_inner: 328.86 | bwd_allreduce: 6.08 | step: 41.19\n",
            "[2024-11-04 12:58:51,414] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 28420.75 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:51,429] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.29 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:51,441] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.25 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:51,448] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.26 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:51,467] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.11 | msg size: 134.25 MB | algbw (Gbps): 10006.49 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:51,468] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.36 | msg size: 80.0 KB | algbw (Gbps): 1.81 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:51,469] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.24 | optimizer_gradients: 6.04 | optimizer_step: 12.05\n",
            "[2024-11-04 12:58:51,470] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 91.32 | bwd_microstep: 339.41 | bwd_inner_microstep: 329.91 | bwd_allreduce_microstep: 9.31 | step_microstep: 50.35\n",
            "[2024-11-04 12:58:51,470] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 91.30 | bwd: 339.40 | bwd_inner: 329.92 | bwd_allreduce: 9.32 | step: 50.36\n",
            "[2024-11-04 12:58:51,969] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 30553.85 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:51,978] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.27 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:51,986] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:51,990] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:52,009] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.10 | msg size: 134.25 MB | algbw (Gbps): 11463.46 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:52,010] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.21 | msg size: 80.0 KB | algbw (Gbps): 3.14 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:52,011] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.05 | optimizer_gradients: 5.97 | optimizer_step: 11.99\n",
            "[2024-11-04 12:58:52,011] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 92.43 | bwd_microstep: 336.08 | bwd_inner_microstep: 329.86 | bwd_allreduce_microstep: 6.15 | step_microstep: 40.59\n",
            "[2024-11-04 12:58:52,012] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 92.41 | bwd: 336.05 | bwd_inner: 329.84 | bwd_allreduce: 6.12 | step: 40.60\n",
            "[2024-11-04 12:58:52,509] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 30567.11 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:52,519] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.26 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:52,527] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:52,531] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:52,549] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 13235.36 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:52,550] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.37 | msg size: 80.0 KB | algbw (Gbps): 1.79 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:52,551] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.13 | optimizer_gradients: 5.97 | optimizer_step: 12.02\n",
            "[2024-11-04 12:58:52,552] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 94.46 | bwd_microstep: 334.17 | bwd_inner_microstep: 327.82 | bwd_allreduce_microstep: 6.28 | step_microstep: 40.18\n",
            "[2024-11-04 12:58:52,552] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 94.43 | bwd: 334.15 | bwd_inner: 327.80 | bwd_allreduce: 6.28 | step: 40.18\n",
            "[2024-11-04 12:58:53,046] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.09 | msg size: 134.33 MB | algbw (Gbps): 26229.66 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:53,055] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.25 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:53,064] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:53,068] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:53,086] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.10 | msg size: 134.25 MB | algbw (Gbps): 11459.73 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:53,087] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.20 | msg size: 80.0 KB | algbw (Gbps): 3.26 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:53,088] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.03 | optimizer_gradients: 5.98 | optimizer_step: 12.03\n",
            "[2024-11-04 12:58:53,089] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 90.19 | bwd_microstep: 334.34 | bwd_inner_microstep: 328.19 | bwd_allreduce_microstep: 6.01 | step_microstep: 40.89\n",
            "[2024-11-04 12:58:53,089] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 90.16 | bwd: 334.34 | bwd_inner: 328.20 | bwd_allreduce: 5.99 | step: 40.89\n",
            "[2024-11-04 12:58:53,586] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.09 | msg size: 134.33 MB | algbw (Gbps): 26347.41 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:53,595] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.28 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:53,604] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:53,609] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:53,627] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 13131.65 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:53,628] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.21 | msg size: 80.0 KB | algbw (Gbps): 3.16 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:53,629] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.96 | optimizer_gradients: 5.99 | optimizer_step: 12.02\n",
            "[2024-11-04 12:58:53,630] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 91.73 | bwd_microstep: 335.23 | bwd_inner_microstep: 328.96 | bwd_allreduce_microstep: 6.12 | step_microstep: 41.71\n",
            "[2024-11-04 12:58:53,630] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 91.71 | bwd: 335.22 | bwd_inner: 328.94 | bwd_allreduce: 6.12 | step: 41.71\n",
            "[2024-11-04 12:58:54,125] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 30875.33 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:54,135] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.25 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:54,143] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:54,147] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:54,165] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 12383.12 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:54,166] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.21 | msg size: 80.0 KB | algbw (Gbps): 3.11 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:54,167] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.01 | optimizer_gradients: 5.98 | optimizer_step: 12.02\n",
            "[2024-11-04 12:58:54,168] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=0, lr=[0.000981771838126524, 0.000981771838126524], mom=[[0.9, 0.95], [0.9, 0.95]]\n",
            "[2024-11-04 12:58:54,168] [INFO] [timer.py:260:stop] epoch=0/micro_step=10/global_step=10, RunningAvgSamplesPerSec=7.480103601913093, CurrSamplesPerSec=7.550250801728475, MemAllocated=0.93GB, MaxMemAllocated=3.31GB\n",
            "[2024-11-04 12:58:54,169] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 91.98 | bwd_microstep: 331.98 | bwd_inner_microstep: 325.83 | bwd_allreduce_microstep: 6.06 | step_microstep: 41.50\n",
            "[2024-11-04 12:58:54,169] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 91.96 | bwd: 331.95 | bwd_inner: 325.81 | bwd_allreduce: 6.04 | step: 41.52\n",
            " samples/sec: 5.064 | iteration       10/     100 | elapsed time per iteration (ms): 789.9 | learning rate: 9.818E-04 | approx flops per GPU: 4.2TFLOPS | lm_loss: 8.465297E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
            "after 10 iterations memory (MB) | allocated: 956.5537109375 | max allocated: 3387.07763671875 | reserved: 4092.0 | max reserved: 4092.0\n",
            "time (ms) | forward: 358.84 | backward: 378.18 | backward-backward: 378.12 | backward-allreduce: 0.00 | optimizer: 50.66 | batch generator: 16.83\n",
            "[2024-11-04 12:58:54,671] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.10 | msg size: 134.33 MB | algbw (Gbps): 22529.31 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:54,681] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.28 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:54,691] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.25 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:54,696] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:54,714] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.10 | msg size: 134.25 MB | algbw (Gbps): 11222.20 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:54,715] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.20 | msg size: 80.0 KB | algbw (Gbps): 3.23 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:54,716] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.03 | optimizer_gradients: 6.00 | optimizer_step: 12.03\n",
            "[2024-11-04 12:58:54,717] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 94.00 | bwd_microstep: 336.68 | bwd_inner_microstep: 330.19 | bwd_allreduce_microstep: 6.39 | step_microstep: 43.26\n",
            "[2024-11-04 12:58:54,717] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 93.98 | bwd: 336.68 | bwd_inner: 330.17 | bwd_allreduce: 6.37 | step: 43.27\n",
            "[2024-11-04 12:58:55,215] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.27 | msg size: 134.33 MB | algbw (Gbps): 8273.80 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:55,225] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.28 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:55,233] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.27 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:55,238] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:55,256] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.13 | msg size: 134.25 MB | algbw (Gbps): 8728.38 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:55,257] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.27 | msg size: 80.0 KB | algbw (Gbps): 2.47 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:55,258] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.24 | optimizer_gradients: 5.98 | optimizer_step: 12.04\n",
            "[2024-11-04 12:58:55,259] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 91.33 | bwd_microstep: 337.56 | bwd_inner_microstep: 331.14 | bwd_allreduce_microstep: 6.28 | step_microstep: 41.98\n",
            "[2024-11-04 12:58:55,260] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 91.31 | bwd: 337.53 | bwd_inner: 331.16 | bwd_allreduce: 6.26 | step: 41.98\n",
            "[2024-11-04 12:58:55,757] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 26880.39 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:55,765] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:55,773] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:55,776] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:55,794] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 13092.57 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:55,795] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.20 | msg size: 80.0 KB | algbw (Gbps): 3.27 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:55,796] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.05 | optimizer_gradients: 5.97 | optimizer_step: 12.01\n",
            "[2024-11-04 12:58:55,796] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 93.17 | bwd_microstep: 336.88 | bwd_inner_microstep: 331.35 | bwd_allreduce_microstep: 5.47 | step_microstep: 37.29\n",
            "[2024-11-04 12:58:55,796] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 93.12 | bwd: 336.85 | bwd_inner: 331.33 | bwd_allreduce: 5.47 | step: 37.29\n",
            "[2024-11-04 12:58:56,289] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.10 | msg size: 134.33 MB | algbw (Gbps): 23007.72 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:56,297] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:56,305] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:56,308] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:56,326] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.11 | msg size: 134.25 MB | algbw (Gbps): 10063.72 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:56,327] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.20 | msg size: 80.0 KB | algbw (Gbps): 3.32 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:56,328] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.93 | optimizer_gradients: 5.94 | optimizer_step: 11.96\n",
            "[2024-11-04 12:58:56,328] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 91.96 | bwd_microstep: 333.92 | bwd_inner_microstep: 328.30 | bwd_allreduce_microstep: 5.57 | step_microstep: 37.15\n",
            "[2024-11-04 12:58:56,328] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 91.93 | bwd: 333.91 | bwd_inner: 328.29 | bwd_allreduce: 5.57 | step: 37.15\n",
            "[2024-11-04 12:58:56,820] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.05 | msg size: 134.33 MB | algbw (Gbps): 45850.67 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:56,828] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:56,836] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:56,840] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.24 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:56,858] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.11 | msg size: 134.25 MB | algbw (Gbps): 10139.10 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:56,859] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.17 | msg size: 80.0 KB | algbw (Gbps): 3.78 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:56,859] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.92 | optimizer_gradients: 5.98 | optimizer_step: 12.00\n",
            "[2024-11-04 12:58:56,860] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 92.87 | bwd_microstep: 332.68 | bwd_inner_microstep: 327.31 | bwd_allreduce_microstep: 5.32 | step_microstep: 37.74\n",
            "[2024-11-04 12:58:56,860] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 92.85 | bwd: 332.66 | bwd_inner: 327.30 | bwd_allreduce: 5.32 | step: 37.75\n",
            "[2024-11-04 12:58:57,351] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.05 | msg size: 134.33 MB | algbw (Gbps): 42096.01 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:57,359] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:57,367] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:57,370] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:57,389] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.10 | msg size: 134.25 MB | algbw (Gbps): 11418.83 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:57,389] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.16 | msg size: 80.0 KB | algbw (Gbps): 3.98 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:57,390] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.87 | optimizer_gradients: 5.96 | optimizer_step: 12.01\n",
            "[2024-11-04 12:58:57,391] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 91.67 | bwd_microstep: 332.60 | bwd_inner_microstep: 327.23 | bwd_allreduce_microstep: 5.33 | step_microstep: 37.54\n",
            "[2024-11-04 12:58:57,391] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 91.62 | bwd: 332.59 | bwd_inner: 327.22 | bwd_allreduce: 5.33 | step: 37.54\n",
            "[2024-11-04 12:58:57,882] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.06 | msg size: 134.33 MB | algbw (Gbps): 35213.31 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:57,890] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.27 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:57,897] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:57,900] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:57,919] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 15572.05 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:57,919] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.16 | msg size: 80.0 KB | algbw (Gbps): 4.10 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:57,920] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 5.94 | optimizer_step: 12.03\n",
            "[2024-11-04 12:58:57,920] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 92.23 | bwd_microstep: 332.08 | bwd_inner_microstep: 326.73 | bwd_allreduce_microstep: 5.30 | step_microstep: 36.68\n",
            "[2024-11-04 12:58:57,920] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 92.21 | bwd: 332.06 | bwd_inner: 326.72 | bwd_allreduce: 5.30 | step: 36.69\n",
            "[2024-11-04 12:58:58,412] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.06 | msg size: 134.33 MB | algbw (Gbps): 37047.14 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:58,420] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:58,428] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:58,433] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.26 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:58,451] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 12228.23 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:58,452] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.17 | msg size: 80.0 KB | algbw (Gbps): 3.76 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:58,453] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.85 | optimizer_gradients: 5.99 | optimizer_step: 12.00\n",
            "[2024-11-04 12:58:58,453] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 90.76 | bwd_microstep: 334.26 | bwd_inner_microstep: 328.93 | bwd_allreduce_microstep: 5.29 | step_microstep: 39.51\n",
            "[2024-11-04 12:58:58,454] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 90.74 | bwd: 334.25 | bwd_inner: 328.92 | bwd_allreduce: 5.29 | step: 39.52\n",
            "[2024-11-04 12:58:58,943] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.06 | msg size: 134.33 MB | algbw (Gbps): 37125.26 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:58,951] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:58,958] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:58,961] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:58,980] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 15746.23 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:58,980] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.15 | msg size: 80.0 KB | algbw (Gbps): 4.41 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:58,981] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.76 | optimizer_gradients: 5.97 | optimizer_step: 11.99\n",
            "[2024-11-04 12:58:58,981] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 90.80 | bwd_microstep: 332.00 | bwd_inner_microstep: 326.52 | bwd_allreduce_microstep: 5.43 | step_microstep: 36.57\n",
            "[2024-11-04 12:58:58,982] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 90.77 | bwd: 331.98 | bwd_inner: 326.51 | bwd_allreduce: 5.43 | step: 36.57\n",
            "[2024-11-04 12:58:59,473] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.12 | msg size: 134.33 MB | algbw (Gbps): 19337.35 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:59,481] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:59,489] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:59,492] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:59,510] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 14099.69 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:59,511] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.15 | msg size: 80.0 KB | algbw (Gbps): 4.42 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:58:59,512] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 5.94 | optimizer_step: 11.98\n",
            "[2024-11-04 12:58:59,512] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=0, lr=[0.0009206544616434248, 0.0009206544616434248], mom=[[0.9, 0.95], [0.9, 0.95]]\n",
            "[2024-11-04 12:58:59,512] [INFO] [timer.py:260:stop] epoch=0/micro_step=20/global_step=20, RunningAvgSamplesPerSec=7.521772037394223, CurrSamplesPerSec=7.592603269524669, MemAllocated=0.93GB, MaxMemAllocated=3.31GB\n",
            "[2024-11-04 12:58:59,512] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 91.02 | bwd_microstep: 334.06 | bwd_inner_microstep: 327.75 | bwd_allreduce_microstep: 6.13 | step_microstep: 37.40\n",
            "[2024-11-04 12:58:59,513] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 90.99 | bwd: 334.07 | bwd_inner: 327.76 | bwd_allreduce: 6.16 | step: 37.39\n",
            " samples/sec: 7.486 | iteration       20/     100 | elapsed time per iteration (ms): 534.3 | learning rate: 9.207E-04 | approx flops per GPU: 6.2TFLOPS | lm_loss: 4.689962E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
            "time (ms) | forward: 158.62 | backward: 334.67 | backward-backward: 334.63 | backward-allreduce: 0.00 | optimizer: 39.08 | batch generator: 2.18\n",
            "[2024-11-04 12:59:00,004] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.04 | msg size: 134.33 MB | algbw (Gbps): 50161.41 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:00,011] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:00,019] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:00,022] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:00,040] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 12788.09 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:00,041] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.15 | msg size: 80.0 KB | algbw (Gbps): 4.27 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:00,041] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.81 | optimizer_gradients: 5.95 | optimizer_step: 12.01\n",
            "[2024-11-04 12:59:00,042] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 92.18 | bwd_microstep: 331.73 | bwd_inner_microstep: 326.47 | bwd_allreduce_microstep: 5.20 | step_microstep: 36.39\n",
            "[2024-11-04 12:59:00,042] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 92.16 | bwd: 331.71 | bwd_inner: 326.47 | bwd_allreduce: 5.20 | step: 36.39\n",
            "[2024-11-04 12:59:00,532] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.06 | msg size: 134.33 MB | algbw (Gbps): 35107.99 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:00,540] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:00,548] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:00,551] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:00,569] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 16173.18 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:00,570] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.14 | msg size: 80.0 KB | algbw (Gbps): 4.61 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:00,570] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.72 | optimizer_gradients: 5.94 | optimizer_step: 12.05\n",
            "[2024-11-04 12:59:00,571] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 91.59 | bwd_microstep: 332.47 | bwd_inner_microstep: 327.18 | bwd_allreduce_microstep: 5.24 | step_microstep: 36.46\n",
            "[2024-11-04 12:59:00,571] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 91.56 | bwd: 332.45 | bwd_inner: 327.17 | bwd_allreduce: 5.24 | step: 36.46\n",
            "[2024-11-04 12:59:01,058] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 30448.17 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:01,067] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:01,074] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:01,077] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:01,095] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 14536.49 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:01,096] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.15 | msg size: 80.0 KB | algbw (Gbps): 4.36 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:01,097] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.77 | optimizer_gradients: 5.93 | optimizer_step: 12.04\n",
            "[2024-11-04 12:59:01,097] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 91.40 | bwd_microstep: 329.64 | bwd_inner_microstep: 324.27 | bwd_allreduce_microstep: 5.34 | step_microstep: 36.79\n",
            "[2024-11-04 12:59:01,097] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 91.38 | bwd: 329.63 | bwd_inner: 324.25 | bwd_allreduce: 5.34 | step: 36.79\n",
            "[2024-11-04 12:59:01,587] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.05 | msg size: 134.33 MB | algbw (Gbps): 41500.66 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:01,595] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:01,602] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:01,605] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:01,624] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 12515.23 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:01,624] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.17 | msg size: 80.0 KB | algbw (Gbps): 3.81 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:01,625] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.87 | optimizer_gradients: 5.94 | optimizer_step: 12.01\n",
            "[2024-11-04 12:59:01,626] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 92.17 | bwd_microstep: 330.99 | bwd_inner_microstep: 325.66 | bwd_allreduce_microstep: 5.29 | step_microstep: 36.94\n",
            "[2024-11-04 12:59:01,626] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 92.15 | bwd: 330.97 | bwd_inner: 325.64 | bwd_allreduce: 5.29 | step: 36.94\n",
            "[2024-11-04 12:59:02,116] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 32202.39 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:02,124] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.25 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:02,131] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:02,134] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:02,153] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 12288.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:02,153] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.21 | msg size: 80.0 KB | algbw (Gbps): 3.14 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:02,154] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.89 | optimizer_gradients: 5.96 | optimizer_step: 12.01\n",
            "[2024-11-04 12:59:02,155] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 91.53 | bwd_microstep: 331.88 | bwd_inner_microstep: 326.43 | bwd_allreduce_microstep: 5.40 | step_microstep: 36.88\n",
            "[2024-11-04 12:59:02,155] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 91.50 | bwd: 331.86 | bwd_inner: 326.42 | bwd_allreduce: 5.40 | step: 36.89\n",
            "[2024-11-04 12:59:02,650] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.05 | msg size: 134.33 MB | algbw (Gbps): 42323.69 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:02,658] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:02,666] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:02,669] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:02,687] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.10 | msg size: 134.25 MB | algbw (Gbps): 11215.05 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:02,688] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.25 | msg size: 80.0 KB | algbw (Gbps): 2.60 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:02,689] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.14 | optimizer_gradients: 5.96 | optimizer_step: 11.99\n",
            "[2024-11-04 12:59:02,689] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 94.49 | bwd_microstep: 334.01 | bwd_inner_microstep: 328.51 | bwd_allreduce_microstep: 5.42 | step_microstep: 37.61\n",
            "[2024-11-04 12:59:02,690] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 94.46 | bwd: 334.00 | bwd_inner: 328.52 | bwd_allreduce: 5.41 | step: 37.62\n",
            "[2024-11-04 12:59:03,180] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.05 | msg size: 134.33 MB | algbw (Gbps): 44545.62 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:03,188] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:03,196] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:03,199] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:03,217] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 11990.74 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:03,218] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.22 | msg size: 80.0 KB | algbw (Gbps): 2.94 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:03,219] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.94 | optimizer_gradients: 5.96 | optimizer_step: 11.99\n",
            "[2024-11-04 12:59:03,219] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 90.94 | bwd_microstep: 333.44 | bwd_inner_microstep: 327.86 | bwd_allreduce_microstep: 5.54 | step_microstep: 36.80\n",
            "[2024-11-04 12:59:03,219] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 90.92 | bwd: 333.43 | bwd_inner: 327.85 | bwd_allreduce: 5.54 | step: 36.81\n",
            "[2024-11-04 12:59:03,712] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.05 | msg size: 134.33 MB | algbw (Gbps): 45672.26 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:03,721] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.27 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:03,728] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:03,731] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:03,750] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.10 | msg size: 134.25 MB | algbw (Gbps): 10977.18 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:03,751] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.30 | msg size: 80.0 KB | algbw (Gbps): 2.15 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:03,752] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.25 | optimizer_gradients: 5.97 | optimizer_step: 12.00\n",
            "[2024-11-04 12:59:03,752] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 93.55 | bwd_microstep: 332.98 | bwd_inner_microstep: 327.48 | bwd_allreduce_microstep: 5.44 | step_microstep: 37.70\n",
            "[2024-11-04 12:59:03,752] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 93.53 | bwd: 332.97 | bwd_inner: 327.47 | bwd_allreduce: 5.42 | step: 37.72\n",
            "[2024-11-04 12:59:04,246] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.09 | msg size: 134.33 MB | algbw (Gbps): 25125.45 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:04,254] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:04,262] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:04,265] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:04,283] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 11986.66 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:04,284] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.17 | msg size: 80.0 KB | algbw (Gbps): 3.95 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:04,284] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.86 | optimizer_gradients: 5.97 | optimizer_step: 11.99\n",
            "[2024-11-04 12:59:04,285] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 91.69 | bwd_microstep: 334.85 | bwd_inner_microstep: 329.43 | bwd_allreduce_microstep: 5.36 | step_microstep: 37.26\n",
            "[2024-11-04 12:59:04,285] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 91.66 | bwd: 334.82 | bwd_inner: 329.42 | bwd_allreduce: 5.36 | step: 37.27\n",
            "[2024-11-04 12:59:04,778] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 31440.46 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:04,788] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.26 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:04,796] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:04,798] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:04,817] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 15565.16 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:04,817] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.16 | msg size: 80.0 KB | algbw (Gbps): 4.20 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:04,818] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.77 | optimizer_gradients: 5.95 | optimizer_step: 12.01\n",
            "[2024-11-04 12:59:04,818] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=0, lr=[0.00082252435921195, 0.00082252435921195], mom=[[0.9, 0.95], [0.9, 0.95]]\n",
            "[2024-11-04 12:59:04,819] [INFO] [timer.py:260:stop] epoch=0/micro_step=30/global_step=30, RunningAvgSamplesPerSec=7.548706799485361, CurrSamplesPerSec=7.554092313898955, MemAllocated=0.93GB, MaxMemAllocated=3.31GB\n",
            "[2024-11-04 12:59:04,819] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 92.04 | bwd_microstep: 333.97 | bwd_inner_microstep: 328.34 | bwd_allreduce_microstep: 5.48 | step_microstep: 38.95\n",
            "[2024-11-04 12:59:04,819] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 92.02 | bwd: 333.99 | bwd_inner: 328.33 | bwd_allreduce: 5.54 | step: 38.95\n",
            " samples/sec: 7.538 | iteration       30/     100 | elapsed time per iteration (ms): 530.6 | learning rate: 8.225E-04 | approx flops per GPU: 6.3TFLOPS | lm_loss: 3.738137E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
            "time (ms) | forward: 158.30 | backward: 332.98 | backward-backward: 332.93 | backward-allreduce: 0.00 | optimizer: 37.70 | batch generator: 1.68\n",
            "[2024-11-04 12:59:05,310] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.05 | msg size: 134.33 MB | algbw (Gbps): 45613.10 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:05,319] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.27 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:05,326] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:05,329] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:05,348] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.06 | msg size: 134.25 MB | algbw (Gbps): 18056.87 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:05,348] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.14 | msg size: 80.0 KB | algbw (Gbps): 4.57 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:05,349] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 5.95 | optimizer_step: 12.00\n",
            "[2024-11-04 12:59:05,349] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 92.34 | bwd_microstep: 331.95 | bwd_inner_microstep: 326.57 | bwd_allreduce_microstep: 5.34 | step_microstep: 37.13\n",
            "[2024-11-04 12:59:05,350] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 92.32 | bwd: 331.94 | bwd_inner: 326.56 | bwd_allreduce: 5.34 | step: 37.14\n",
            "[2024-11-04 12:59:05,851] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.11 | msg size: 134.33 MB | algbw (Gbps): 21092.13 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:05,862] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.28 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:05,871] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.24 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:05,875] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:05,894] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.10 | msg size: 134.25 MB | algbw (Gbps): 10953.26 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:05,894] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.18 | msg size: 80.0 KB | algbw (Gbps): 3.60 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:05,896] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.95 | optimizer_gradients: 5.99 | optimizer_step: 12.02\n",
            "[2024-11-04 12:59:05,896] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 92.41 | bwd_microstep: 343.26 | bwd_inner_microstep: 336.85 | bwd_allreduce_microstep: 6.24 | step_microstep: 42.24\n",
            "[2024-11-04 12:59:05,896] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 92.39 | bwd: 343.27 | bwd_inner: 336.88 | bwd_allreduce: 6.24 | step: 42.25\n",
            "[2024-11-04 12:59:06,396] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.11 | msg size: 134.33 MB | algbw (Gbps): 21161.85 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:06,406] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:06,413] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:06,417] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:06,435] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 12844.10 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:06,436] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.20 | msg size: 80.0 KB | algbw (Gbps): 3.34 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:06,437] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.93 | optimizer_gradients: 5.96 | optimizer_step: 11.99\n",
            "[2024-11-04 12:59:06,438] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 92.79 | bwd_microstep: 335.18 | bwd_inner_microstep: 328.93 | bwd_allreduce_microstep: 6.13 | step_microstep: 38.83\n",
            "[2024-11-04 12:59:06,438] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 92.77 | bwd: 335.18 | bwd_inner: 328.91 | bwd_allreduce: 6.14 | step: 38.83\n",
            "[2024-11-04 12:59:06,936] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.13 | msg size: 134.33 MB | algbw (Gbps): 17023.60 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:06,946] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.31 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:06,955] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.31 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:06,960] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.26 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:06,979] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.11 | msg size: 134.25 MB | algbw (Gbps): 10037.89 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:06,979] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.21 | msg size: 80.0 KB | algbw (Gbps): 3.15 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:06,980] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.09 | optimizer_gradients: 6.01 | optimizer_step: 11.99\n",
            "[2024-11-04 12:59:06,981] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 92.51 | bwd_microstep: 337.50 | bwd_inner_microstep: 330.41 | bwd_allreduce_microstep: 6.87 | step_microstep: 42.40\n",
            "[2024-11-04 12:59:06,981] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 92.49 | bwd: 337.50 | bwd_inner: 330.44 | bwd_allreduce: 6.90 | step: 42.41\n",
            "[2024-11-04 12:59:07,485] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.10 | msg size: 134.33 MB | algbw (Gbps): 23128.61 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:07,495] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.29 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:07,503] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.25 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:07,509] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:07,528] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.10 | msg size: 134.25 MB | algbw (Gbps): 11348.87 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:07,528] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.21 | msg size: 80.0 KB | algbw (Gbps): 3.18 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:07,530] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.04 | optimizer_gradients: 6.00 | optimizer_step: 12.02\n",
            "[2024-11-04 12:59:07,530] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 94.75 | bwd_microstep: 339.28 | bwd_inner_microstep: 332.92 | bwd_allreduce_microstep: 6.26 | step_microstep: 43.16\n",
            "[2024-11-04 12:59:07,531] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 94.73 | bwd: 339.28 | bwd_inner: 332.90 | bwd_allreduce: 6.24 | step: 43.17\n",
            "[2024-11-04 12:59:08,030] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 27510.40 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:08,042] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.30 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:08,050] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.25 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:08,055] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.24 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:08,074] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.26 | msg size: 134.25 MB | algbw (Gbps): 4262.70 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:08,074] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.35 | msg size: 80.0 KB | algbw (Gbps): 1.88 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:08,076] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.40 | optimizer_gradients: 6.02 | optimizer_step: 12.00\n",
            "[2024-11-04 12:59:08,076] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 93.30 | bwd_microstep: 338.54 | bwd_inner_microstep: 331.16 | bwd_allreduce_microstep: 7.19 | step_microstep: 42.78\n",
            "[2024-11-04 12:59:08,077] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 93.28 | bwd: 338.52 | bwd_inner: 331.14 | bwd_allreduce: 7.22 | step: 42.79\n",
            "[2024-11-04 12:59:08,576] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 134.33 MB | algbw (Gbps): 14620.43 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:08,585] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.26 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:08,593] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:08,597] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:08,616] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.10 | msg size: 134.25 MB | algbw (Gbps): 10997.76 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:08,617] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.19 | msg size: 80.0 KB | algbw (Gbps): 3.37 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:08,618] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.03 | optimizer_gradients: 6.01 | optimizer_step: 12.00\n",
            "[2024-11-04 12:59:08,618] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 94.35 | bwd_microstep: 334.99 | bwd_inner_microstep: 328.81 | bwd_allreduce_microstep: 6.12 | step_microstep: 40.60\n",
            "[2024-11-04 12:59:08,619] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 94.33 | bwd: 334.99 | bwd_inner: 328.80 | bwd_allreduce: 6.12 | step: 40.61\n",
            "[2024-11-04 12:59:09,122] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 29442.57 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:09,132] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.25 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:09,140] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:09,144] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:09,162] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 12135.46 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:09,163] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.19 | msg size: 80.0 KB | algbw (Gbps): 3.53 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:09,164] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.97 | optimizer_gradients: 5.99 | optimizer_step: 12.02\n",
            "[2024-11-04 12:59:09,165] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 94.14 | bwd_microstep: 340.24 | bwd_inner_microstep: 334.20 | bwd_allreduce_microstep: 5.97 | step_microstep: 40.19\n",
            "[2024-11-04 12:59:09,165] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 94.12 | bwd: 340.21 | bwd_inner: 334.18 | bwd_allreduce: 5.97 | step: 40.22\n",
            "[2024-11-04 12:59:09,669] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 28148.13 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:09,680] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.28 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:09,689] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.24 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:09,693] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:09,711] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 13063.41 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:09,712] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.20 | msg size: 80.0 KB | algbw (Gbps): 3.34 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:09,713] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.96 | optimizer_gradients: 5.99 | optimizer_step: 12.01\n",
            "[2024-11-04 12:59:09,714] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 96.39 | bwd_microstep: 338.79 | bwd_inner_microstep: 332.57 | bwd_allreduce_microstep: 6.14 | step_microstep: 42.35\n",
            "[2024-11-04 12:59:09,714] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 96.37 | bwd: 338.79 | bwd_inner: 332.55 | bwd_allreduce: 6.12 | step: 42.35\n",
            "[2024-11-04 12:59:10,217] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 28958.32 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:10,227] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.26 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:10,235] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:10,239] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:10,258] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.11 | msg size: 134.25 MB | algbw (Gbps): 10517.88 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:10,259] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.20 | msg size: 80.0 KB | algbw (Gbps): 3.27 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:10,260] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.23 | optimizer_gradients: 6.01 | optimizer_step: 12.01\n",
            "[2024-11-04 12:59:10,261] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=0, lr=[0.0006971805834928398, 0.0006971805834928398], mom=[[0.9, 0.95], [0.9, 0.95]]\n",
            "[2024-11-04 12:59:10,261] [INFO] [timer.py:260:stop] epoch=0/micro_step=40/global_step=40, RunningAvgSamplesPerSec=7.51885362539845, CurrSamplesPerSec=7.394912883784955, MemAllocated=0.93GB, MaxMemAllocated=3.31GB\n",
            "[2024-11-04 12:59:10,262] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 97.54 | bwd_microstep: 335.13 | bwd_inner_microstep: 329.01 | bwd_allreduce_microstep: 6.04 | step_microstep: 41.95\n",
            "[2024-11-04 12:59:10,262] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 97.51 | bwd: 335.10 | bwd_inner: 328.99 | bwd_allreduce: 6.02 | step: 41.96\n",
            " samples/sec: 7.349 | iteration       40/     100 | elapsed time per iteration (ms): 544.3 | learning rate: 6.972E-04 | approx flops per GPU: 6.1TFLOPS | lm_loss: 3.487418E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
            "time (ms) | forward: 162.21 | backward: 338.14 | backward-backward: 337.88 | backward-allreduce: 0.00 | optimizer: 41.83 | batch generator: 3.46\n",
            "[2024-11-04 12:59:10,760] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 28227.10 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:10,770] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.26 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:10,778] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:10,783] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:10,801] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.10 | msg size: 134.25 MB | algbw (Gbps): 10915.89 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:10,802] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.22 | msg size: 80.0 KB | algbw (Gbps): 2.96 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:10,803] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.00 | optimizer_gradients: 6.07 | optimizer_step: 12.02\n",
            "[2024-11-04 12:59:10,804] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 94.77 | bwd_microstep: 334.03 | bwd_inner_microstep: 327.57 | bwd_allreduce_microstep: 6.40 | step_microstep: 40.82\n",
            "[2024-11-04 12:59:10,804] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 94.74 | bwd: 334.01 | bwd_inner: 327.55 | bwd_allreduce: 6.37 | step: 40.82\n",
            "[2024-11-04 12:59:11,305] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 28047.24 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:11,315] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.24 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:11,324] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.32 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:11,331] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.25 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:11,349] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 12506.34 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:11,350] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.22 | msg size: 80.0 KB | algbw (Gbps): 3.02 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:11,352] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.28 | optimizer_gradients: 6.01 | optimizer_step: 12.03\n",
            "[2024-11-04 12:59:11,352] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 92.72 | bwd_microstep: 337.60 | bwd_inner_microstep: 331.40 | bwd_allreduce_microstep: 6.09 | step_microstep: 45.07\n",
            "[2024-11-04 12:59:11,353] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 92.70 | bwd: 337.58 | bwd_inner: 331.39 | bwd_allreduce: 6.07 | step: 45.08\n",
            "[2024-11-04 12:59:11,856] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 134.33 MB | algbw (Gbps): 15744.83 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:11,867] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.27 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:11,875] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.25 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:11,879] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:11,897] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.11 | msg size: 134.25 MB | algbw (Gbps): 9997.96 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:11,898] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.22 | msg size: 80.0 KB | algbw (Gbps): 3.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:11,899] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.04 | optimizer_gradients: 6.01 | optimizer_step: 12.05\n",
            "[2024-11-04 12:59:11,900] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 92.22 | bwd_microstep: 341.99 | bwd_inner_microstep: 334.96 | bwd_allreduce_microstep: 6.82 | step_microstep: 40.51\n",
            "[2024-11-04 12:59:11,900] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 92.19 | bwd: 341.98 | bwd_inner: 334.99 | bwd_allreduce: 6.83 | step: 40.52\n",
            "[2024-11-04 12:59:12,400] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.13 | msg size: 134.33 MB | algbw (Gbps): 16929.48 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:12,410] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.26 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:12,419] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.24 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:12,423] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:12,442] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.10 | msg size: 134.25 MB | algbw (Gbps): 10946.45 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:12,442] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.21 | msg size: 80.0 KB | algbw (Gbps): 3.10 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:12,444] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.05 | optimizer_gradients: 5.98 | optimizer_step: 12.01\n",
            "[2024-11-04 12:59:12,444] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 92.90 | bwd_microstep: 337.59 | bwd_inner_microstep: 331.20 | bwd_allreduce_microstep: 6.27 | step_microstep: 41.65\n",
            "[2024-11-04 12:59:12,445] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 92.88 | bwd: 337.59 | bwd_inner: 331.18 | bwd_allreduce: 6.29 | step: 41.66\n",
            "[2024-11-04 12:59:12,938] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.06 | msg size: 134.33 MB | algbw (Gbps): 39834.06 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:12,947] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:12,954] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:12,957] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:12,976] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 14861.84 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:12,976] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.14 | msg size: 80.0 KB | algbw (Gbps): 4.54 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:12,977] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.72 | optimizer_gradients: 5.96 | optimizer_step: 12.02\n",
            "[2024-11-04 12:59:12,977] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 93.26 | bwd_microstep: 332.99 | bwd_inner_microstep: 327.77 | bwd_allreduce_microstep: 5.16 | step_microstep: 37.05\n",
            "[2024-11-04 12:59:12,978] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 93.24 | bwd: 333.00 | bwd_inner: 327.76 | bwd_allreduce: 5.15 | step: 37.05\n",
            "[2024-11-04 12:59:13,471] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.06 | msg size: 134.33 MB | algbw (Gbps): 37600.97 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:13,479] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:13,486] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:13,490] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:13,508] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 14584.68 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:13,508] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.14 | msg size: 80.0 KB | algbw (Gbps): 4.57 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:13,509] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.74 | optimizer_gradients: 5.93 | optimizer_step: 12.00\n",
            "[2024-11-04 12:59:13,510] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 92.58 | bwd_microstep: 334.24 | bwd_inner_microstep: 328.88 | bwd_allreduce_microstep: 5.32 | step_microstep: 36.90\n",
            "[2024-11-04 12:59:13,510] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 92.56 | bwd: 334.23 | bwd_inner: 328.87 | bwd_allreduce: 5.32 | step: 36.90\n",
            "[2024-11-04 12:59:14,001] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.06 | msg size: 134.33 MB | algbw (Gbps): 35497.29 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:14,009] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:14,018] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:14,021] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:14,039] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.14 | msg size: 134.25 MB | algbw (Gbps): 8044.08 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:14,040] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.24 | msg size: 80.0 KB | algbw (Gbps): 2.76 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:14,041] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.13 | optimizer_gradients: 5.95 | optimizer_step: 12.00\n",
            "[2024-11-04 12:59:14,042] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 91.99 | bwd_microstep: 332.49 | bwd_inner_microstep: 327.13 | bwd_allreduce_microstep: 5.31 | step_microstep: 38.81\n",
            "[2024-11-04 12:59:14,042] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 91.96 | bwd: 332.47 | bwd_inner: 327.12 | bwd_allreduce: 5.31 | step: 38.82\n",
            "[2024-11-04 12:59:14,538] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.05 | msg size: 134.33 MB | algbw (Gbps): 47844.17 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:14,546] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:14,553] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:14,556] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:14,574] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 15156.26 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:14,575] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.15 | msg size: 80.0 KB | algbw (Gbps): 4.38 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:14,576] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.76 | optimizer_gradients: 5.94 | optimizer_step: 12.00\n",
            "[2024-11-04 12:59:14,577] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 92.55 | bwd_microstep: 334.37 | bwd_inner_microstep: 329.11 | bwd_allreduce_microstep: 5.22 | step_microstep: 37.19\n",
            "[2024-11-04 12:59:14,577] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 92.52 | bwd: 334.36 | bwd_inner: 329.10 | bwd_allreduce: 5.22 | step: 37.21\n",
            "[2024-11-04 12:59:15,067] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.05 | msg size: 134.33 MB | algbw (Gbps): 49947.96 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:15,075] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:15,083] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:15,086] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:15,104] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.12 | msg size: 134.25 MB | algbw (Gbps): 9623.42 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:15,105] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.25 | msg size: 80.0 KB | algbw (Gbps): 2.62 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:15,107] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.21 | optimizer_gradients: 5.92 | optimizer_step: 11.95\n",
            "[2024-11-04 12:59:15,107] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 91.96 | bwd_microstep: 331.35 | bwd_inner_microstep: 326.17 | bwd_allreduce_microstep: 5.14 | step_microstep: 38.19\n",
            "[2024-11-04 12:59:15,108] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 91.94 | bwd: 331.34 | bwd_inner: 326.16 | bwd_allreduce: 5.14 | step: 38.21\n",
            "[2024-11-04 12:59:15,600] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 33761.56 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:15,608] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:15,616] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:15,619] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:15,637] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 11986.66 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:15,638] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.15 | msg size: 80.0 KB | algbw (Gbps): 4.28 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:15,639] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.80 | optimizer_gradients: 5.93 | optimizer_step: 11.97\n",
            "[2024-11-04 12:59:15,639] [INFO] [logging.py:96:log_dist] [Rank 0] step=50, skipped=0, lr=[0.0005571396837256637, 0.0005571396837256637], mom=[[0.9, 0.95], [0.9, 0.95]]\n",
            "[2024-11-04 12:59:15,639] [INFO] [timer.py:260:stop] epoch=0/micro_step=50/global_step=50, RunningAvgSamplesPerSec=7.519716156070648, CurrSamplesPerSec=7.607117417068435, MemAllocated=0.93GB, MaxMemAllocated=3.31GB\n",
            "[2024-11-04 12:59:15,639] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 93.74 | bwd_microstep: 330.63 | bwd_inner_microstep: 325.39 | bwd_allreduce_microstep: 5.20 | step_microstep: 37.35\n",
            "[2024-11-04 12:59:15,640] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 93.72 | bwd: 330.62 | bwd_inner: 325.38 | bwd_allreduce: 5.20 | step: 37.36\n",
            " samples/sec: 7.439 | iteration       50/     100 | elapsed time per iteration (ms): 537.7 | learning rate: 5.571E-04 | approx flops per GPU: 6.2TFLOPS | lm_loss: 3.223305E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
            "time (ms) | forward: 160.53 | backward: 335.21 | backward-backward: 335.09 | backward-allreduce: 0.00 | optimizer: 40.03 | batch generator: 3.23\n",
            "-------------------------------------------------------------------------------------------------------\n",
            " validation results at iteration 50 | lm_loss value: 3.174141E+00 | lm_loss_ppl value: 2.390628E+01 | \n",
            "-------------------------------------------------------------------------------------------------------\n",
            "[2024-11-04 12:59:17,729] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 33095.22 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:17,737] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:17,745] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:17,748] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:17,766] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.10 | msg size: 134.25 MB | algbw (Gbps): 10868.69 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:17,767] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.19 | msg size: 80.0 KB | algbw (Gbps): 3.51 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:17,768] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.94 | optimizer_gradients: 5.94 | optimizer_step: 11.99\n",
            "[2024-11-04 12:59:17,768] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 1022.56 | bwd_microstep: 333.90 | bwd_inner_microstep: 328.59 | bwd_allreduce_microstep: 5.27 | step_microstep: 36.67\n",
            "[2024-11-04 12:59:17,768] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 1022.33 | bwd: 333.89 | bwd_inner: 328.58 | bwd_allreduce: 5.27 | step: 36.67\n",
            "[2024-11-04 12:59:18,264] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.05 | msg size: 134.33 MB | algbw (Gbps): 48704.44 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:18,272] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:18,280] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:18,283] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:18,301] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 12788.09 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:18,302] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.17 | msg size: 80.0 KB | algbw (Gbps): 3.81 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:18,303] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.81 | optimizer_gradients: 5.95 | optimizer_step: 11.97\n",
            "[2024-11-04 12:59:18,303] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 92.39 | bwd_microstep: 336.92 | bwd_inner_microstep: 331.68 | bwd_allreduce_microstep: 5.18 | step_microstep: 36.82\n",
            "[2024-11-04 12:59:18,303] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 92.37 | bwd: 336.89 | bwd_inner: 331.67 | bwd_allreduce: 5.18 | step: 36.83\n",
            "[2024-11-04 12:59:18,796] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 28227.10 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:18,804] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:18,811] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:18,814] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:18,832] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 14861.84 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:18,833] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.15 | msg size: 80.0 KB | algbw (Gbps): 4.45 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:18,834] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.82 | optimizer_gradients: 5.92 | optimizer_step: 11.95\n",
            "[2024-11-04 12:59:18,834] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 92.77 | bwd_microstep: 333.24 | bwd_inner_microstep: 327.96 | bwd_allreduce_microstep: 5.24 | step_microstep: 36.52\n",
            "[2024-11-04 12:59:18,834] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 92.75 | bwd: 333.22 | bwd_inner: 327.95 | bwd_allreduce: 5.24 | step: 36.52\n",
            "[2024-11-04 12:59:19,326] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 26839.42 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:19,335] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:19,342] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:19,345] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:19,363] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 15924.36 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:19,364] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.14 | msg size: 80.0 KB | algbw (Gbps): 4.61 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:19,364] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.72 | optimizer_gradients: 5.92 | optimizer_step: 12.04\n",
            "[2024-11-04 12:59:19,365] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 93.18 | bwd_microstep: 332.52 | bwd_inner_microstep: 327.18 | bwd_allreduce_microstep: 5.29 | step_microstep: 36.31\n",
            "[2024-11-04 12:59:19,365] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 93.14 | bwd: 332.50 | bwd_inner: 327.17 | bwd_allreduce: 5.29 | step: 36.31\n",
            "[2024-11-04 12:59:19,861] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.06 | msg size: 134.33 MB | algbw (Gbps): 35497.29 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:19,869] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:19,876] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:19,879] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:19,897] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 16330.78 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:19,898] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.17 | msg size: 80.0 KB | algbw (Gbps): 3.76 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:19,899] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.75 | optimizer_gradients: 5.96 | optimizer_step: 11.99\n",
            "[2024-11-04 12:59:19,899] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 90.95 | bwd_microstep: 338.42 | bwd_inner_microstep: 333.01 | bwd_allreduce_microstep: 5.37 | step_microstep: 36.31\n",
            "[2024-11-04 12:59:19,899] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 90.92 | bwd: 338.40 | bwd_inner: 333.00 | bwd_allreduce: 5.37 | step: 36.30\n",
            "[2024-11-04 12:59:20,392] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 32365.18 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:20,400] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:20,408] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:20,411] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:20,429] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 15711.09 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:20,430] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.14 | msg size: 80.0 KB | algbw (Gbps): 4.61 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:20,430] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.73 | optimizer_gradients: 5.93 | optimizer_step: 11.95\n",
            "[2024-11-04 12:59:20,431] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 92.72 | bwd_microstep: 334.11 | bwd_inner_microstep: 328.78 | bwd_allreduce_microstep: 5.28 | step_microstep: 36.44\n",
            "[2024-11-04 12:59:20,431] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 92.70 | bwd: 334.10 | bwd_inner: 328.77 | bwd_allreduce: 5.28 | step: 36.44\n",
            "[2024-11-04 12:59:20,925] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 32026.66 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:20,933] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:20,940] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:20,943] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:20,961] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 17251.39 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:20,962] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.16 | msg size: 80.0 KB | algbw (Gbps): 4.21 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:20,963] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.73 | optimizer_gradients: 5.91 | optimizer_step: 11.94\n",
            "[2024-11-04 12:59:20,963] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 91.42 | bwd_microstep: 335.86 | bwd_inner_microstep: 330.60 | bwd_allreduce_microstep: 5.21 | step_microstep: 36.44\n",
            "[2024-11-04 12:59:20,963] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 91.40 | bwd: 335.84 | bwd_inner: 330.59 | bwd_allreduce: 5.21 | step: 36.44\n",
            "[2024-11-04 12:59:21,455] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.05 | msg size: 134.33 MB | algbw (Gbps): 48536.61 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:21,463] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:21,471] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:21,474] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:21,492] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 15585.84 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:21,492] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.19 | msg size: 80.0 KB | algbw (Gbps): 3.53 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:21,493] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.83 | optimizer_gradients: 5.92 | optimizer_step: 11.98\n",
            "[2024-11-04 12:59:21,494] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 92.89 | bwd_microstep: 333.13 | bwd_inner_microstep: 327.94 | bwd_allreduce_microstep: 5.15 | step_microstep: 36.49\n",
            "[2024-11-04 12:59:21,494] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 92.87 | bwd: 333.12 | bwd_inner: 327.93 | bwd_allreduce: 5.15 | step: 36.50\n",
            "[2024-11-04 12:59:21,986] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.06 | msg size: 134.33 MB | algbw (Gbps): 38027.33 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:21,994] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:22,002] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:22,005] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:22,023] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 14441.05 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:22,024] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.16 | msg size: 80.0 KB | algbw (Gbps): 4.12 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:22,024] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.81 | optimizer_gradients: 5.97 | optimizer_step: 12.01\n",
            "[2024-11-04 12:59:22,025] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 92.61 | bwd_microstep: 333.58 | bwd_inner_microstep: 328.36 | bwd_allreduce_microstep: 5.17 | step_microstep: 36.74\n",
            "[2024-11-04 12:59:22,025] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 92.59 | bwd: 333.56 | bwd_inner: 328.35 | bwd_allreduce: 5.17 | step: 36.75\n",
            "[2024-11-04 12:59:22,520] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.09 | msg size: 134.33 MB | algbw (Gbps): 24226.56 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:22,532] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.29 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:22,542] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.25 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:22,546] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:22,565] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.10 | msg size: 134.25 MB | algbw (Gbps): 10994.32 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:22,566] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.22 | msg size: 80.0 KB | algbw (Gbps): 2.97 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:22,567] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.09 | optimizer_gradients: 6.00 | optimizer_step: 12.06\n",
            "[2024-11-04 12:59:22,567] [INFO] [logging.py:96:log_dist] [Rank 0] step=60, skipped=0, lr=[0.0004163858311022763, 0.0004163858311022763], mom=[[0.9, 0.95], [0.9, 0.95]]\n",
            "[2024-11-04 12:59:22,568] [INFO] [timer.py:260:stop] epoch=0/micro_step=60/global_step=60, RunningAvgSamplesPerSec=7.526360733938693, CurrSamplesPerSec=7.427997127482572, MemAllocated=0.93GB, MaxMemAllocated=3.31GB\n",
            "[2024-11-04 12:59:22,568] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 92.29 | bwd_microstep: 338.10 | bwd_inner_microstep: 329.55 | bwd_allreduce_microstep: 7.88 | step_microstep: 44.19\n",
            "[2024-11-04 12:59:22,569] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 92.26 | bwd: 338.09 | bwd_inner: 329.98 | bwd_allreduce: 7.90 | step: 44.19\n",
            " samples/sec: 5.773 | iteration       60/     100 | elapsed time per iteration (ms): 692.9 | learning rate: 4.164E-04 | approx flops per GPU: 4.8TFLOPS | lm_loss: 3.151922E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
            "time (ms) | forward: 158.64 | backward: 335.25 | backward-backward: 335.22 | backward-allreduce: 0.00 | optimizer: 37.84 | batch generator: 3.75\n",
            "[2024-11-04 12:59:23,075] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.54 | msg size: 134.33 MB | algbw (Gbps): 4184.09 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:23,085] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:23,093] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:23,097] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:23,115] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 13494.18 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:23,116] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.18 | msg size: 80.0 KB | algbw (Gbps): 3.58 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:23,117] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.87 | optimizer_gradients: 5.97 | optimizer_step: 12.01\n",
            "[2024-11-04 12:59:23,117] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 93.62 | bwd_microstep: 344.33 | bwd_inner_microstep: 336.54 | bwd_allreduce_microstep: 7.65 | step_microstep: 39.09\n",
            "[2024-11-04 12:59:23,118] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 93.60 | bwd: 344.31 | bwd_inner: 336.52 | bwd_allreduce: 7.68 | step: 39.09\n",
            "[2024-11-04 12:59:23,615] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 32128.94 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:23,624] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:23,632] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:23,636] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:23,654] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.10 | msg size: 134.25 MB | algbw (Gbps): 11392.95 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:23,655] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.18 | msg size: 80.0 KB | algbw (Gbps): 3.64 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:23,656] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.96 | optimizer_gradients: 5.96 | optimizer_step: 11.96\n",
            "[2024-11-04 12:59:23,656] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 91.92 | bwd_microstep: 336.94 | bwd_inner_microstep: 331.08 | bwd_allreduce_microstep: 5.79 | step_microstep: 38.81\n",
            "[2024-11-04 12:59:23,657] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 91.90 | bwd: 336.91 | bwd_inner: 331.06 | bwd_allreduce: 5.79 | step: 38.82\n",
            "[2024-11-04 12:59:24,160] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.10 | msg size: 134.33 MB | algbw (Gbps): 23617.25 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:24,170] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.26 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:24,180] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:24,183] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:24,202] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 12190.10 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:24,203] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.22 | msg size: 80.0 KB | algbw (Gbps): 3.01 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:24,204] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.06 | optimizer_gradients: 5.98 | optimizer_step: 11.97\n",
            "[2024-11-04 12:59:24,205] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 94.65 | bwd_microstep: 339.83 | bwd_inner_microstep: 333.76 | bwd_allreduce_microstep: 6.00 | step_microstep: 42.19\n",
            "[2024-11-04 12:59:24,205] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 94.63 | bwd: 339.81 | bwd_inner: 333.74 | bwd_allreduce: 6.00 | step: 42.20\n",
            "[2024-11-04 12:59:24,713] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.10 | msg size: 134.33 MB | algbw (Gbps): 22457.47 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:24,724] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.30 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:24,732] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.26 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:24,737] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:24,755] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.11 | msg size: 134.25 MB | algbw (Gbps): 10574.77 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:24,756] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.24 | msg size: 80.0 KB | algbw (Gbps): 2.75 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:24,757] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.11 | optimizer_gradients: 6.01 | optimizer_step: 12.01\n",
            "[2024-11-04 12:59:24,758] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 95.51 | bwd_microstep: 339.64 | bwd_inner_microstep: 333.33 | bwd_allreduce_microstep: 6.17 | step_microstep: 42.15\n",
            "[2024-11-04 12:59:24,758] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 95.49 | bwd: 339.64 | bwd_inner: 333.34 | bwd_allreduce: 6.15 | step: 42.16\n",
            "[2024-11-04 12:59:25,261] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 32172.97 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:25,271] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.24 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:25,279] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.26 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:25,283] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:25,301] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.10 | msg size: 134.25 MB | algbw (Gbps): 11215.05 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:25,302] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.21 | msg size: 80.0 KB | algbw (Gbps): 3.07 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:25,304] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.07 | optimizer_gradients: 5.98 | optimizer_step: 12.00\n",
            "[2024-11-04 12:59:25,304] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 93.25 | bwd_microstep: 339.21 | bwd_inner_microstep: 333.12 | bwd_allreduce_microstep: 6.02 | step_microstep: 40.95\n",
            "[2024-11-04 12:59:25,304] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 93.22 | bwd: 339.19 | bwd_inner: 333.07 | bwd_allreduce: 6.00 | step: 40.96\n",
            "[2024-11-04 12:59:25,807] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 29628.37 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:25,817] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.27 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:25,825] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:25,830] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:25,848] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 12361.37 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:25,849] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.21 | msg size: 80.0 KB | algbw (Gbps): 3.14 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:25,850] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.00 | optimizer_gradients: 5.98 | optimizer_step: 12.00\n",
            "[2024-11-04 12:59:25,851] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 93.13 | bwd_microstep: 339.55 | bwd_inner_microstep: 333.38 | bwd_allreduce_microstep: 6.05 | step_microstep: 41.28\n",
            "[2024-11-04 12:59:25,852] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 93.11 | bwd: 339.52 | bwd_inner: 333.38 | bwd_allreduce: 6.03 | step: 41.29\n",
            "[2024-11-04 12:59:26,352] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 27202.25 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:26,362] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:26,370] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:26,375] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:26,393] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 12497.45 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:26,394] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.18 | msg size: 80.0 KB | algbw (Gbps): 3.61 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:26,395] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.96 | optimizer_gradients: 5.96 | optimizer_step: 12.00\n",
            "[2024-11-04 12:59:26,395] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 92.64 | bwd_microstep: 338.40 | bwd_inner_microstep: 331.52 | bwd_allreduce_microstep: 6.75 | step_microstep: 40.54\n",
            "[2024-11-04 12:59:26,396] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 92.62 | bwd: 338.39 | bwd_inner: 331.49 | bwd_allreduce: 6.78 | step: 40.53\n",
            "[2024-11-04 12:59:26,895] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 26576.09 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:26,904] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.26 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:26,912] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:26,917] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:26,935] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 12493.02 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:26,935] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.20 | msg size: 80.0 KB | algbw (Gbps): 3.30 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:26,937] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.93 | optimizer_gradients: 5.95 | optimizer_step: 11.96\n",
            "[2024-11-04 12:59:26,937] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 92.93 | bwd_microstep: 337.20 | bwd_inner_microstep: 331.20 | bwd_allreduce_microstep: 5.94 | step_microstep: 40.21\n",
            "[2024-11-04 12:59:26,938] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 92.90 | bwd: 337.18 | bwd_inner: 331.18 | bwd_allreduce: 5.94 | step: 40.21\n",
            "[2024-11-04 12:59:27,438] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 31440.46 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:27,447] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:27,455] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:27,461] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:27,479] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 13156.20 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:27,480] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.19 | msg size: 80.0 KB | algbw (Gbps): 3.47 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:27,481] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.96 | optimizer_gradients: 5.97 | optimizer_step: 12.00\n",
            "[2024-11-04 12:59:27,481] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 92.62 | bwd_microstep: 338.51 | bwd_inner_microstep: 332.53 | bwd_allreduce_microstep: 5.91 | step_microstep: 41.62\n",
            "[2024-11-04 12:59:27,482] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 92.60 | bwd: 338.48 | bwd_inner: 332.51 | bwd_allreduce: 5.91 | step: 41.62\n",
            "[2024-11-04 12:59:27,979] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 32365.18 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:27,989] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:27,996] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:28,001] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.29 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:28,019] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 13305.42 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:28,020] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.19 | msg size: 80.0 KB | algbw (Gbps): 3.52 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:28,021] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.94 | optimizer_gradients: 5.98 | optimizer_step: 11.99\n",
            "[2024-11-04 12:59:28,021] [INFO] [logging.py:96:log_dist] [Rank 0] step=70, skipped=0, lr=[0.0002889743906929609, 0.0002889743906929609], mom=[[0.9, 0.95], [0.9, 0.95]]\n",
            "[2024-11-04 12:59:28,022] [INFO] [timer.py:260:stop] epoch=0/micro_step=70/global_step=70, RunningAvgSamplesPerSec=7.513129235636418, CurrSamplesPerSec=7.5007683080635905, MemAllocated=0.93GB, MaxMemAllocated=3.31GB\n",
            "[2024-11-04 12:59:28,022] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 93.41 | bwd_microstep: 335.08 | bwd_inner_microstep: 329.12 | bwd_allreduce_microstep: 5.89 | step_microstep: 40.93\n",
            "[2024-11-04 12:59:28,022] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 93.38 | bwd: 335.06 | bwd_inner: 329.10 | bwd_allreduce: 5.89 | step: 40.94\n",
            " samples/sec: 7.334 | iteration       70/     100 | elapsed time per iteration (ms): 545.4 | learning rate: 2.890E-04 | approx flops per GPU: 6.1TFLOPS | lm_loss: 3.165251E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
            "time (ms) | forward: 162.39 | backward: 339.33 | backward-backward: 339.27 | backward-allreduce: 0.00 | optimizer: 41.57 | batch generator: 4.50\n",
            "[2024-11-04 12:59:28,524] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 29740.97 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:28,534] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:28,542] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:28,546] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:28,564] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 12240.99 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:28,565] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.20 | msg size: 80.0 KB | algbw (Gbps): 3.30 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:28,566] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.99 | optimizer_gradients: 5.97 | optimizer_step: 11.99\n",
            "[2024-11-04 12:59:28,567] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 94.22 | bwd_microstep: 334.99 | bwd_inner_microstep: 328.99 | bwd_allreduce_microstep: 5.94 | step_microstep: 40.05\n",
            "[2024-11-04 12:59:28,567] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 94.19 | bwd: 334.96 | bwd_inner: 328.97 | bwd_allreduce: 5.94 | step: 40.08\n",
            "[2024-11-04 12:59:29,069] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 29778.70 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:29,079] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:29,086] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:29,090] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:29,109] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 13747.20 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:29,109] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.18 | msg size: 80.0 KB | algbw (Gbps): 3.58 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:29,111] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.90 | optimizer_gradients: 5.98 | optimizer_step: 12.00\n",
            "[2024-11-04 12:59:29,111] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 97.54 | bwd_microstep: 336.00 | bwd_inner_microstep: 330.00 | bwd_allreduce_microstep: 5.94 | step_microstep: 39.93\n",
            "[2024-11-04 12:59:29,112] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 97.52 | bwd: 335.98 | bwd_inner: 329.98 | bwd_allreduce: 5.94 | step: 39.94\n",
            "[2024-11-04 12:59:29,614] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.09 | msg size: 134.33 MB | algbw (Gbps): 23824.97 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:29,624] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.27 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:29,632] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:29,637] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:29,655] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.10 | msg size: 134.25 MB | algbw (Gbps): 11018.42 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:29,656] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.25 | msg size: 80.0 KB | algbw (Gbps): 2.64 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:29,657] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.07 | optimizer_gradients: 6.00 | optimizer_step: 12.01\n",
            "[2024-11-04 12:59:29,658] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 94.06 | bwd_microstep: 339.11 | bwd_inner_microstep: 332.83 | bwd_allreduce_microstep: 6.17 | step_microstep: 41.31\n",
            "[2024-11-04 12:59:29,658] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 94.04 | bwd: 339.08 | bwd_inner: 332.81 | bwd_allreduce: 6.15 | step: 41.31\n",
            "[2024-11-04 12:59:30,166] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 29006.02 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:30,174] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:30,181] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:30,184] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:30,202] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 16569.13 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:30,203] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.17 | msg size: 80.0 KB | algbw (Gbps): 3.95 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:30,204] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.77 | optimizer_gradients: 5.93 | optimizer_step: 11.97\n",
            "[2024-11-04 12:59:30,204] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 100.87 | bwd_microstep: 336.14 | bwd_inner_microstep: 330.14 | bwd_allreduce_microstep: 5.87 | step_microstep: 36.46\n",
            "[2024-11-04 12:59:30,204] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 100.84 | bwd: 336.11 | bwd_inner: 330.16 | bwd_allreduce: 5.85 | step: 36.46\n",
            "[2024-11-04 12:59:30,700] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.04 | msg size: 134.33 MB | algbw (Gbps): 50268.83 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:30,708] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:30,716] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:30,719] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:30,737] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 15655.18 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:30,737] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.15 | msg size: 80.0 KB | algbw (Gbps): 4.42 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:30,738] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.73 | optimizer_gradients: 5.91 | optimizer_step: 11.94\n",
            "[2024-11-04 12:59:30,738] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 94.04 | bwd_microstep: 335.13 | bwd_inner_microstep: 329.99 | bwd_allreduce_microstep: 5.09 | step_microstep: 36.29\n",
            "[2024-11-04 12:59:30,739] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 94.01 | bwd: 335.11 | bwd_inner: 329.98 | bwd_allreduce: 5.09 | step: 36.29\n",
            "[2024-11-04 12:59:31,233] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.06 | msg size: 134.33 MB | algbw (Gbps): 37782.52 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:31,241] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:31,248] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:31,251] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:31,270] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 15274.67 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:31,270] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.17 | msg size: 80.0 KB | algbw (Gbps): 3.89 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:31,271] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.79 | optimizer_gradients: 5.91 | optimizer_step: 11.99\n",
            "[2024-11-04 12:59:31,271] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 93.12 | bwd_microstep: 334.87 | bwd_inner_microstep: 329.68 | bwd_allreduce_microstep: 5.15 | step_microstep: 36.44\n",
            "[2024-11-04 12:59:31,272] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 93.10 | bwd: 334.86 | bwd_inner: 329.67 | bwd_allreduce: 5.15 | step: 36.44\n",
            "[2024-11-04 12:59:31,768] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 29029.93 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:31,776] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:31,783] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:31,786] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:31,804] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 12097.91 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:31,805] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.20 | msg size: 80.0 KB | algbw (Gbps): 3.31 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:31,806] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.00 | optimizer_gradients: 5.93 | optimizer_step: 11.97\n",
            "[2024-11-04 12:59:31,807] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 93.41 | bwd_microstep: 336.55 | bwd_inner_microstep: 331.27 | bwd_allreduce_microstep: 5.24 | step_microstep: 37.31\n",
            "[2024-11-04 12:59:31,807] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 93.38 | bwd: 336.54 | bwd_inner: 331.26 | bwd_allreduce: 5.24 | step: 37.33\n",
            "[2024-11-04 12:59:32,304] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.09 | msg size: 134.33 MB | algbw (Gbps): 26200.38 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:32,312] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:32,320] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:32,323] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:32,342] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.11 | msg size: 134.25 MB | algbw (Gbps): 10439.88 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:32,342] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.18 | msg size: 80.0 KB | algbw (Gbps): 3.56 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:32,343] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.95 | optimizer_gradients: 5.93 | optimizer_step: 11.98\n",
            "[2024-11-04 12:59:32,344] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 92.77 | bwd_microstep: 335.93 | bwd_inner_microstep: 330.49 | bwd_allreduce_microstep: 5.40 | step_microstep: 37.82\n",
            "[2024-11-04 12:59:32,344] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 92.75 | bwd: 335.92 | bwd_inner: 330.47 | bwd_allreduce: 5.40 | step: 37.82\n",
            "[2024-11-04 12:59:32,841] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.10 | msg size: 134.33 MB | algbw (Gbps): 22601.61 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:32,850] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:32,857] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:32,860] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:32,878] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.06 | msg size: 134.25 MB | algbw (Gbps): 20378.02 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:32,879] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.14 | msg size: 80.0 KB | algbw (Gbps): 4.57 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:32,880] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.70 | optimizer_gradients: 5.94 | optimizer_step: 11.97\n",
            "[2024-11-04 12:59:32,880] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 94.30 | bwd_microstep: 336.59 | bwd_inner_microstep: 330.46 | bwd_allreduce_microstep: 6.02 | step_microstep: 37.32\n",
            "[2024-11-04 12:59:32,880] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 94.27 | bwd: 336.60 | bwd_inner: 330.45 | bwd_allreduce: 6.05 | step: 37.31\n",
            "[2024-11-04 12:59:33,378] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.06 | msg size: 134.33 MB | algbw (Gbps): 36680.53 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:33,386] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.24 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:33,393] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:33,397] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:33,415] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 14811.80 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:33,415] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.15 | msg size: 80.0 KB | algbw (Gbps): 4.27 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:33,416] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.73 | optimizer_gradients: 5.93 | optimizer_step: 12.00\n",
            "[2024-11-04 12:59:33,416] [INFO] [logging.py:96:log_dist] [Rank 0] step=80, skipped=0, lr=[0.0001876283841110236, 0.0001876283841110236], mom=[[0.9, 0.95], [0.9, 0.95]]\n",
            "[2024-11-04 12:59:33,417] [INFO] [timer.py:260:stop] epoch=0/micro_step=80/global_step=80, RunningAvgSamplesPerSec=7.5107712945330425, CurrSamplesPerSec=7.516603114397221, MemAllocated=0.93GB, MaxMemAllocated=3.31GB\n",
            "[2024-11-04 12:59:33,417] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 94.65 | bwd_microstep: 335.57 | bwd_inner_microstep: 330.39 | bwd_allreduce_microstep: 5.13 | step_microstep: 37.41\n",
            "[2024-11-04 12:59:33,417] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 94.63 | bwd: 335.56 | bwd_inner: 330.38 | bwd_allreduce: 5.13 | step: 37.41\n",
            " samples/sec: 7.415 | iteration       80/     100 | elapsed time per iteration (ms): 539.5 | learning rate: 1.876E-04 | approx flops per GPU: 6.2TFLOPS | lm_loss: 3.016550E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
            "time (ms) | forward: 162.54 | backward: 336.42 | backward-backward: 336.37 | backward-allreduce: 0.00 | optimizer: 38.62 | batch generator: 2.92\n",
            "[2024-11-04 12:59:33,914] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.06 | msg size: 134.33 MB | algbw (Gbps): 39744.14 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:33,922] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:33,929] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:33,932] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:33,950] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 17200.80 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:33,951] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.14 | msg size: 80.0 KB | algbw (Gbps): 4.52 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:33,952] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.72 | optimizer_gradients: 5.95 | optimizer_step: 12.00\n",
            "[2024-11-04 12:59:33,952] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 93.09 | bwd_microstep: 336.84 | bwd_inner_microstep: 331.44 | bwd_allreduce_microstep: 5.35 | step_microstep: 36.20\n",
            "[2024-11-04 12:59:33,952] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 93.07 | bwd: 336.82 | bwd_inner: 331.43 | bwd_allreduce: 5.35 | step: 36.20\n",
            "[2024-11-04 12:59:34,447] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.04 | msg size: 134.33 MB | algbw (Gbps): 50268.83 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:34,455] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:34,462] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:34,465] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:34,483] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 16952.23 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:34,484] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.14 | msg size: 80.0 KB | algbw (Gbps): 4.72 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:34,485] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.73 | optimizer_gradients: 5.93 | optimizer_step: 11.95\n",
            "[2024-11-04 12:59:34,485] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 89.71 | bwd_microstep: 338.37 | bwd_inner_microstep: 332.49 | bwd_allreduce_microstep: 5.83 | step_microstep: 36.35\n",
            "[2024-11-04 12:59:34,486] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 89.68 | bwd: 338.36 | bwd_inner: 332.48 | bwd_allreduce: 5.74 | step: 36.37\n",
            "[2024-11-04 12:59:34,983] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.05 | msg size: 134.33 MB | algbw (Gbps): 49771.47 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:34,991] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.24 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:34,999] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:35,002] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:35,020] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 15496.62 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:35,020] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.15 | msg size: 80.0 KB | algbw (Gbps): 4.36 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:35,021] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.77 | optimizer_gradients: 5.91 | optimizer_step: 12.00\n",
            "[2024-11-04 12:59:35,022] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 92.47 | bwd_microstep: 337.14 | bwd_inner_microstep: 331.90 | bwd_allreduce_microstep: 5.19 | step_microstep: 36.95\n",
            "[2024-11-04 12:59:35,022] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 92.46 | bwd: 337.12 | bwd_inner: 331.89 | bwd_allreduce: 5.19 | step: 36.97\n",
            "[2024-11-04 12:59:35,518] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 27935.99 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:35,526] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:35,533] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:35,536] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:35,554] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 16180.61 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:35,555] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.19 | msg size: 80.0 KB | algbw (Gbps): 3.37 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:35,556] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.77 | optimizer_gradients: 5.94 | optimizer_step: 11.95\n",
            "[2024-11-04 12:59:35,556] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 93.48 | bwd_microstep: 336.06 | bwd_inner_microstep: 330.84 | bwd_allreduce_microstep: 5.18 | step_microstep: 36.68\n",
            "[2024-11-04 12:59:35,556] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 93.46 | bwd: 336.05 | bwd_inner: 330.83 | bwd_allreduce: 5.18 | step: 36.68\n",
            "[2024-11-04 12:59:36,054] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 30487.72 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:36,062] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:36,070] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:36,073] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:36,091] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 13882.77 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:36,092] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.17 | msg size: 80.0 KB | algbw (Gbps): 3.90 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:36,092] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.85 | optimizer_gradients: 5.91 | optimizer_step: 12.00\n",
            "[2024-11-04 12:59:36,093] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 92.77 | bwd_microstep: 337.58 | bwd_inner_microstep: 332.18 | bwd_allreduce_microstep: 5.35 | step_microstep: 37.43\n",
            "[2024-11-04 12:59:36,093] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 92.75 | bwd: 337.56 | bwd_inner: 332.17 | bwd_allreduce: 5.35 | step: 37.43\n",
            "[2024-11-04 12:59:36,588] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 30007.08 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:36,596] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:36,604] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:36,607] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:36,625] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.10 | msg size: 134.25 MB | algbw (Gbps): 11404.03 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:36,626] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.23 | msg size: 80.0 KB | algbw (Gbps): 2.87 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:36,627] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.93 | optimizer_gradients: 5.94 | optimizer_step: 11.96\n",
            "[2024-11-04 12:59:36,627] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 93.47 | bwd_microstep: 335.70 | bwd_inner_microstep: 330.46 | bwd_allreduce_microstep: 5.20 | step_microstep: 36.78\n",
            "[2024-11-04 12:59:36,627] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 93.45 | bwd: 335.69 | bwd_inner: 330.45 | bwd_allreduce: 5.20 | step: 36.79\n",
            "[2024-11-04 12:59:37,126] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.04 | msg size: 134.33 MB | algbw (Gbps): 53032.10 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:37,134] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.36 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:37,142] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:37,145] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:37,163] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 14675.91 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:37,163] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.14 | msg size: 80.0 KB | algbw (Gbps): 4.66 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:37,164] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.73 | optimizer_gradients: 5.92 | optimizer_step: 11.98\n",
            "[2024-11-04 12:59:37,165] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 93.87 | bwd_microstep: 338.24 | bwd_inner_microstep: 332.85 | bwd_allreduce_microstep: 5.17 | step_microstep: 36.29\n",
            "[2024-11-04 12:59:37,165] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 93.85 | bwd: 338.23 | bwd_inner: 332.83 | bwd_allreduce: 5.17 | step: 36.29\n",
            "[2024-11-04 12:59:37,659] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.04 | msg size: 134.33 MB | algbw (Gbps): 52400.76 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:37,667] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:37,675] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:37,678] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:37,696] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 15026.83 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:37,697] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.14 | msg size: 80.0 KB | algbw (Gbps): 4.57 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:37,697] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.76 | optimizer_gradients: 5.94 | optimizer_step: 11.95\n",
            "[2024-11-04 12:59:37,698] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 93.68 | bwd_microstep: 334.79 | bwd_inner_microstep: 329.65 | bwd_allreduce_microstep: 5.10 | step_microstep: 36.70\n",
            "[2024-11-04 12:59:37,698] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 93.65 | bwd: 334.77 | bwd_inner: 329.63 | bwd_allreduce: 5.10 | step: 36.70\n",
            "[2024-11-04 12:59:38,194] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.05 | msg size: 134.33 MB | algbw (Gbps): 48270.47 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:38,202] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:38,210] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.26 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:38,214] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:38,232] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 14836.78 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:38,232] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.15 | msg size: 80.0 KB | algbw (Gbps): 4.40 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:38,233] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.76 | optimizer_gradients: 5.91 | optimizer_step: 11.91\n",
            "[2024-11-04 12:59:38,234] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 92.11 | bwd_microstep: 337.99 | bwd_inner_microstep: 332.79 | bwd_allreduce_microstep: 5.15 | step_microstep: 37.10\n",
            "[2024-11-04 12:59:38,234] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 92.08 | bwd: 337.97 | bwd_inner: 332.78 | bwd_allreduce: 5.15 | step: 37.10\n",
            "[2024-11-04 12:59:38,729] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.05 | msg size: 134.33 MB | algbw (Gbps): 44016.64 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:38,737] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:38,744] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:38,747] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:38,766] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.07 | msg size: 134.25 MB | algbw (Gbps): 17108.81 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:38,766] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.14 | msg size: 80.0 KB | algbw (Gbps): 4.70 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:38,767] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.72 | optimizer_gradients: 5.93 | optimizer_step: 11.97\n",
            "[2024-11-04 12:59:38,767] [INFO] [logging.py:96:log_dist] [Rank 0] step=90, skipped=0, lr=[0.00012246799701657457, 0.00012246799701657457], mom=[[0.9, 0.95], [0.9, 0.95]]\n",
            "[2024-11-04 12:59:38,768] [INFO] [timer.py:260:stop] epoch=0/micro_step=90/global_step=90, RunningAvgSamplesPerSec=7.513380457784022, CurrSamplesPerSec=7.546959730423568, MemAllocated=0.93GB, MaxMemAllocated=3.31GB\n",
            "[2024-11-04 12:59:38,768] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 94.54 | bwd_microstep: 334.50 | bwd_inner_microstep: 329.23 | bwd_allreduce_microstep: 5.21 | step_microstep: 36.84\n",
            "[2024-11-04 12:59:38,768] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 94.52 | bwd: 334.48 | bwd_inner: 329.22 | bwd_allreduce: 5.22 | step: 36.85\n",
            " samples/sec: 7.475 | iteration       90/     100 | elapsed time per iteration (ms): 535.1 | learning rate: 1.225E-04 | approx flops per GPU: 6.2TFLOPS | lm_loss: 2.838070E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
            "time (ms) | forward: 159.11 | backward: 337.05 | backward-backward: 337.00 | backward-allreduce: 0.00 | optimizer: 37.25 | batch generator: 1.74\n",
            "[2024-11-04 12:59:39,267] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.06 | msg size: 134.33 MB | algbw (Gbps): 40174.91 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:39,275] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:39,282] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:39,285] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.17 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:39,304] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 14718.88 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:39,304] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.15 | msg size: 80.0 KB | algbw (Gbps): 4.29 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:39,305] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.78 | optimizer_gradients: 5.94 | optimizer_step: 11.95\n",
            "[2024-11-04 12:59:39,305] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 93.88 | bwd_microstep: 337.34 | bwd_inner_microstep: 332.06 | bwd_allreduce_microstep: 5.23 | step_microstep: 36.73\n",
            "[2024-11-04 12:59:39,306] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 93.86 | bwd: 337.32 | bwd_inner: 332.05 | bwd_allreduce: 5.24 | step: 36.73\n",
            "[2024-11-04 12:59:39,801] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.06 | msg size: 134.33 MB | algbw (Gbps): 39676.97 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:39,810] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:39,817] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.15 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:39,820] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.14 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:39,838] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.08 | msg size: 134.25 MB | algbw (Gbps): 14880.69 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:39,839] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.14 | msg size: 80.0 KB | algbw (Gbps): 4.63 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:39,840] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.73 | optimizer_gradients: 5.93 | optimizer_step: 12.01\n",
            "[2024-11-04 12:59:39,840] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 93.99 | bwd_microstep: 334.77 | bwd_inner_microstep: 329.46 | bwd_allreduce_microstep: 5.26 | step_microstep: 37.17\n",
            "[2024-11-04 12:59:39,840] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 93.97 | bwd: 334.76 | bwd_inner: 329.45 | bwd_allreduce: 5.26 | step: 37.18\n",
            "[2024-11-04 12:59:40,340] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 28420.75 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:40,349] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:40,357] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:40,360] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:40,379] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.16 | msg size: 134.25 MB | algbw (Gbps): 7235.37 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:40,380] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.25 | msg size: 80.0 KB | algbw (Gbps): 2.60 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:40,381] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.16 | optimizer_gradients: 5.96 | optimizer_step: 11.96\n",
            "[2024-11-04 12:59:40,382] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 93.38 | bwd_microstep: 340.58 | bwd_inner_microstep: 334.65 | bwd_allreduce_microstep: 5.88 | step_microstep: 39.13\n",
            "[2024-11-04 12:59:40,382] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 93.36 | bwd: 340.56 | bwd_inner: 334.64 | bwd_allreduce: 5.88 | step: 39.14\n",
            "[2024-11-04 12:59:40,883] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 29740.97 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:40,892] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:40,900] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:40,904] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.25 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:40,923] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 11962.21 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:40,924] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.17 | msg size: 80.0 KB | algbw (Gbps): 3.77 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:40,925] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.90 | optimizer_gradients: 5.97 | optimizer_step: 11.97\n",
            "[2024-11-04 12:59:40,926] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 93.92 | bwd_microstep: 337.92 | bwd_inner_microstep: 332.00 | bwd_allreduce_microstep: 5.85 | step_microstep: 40.60\n",
            "[2024-11-04 12:59:40,926] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 93.90 | bwd: 337.89 | bwd_inner: 331.98 | bwd_allreduce: 5.85 | step: 40.61\n",
            "[2024-11-04 12:59:41,430] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.10 | msg size: 134.33 MB | algbw (Gbps): 22414.58 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:41,441] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.31 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:41,450] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:41,454] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:41,473] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.13 | msg size: 134.25 MB | algbw (Gbps): 8982.35 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:41,474] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.25 | msg size: 80.0 KB | algbw (Gbps): 2.62 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:41,475] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.23 | optimizer_gradients: 5.99 | optimizer_step: 11.99\n",
            "[2024-11-04 12:59:41,476] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 95.28 | bwd_microstep: 340.00 | bwd_inner_microstep: 333.72 | bwd_allreduce_microstep: 6.13 | step_microstep: 43.01\n",
            "[2024-11-04 12:59:41,476] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 95.26 | bwd: 340.00 | bwd_inner: 333.71 | bwd_allreduce: 6.13 | step: 43.01\n",
            "[2024-11-04 12:59:41,985] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.08 | msg size: 134.33 MB | algbw (Gbps): 27360.77 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:41,994] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.24 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:42,002] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:42,006] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:42,025] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 12077.16 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:42,025] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.22 | msg size: 80.0 KB | algbw (Gbps): 2.99 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:42,027] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.04 | optimizer_gradients: 5.98 | optimizer_step: 12.00\n",
            "[2024-11-04 12:59:42,027] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 98.87 | bwd_microstep: 340.77 | bwd_inner_microstep: 334.89 | bwd_allreduce_microstep: 5.81 | step_microstep: 40.62\n",
            "[2024-11-04 12:59:42,028] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 98.84 | bwd: 340.74 | bwd_inner: 334.87 | bwd_allreduce: 5.81 | step: 40.64\n",
            "[2024-11-04 12:59:42,536] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.09 | msg size: 134.33 MB | algbw (Gbps): 25997.28 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:42,546] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.23 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:42,554] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.20 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:42,558] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:42,576] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.10 | msg size: 134.25 MB | algbw (Gbps): 11222.20 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:42,577] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.17 | msg size: 80.0 KB | algbw (Gbps): 3.80 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:42,578] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.92 | optimizer_gradients: 5.98 | optimizer_step: 11.99\n",
            "[2024-11-04 12:59:42,579] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 99.23 | bwd_microstep: 337.28 | bwd_inner_microstep: 331.14 | bwd_allreduce_microstep: 6.03 | step_microstep: 40.56\n",
            "[2024-11-04 12:59:42,579] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 99.21 | bwd: 337.28 | bwd_inner: 331.12 | bwd_allreduce: 6.00 | step: 40.57\n",
            "[2024-11-04 12:59:43,081] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 30902.43 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:43,091] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.25 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:43,099] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.24 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:43,103] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.18 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:43,122] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 11966.28 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:43,123] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.20 | msg size: 80.0 KB | algbw (Gbps): 3.23 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:43,124] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.10 | optimizer_gradients: 6.69 | optimizer_step: 12.00\n",
            "[2024-11-04 12:59:43,125] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 95.09 | bwd_microstep: 336.96 | bwd_inner_microstep: 330.85 | bwd_allreduce_microstep: 5.98 | step_microstep: 40.95\n",
            "[2024-11-04 12:59:43,125] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 95.07 | bwd: 336.96 | bwd_inner: 330.83 | bwd_allreduce: 6.01 | step: 40.96\n",
            "[2024-11-04 12:59:43,635] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 30161.29 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:43,645] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.27 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:43,653] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:43,657] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:43,675] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.09 | msg size: 134.25 MB | algbw (Gbps): 12788.09 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:43,676] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.18 | msg size: 80.0 KB | algbw (Gbps): 3.63 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:43,677] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 0.93 | optimizer_gradients: 5.94 | optimizer_step: 11.95\n",
            "[2024-11-04 12:59:43,678] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 101.16 | bwd_microstep: 341.48 | bwd_inner_microstep: 335.49 | bwd_allreduce_microstep: 5.92 | step_microstep: 40.32\n",
            "[2024-11-04 12:59:43,678] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 101.13 | bwd: 341.45 | bwd_inner: 335.47 | bwd_allreduce: 5.92 | step: 40.33\n",
            "[2024-11-04 12:59:44,185] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.07 | msg size: 134.33 MB | algbw (Gbps): 31038.62 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:44,198] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.24 | msg size: 1.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:44,206] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.22 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:44,214] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.21 | msg size: 4.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:44,233] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.15 | msg size: 134.25 MB | algbw (Gbps): 7274.25 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:44,234] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_gather_into_tensor | time (ms): 0.20 | msg size: 80.0 KB | algbw (Gbps): 3.26 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:44,235] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | optimizer_allgather: 1.39 | optimizer_gradients: 5.99 | optimizer_step: 12.00\n",
            "[2024-11-04 12:59:44,235] [INFO] [logging.py:96:log_dist] [Rank 0] step=100, skipped=0, lr=[0.0001, 0.0001], mom=[[0.9, 0.95], [0.9, 0.95]]\n",
            "[2024-11-04 12:59:44,237] [INFO] [timer.py:260:stop] epoch=0/micro_step=100/global_step=100, RunningAvgSamplesPerSec=7.5019815628437145, CurrSamplesPerSec=7.264376694887551, MemAllocated=0.93GB, MaxMemAllocated=3.31GB\n",
            "[2024-11-04 12:59:44,237] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd_microstep: 98.89 | bwd_microstep: 339.46 | bwd_inner_microstep: 332.79 | bwd_allreduce_microstep: 6.54 | step_microstep: 48.98\n",
            "[2024-11-04 12:59:44,238] [INFO] [logging.py:96:log_dist] [Rank 0] time (ms) | fwd: 98.87 | bwd: 339.46 | bwd_inner: 332.78 | bwd_allreduce: 6.58 | step: 48.99\n",
            " samples/sec: 7.312 | iteration      100/     100 | elapsed time per iteration (ms): 547.0 | learning rate: 1.000E-04 | approx flops per GPU: 6.1TFLOPS | lm_loss: 2.784878E+00 | loss scale: 4096.0 | number of skipped iterations:   0 | number of nan iterations:   0 |\n",
            "time (ms) | forward: 164.42 | backward: 339.03 | backward-backward: 338.98 | backward-allreduce: 0.00 | optimizer: 41.49 | batch generator: 3.59\n",
            "--------------------------------------------------------------------------------------------------------\n",
            " validation results at iteration 100 | lm_loss value: 2.736050E+00 | lm_loss_ppl value: 1.542593E+01 | \n",
            "--------------------------------------------------------------------------------------------------------\n",
            "---------------------------------------------------------------------------------------------------------------------------\n",
            " validation results at the end of training for val data | lm_loss value: 2.810510E+00 | lm_loss_ppl value: 1.661839E+01 | \n",
            "---------------------------------------------------------------------------------------------------------------------------\n",
            "[2024-11-04 12:59:47,540] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: barrier | time (ms): 0.44 | msg size: 0B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:47,540] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step100 is about to be saved!\n",
            "[2024-11-04 12:59:47,541] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.19 | msg size: 20.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:47,541] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: all_reduce | time (ms): 0.16 | msg size: 20.0 B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1898: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
            "  warnings.warn(\n",
            "[2024-11-04 12:59:47,587] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: checkpoints/global_step100/mp_rank_00_model_states.pt\n",
            "[2024-11-04 12:59:47,587] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/global_step100/mp_rank_00_model_states.pt...\n",
            "[2024-11-04 12:59:47,947] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/global_step100/mp_rank_00_model_states.pt.\n",
            "[2024-11-04 12:59:47,948] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: barrier | time (ms): 0.48 | msg size: 0B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "[2024-11-04 12:59:47,950] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving checkpoints/global_step100/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
            "[2024-11-04 13:00:42,007] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved checkpoints/global_step100/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
            "[2024-11-04 13:00:42,030] [INFO] [engine.py:3426:_save_zero_checkpoint] zero checkpoint saved checkpoints/global_step100/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
            "[2024-11-04 13:00:42,030] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step100 is ready now!\n",
            "[2024-11-04 13:00:42,031] [INFO] [logging.py:96:log_dist] [Rank 0] comm op: barrier | time (ms): 0.57 | msg size: 0B | algbw (Gbps): 0.00 | busbw (Gbps): 0.00\n",
            "Evaluating iter 10/10\n",
            "----------------------------------------------------------------------------------------------------------------------\n",
            " test results at the end of training for test data | lm_loss value: 2.808052E+00 | lm_loss_ppl value: 1.657759E+01 | \n",
            "----------------------------------------------------------------------------------------------------------------------\n",
            "[2024-11-04 13:00:48,097] [INFO] [launch.py:347:main] Process 12457 exits successfully.\n",
            "CPU times: user 1.36 s, sys: 141 ms, total: 1.5 s\n",
            "Wall time: 3min 34s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show datasets\n",
        "!pip install datasets==1.18.0\n",
        "!pip install hf-transfer\n",
        "!pip install lm-eval --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsoKIdFh99O_",
        "outputId": "f4e61197-95a4-4b64-df1e-e782f398068f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: datasets\n",
            "Version: 3.1.0\n",
            "Summary: HuggingFace community-driven open-source library of datasets\n",
            "Home-page: https://github.com/huggingface/datasets\n",
            "Author: HuggingFace Inc.\n",
            "Author-email: thomas@huggingface.co\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: aiohttp, dill, filelock, fsspec, huggingface-hub, multiprocess, numpy, packaging, pandas, pyarrow, pyyaml, requests, tqdm, xxhash\n",
            "Required-by: evaluate, lm_eval\n",
            "Collecting datasets==1.18.0\n",
            "  Downloading datasets-1.18.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==1.18.0) (1.26.4)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==1.18.0) (17.0.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from datasets==1.18.0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==1.18.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==1.18.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets==1.18.0) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==1.18.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets==1.18.0) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->datasets==1.18.0) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==1.18.0) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets==1.18.0) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==1.18.0) (24.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==1.18.0) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==1.18.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==1.18.0) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==1.18.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==1.18.0) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==1.18.0) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==1.18.0) (4.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.18.0) (3.16.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.18.0) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.18.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==1.18.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==1.18.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==1.18.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==1.18.0) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==1.18.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==1.18.0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==1.18.0) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==1.18.0) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets==1.18.0) (0.2.0)\n",
            "Downloading datasets-1.18.0-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.3/311.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: datasets\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 3.1.0\n",
            "    Uninstalling datasets-3.1.0:\n",
            "      Successfully uninstalled datasets-3.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "evaluate 0.4.3 requires datasets>=2.0.0, but you have datasets 1.18.0 which is incompatible.\n",
            "lm-eval 0.4.1 requires datasets>=2.14.0, but you have datasets 1.18.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-1.18.0\n",
            "Collecting hf-transfer\n",
            "  Downloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Downloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: hf-transfer\n",
            "Successfully installed hf-transfer-0.1.8\n",
            "Requirement already satisfied: lm-eval in /usr/local/lib/python3.10/dist-packages (0.4.1)\n",
            "Collecting lm-eval\n",
            "  Downloading lm_eval-0.4.5-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from lm-eval) (0.34.2)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (from lm-eval) (0.4.3)\n",
            "Collecting datasets>=2.16.0 (from lm-eval)\n",
            "  Using cached datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.10/dist-packages (from lm-eval) (4.0.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from lm-eval) (2.10.1)\n",
            "Requirement already satisfied: peft>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from lm-eval) (0.13.2)\n",
            "Requirement already satisfied: pybind11>=2.6.2 in /usr/local/lib/python3.10/dist-packages (from lm-eval) (2.13.6)\n",
            "Requirement already satisfied: pytablewriter in /usr/local/lib/python3.10/dist-packages (from lm-eval) (1.2.0)\n",
            "Requirement already satisfied: rouge-score>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from lm-eval) (0.1.2)\n",
            "Requirement already satisfied: sacrebleu>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from lm-eval) (2.4.3)\n",
            "Requirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from lm-eval) (1.5.2)\n",
            "Requirement already satisfied: sqlitedict in /usr/local/lib/python3.10/dist-packages (from lm-eval) (2.1.0)\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.10/dist-packages (from lm-eval) (2.3.0)\n",
            "Requirement already satisfied: tqdm-multiprocess in /usr/local/lib/python3.10/dist-packages (from lm-eval) (0.0.11)\n",
            "Requirement already satisfied: transformers>=4.1 in /usr/local/lib/python3.10/dist-packages (from lm-eval) (4.38.0)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.10/dist-packages (from lm-eval) (0.23.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from lm-eval) (0.3.8)\n",
            "Collecting word2number (from lm-eval)\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from lm-eval) (10.5.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->lm-eval) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->lm-eval) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->lm-eval) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->lm-eval) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->lm-eval) (0.24.7)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->lm-eval) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm-eval) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm-eval) (17.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm-eval) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm-eval) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm-eval) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm-eval) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm-eval) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.16.0->lm-eval) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm-eval) (3.10.10)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm-eval) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm-eval) (3.8.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm-eval) (1.16.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm-eval) (2.10.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm-eval) (2024.9.11)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm-eval) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm-eval) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm-eval) (5.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm-eval) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm-eval) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm-eval) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8->lm-eval) (12.6.77)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.1->lm-eval) (0.15.2)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->lm-eval) (24.2.0)\n",
            "Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm-eval) (75.1.0)\n",
            "Requirement already satisfied: DataProperty<2,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm-eval) (1.0.1)\n",
            "Requirement already satisfied: mbstrdecoder<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm-eval) (1.1.3)\n",
            "Requirement already satisfied: pathvalidate<4,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm-eval) (3.2.1)\n",
            "Requirement already satisfied: tabledata<2,>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm-eval) (1.3.3)\n",
            "Requirement already satisfied: tcolorpy<1,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm-eval) (0.1.6)\n",
            "Requirement already satisfied: typepy<2,>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval) (1.3.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval) (4.0.3)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm-eval) (5.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm-eval) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm-eval) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm-eval) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm-eval) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.9 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval) (2024.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8->lm-eval) (3.0.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score>=0.0.4->lm-eval) (8.1.7)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->lm-eval) (2024.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8->lm-eval) (1.3.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.16.0->lm-eval) (0.2.0)\n",
            "Downloading lm_eval-0.4.5-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "Building wheels for collected packages: word2number\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5568 sha256=7a75e5877c9cb61a3857c4098b8ad1265b1cfa0a18125be9bd16b5ba46aec46d\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/ff/26/d3cfbd971e96c5aa3737ecfced81628830d7359b55fbb8ca3b\n",
            "Successfully built word2number\n",
            "Installing collected packages: word2number, datasets, lm-eval\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 1.18.0\n",
            "    Uninstalling datasets-1.18.0:\n",
            "      Successfully uninstalled datasets-1.18.0\n",
            "  Attempting uninstall: lm-eval\n",
            "    Found existing installation: lm_eval 0.4.1\n",
            "    Uninstalling lm_eval-0.4.1:\n",
            "      Successfully uninstalled lm_eval-0.4.1\n",
            "Successfully installed datasets-3.1.0 lm-eval-0.4.5 word2number-1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "M3Wp-zQC-EXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gpt-neox\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorboard.backend.event_processing import event_accumulator\n",
        "import os\n",
        "import numpy as np\n",
        "# Path to the latest log file\n",
        "log_dir = \"tensorboard\"\n",
        "log_files = [os.path.join(log_dir, d) for d in os.listdir(log_dir)]\n",
        "latest_log_dir = max(log_files, key=os.path.getmtime)\n",
        "\n",
        "# Initialize EventAccumulator to load scalar data\n",
        "ea = event_accumulator.EventAccumulator(latest_log_dir)\n",
        "ea.Reload()  # Load all logs\n",
        "\n",
        "# List all scalar keys available in the logs\n",
        "scalar_keys = ea.Tags()['scalars']\n",
        "print(\"Available scalar keys:\", scalar_keys)\n",
        "\n",
        "# Extract training and validation losses\n",
        "train_loss = ea.Scalars('train/lm_loss')  # Adjust for actual name if necessary\n",
        "val_loss = ea.Scalars('validation/lm_loss')  # Adjust for actual name if necessary\n",
        "\n",
        "# Convert to lists for plotting\n",
        "train_loss_values = [x.value for x in train_loss]\n",
        "val_loss_values = [x.value for x in val_loss]\n",
        "\n",
        "# Find the lengths of both arrays\n",
        "len_train = len(train_loss_values)\n",
        "len_val = len(val_loss_values)\n",
        "\n",
        "iterations = None\n",
        "# Interpolate the shorter array\n",
        "if len_train != len_val:\n",
        "    if len_train > len_val:\n",
        "        # Interpolate validation loss to match the training loss length\n",
        "        iterations = np.linspace(1, len_train, len_train)\n",
        "        val_iterations = np.linspace(1, len_train, len_val)\n",
        "        val_loss_values = np.interp(iterations, val_iterations, val_loss_values)\n",
        "    else:\n",
        "        # Interpolate training loss to match the validation loss length\n",
        "        iterations = np.linspace(1, len_val, len_val)\n",
        "        train_iterations = np.linspace(1, len_val, len_train)\n",
        "        train_loss_values = np.interp(iterations, train_iterations, train_loss_values)\n",
        "else:\n",
        "    iterations = range(1, len_train + 1)\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(iterations, train_loss_values, label='Training Loss')\n",
        "plt.plot(iterations, val_loss_values, label='Validation Loss')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "id": "rYKP6ya8Iqej",
        "outputId": "34f4594b-a088-4e48-afb4-6e7f87d812a1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gpt-neox\n",
            "Available scalar keys: ['timers/forward', 'timers/backward', 'timers/backward-backward', 'timers/backward-allreduce', 'timers/optimizer', 'timers/batch generator', 'train/learning_rate', 'train/lm_loss', 'train/loss_scale', 'runtime/samples_per_sec', 'runtime/iteration_time', 'runtime/flops_per_sec_per_gpu', 'validation/lm_loss', 'validation/lm_loss_ppl', 'test/lm_loss', 'test/lm_loss_ppl']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HuggingFace Inference"
      ],
      "metadata": {
        "id": "RNB4sSsS-RN3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert Our Model to HuggingFace Format"
      ],
      "metadata": {
        "id": "5IOlAoGw-jZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the path to the checkpoints directory\n",
        "checkpoints_dir = \"/content/gpt-neox/checkpoints\"\n",
        "\n",
        "# Read the 'latest' file to get the latest checkpoint name\n",
        "with open(os.path.join(checkpoints_dir, \"latest\"), \"r\") as f:\n",
        "    latest_checkpoint_name = f.read().strip()\n",
        "\n",
        "# Construct the full path to the latest checkpoint directory\n",
        "latest_checkpoint_path = os.path.join(checkpoints_dir, latest_checkpoint_name)\n",
        "print(\"Path to the latest checkpoint:\", latest_checkpoint_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfKL-k5k-DQj",
        "outputId": "b2b98a40-30b5-4aa7-926e-d3ab2e29c0d1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to the latest checkpoint: /content/gpt-neox/checkpoints/global_step100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./tools/ckpts/convert_neox_to_hf.py --input_dir {latest_checkpoint_path} --config_file /content/GPT-NeoX-Colab/configs/CC19M.yml --output_dir hf_model/save/location --precision auto --architecture neox"
      ],
      "metadata": {
        "id": "nPbSUBro-25L",
        "outputId": "f3cc7f27-38b1-460b-8a07-0ec68b68a1fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-11-04 13:04:31,538] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "Detected 'pipe-parallel-size' of 0, assuming model is saved as Sequential...\n",
            "> building GPT2BPETokenizer tokenizer ...\n",
            " > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)\n",
            "Auto-detecting precision to save model into...\n",
            "Saving weights in fp16 precision...\n",
            "['sequential.0.word_embeddings.weight', 'sequential.2.input_layernorm.weight', 'sequential.2.input_layernorm.bias', 'sequential.2.attention.query_key_value.weight', 'sequential.2.attention.query_key_value.bias', 'sequential.2.attention.dense.weight', 'sequential.2.attention.dense.bias', 'sequential.2.post_attention_layernorm.weight', 'sequential.2.post_attention_layernorm.bias', 'sequential.2.mlp.linear1.weight', 'sequential.2.mlp.linear1.bias', 'sequential.2.mlp.linear2.weight', 'sequential.2.mlp.linear2.bias', 'sequential.3.input_layernorm.weight', 'sequential.3.input_layernorm.bias', 'sequential.3.attention.query_key_value.weight', 'sequential.3.attention.query_key_value.bias', 'sequential.3.attention.dense.weight', 'sequential.3.attention.dense.bias', 'sequential.3.post_attention_layernorm.weight', 'sequential.3.post_attention_layernorm.bias', 'sequential.3.mlp.linear1.weight', 'sequential.3.mlp.linear1.bias', 'sequential.3.mlp.linear2.weight', 'sequential.3.mlp.linear2.bias', 'sequential.4.input_layernorm.weight', 'sequential.4.input_layernorm.bias', 'sequential.4.attention.query_key_value.weight', 'sequential.4.attention.query_key_value.bias', 'sequential.4.attention.dense.weight', 'sequential.4.attention.dense.bias', 'sequential.4.post_attention_layernorm.weight', 'sequential.4.post_attention_layernorm.bias', 'sequential.4.mlp.linear1.weight', 'sequential.4.mlp.linear1.bias', 'sequential.4.mlp.linear2.weight', 'sequential.4.mlp.linear2.bias', 'sequential.5.input_layernorm.weight', 'sequential.5.input_layernorm.bias', 'sequential.5.attention.query_key_value.weight', 'sequential.5.attention.query_key_value.bias', 'sequential.5.attention.dense.weight', 'sequential.5.attention.dense.bias', 'sequential.5.post_attention_layernorm.weight', 'sequential.5.post_attention_layernorm.bias', 'sequential.5.mlp.linear1.weight', 'sequential.5.mlp.linear1.bias', 'sequential.5.mlp.linear2.weight', 'sequential.5.mlp.linear2.bias', 'sequential.6.input_layernorm.weight', 'sequential.6.input_layernorm.bias', 'sequential.6.attention.query_key_value.weight', 'sequential.6.attention.query_key_value.bias', 'sequential.6.attention.dense.weight', 'sequential.6.attention.dense.bias', 'sequential.6.post_attention_layernorm.weight', 'sequential.6.post_attention_layernorm.bias', 'sequential.6.mlp.linear1.weight', 'sequential.6.mlp.linear1.bias', 'sequential.6.mlp.linear2.weight', 'sequential.6.mlp.linear2.bias', 'sequential.7.input_layernorm.weight', 'sequential.7.input_layernorm.bias', 'sequential.7.attention.query_key_value.weight', 'sequential.7.attention.query_key_value.bias', 'sequential.7.attention.dense.weight', 'sequential.7.attention.dense.bias', 'sequential.7.post_attention_layernorm.weight', 'sequential.7.post_attention_layernorm.bias', 'sequential.7.mlp.linear1.weight', 'sequential.7.mlp.linear1.bias', 'sequential.7.mlp.linear2.weight', 'sequential.7.mlp.linear2.bias', 'sequential.9.norm.weight', 'sequential.9.norm.bias', 'sequential.10.final_linear.weight']\n",
            "Detected MLP naming convention: new\n",
            "100% 6/6 [00:00<00:00, 132.00it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code Completion"
      ],
      "metadata": {
        "id": "GVuBSMByImpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPTNeoXForCausalLM\n",
        "import torch\n",
        "\n",
        "# Move to model directory\n",
        "%cd /content/gpt-neox\n",
        "\n",
        "# Assuming CharLevelTokenizer is properly imported and instantiated\n",
        "from megatron.tokenizer.tokenizer import _GPT2BPETokenizer\n",
        "tokenizer = _GPT2BPETokenizer(vocab_file=\"data/gpt2-vocab.json\", merge_file=\"data/gpt2-merges.txt\")\n",
        "\n",
        "# Load your model\n",
        "model_path = \"/content/gpt-neox/hf_model/save/location\"\n",
        "model = GPTNeoXForCausalLM.from_pretrained(model_path)\n",
        "\n",
        "# Define a simple char-level tokenizer if not provided\n",
        "def token_level_tokenize(text):\n",
        "    return tokenizer.tokenize(text)\n",
        "\n",
        "def token_level_detokenize(tokens):\n",
        "    return tokenizer.detokenize(tokens)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Prompt the user for input\n",
        "input_text = \"\"\"<s> import sys , os <EOL> import imp <EOL> from optparse import make_option <EOL> from django . conf import settings <EOL> from django . utils . importlib import import_module <EOL> from django . core . management import call_command <EOL> from django . core . management import BaseCommand <EOL> from django . db import connections <EOL> def import_app ( app_label , verbosity ) : <EOL> try : <EOL> app_path = __import__ ( app_label , { } , { } , [ app_label . split ( '<STR_LIT:.>' ) [ - <NUM_LIT:1> ] ] ) . __path__ <EOL>\"\"\"\n",
        "\n",
        "# Tokenize and prepare input\n",
        "input_ids = torch.tensor([token_level_tokenize(input_text)], dtype=torch.long)\n",
        "attention_mask = torch.ones_like(input_ids)  # Create an attention mask for non-padded input\n",
        "\n",
        "# Generate text with specified pad_token_id and attention_mask\n",
        "with torch.no_grad():\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        max_length=200,          # Adjust this for desired output length\n",
        "        temperature=0.7,        # Controls creativity\n",
        "        top_k=50,               # Controls diversity\n",
        "        top_p=0.9,              # Nucleus sampling\n",
        "        num_return_sequences=1, # Number of sequences to return\n",
        "        pad_token_id=model.config.eos_token_id,  # Set pad_token_id explicitly\n",
        "        do_sample=True           # Enable sampling mode to use temperature and top_p\n",
        "    )\n",
        "\n",
        "# Decode the generated text\n",
        "generated_text = token_level_detokenize(output[0].tolist())\n",
        "\n",
        "# Function to replace special tokens with original representations\n",
        "def replace_special_tokens(text):\n",
        "    replacements = {\n",
        "        \"<EOL>\": \"\\n\",  # Replace with actual newline\n",
        "        \"<s>\": \"\",\n",
        "        \"</s>\": \"\",     # Remove end token\n",
        "        \"<STR_LIT>\": \"STR_LITERAL\",  # Example replacement, adjust as necessary\n",
        "        \"<NUM_LIT>\": \"NUM_LITERAL\",   # Example replacement, adjust as necessary\n",
        "    }\n",
        "\n",
        "    for token, replacement in replacements.items():\n",
        "        text = text.replace(token, replacement)\n",
        "\n",
        "    return text.strip()  # Strip leading/trailing whitespace\n",
        "\n",
        "# Replace special tokens in the generated text\n",
        "final_text = replace_special_tokens(generated_text)\n",
        "\n",
        "# Print the final output\n",
        "print(\"Generated text:\", final_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztr-ItKf_G1M",
        "outputId": "a9fb1dc1-540e-40bc-f48e-ab7486c97ec4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gpt-neox\n",
            "Generated text: import sys, os \n",
            " import imp \n",
            " from optparse import make_option \n",
            " from django. conf import settings \n",
            " from django. utils. importlib import import_module \n",
            " from django. core. management import call_command \n",
            " from django. core. management import BaseCommand \n",
            " from django. db import connections \n",
            " def import_app ( app_label, verbosity ) : \n",
            " try : \n",
            " app_path = __import__ ( app_label, { }, { }, [ app_label. split ( '<STR_LIT:.>' ) [ - <NUM_LIT:1> ] ] ). __path__ \n",
            " if self. assertEOL> for self. _name ) \n",
            " self. test_LIT>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/gpt-neox/data/gpt2-vocab.json /content/gpt-neox/hf_model/save/location/vocab.json\n",
        "!cp /content/gpt-neox/data/gpt2-merges.txt /content/gpt-neox/hf_model/save/location/merges.txt\n",
        "%cd /content/CodeXGLUE/Code-Code/CodeCompletion-token/code\n",
        "!python -u run_lm.py \\\n",
        "        --data_dir=../dataset/py150/token_completion \\\n",
        "        --lit_file=../dataset/py150/literals.json \\\n",
        "        --langs=$LANG \\\n",
        "        --output_dir=../dataset/py150 \\\n",
        "        --pretrain_dir=/content/gpt-neox/hf_model/save/location \\\n",
        "        --log_file=../completion_python_eval.log \\\n",
        "        --model_type=gpt2neox \\\n",
        "        --block_size=2048 \\\n",
        "        --do_eval \\\n",
        "        --per_gpu_eval_batch_size=4 \\\n",
        "        --logging_steps=100 \\\n",
        "        --seed=42"
      ],
      "metadata": {
        "id": "AmLwXfGIc8uJ",
        "outputId": "01d38644-8106-405b-e176-1bfc721b85be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CodeXGLUE/Code-Code/CodeCompletion-token/code\n",
            "11/04/2024 13:11:56 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False, world size: 1\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPTNeoXTokenizerFast'. \n",
            "The class this function is called from is 'GPT2Tokenizer'.\n",
            "11/04/2024 13:11:58 - INFO - __main__ -   Model has a total of 70622208 trainable parameters\n",
            "11/04/2024 13:11:58 - INFO - __main__ -   Training/evaluation parameters Namespace(data_dir='../dataset/py150/token_completion', langs='en_US.UTF-8', output_dir='../dataset/py150', model_type='gpt2neox', pretrain_dir='/content/gpt-neox/hf_model/save/location', config_dir=None, tokenizer_dir=None, lit_file='../dataset/py150/literals.json', load_name='pretrained', mlm=False, mlm_probability=0.15, cache_dir='', block_size=2048, do_train=False, do_eval=True, evaluate_during_training=False, do_lower_case=False, per_gpu_train_batch_size=4, per_gpu_eval_batch_size=4, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, warmup_steps=0, logging_steps=100, save_steps=5000, save_total_limit=None, eval_all_checkpoints=False, no_cuda=False, overwrite_output_dir=False, overwrite_cache=False, seed=42, not_pretrain=False, fp16=False, fp16_opt_level='O1', local_rank=-1, node_index=-1, gpu_per_node=-1, server_ip='', server_port='', log_file='../completion_python_eval.log', tensorboard_dir=None, n_gpu=1, device=device(type='cuda'), start_epoch=0, start_step=0)\n",
            "11/04/2024 13:11:59 - INFO - __main__ -   Data size: 50000\n",
            "11/04/2024 13:11:59 - WARNING - __main__ -   load 0\n",
            "11/04/2024 13:12:40 - WARNING - __main__ -   load 10\n",
            "11/04/2024 13:13:25 - WARNING - __main__ -   load 20\n",
            "11/04/2024 13:14:04 - WARNING - __main__ -   load 30\n",
            "11/04/2024 13:14:57 - WARNING - __main__ -   load 40\n",
            "11/04/2024 13:15:39 - WARNING - __main__ -   load 50\n",
            "11/04/2024 13:16:22 - WARNING - __main__ -   load 60\n",
            "11/04/2024 13:17:04 - WARNING - __main__ -   load 70\n",
            "11/04/2024 13:17:45 - WARNING - __main__ -   load 80\n",
            "11/04/2024 13:18:34 - WARNING - __main__ -   load 90\n",
            "11/04/2024 13:19:09 - INFO - __main__ -   tokens: 67042146\n",
            "11/04/2024 13:19:09 - INFO - __main__ -   10000 samples\n",
            "11/04/2024 13:19:10 - INFO - __main__ -   20000 samples\n",
            "11/04/2024 13:19:10 - INFO - __main__ -   30000 samples\n",
            "11/04/2024 13:19:16 - INFO - __main__ -   0 are done!\n",
            "11/04/2024 13:19:16 - INFO - __main__ -   5140, 0.05875486381322957\n",
            "11/04/2024 13:19:58 - INFO - __main__ -   100 are done!\n",
            "11/04/2024 13:19:58 - INFO - __main__ -   543556, 0.06812361559802486\n",
            "11/04/2024 13:20:39 - INFO - __main__ -   200 are done!\n",
            "11/04/2024 13:20:39 - INFO - __main__ -   1082793, 0.06842120331402217\n",
            "11/04/2024 13:21:23 - INFO - __main__ -   300 are done!\n",
            "11/04/2024 13:21:23 - INFO - __main__ -   1622875, 0.06511592081953324\n",
            "11/04/2024 13:22:07 - INFO - __main__ -   400 are done!\n",
            "11/04/2024 13:22:07 - INFO - __main__ -   2160297, 0.06447400519465611\n",
            "11/04/2024 13:22:51 - INFO - __main__ -   500 are done!\n",
            "11/04/2024 13:22:51 - INFO - __main__ -   2687725, 0.06300719009571291\n",
            "11/04/2024 13:23:35 - INFO - __main__ -   600 are done!\n",
            "11/04/2024 13:23:35 - INFO - __main__ -   3220498, 0.06300795715445251\n",
            "11/04/2024 13:24:18 - INFO - __main__ -   700 are done!\n",
            "11/04/2024 13:24:18 - INFO - __main__ -   3741981, 0.06223227750221073\n",
            "11/04/2024 13:25:03 - INFO - __main__ -   800 are done!\n",
            "11/04/2024 13:25:03 - INFO - __main__ -   4268538, 0.06141306461369209\n",
            "11/04/2024 13:25:46 - INFO - __main__ -   900 are done!\n",
            "11/04/2024 13:25:46 - INFO - __main__ -   4814346, 0.06093330225953847\n",
            "11/04/2024 13:26:30 - INFO - __main__ -   1000 are done!\n",
            "11/04/2024 13:26:30 - INFO - __main__ -   5348001, 0.06106917332289205\n",
            "11/04/2024 13:27:16 - INFO - __main__ -   1100 are done!\n",
            "11/04/2024 13:27:16 - INFO - __main__ -   5837797, 0.05873636921599021\n",
            "11/04/2024 13:28:00 - INFO - __main__ -   1200 are done!\n",
            "11/04/2024 13:28:00 - INFO - __main__ -   6343418, 0.0583939131868655\n",
            "11/04/2024 13:28:44 - INFO - __main__ -   1300 are done!\n",
            "11/04/2024 13:28:44 - INFO - __main__ -   6878339, 0.058287618566052066\n",
            "11/04/2024 13:29:28 - INFO - __main__ -   1400 are done!\n",
            "11/04/2024 13:29:28 - INFO - __main__ -   7416186, 0.057976431551204355\n",
            "11/04/2024 13:30:13 - INFO - __main__ -   1500 are done!\n",
            "11/04/2024 13:30:13 - INFO - __main__ -   7959551, 0.05821848493715286\n",
            "11/04/2024 13:30:57 - INFO - __main__ -   1600 are done!\n",
            "11/04/2024 13:30:57 - INFO - __main__ -   8488074, 0.058877667654641086\n"
          ]
        }
      ]
    }
  ]
}