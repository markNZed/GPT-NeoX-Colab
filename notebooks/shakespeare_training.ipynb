{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/markNZed/GPT-NeoX-Colab/blob/main/notebooks/shakespeare_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52lBrppZd_A0"
   },
   "source": [
    "# Training a tiny SLM on a corpus of Shakespeare\n",
    "The intention of this notebook is to demonstrate a setup for experimenting with a tiny SLM.\n",
    "The following tools are used:\n",
    "* Colab (https://colab.research.google.com/) for notebook execution\n",
    "* DagsHub (https://dagshub.com/) for project tracking\n",
    "* MLFlow (https://mlflow.org/) for experiment tracking\n",
    "* Hydra (https://hydra.cc/) for configuration management\n",
    "* GPTNeoX (https://github.com/EleutherAI/gpt-neox) for model training\n",
    "* Tensorboard (https://www.tensorflow.org/tensorboard) for experiment monitoring\n",
    "* DVC (https://dvc.org/) for data management\n",
    "* GitHub (https://github.com/) for code management\n",
    "* Backblaze (https://backblaze.com/) for data storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uYyxsLpOuQR1",
    "outputId": "d5b7930f-46bb-45be-abc3-6ab5b2744c54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Date and Time: 2024-12-01 07:57:33.636842\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(\"Current Date and Time:\", datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sR5zBqZ0Q25t",
    "outputId": "3acfaba5-a6bc-4d38-aac5-580eab96cf21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isColab: False\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  from google import colab\n",
    "  isColab = True\n",
    "except:\n",
    "  isColab = False\n",
    "\n",
    "try:\n",
    "  from google.colab import userdata\n",
    "  if userdata.get('GITHUB_NAME'):\n",
    "    !git config --global user.name \"{userdata.get('GITHUB_NAME')}\"\n",
    "  if userdata.get('GITHUB_EMAIL'):\n",
    "    !git config --global user.email \"{userdata.get('GITHUB_EMAIL')}\"\n",
    "  if userdata.get('AWS_SECRET_ACCESS_KEY'):\n",
    "    !echo \"export AWS_SECRET_ACCESS_KEY={userdata.get('AWS_SECRET_ACCESS_KEY')}\" >> ~/.bashrc\n",
    "    os.environ['AWS_SECRET_ACCESS_KEY'] = userdata.get('AWS_SECRET_ACCESS_KEY')\n",
    "  if userdata.get('AWS_ACCESS_KEY_ID'):\n",
    "    !echo \"export AWS_ACCESS_KEY_ID={userdata.get('AWS_ACCESS_KEY_ID')}\" >> ~/.bashrc\n",
    "    os.environ['AWS_ACCESS_KEY_ID'] = userdata.get('AWS_ACCESS_KEY_ID')\n",
    "except:\n",
    "   pass\n",
    "\n",
    "print(\"isColab:\", isColab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HBH4eN9Id_A7"
   },
   "outputs": [],
   "source": [
    "# We could modify these paths to \"stub\" behavior for test/dev\n",
    "workspaceDir = \"/content\"\n",
    "gpt_neox_colabDir = f\"{workspaceDir}/GPT-NeoX-Colab\"\n",
    "if not isColab:\n",
    "  !sudo ln -s /workspace /content/GPT-NeoX-Colab\n",
    "GPTNeoXDirName = \"gpt-neox\"\n",
    "GPTNeoXDir = f\"{workspaceDir}/{GPTNeoXDirName}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74e27VRVq07s"
   },
   "source": [
    "# Cloning Git Repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "j_hUsQxlhnou",
    "outputId": "b5d10deb-6d4c-45e4-9721-940a07e26f91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "CPU times: user 80 μs, sys: 1.05 ms, total: 1.13 ms\n",
      "Wall time: 984 μs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/.venv/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#@title Clone GPT-NeoX-Colab\n",
    "%cd {workspaceDir}\n",
    "if isColab:\n",
    "  # Don't use --depth 1 because that does not play nice with git-annex\n",
    "  if userdata.get('GITHUB_PAT'):\n",
    "    !git clone --depth 1 https://{userdata.get('GITHUB_PAT')}@github.com/markNZed/GPT-NeoX-Colab.git\n",
    "    print(\"Cloned with PAT\")\n",
    "  else:\n",
    "    !git clone --depth 1 https://github.com/markNZed/GPT-NeoX-Colab.git\n",
    "    print(\"Cloned without PAT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jp8wncmZDAew",
    "outputId": "2cd8973e-8258-481e-a295-62f58c19868c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n",
      "Install DVC\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "CPU times: user 24.6 ms, sys: 7.25 ms, total: 31.9 ms\n",
      "Wall time: 1.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sys\n",
    "%cd {gpt_neox_colabDir}\n",
    "print(\"Install DVC\")\n",
    "%pip install -q python-dotenv dvc==3.2.0 s3fs==2024.2.0 fsspec==2024.2.0 \n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "activate_script = f\"{gpt_neox_colabDir}/.venv/bin/activate\"\n",
    "USE_VENV = False\n",
    "if USE_VENV:\n",
    "  # Disabling pydevd_plugins so we do not get a restart warning\n",
    "  #if \"pydevd_plugins\" in sys.modules:\n",
    "  #  del sys.modules[\"pydevd_plugins\"]\n",
    "  venv_dir = \".venv\"\n",
    "  venv_tar_file = f\"{venv_dir}.tar\"\n",
    "  venv_gz_file = f\"{venv_tar_file}.gz\"\n",
    "  if not os.path.isdir(venv_dir):\n",
    "    if not os.path.isfile(venv_gz_file):\n",
    "      print(f\"Downloading {venv_gz_file}\")\n",
    "      !dvc pull -q {venv_gz_file}\n",
    "    if not os.path.isfile(venv_tar_file):\n",
    "      print(f\"Unzipping {venv_gz_file}\")\n",
    "      !sudo apt-get install -y pigz\n",
    "      !pigz -d -p 4 {venv_gz_file}\n",
    "    if not os.path.isfile(venv_dir):\n",
    "      print(f\"Untarring {venv_tar_file}\")\n",
    "      !tar -xf {venv_tar_file}\n",
    "      !rm {venv_tar_file}\n",
    "elif isColab:\n",
    "    !uv sync -q --dev\n",
    "    !uv run pip install -q -e .\n",
    "    !source {activate_script} && pip install -q -r requirements_colab.txt\n",
    "    !source {activate_script} && pip install -q ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y8Mic7aoiNxi",
    "outputId": "2b90a097-de42-463b-c0c9-6bdd17ca9cf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n",
      "\u001b[31mERROR\u001b[39m: failed to pull data from the cloud - Can't remove the following unsaved files without confirmation. Use `--force` to force.\n",
      "/workspace/data/shakespeare/config.json\n",
      "/workspace/data/shakespeare/generation_config.json\n",
      "/workspace/data/shakespeare/model.safetensors\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#@title Fetch training data\n",
    "%cd {gpt_neox_colabDir}\n",
    "!dvc --quiet pull \"data/shakespeare\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "FjLEIFCR6d8m",
    "outputId": "4d334a01-1a25-40fd-e546-207ae445c15d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "Cloning into 'gpt-neox'...\n",
      "remote: Enumerating objects: 296, done.\u001b[K\n",
      "remote: Counting objects: 100% (296/296), done.\u001b[K\n",
      "remote: Compressing objects: 100% (231/231), done.\u001b[K\n",
      "remote: Total 296 (delta 74), reused 138 (delta 43), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (296/296), 2.50 MiB | 2.58 MiB/s, done.\n",
      "Resolving deltas: 100% (74/74), done.\n",
      "CPU times: user 44.7 ms, sys: 10.4 ms, total: 55.1 ms\n",
      "Wall time: 1.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#@title Clone GPT-NeoX\n",
    "%cd {workspaceDir}\n",
    "#!git clone ---depth 1 https://github.com/EleutherAI/gpt-neox\n",
    "!git clone -b pipe_parallel_size_1 --depth 1 https://github.com/markNZed/gpt-neox.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Va0pS1dvd_BD"
   },
   "source": [
    "# Python Environment\n",
    "It is faster to download a Python virtual environment and unzip it than to install all the dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "id": "AUmdStRWhrUR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gpt-neox\n"
     ]
    }
   ],
   "source": [
    "if not USE_VENV:\n",
    "    # Could not redirect to /dev/null in the standard Colab notebook (maybe no output for a particular time?)\n",
    "    # Currently deepspeed from GTP-NeoX is not compatible with logging in torch >= 2.4\n",
    "    !source {activate_script} && pip install -q torch==2.3 torchaudio==2.3.0 torchvision==0.18.0 transformers==4.38.0 sentence-transformers==2.2.2\n",
    "    !source {activate_script} && pip install -q fsspec==2024.2.0 datasets==2.14.0 evaluate==0.4.3 lm-eval==0.4.1 tensorboard==2.17.1 tensorflow==2.17.1\n",
    "    %cd {GPTNeoXDir}\n",
    "    !source {activate_script} && pip install -q -r ./requirements/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2jzX5ohGax6p"
   },
   "source": [
    "# Preparing Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N-hmZjCc-WnV",
    "outputId": "01e5c12d-dabd-4591-8688-55bb19c4a181"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gpt-neox\n"
     ]
    }
   ],
   "source": [
    "#@title Converting text data to jsonl format\n",
    "import os\n",
    "\n",
    "%cd {GPTNeoXDir}\n",
    "!mkdir -p data\n",
    "\n",
    "# Check if the converted file exists\n",
    "if not os.path.isfile(f\"{gpt_neox_colabDir}/data/shakespeare/shakespeare.jsonl\"):\n",
    "    !source {activate_script} && python -c \"import gpt_neox_colab.utils; gpt_neox_colab.utils.ml.text2jsonl(\\\"{gpt_neox_colabDir}/data/shakespeare/shakespeare.txt\\\", \\\"{gpt_neox_colabDir}/data/shakespeare/shakespeare.jsonl\\\")\"\n",
    "\n",
    "!cp {gpt_neox_colabDir}/data/shakespeare/shakespeare.jsonl {GPTNeoXDir}/data/shakespeare.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x57thNaLa-yN"
   },
   "source": [
    "# Tokenizing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JyD8RujkEUsr",
    "outputId": "2f8badb0-929e-4bb9-bd88-65306cb81133"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gpt-neox\n",
      "/content/gpt-neox/processed_data\n",
      "CPU times: user 2.44 ms, sys: 53.9 ms, total: 56.3 ms\n",
      "Wall time: 404 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#@title Tokenizing jsonl formatted data\n",
    "import os\n",
    "\n",
    "%cd {GPTNeoXDir}\n",
    "!mkdir -p processed_data\n",
    "%cd processed_data\n",
    "\n",
    "# Check if the tokenized files exists\n",
    "a = f\"{gpt_neox_colabDir}/data/shakespeare/shakespeare_text_document.idx\"\n",
    "b = f\"{gpt_neox_colabDir}/data/shakespeare/shakespeare_text_document.bin\"\n",
    "if not os.path.isfile(a) or not os.path.isfile(b):\n",
    "    cmd = f\"\"\"\n",
    "    source {activate_script} && python {GPTNeoXDir}/tools/datasets/preprocess_data.py \\\n",
    "        --input {GPTNeoXDir}/data/shakespeare.jsonl \\\n",
    "        --output-prefix shakespeare \\\n",
    "        --tokenizer-type CharLevelTokenizer \\\n",
    "        --dataset-impl mmap \\\n",
    "        --append-eod\n",
    "    \"\"\"\n",
    "    print(f\"Command: {cmd}\")\n",
    "    !source {activate_script} && python {GPTNeoXDir}/tools/datasets/preprocess_data.py \\\n",
    "        --input {GPTNeoXDir}/data/shakespeare.jsonl \\\n",
    "        --output-prefix shakespeare \\\n",
    "        --tokenizer-type CharLevelTokenizer \\\n",
    "        --dataset-impl mmap \\\n",
    "        --append-eod\n",
    "    !cp {GPTNeoXDir}/processed_data/shakespeare_text_document.bin {gpt_neox_colabDir}/data/shakespeare\n",
    "    !cp {GPTNeoXDir}/processed_data/shakespeare_text_document.idx {gpt_neox_colabDir}/data/shakespeare\n",
    "\n",
    "!cp {gpt_neox_colabDir}/data/shakespeare/shakespeare_text_document.bin {GPTNeoXDir}/processed_data\n",
    "!cp {gpt_neox_colabDir}/data/shakespeare/shakespeare_text_document.idx {GPTNeoXDir}/processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YNM2gpADtjM9",
    "outputId": "9647270b-ef75-4eb0-9783-14988764151f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PtOHyiVDhrUZ",
    "outputId": "07af7289-e7a0-4b2c-a3cf-26965ee3152b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running command: \n",
      "nohup nohup bash -c \" source /content/GPT-NeoX-Colab/.venv/bin/activate && cd /content/gpt-neox && python ./deepy.py train.py --conf_dir /content/GPT-NeoX-Colab/configs shakespeare shakespeare_deepy \"\n",
      "\n",
      "Started training with PID: 84467\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "# Start a detached background process using the temp config\n",
    "# If we want to run from scratch again: rm -rf /content/gpt-neox/logs/* /content/gpt-neox/tensorboard/* /content/gpt-neox/checkpoints/*\n",
    "cmd = f\"\"\"\n",
    "nohup nohup bash -c \" source {activate_script} && \\\n",
    "cd {GPTNeoXDir} && \\\n",
    "python ./deepy.py train.py --conf_dir {gpt_neox_colabDir}/configs shakespeare shakespeare_deepy \"\n",
    "\"\"\"\n",
    "print(\"Running command:\", cmd)\n",
    "#cmd = \"nohup bash -c ls\" # Used to test without running on GPU\n",
    "\n",
    "# Redirect stdout and stderr to os.devnull\n",
    "with open(os.devnull, 'w') as devnull:\n",
    "    process = subprocess.Popen(\n",
    "        cmd,\n",
    "        shell=True,\n",
    "        executable='/bin/bash',\n",
    "        preexec_fn=os.setsid,  # Starts the process in a new session\n",
    "        stdout=devnull,  # Suppress stdout\n",
    "        stderr=devnull   # Suppress stderr\n",
    "    )\n",
    "\n",
    "pid = process.pid\n",
    "print(f\"Started training with PID: {pid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WVCgdZ1Ma9TI",
    "outputId": "1f8443d7-827a-4a19-8848-c99d4b99e19d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard log directory found. You can now launch TensorBoard.\n"
     ]
    }
   ],
   "source": [
    "#@title Wait until tensorboard log directory is created\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Path to the TensorBoard log directory\n",
    "tensorboard_log_dir = f\"{GPTNeoXDir}/tensorboard\"\n",
    "\n",
    "# Wait for the directory to be created\n",
    "while not os.path.exists(tensorboard_log_dir):\n",
    "    print(\"Waiting for TensorBoard log directory to be created...\")\n",
    "    time.sleep(10)  # Check every X seconds\n",
    "\n",
    "print(\"TensorBoard log directory found. You can now launch TensorBoard.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "bfefGgc-ln-J",
    "outputId": "c22a2698-0eb1-46f7-fcab-44d24758af34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gpt-neox\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 76591), started 0:32:40 ago. (Use '!kill 76591' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b38543f09e138a6f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b38543f09e138a6f\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Need to delete everything in checkpoints and tensorboard dir for a fresh run\n",
    "%cd {GPTNeoXDir}\n",
    "%tensorboard --logdir tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1j3_fG5vV7AB",
    "outputId": "baf08d75-3452-45ab-cb6d-83e2ca074e3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No log files found.\n"
     ]
    }
   ],
   "source": [
    "#@title Find the latest log file\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Define the log directory and pattern for log files\n",
    "experimentDir = f\"{GPTNeoXDir}/logs\"\n",
    "log_pattern = os.path.join(experimentDir, \"*_stdout.txt\")\n",
    "\n",
    "# Get the list of log files that match the pattern\n",
    "log_files = glob.glob(log_pattern)\n",
    "\n",
    "# Ensure there are log files in the directory\n",
    "if log_files:\n",
    "    # Find the latest log file based on modification time\n",
    "    latest_log = max(log_files, key=os.path.getmtime)\n",
    "    print(\"Latest log file:\", latest_log)\n",
    "else:\n",
    "    latest_log = None\n",
    "    print(\"No log files found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QszVj7_vSP7L"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fn13kNSRacnA",
    "outputId": "e7217bb7-65a4-411d-d0c0-de9bc6d1b81f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is still running...\n",
      "Training is still running...\n"
     ]
    }
   ],
   "source": [
    "#@title Read the latest log file and extract the iteration count\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "\n",
    "# File to store the last read position (persistence between script runs)\n",
    "file_position = 0\n",
    "# Regular expression to match \"iteration <number> / <total>\"\n",
    "iteration_pattern = re.compile(r\"iteration\\s+(\\d+)\\s*/\\s*\\d+\")\n",
    "\n",
    "def read_new_iterations():\n",
    "    global file_position\n",
    "    # Open the log file and seek to the last position\n",
    "    with open(latest_log, \"r\") as file:\n",
    "        file.seek(file_position)\n",
    "        # Read new lines\n",
    "        new_lines = file.readlines()\n",
    "        file_position = file.tell()\n",
    "        # Process lines containing \"iteration\"\n",
    "        last_match = None\n",
    "        for line in new_lines:\n",
    "            match = iteration_pattern.search(line)\n",
    "            if match:\n",
    "                last_match = match\n",
    "        if last_match:\n",
    "            # Extract the iteration count from the regex match\n",
    "            iteration_count = int(last_match.group(1))\n",
    "            print(f\"{iteration_count} iterations\")\n",
    "\n",
    "# Periodically check if the process has completed\n",
    "while True:\n",
    "    # Poll the process to see if it has terminated\n",
    "    if process.poll() is not None:\n",
    "        # Process has completed\n",
    "        print(\"Training has completed.\")\n",
    "        break\n",
    "    else:\n",
    "        if latest_log:\n",
    "            read_new_iterations()\n",
    "        elif os.path.exists(f\"{experimentDir}/logs\"):\n",
    "            latest_log = get_latest_file(f\"{experimentDir}/logs\", \"*_stdout.txt\")\n",
    "        print(\"Training is still running...\")\n",
    "        time.sleep(30)  # Check every X seconds\n",
    "\n",
    "print(\"Training has finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lJb7TUqi4vVg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available scalar keys: ['validation/lm_loss', 'validation/lm_loss_ppl', 'test/lm_loss', 'test/lm_loss_ppl']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Key train/lm_loss was not found in Reservoir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvailable scalar keys:\u001b[39m\u001b[38;5;124m\"\u001b[39m, scalar_keys)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Extract training and validation losses\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mea\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mScalars\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain/lm_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Adjust for actual name if necessary\u001b[39;00m\n\u001b[1;32m     22\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m ea\u001b[38;5;241m.\u001b[39mScalars(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation/lm_loss\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Adjust for actual name if necessary\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Convert to lists for plotting\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/.venv/lib/python3.10/site-packages/tensorboard/backend/event_processing/event_accumulator.py:603\u001b[0m, in \u001b[0;36mEventAccumulator.Scalars\u001b[0;34m(self, tag)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mScalars\u001b[39m(\u001b[38;5;28mself\u001b[39m, tag):\n\u001b[1;32m    592\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Given a summary tag, return all associated `ScalarEvent`s.\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \n\u001b[1;32m    594\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;124;03m      An array of `ScalarEvent`s.\u001b[39;00m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 603\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalars\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mItems\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/.venv/lib/python3.10/site-packages/tensorboard/backend/event_processing/reservoir.py:110\u001b[0m, in \u001b[0;36mReservoir.Items\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mutex:\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buckets:\n\u001b[0;32m--> 110\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m was not found in Reservoir\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m key)\n\u001b[1;32m    111\u001b[0m     bucket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buckets[key]\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bucket\u001b[38;5;241m.\u001b[39mItems()\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Key train/lm_loss was not found in Reservoir'"
     ]
    }
   ],
   "source": [
    "#@title Display training and validation Loss\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import os\n",
    "import numpy as np\n",
    "# Path to the latest log file\n",
    "log_dir = \"tensorboard\"\n",
    "log_files = [os.path.join(log_dir, d) for d in os.listdir(log_dir)]\n",
    "latest_log_dir = max(log_files, key=os.path.getmtime)\n",
    "\n",
    "# Initialize EventAccumulator to load scalar data\n",
    "ea = event_accumulator.EventAccumulator(latest_log_dir)\n",
    "ea.Reload()  # Load all logs\n",
    "\n",
    "# List all scalar keys available in the logs\n",
    "scalar_keys = ea.Tags()['scalars']\n",
    "print(\"Available scalar keys:\", scalar_keys)\n",
    "\n",
    "# Extract training and validation losses\n",
    "train_loss = ea.Scalars('train/lm_loss')  # Adjust for actual name if necessary\n",
    "val_loss = ea.Scalars('validation/lm_loss')  # Adjust for actual name if necessary\n",
    "\n",
    "# Convert to lists for plotting\n",
    "train_loss_values = [x.value for x in train_loss]\n",
    "val_loss_values = [x.value for x in val_loss]\n",
    "\n",
    "# Find the lengths of both arrays\n",
    "len_train = len(train_loss_values)\n",
    "len_val = len(val_loss_values)\n",
    "\n",
    "iterations = None\n",
    "# Interpolate the shorter array\n",
    "if len_train != len_val:\n",
    "    if len_train > len_val:\n",
    "        # Interpolate validation loss to match the training loss length\n",
    "        iterations = np.linspace(1, len_train, len_train)\n",
    "        val_iterations = np.linspace(1, len_train, len_val)\n",
    "        val_loss_values = np.interp(iterations, val_iterations, val_loss_values)\n",
    "    else:\n",
    "        # Interpolate training loss to match the validation loss length\n",
    "        iterations = np.linspace(1, len_val, len_val)\n",
    "        train_iterations = np.linspace(1, len_val, len_train)\n",
    "        train_loss_values = np.interp(iterations, train_iterations, train_loss_values)\n",
    "else:\n",
    "    iterations = range(1, len_train + 1)\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(iterations, train_loss_values, label='Training Loss')\n",
    "plt.plot(iterations, val_loss_values, label='Validation Loss')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sk8DhmmEZFyz"
   },
   "source": [
    "# Inference with GPT-NeoX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PKb0Ar6NZFyz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gpt-neox\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/.venv/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-01 08:07:38,362] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "/content/gpt-neox/megatron/neox_arguments/arguments.py:1101: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert (\n",
      "/content/gpt-neox/megatron/neox_arguments/arguments.py:1110: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert (\n",
      "NeoXArgs.from_ymls() ['/content/GPT-NeoX-Colab/configs/shakespeare.yml', '/content/GPT-NeoX-Colab/configs/shakespeare_gen.yml']\n",
      "INFO:root:NeoXArgs.calculate_derived() Total number of GPUs determined to be: 1\n",
      "-------------------- arguments --------------------\n",
      "  attention_config ................ ['global', 'global', 'global', 'global']updated\n",
      "  batch_size ...................... 8...........................updated\n",
      "  checkpoint_factor ............... 50..........................updated\n",
      "  config_files .................... {'shakespeare.yml': '{\\n  \"pipe_parallel_size\": 0, # Because running on one GPU\\n  \"model_parallel_size\": 1, # Because running on one GPU\\n\\n  # model settings\\n  \"num_layers\": 4,\\n  \"hidden_size\": 256,\\n  \"num_attention_heads\": 4,\\n  \"seq_length\": 512,\\n  \"max_position_embeddings\": 512,\\n  \"pos_emb\": \"rotary\",\\n  \"no_weight_tying\": false, # Sharing embedding and output weights\\n  \"gpt_j_residual\": false,\\n  \"output_layer_parallelism\": \"column\",\\n\\n  \"scaled_upper_triang_masked_softmax_fusion\": false,\\n  \"bias_gelu_fusion\": false,\\n  \"rope_fusion\": false,\\n  \"layernorm_fusion\": false,\\n\\n  # init methods\\n  \"init_method\": \"small_init\",\\n  \"output_layer_init_method\": \"wang_init\",\\n\\n  \"optimizer\": {\\n    \"type\": \"Adam\",\\n    \"params\": {\\n      \"lr\": 0.001,\\n      \"betas\": [0.9, 0.95],\\n      \"eps\": 1.0e-8\\n    }\\n  },\\n  \"min_lr\": 0.0001,\\n\\n  \"zero_optimization\": {\\n    \"stage\": 1,\\n    \"allgather_partitions\": true,\\n    \"allgather_bucket_size\": 500000000,\\n    \"overlap_comm\": true,\\n    \"reduce_scatter\": true,\\n    \"reduce_bucket_size\": 500000000,\\n    \"contiguous_gradients\": true\\n  },\\n\\n  \"train_micro_batch_size_per_gpu\": 8, #256, # 8, #8 for 4GB #256 for 16GB\\n  \"gradient_accumulation_steps\": 1,\\n  \"data_impl\": \"mmap\",\\n  \"num_workers\": 1,\\n\\n  # activation checkpointing\\n  \"checkpoint_activations\": false, # We are not memory bound\\n  \"checkpoint_num_layers\": 1,\\n  \"partition_activations\": true,\\n  \"synchronize_each_layer\": true,\\n\\n  # regularization\\n  \"gradient_clipping\": 1.0,\\n  \"weight_decay\": 0.1,\\n  \"hidden_dropout\": 0,\\n  \"attention_dropout\": 0,\\n\\n  # precision settings\\n  \"fp16\": {\\n    \"fp16\": true,\\n    \"enabled\": true,\\n    \"loss_scale\": 0,\\n    \"loss_scale_window\": 1000,\\n    \"initial_scale_power\": 12,\\n    \"hysteresis\": 2,\\n    \"min_loss_scale\": 1\\n  },\\n\\n  \"train_iters\": 800,\\n  \"lr_decay_iters\": 800,\\n  \"distributed_backend\": \"nccl\",\\n  \"lr_decay_style\": \"linear\",\\n  \"warmup\": 0.01,\\n  \"checkpoint_factor\": 50, # Must be defined if save is set\\n  \"eval_interval\": 30,\\n  \"eval_iters\": 2,\\n\\n  \"log_interval\": 10,\\n  \"steps_per_print\": 10,\\n  \"wall_clock_breakdown\": true,\\n\\n  # Required for model conversion into HF format\\n  \"tokenizer_type\": \"CharLevelTokenizer\",\\n\\n  # additional deepspeed args not specified above\\n  \"deepspeed_extra_args\": {\\n    \"comms_logger\": {\\n      \"enabled\": true,\\n      \"verbose\": false,\\n      \"prof_all\": true,\\n      \"debug\": false\\n    }\\n  }\\n}\\n', 'shakespeare_gen.yml': '# Parameters used for text generation\\n{\\n  # Text gen type: `input-file`, `unconditional` or `interactive`\\n  \"text_gen_type\": \"unconditional\",\\n\\n  # Params for all\\n  \"maximum_tokens\": 102,\\n  \"prompt_end\": \"\\\\n\",\\n  \"temperature\": 1.0,\\n  \"top_p\": 0.0,\\n  \"top_k\": 0,\\n  \"recompute\": false,\\n\\n  # `unconditional`: samples\\n  \"num_samples\": 10,\\n\\n  # input/output file\\n  \"sample_input_file\": \"sample_input.txt\",\\n  \"sample_output_file\": \"sample_output.txt\",\\n\\n  \"data_path\": \"processed_data/shakespeare_text_document\",\\n\\n  \"save\": \"checkpoints\",\\n  \"load\": \"checkpoints\",\\n  \"checkpoint_validation_with_forward_pass\": False,\\n\\n  \"tensorboard_dir\": \"tensorboard_gen\",\\n  \"log_dir\": \"logs_gen\",\\n}'}updated\n",
      "  data_impl ....................... mmap........................updated\n",
      "  data_path ....................... processed_data/shakespeare_text_documentupdated\n",
      "  deepspeed_extra_args ............ {'comms_logger': {'enabled': True, 'verbose': False, 'prof_all': True, 'debug': False}}updated\n",
      "  dynamic_loss_scale .............. True........................updated\n",
      "  eval_interval ................... 30..........................updated\n",
      "  eval_iters ...................... 2...........................updated\n",
      "  fp16 ............................ {'fp16': True, 'enabled': True, 'loss_scale': 0, 'loss_scale_window': 1000, 'initial_scale_power': 12, 'hysteresis': 2, 'min_loss_scale': 1}updated\n",
      "  global_num_gpus ................. 1...........................updated\n",
      "  hidden_size ..................... 256.........................updated\n",
      "  init_method ..................... small_init..................updated\n",
      "  load ............................ checkpoints.................updated\n",
      "  log_dir ......................... logs_gen....................updated\n",
      "  log_interval .................... 10..........................updated\n",
      "  lr .............................. 0.001.......................updated\n",
      "  lr_decay_iters .................. 800.........................updated\n",
      "  max_position_embeddings ......... 512.........................updated\n",
      "  maximum_tokens .................. 102.........................updated\n",
      "  min_lr .......................... 0.0001......................updated\n",
      "  num_attention_heads ............. 4...........................updated\n",
      "  num_layers ...................... 4...........................updated\n",
      "  num_samples ..................... 10..........................updated\n",
      "  num_workers ..................... 1...........................updated\n",
      "  optimizer ....................... {'type': 'Adam', 'params': {'lr': 0.001, 'betas': [0.9, 0.95], 'eps': 1e-08}}updated\n",
      "  optimizer_type .................. Adam........................updated\n",
      "  output_layer_init_method ........ wang_init...................updated\n",
      "  partition_activations ........... True........................updated\n",
      "  pos_emb ......................... rotary......................updated\n",
      "  precision ....................... fp16........................updated\n",
      "  sample_input_file ............... sample_input.txt............updated\n",
      "  sample_output_file .............. sample_output.txt...........updated\n",
      "  save ............................ checkpoints.................updated\n",
      "  seq_length ...................... 512.........................updated\n",
      "  sparsity_config ................. {}..........................updated\n",
      "  synchronize_each_layer .......... True........................updated\n",
      "  temperature ..................... 1.0.........................updated\n",
      "  tensorboard_dir ................. tensorboard_gen.............updated\n",
      "  text_gen_type ................... unconditional...............updated\n",
      "  tokenizer_type .................. CharLevelTokenizer..........updated\n",
      "  train_batch_size ................ 8...........................updated\n",
      "  train_iters ..................... 800.........................updated\n",
      "  train_micro_batch_size_per_gpu .. 8...........................updated\n",
      "  user_script ..................... generate.py.................updated\n",
      "  wall_clock_breakdown ............ True........................updated\n",
      "  zero_allgather_bucket_size ...... 500000000...................updated\n",
      "  zero_contiguous_gradients ....... True........................updated\n",
      "  zero_optimization ............... {'stage': 1, 'allgather_partitions': True, 'allgather_bucket_size': 500000000, 'overlap_comm': True, 'reduce_scatter': True, 'reduce_bucket_size': 500000000, 'contiguous_gradients': True}updated\n",
      "  zero_reduce_bucket_size ......... 500000000...................updated\n",
      "  zero_reduce_scatter ............. True........................updated\n",
      "  zero_stage ...................... 1...........................updated\n",
      "  account ......................... None........................default\n",
      "  activation ...................... gelu........................default\n",
      "  activation_checkpointing ........ None........................default\n",
      "  adlr_autoresume ................. False.......................default\n",
      "  adlr_autoresume_interval ........ 1000........................default\n",
      "  allow_chopped ................... True........................default\n",
      "  amp ............................. None........................default\n",
      "  apply_query_key_layer_scaling ... False.......................default\n",
      "  attention_dropout ............... 0...........................default\n",
      "  attention_softmax_in_fp32 ....... False.......................default\n",
      "  autotuning ...................... None........................default\n",
      "  autotuning_run .................. None........................default\n",
      "  base_shapes_file ................ None........................default\n",
      "  bf16 ............................ None........................default\n",
      "  bias_dropout_fusion ............. False.......................default\n",
      "  bias_gelu_fusion ................ False.......................default\n",
      "  char_level_ppl .................. False.......................default\n",
      "  checkpoint ...................... None........................default\n",
      "  checkpoint_activations .......... False.......................default\n",
      "  checkpoint_in_cpu ............... False.......................default\n",
      "  checkpoint_num_layers ........... 1...........................default\n",
      "  checkpoint_scale ................ linear......................default\n",
      "  checkpoint_validation_with_forward_pass  False................default\n",
      "  clip_grad ....................... 1.0.........................default\n",
      "  comet_experiment ................ None........................default\n",
      "  comet_experiment_name ........... None........................default\n",
      "  comet_others .................... None........................default\n",
      "  comet_project ................... None........................default\n",
      "  comet_tags ...................... None........................default\n",
      "  comet_workspace ................. None........................default\n",
      "  comment ......................... None........................default\n",
      "  comms_logger .................... None........................default\n",
      "  communication_data_type ......... None........................default\n",
      "  compression_training ............ None........................default\n",
      "  contiguous_checkpointing ........ False.......................default\n",
      "  coord_check ..................... False.......................default\n",
      "  create_moe_param_group .......... True........................default\n",
      "  csv_monitor ..................... None........................default\n",
      "  curriculum_learning ............. None........................default\n",
      "  curriculum_seqlen ............... 0...........................default\n",
      "  data_efficiency ................. None........................default\n",
      "  data_types ...................... None........................default\n",
      "  dataset_impl .................... gpt2........................default\n",
      "  deepscale ....................... False.......................default\n",
      "  deepscale_config ................ None........................default\n",
      "  deepspeed ....................... True........................default\n",
      "  deepspeed_activation_checkpointing  True......................default\n",
      "  deepspeed_mpi ................... False.......................default\n",
      "  deepspeed_slurm ................. False.......................default\n",
      "  detect_nvlink_pairs ............. False.......................default\n",
      "  dim_att ......................... None........................default\n",
      "  distributed_backend ............. nccl........................default\n",
      "  do_test ......................... None........................default\n",
      "  do_train ........................ None........................default\n",
      "  do_valid ........................ None........................default\n",
      "  dpo_beta ........................ 0.1.........................default\n",
      "  dpo_fp32 ........................ True........................default\n",
      "  dpo_reference_free .............. False.......................default\n",
      "  dump_state ...................... False.......................default\n",
      "  elasticity ...................... None........................default\n",
      "  enable_expert_tensor_parallelism  False.......................default\n",
      "  eod_mask_loss ................... False.......................default\n",
      "  eval_results_prefix ............. ............................default\n",
      "  eval_tasks ...................... None........................default\n",
      "  exclude ......................... None........................default\n",
      "  exit_interval ................... None........................default\n",
      "  expansion_factor ................ None........................default\n",
      "  expert_interval ................. 2...........................default\n",
      "  extra_save_iters ................ None........................default\n",
      "  ffn_dim ......................... None........................default\n",
      "  finetune ........................ False.......................default\n",
      "  flops_profiler .................. None........................default\n",
      "  force_multi ..................... False.......................default\n",
      "  fp16_lm_cross_entropy ........... False.......................default\n",
      "  fp32_allreduce .................. False.......................default\n",
      "  git_hash ........................ 73865bc.....................default\n",
      "  gmlp_attn_dim ................... 64..........................default\n",
      "  gpt_j_residual .................. False.......................default\n",
      "  gpt_j_tied ...................... False.......................default\n",
      "  gradient_accumulation_steps ..... 1...........................default\n",
      "  gradient_clipping ............... 1.0.........................default\n",
      "  gradient_noise_scale_cpu_offload  False.......................default\n",
      "  gradient_noise_scale_n_batches .. 5...........................default\n",
      "  gradient_predivide_factor ....... 1.0.........................default\n",
      "  head_size ....................... None........................default\n",
      "  hidden_dropout .................. 0...........................default\n",
      "  hostfile ........................ None........................default\n",
      "  hysteresis ...................... 2...........................default\n",
      "  include ......................... None........................default\n",
      "  init_method_std ................. 0.02........................default\n",
      "  intermediate_size ............... None........................default\n",
      "  is_pipe_parallel ................ False.......................default\n",
      "  iteration ....................... None........................default\n",
      "  keep_last_n_checkpoints ......... None........................default\n",
      "  kto_beta ........................ 0.1.........................default\n",
      "  kto_desirable_weight ............ 1.0.........................default\n",
      "  kto_fp32 ........................ True........................default\n",
      "  kto_undesirable_weight .......... 1.0.........................default\n",
      "  launcher ........................ pdsh........................default\n",
      "  layernorm_epsilon ............... 1e-05.......................default\n",
      "  layernorm_fusion ................ False.......................default\n",
      "  lazy_mpu_init ................... False.......................default\n",
      "  local_rank ...................... None........................default\n",
      "  log_grad_norm ................... False.......................default\n",
      "  log_grad_pct_zeros .............. False.......................default\n",
      "  log_gradient_noise_scale ........ False.......................default\n",
      "  log_optimizer_states ............ False.......................default\n",
      "  log_param_norm .................. False.......................default\n",
      "  loss_scale ...................... None........................default\n",
      "  loss_scale_window ............... 1000.0......................default\n",
      "  lr_decay_fraction ............... None........................default\n",
      "  lr_decay_style .................. linear......................default\n",
      "  make_vocab_size_divisible_by .... 128.........................default\n",
      "  mamba_causal_conv_fusion ........ False.......................default\n",
      "  mamba_inner_func_fusion ......... False.......................default\n",
      "  mamba_selective_fp32_params ..... True........................default\n",
      "  mamba_selective_scan_fusion ..... False.......................default\n",
      "  mamba_use_bias_in_conv .......... True........................default\n",
      "  mamba_use_bias_in_linears ....... False.......................default\n",
      "  master_addr ..................... None........................default\n",
      "  master_port ..................... 29500.......................default\n",
      "  memory_profiling ................ False.......................default\n",
      "  memory_profiling_path ........... None........................default\n",
      "  merge_file ...................... None........................default\n",
      "  min_scale ....................... 1.0.........................default\n",
      "  mlp_multiple_of ................. 1...........................default\n",
      "  mmap_warmup ..................... False.......................default\n",
      "  model_parallel_size ............. 1...........................default\n",
      "  moe_eval_capacity_factor ........ 1.0.........................default\n",
      "  moe_expert_parallel_size ........ 1...........................default\n",
      "  moe_glu ......................... False.......................default\n",
      "  moe_jitter_eps .................. None........................default\n",
      "  moe_lbl_in_fp32 ................. False.......................default\n",
      "  moe_loss_coeff .................. 0.1.........................default\n",
      "  moe_min_capacity ................ 4...........................default\n",
      "  moe_num_experts ................. 1...........................default\n",
      "  moe_token_dropping .............. False.......................default\n",
      "  moe_top_k ....................... 1...........................default\n",
      "  moe_train_capacity_factor ....... 1.0.........................default\n",
      "  moe_type ........................ megablocks..................default\n",
      "  moe_use_residual ................ True........................default\n",
      "  mup_attn_temp ................... 1.0.........................default\n",
      "  mup_embedding_mult .............. 1.0.........................default\n",
      "  mup_init_scale .................. 1.0.........................default\n",
      "  mup_output_temp ................. 1.0.........................default\n",
      "  mup_rp_embedding_mult ........... 1.0.........................default\n",
      "  mup_width_scale ................. 2...........................default\n",
      "  neg_test_data_paths ............. None........................default\n",
      "  neg_test_label_data_paths ....... None........................default\n",
      "  neg_train_data_paths ............ None........................default\n",
      "  neg_train_label_data_paths ...... None........................default\n",
      "  neg_valid_data_paths ............ None........................default\n",
      "  neg_valid_label_data_paths ...... None........................default\n",
      "  no_load_optim ................... False.......................default\n",
      "  no_load_rng ..................... False.......................default\n",
      "  no_save_optim ................... False.......................default\n",
      "  no_save_rng ..................... False.......................default\n",
      "  no_ssh_check .................... False.......................default\n",
      "  no_weight_tying ................. False.......................default\n",
      "  norm ............................ layernorm...................default\n",
      "  num_gpus ........................ None........................default\n",
      "  num_kv_heads .................... None........................default\n",
      "  num_nodes ....................... -1..........................default\n",
      "  num_unique_layers ............... None........................default\n",
      "  onnx_safe ....................... False.......................default\n",
      "  opt_pos_emb_offset .............. 0...........................default\n",
      "  output_layer_parallelism ........ column......................default\n",
      "  override_lr_scheduler ........... False.......................default\n",
      "  pack_impl ....................... packed......................default\n",
      "  padded_vocab_size ............... None........................default\n",
      "  param_sharing_style ............. grouped.....................default\n",
      "  pipe_parallel_size .............. 0...........................default\n",
      "  pipe_partition_method ........... type:transformer|mlp........default\n",
      "  pos_test_data_paths ............. None........................default\n",
      "  pos_test_label_data_paths ....... None........................default\n",
      "  pos_train_data_paths ............ None........................default\n",
      "  pos_train_label_data_paths ...... None........................default\n",
      "  pos_valid_data_paths ............ None........................default\n",
      "  pos_valid_label_data_paths ...... None........................default\n",
      "  precompute_model_name ........... None........................default\n",
      "  prescale_gradients .............. False.......................default\n",
      "  profile ......................... False.......................default\n",
      "  profile_backward ................ False.......................default\n",
      "  profile_step_start .............. 10..........................default\n",
      "  profile_step_stop ............... 12..........................default\n",
      "  prompt_end ...................... \n",
      "...........................default\n",
      "  rank ............................ None........................default\n",
      "  recompute ....................... False.......................default\n",
      "  return_logits ................... False.......................default\n",
      "  rms_norm_epsilon ................ 1e-08.......................default\n",
      "  rmsnorm_fusion .................. False.......................default\n",
      "  rope_fusion ..................... False.......................default\n",
      "  rotary_emb_base ................. 10000.......................default\n",
      "  rotary_pct ...................... 1.0.........................default\n",
      "  rotary_save_freqs_buffer ........ False.......................default\n",
      "  rpe_max_distance ................ 128.........................default\n",
      "  rpe_num_buckets ................. 32..........................default\n",
      "  s3_chunk_size ................... 104857600...................default\n",
      "  s3_path ......................... None........................default\n",
      "  save_base_shapes ................ False.......................default\n",
      "  scaled_masked_softmax_fusion .... False.......................default\n",
      "  scaled_upper_triang_masked_softmax_fusion  False..............default\n",
      "  scalenorm_epsilon ............... 1e-08.......................default\n",
      "  scheduler ....................... None........................default\n",
      "  seed ............................ 1234........................default\n",
      "  sequence_parallel ............... False.......................default\n",
      "  short_seq_prob .................. 0.1.........................default\n",
      "  sliding_window_width ............ None........................default\n",
      "  soft_prompt_tuning .............. None........................default\n",
      "  sparse_attention ................ None........................default\n",
      "  sparse_gradients ................ False.......................default\n",
      "  split ........................... 969, 30, 1..................default\n",
      "  steps_per_print ................. 10..........................default\n",
      "  tensorboard ..................... None........................default\n",
      "  test_data_paths ................. None........................default\n",
      "  test_data_weights ............... None........................default\n",
      "  test_label_data_paths ........... None........................default\n",
      "  test_reward_data_paths .......... None........................default\n",
      "  top_k ........................... 0...........................default\n",
      "  top_p ........................... 0.0.........................default\n",
      "  train_data_paths ................ None........................default\n",
      "  train_data_weights .............. None........................default\n",
      "  train_epochs .................... None........................default\n",
      "  train_impl ...................... normal......................default\n",
      "  train_label_data_paths .......... None........................default\n",
      "  train_reward_data_paths ......... None........................default\n",
      "  use_bias_in_attn_linear ......... True........................default\n",
      "  use_bias_in_mlp ................. True........................default\n",
      "  use_bias_in_norms ............... True........................default\n",
      "  use_bnb_optimizer ............... False.......................default\n",
      "  use_checkpoint_lr_scheduler ..... False.......................default\n",
      "  use_comet ....................... None........................default\n",
      "  use_cpu_initialization .......... False.......................default\n",
      "  use_flashattn_swiglu ............ False.......................default\n",
      "  use_mup ......................... False.......................default\n",
      "  use_qk_layernorm ................ False.......................default\n",
      "  use_shared_fs ................... True........................default\n",
      "  use_tutel ....................... False.......................default\n",
      "  use_wandb ....................... None........................default\n",
      "  valid_data_paths ................ None........................default\n",
      "  valid_data_weights .............. None........................default\n",
      "  valid_label_data_paths .......... None........................default\n",
      "  valid_reward_data_paths ......... None........................default\n",
      "  vocab_file ...................... None........................default\n",
      "  wandb ........................... None........................default\n",
      "  wandb_group ..................... None........................default\n",
      "  wandb_host ...................... https://api.wandb.ai........default\n",
      "  wandb_init_all_ranks ............ False.......................default\n",
      "  wandb_project ................... neox........................default\n",
      "  wandb_team ...................... None........................default\n",
      "  warmup .......................... 0.01........................default\n",
      "  weight_by_num_documents ......... False.......................default\n",
      "  weight_decay .................... 0.1.........................default\n",
      "  weighted_sampler_alpha .......... 1.0.........................default\n",
      "  world_size ...................... None........................default\n",
      "  z_loss .......................... 0.0.........................default\n",
      "---------------- end of arguments ----------------\n",
      "NeoXArgs.configure_distributed_args() using world size: 1 and model-parallel size: 1 \n",
      "[2024-12-01 08:07:39,826] [WARNING] [runner.py:217:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
      "[2024-12-01 08:07:39,826] [INFO] [runner.py:586:main] cmd = /content/GPT-NeoX-Colab/.venv/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None generate.py --deepspeed_config eyJ0cmFpbl9iYXRjaF9zaXplIjogOCwgInRyYWluX21pY3JvX2JhdGNoX3NpemVfcGVyX2dwdSI6IDgsICJvcHRpbWl6ZXIiOiB7InR5cGUiOiAiQWRhbSIsICJwYXJhbXMiOiB7ImxyIjogMC4wMDEsICJiZXRhcyI6IFswLjksIDAuOTVdLCAiZXBzIjogMWUtMDh9fSwgImZwMTYiOiB7ImZwMTYiOiB0cnVlLCAiZW5hYmxlZCI6IHRydWUsICJsb3NzX3NjYWxlIjogMCwgImxvc3Nfc2NhbGVfd2luZG93IjogMTAwMCwgImluaXRpYWxfc2NhbGVfcG93ZXIiOiAxMiwgImh5c3RlcmVzaXMiOiAyLCAibWluX2xvc3Nfc2NhbGUiOiAxfSwgInplcm9fb3B0aW1pemF0aW9uIjogeyJzdGFnZSI6IDEsICJhbGxnYXRoZXJfcGFydGl0aW9ucyI6IHRydWUsICJhbGxnYXRoZXJfYnVja2V0X3NpemUiOiA1MDAwMDAwMDAsICJvdmVybGFwX2NvbW0iOiB0cnVlLCAicmVkdWNlX3NjYXR0ZXIiOiB0cnVlLCAicmVkdWNlX2J1Y2tldF9zaXplIjogNTAwMDAwMDAwLCAiY29udGlndW91c19ncmFkaWVudHMiOiB0cnVlfSwgIndhbGxfY2xvY2tfYnJlYWtkb3duIjogdHJ1ZSwgImNvbW1zX2xvZ2dlciI6IHsiZW5hYmxlZCI6IHRydWUsICJ2ZXJib3NlIjogZmFsc2UsICJwcm9mX2FsbCI6IHRydWUsICJkZWJ1ZyI6IGZhbHNlfX0= --megatron_config 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\n",
      "[2024-12-01 08:07:40,853] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-12-01 08:07:42,226] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0]}\n",
      "[2024-12-01 08:07:42,226] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0\n",
      "[2024-12-01 08:07:42,226] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
      "[2024-12-01 08:07:42,226] [INFO] [launch.py:163:main] dist_world_size=1\n",
      "[2024-12-01 08:07:42,226] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0\n",
      "/content/gpt-neox/megatron/neox_arguments/arguments.py:1101: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert (\n",
      "/content/gpt-neox/megatron/neox_arguments/arguments.py:1110: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert (\n",
      "[2024-12-01 08:07:43,289] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba\n",
      "For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer\n",
      "NeoXArgs.configure_distributed_args() using world size: 1 and model-parallel size: 1 \n",
      "> building CharLevelTokenizer tokenizer ...\n",
      " > padded vocab (size: 512) with 0 dummy tokens (new size: 512)\n",
      "> initializing torch distributed ...\n",
      "[2024-12-01 08:07:45,083] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-12-01 08:07:45,083] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "> initializing model parallel with size 1\n",
      "MPU DP: [0]\n",
      "MPU PP: [0]\n",
      "MPU MP: [0]\n",
      "> setting random seeds to 1234 ...\n",
      "[2024-12-01 08:07:45,088] [INFO] [checkpointing.py:227:model_parallel_cuda_manual_seed] > initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234\n",
      "make: Entering directory '/content/gpt-neox/megatron/data'\n",
      "make: Nothing to be done for 'default'.\n",
      "make: Leaving directory '/content/gpt-neox/megatron/data'\n",
      "building GPT2 model ...\n",
      "SEED_LAYERS=False BASE_SEED=1234 SEED_FN=None\n",
      "Using topology: {ProcessCoord(pipe=0, data=0, model=0): 0}\n",
      "[2024-12-01 08:07:45,118] [INFO] [module.py:375:_partition_layers] Partitioning pipeline stages with method type:transformer|mlp\n",
      "stage=0 layers=9\n",
      "     0: EmbeddingPipe\n",
      "     1: _pre_transformer_block\n",
      "     2: ParallelTransformerLayerPipe\n",
      "     3: ParallelTransformerLayerPipe\n",
      "     4: ParallelTransformerLayerPipe\n",
      "     5: ParallelTransformerLayerPipe\n",
      "     6: _post_transformer_block\n",
      "     7: NormPipe\n",
      "     8: EmbeddingPipe\n",
      "  loss: partial\n",
      "Configuring Optimizer type: adam with params: {'lr': 0.0}\n",
      "WARNING: APEX not installed - defaulting to deepspeed's fused adam\n",
      "Using /home/vscode/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/vscode/.cache/torch_extensions/py310_cu121/fused_adam/build.ninja...\n",
      "/content/GPT-NeoX-Colab/.venv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Building extension module fused_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.02935504913330078 seconds\n",
      "/content/GPT-NeoX-Colab/.venv/lib/python3.10/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "> learning rate decay style: linear\n",
      "DeepSpeed is enabled.\n",
      "[2024-12-01 08:07:45,960] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.12.4+02e2ebf, git-hash=02e2ebf, git-branch=HEAD\n",
      "[2024-12-01 08:07:46,091] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-12-01 08:07:46,092] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-12-01 08:07:46,092] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-12-01 08:07:46,092] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam\n",
      "[2024-12-01 08:07:46,092] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>\n",
      "[2024-12-01 08:07:46,092] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 1 optimizer\n",
      "[2024-12-01 08:07:46,092] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 500000000\n",
      "[2024-12-01 08:07:46,092] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 500000000\n",
      "[2024-12-01 08:07:46,092] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-12-01 08:07:46,092] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-12-01 08:07:46,216] [INFO] [utils.py:802:see_memory_usage] Before initializing optimizer states\n",
      "[2024-12-01 08:07:46,216] [INFO] [utils.py:803:see_memory_usage] MA 0.01 GB         Max_MA 0.01 GB         CA 0.01 GB         Max_CA 0 GB \n",
      "[2024-12-01 08:07:46,216] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 8.24 GB, percent = 26.5%\n",
      "[2024-12-01 08:07:46,339] [INFO] [utils.py:802:see_memory_usage] After initializing optimizer states\n",
      "[2024-12-01 08:07:46,340] [INFO] [utils.py:803:see_memory_usage] MA 0.01 GB         Max_MA 0.01 GB         CA 0.02 GB         Max_CA 0 GB \n",
      "[2024-12-01 08:07:46,340] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 8.23 GB, percent = 26.5%\n",
      "[2024-12-01 08:07:46,340] [INFO] [stage_1_and_2.py:517:__init__] optimizer state initialized\n",
      "[2024-12-01 08:07:46,458] [INFO] [utils.py:802:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-12-01 08:07:46,459] [INFO] [utils.py:803:see_memory_usage] MA 0.01 GB         Max_MA 0.01 GB         CA 0.02 GB         Max_CA 0 GB \n",
      "[2024-12-01 08:07:46,459] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 8.23 GB, percent = 26.5%\n",
      "[2024-12-01 08:07:46,459] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam\n",
      "[2024-12-01 08:07:46,459] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-12-01 08:07:46,459] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <megatron.learning_rates.AnnealingLR object at 0x7437061483d0>\n",
      "[2024-12-01 08:07:46,459] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0], mom=[(0.9, 0.999)]\n",
      "[2024-12-01 08:07:46,459] [INFO] [config.py:979:print] DeepSpeedEngine configuration:\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   amp_enabled .................. False\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   amp_params ................... False\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   bfloat16_enabled ............. False\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x74370dab2920>\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   communication_data_type ...... None\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   curriculum_enabled_legacy .... False\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   curriculum_params_legacy ..... False\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   data_efficiency_enabled ...... False\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   dataloader_drop_last ......... False\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   disable_allgather ............ False\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   dump_state ................... False\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   dynamic_loss_scale_args ...... {'init_scale': 4096, 'scale_window': 1000, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   eigenvalue_enabled ........... False\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   eigenvalue_verbose ........... False\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   elasticity_enabled ........... False\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   fp16_auto_cast ............... False\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   fp16_enabled ................. True\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   global_rank .................. 0\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   grad_accum_dtype ............. None\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   gradient_accumulation_steps .. 1\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   gradient_clipping ............ 0.0\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   initial_dynamic_scale ........ 4096\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   load_universal_checkpoint .... False\n",
      "[2024-12-01 08:07:46,460] [INFO] [config.py:983:print]   loss_scale ................... 0\n",
      "[2024-12-01 08:07:46,461] [INFO] [config.py:983:print]   memory_breakdown ............. False\n",
      "[2024-12-01 08:07:46,461] [INFO] [config.py:983:print]   mics_hierarchial_params_gather  False\n",
      "[2024-12-01 08:07:46,461] [INFO] [config.py:983:print]   mics_shard_size .............. -1\n",
      "[2024-12-01 08:07:46,461] [INFO] [config.py:983:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-12-01 08:07:46,461] [INFO] [config.py:983:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-12-01 08:07:46,461] [INFO] [config.py:983:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-12-01 08:07:46,461] [INFO] [config.py:983:print]   optimizer_name ............... None\n",
      "[2024-12-01 08:07:46,461] [INFO] [config.py:983:print]   optimizer_params ............. None\n",
      "[2024-12-01 08:07:46,461] [INFO] [config.py:983:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-12-01 08:07:46,461] [INFO] [config.py:983:print]   pld_enabled .................. False\n",
      "[2024-12-01 08:07:46,461] [INFO] [config.py:983:print]   pld_params ................... False\n",
      "[2024-12-01 08:07:46,461] [INFO] [config.py:983:print]   prescale_gradients ........... False\n",
      "[2024-12-01 08:07:46,461] [INFO] [config.py:983:print]   scheduler_name ............... None\n",
      "[2024-12-01 08:07:46,461] [INFO] [config.py:983:print]   scheduler_params ............. None\n",
      "[2024-12-01 08:07:46,461] [INFO] [config.py:983:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-12-01 08:07:46,461] [INFO] [config.py:983:print]   sparse_attention ............. None\n",
      "[2024-12-01 08:07:46,461] [INFO] [config.py:983:print]   sparse_gradients_enabled ..... False\n",
      "[2024-12-01 08:07:46,461] [INFO] [config.py:983:print]   steps_per_print .............. 10\n",
      "[2024-12-01 08:07:46,461] [INFO] [config.py:983:print]   train_batch_size ............. 8\n",
      "[2024-12-01 08:07:46,461] [INFO] [config.py:983:print]   train_micro_batch_size_per_gpu  8\n",
      "[2024-12-01 08:07:46,461] [INFO] [config.py:983:print]   use_data_before_expert_parallel_  False\n",
      "[2024-12-01 08:07:46,461] [INFO] [config.py:983:print]   use_node_local_storage ....... False\n",
      "[2024-12-01 08:07:46,461] [INFO] [config.py:983:print]   wall_clock_breakdown ......... True\n",
      "[2024-12-01 08:07:46,461] [INFO] [config.py:983:print]   weight_quantization_config ... None\n",
      "[2024-12-01 08:07:46,461] [INFO] [config.py:983:print]   world_size ................... 1\n",
      "[2024-12-01 08:07:46,461] [INFO] [config.py:983:print]   zero_allow_untested_optimizer  False\n",
      "[2024-12-01 08:07:46,461] [INFO] [config.py:983:print]   zero_config .................. stage=1 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-12-01 08:07:46,461] [INFO] [config.py:983:print]   zero_enabled ................. True\n",
      "[2024-12-01 08:07:46,461] [INFO] [config.py:983:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-12-01 08:07:46,461] [INFO] [config.py:983:print]   zero_optimization_stage ...... 1\n",
      "[2024-12-01 08:07:46,461] [INFO] [config.py:969:print_user_config]   json = {\n",
      "    \"train_batch_size\": 8, \n",
      "    \"train_micro_batch_size_per_gpu\": 8, \n",
      "    \"optimizer\": {\n",
      "        \"params\": {\n",
      "            \"lr\": 0.0\n",
      "        }\n",
      "    }, \n",
      "    \"fp16\": {\n",
      "        \"fp16\": true, \n",
      "        \"enabled\": true, \n",
      "        \"loss_scale\": 0, \n",
      "        \"loss_scale_window\": 1000, \n",
      "        \"initial_scale_power\": 12, \n",
      "        \"hysteresis\": 2, \n",
      "        \"min_loss_scale\": 1\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 1, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 5.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 5.000000e+08, \n",
      "        \"contiguous_gradients\": true\n",
      "    }, \n",
      "    \"wall_clock_breakdown\": true, \n",
      "    \"comms_logger\": {\n",
      "        \"enabled\": true, \n",
      "        \"verbose\": false, \n",
      "        \"prof_all\": true, \n",
      "        \"debug\": false\n",
      "    }\n",
      "}\n",
      " > number of parameters on model parallel rank 0: 3290624\n",
      " > total params: 3,290,624\n",
      "[2024-12-01 08:07:46,499] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from checkpoints/global_step800/mp_rank_00_model_states.pt...\n",
      "[2024-12-01 08:07:46,504] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from checkpoints/global_step800/mp_rank_00_model_states.pt.\n",
      "[2024-12-01 08:07:46,504] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from checkpoints/global_step800/mp_rank_00_model_states.pt...\n",
      "[2024-12-01 08:07:46,509] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from checkpoints/global_step800/mp_rank_00_model_states.pt.\n",
      " > validated currently set args with arguments in the checkpoint ...\n",
      "  successfully loaded checkpoints/global_step800/mp_rank_00_model_states.pt\n",
      "Loading checkpoint and starting from iteration 800\n",
      "Finished loading model\n",
      "Generating samples unconditionally and saving results to sample_output.txt\n",
      "generate_samples_unconditional() generating...\n",
      "generate_samples_unconditional() done\n",
      "[2024-12-01 08:07:50,234] [INFO] [launch.py:347:main] Process 77968 exits successfully.\n",
      "{\"context\": \"\", \"text\": \"HEBIONO:\", \"length\": 8, \"finished\": true, \"message\": null, \"duration_seconds\": 0.4449276924133301}\n",
      "{\"context\": \"\", \"text\": \"Thirdly by loes: brief, you haste caple-short:\", \"length\": 46, \"finished\": true, \"message\": null, \"duration_seconds\": 0.17642927169799805}\n",
      "{\"context\": \"\", \"text\": \"Sets all forth thee, distressive death; and you:\", \"length\": 48, \"finished\": true, \"message\": null, \"duration_seconds\": 0.1887218952178955}\n",
      "{\"context\": \"\", \"text\": \"DUKE VINCENTIO:\", \"length\": 15, \"finished\": true, \"message\": null, \"duration_seconds\": 0.059146881103515625}\n",
      "{\"context\": \"\", \"text\": \"Be lues? and die, friends purpose when hone\", \"length\": 43, \"finished\": true, \"message\": null, \"duration_seconds\": 0.16297364234924316}\n",
      "{\"context\": \"\", \"text\": \"Your hands the row small well?\", \"length\": 30, \"finished\": true, \"message\": null, \"duration_seconds\": 0.1116030216217041}\n",
      "{\"context\": \"\", \"text\": \"whictlem, in night one?\", \"length\": 23, \"finished\": true, \"message\": null, \"duration_seconds\": 0.09055852890014648}\n",
      "{\"context\": \"\", \"text\": \"Ramerly, because, I can lang no little Roler.\", \"length\": 45, \"finished\": true, \"message\": null, \"duration_seconds\": 0.1740272045135498}\n",
      "{\"context\": \"\", \"text\": \"Good for ser! nay, I shall I stay be wast's ride.\", \"length\": 49, \"finished\": true, \"message\": null, \"duration_seconds\": 0.1929950714111328}\n",
      "{\"context\": \"\", \"text\": \"Lyband well your neight her lears a consey.\", \"length\": 43, \"finished\": true, \"message\": null, \"duration_seconds\": 0.1609330177307129}\n",
      "CPU times: user 278 ms, sys: 63.9 ms, total: 342 ms\n",
      "Wall time: 15.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%cd {GPTNeoXDir}\n",
    "# This has issues if used during training -  The server socket has failed to bind to [::]:29500 (errno: 98 - Address already\n",
    "# This will write over the logs\n",
    "!source {activate_script} && python ./deepy.py generate.py -d configs {gpt_neox_colabDir}/configs/shakespeare {gpt_neox_colabDir}/configs/shakespeare_gen\n",
    "!cat sample_output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ajLR98lDi9_8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets==2.14.6\n",
      "  Downloading datasets-2.14.6-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /workspace/.venv/lib/python3.10/site-packages (from datasets==2.14.6) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /workspace/.venv/lib/python3.10/site-packages (from datasets==2.14.6) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /workspace/.venv/lib/python3.10/site-packages (from datasets==2.14.6) (0.3.7)\n",
      "Requirement already satisfied: pandas in /workspace/.venv/lib/python3.10/site-packages (from datasets==2.14.6) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /workspace/.venv/lib/python3.10/site-packages (from datasets==2.14.6) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /workspace/.venv/lib/python3.10/site-packages (from datasets==2.14.6) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /workspace/.venv/lib/python3.10/site-packages (from datasets==2.14.6) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /workspace/.venv/lib/python3.10/site-packages (from datasets==2.14.6) (0.70.15)\n",
      "Collecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.14.6)\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: aiohttp in /workspace/.venv/lib/python3.10/site-packages (from datasets==2.14.6) (3.11.8)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /workspace/.venv/lib/python3.10/site-packages (from datasets==2.14.6) (0.26.3)\n",
      "Requirement already satisfied: packaging in /workspace/.venv/lib/python3.10/site-packages (from datasets==2.14.6) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /workspace/.venv/lib/python3.10/site-packages (from datasets==2.14.6) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /workspace/.venv/lib/python3.10/site-packages (from aiohttp->datasets==2.14.6) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /workspace/.venv/lib/python3.10/site-packages (from aiohttp->datasets==2.14.6) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /workspace/.venv/lib/python3.10/site-packages (from aiohttp->datasets==2.14.6) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /workspace/.venv/lib/python3.10/site-packages (from aiohttp->datasets==2.14.6) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /workspace/.venv/lib/python3.10/site-packages (from aiohttp->datasets==2.14.6) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /workspace/.venv/lib/python3.10/site-packages (from aiohttp->datasets==2.14.6) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /workspace/.venv/lib/python3.10/site-packages (from aiohttp->datasets==2.14.6) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /workspace/.venv/lib/python3.10/site-packages (from aiohttp->datasets==2.14.6) (1.18.0)\n",
      "Requirement already satisfied: filelock in /workspace/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.6) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /workspace/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.6) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /workspace/.venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.14.6) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspace/.venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.14.6) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspace/.venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.14.6) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /workspace/.venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.14.6) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /workspace/.venv/lib/python3.10/site-packages (from pandas->datasets==2.14.6) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /workspace/.venv/lib/python3.10/site-packages (from pandas->datasets==2.14.6) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /workspace/.venv/lib/python3.10/site-packages (from pandas->datasets==2.14.6) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /workspace/.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.14.6) (1.16.0)\n",
      "Downloading datasets-2.14.6-py3-none-any.whl (493 kB)\n",
      "Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "Installing collected packages: fsspec, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.10.0\n",
      "    Uninstalling fsspec-2024.10.0:\n",
      "      Successfully uninstalled fsspec-2024.10.0\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.14.0\n",
      "    Uninstalling datasets-2.14.0:\n",
      "      Successfully uninstalled datasets-2.14.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "s3fs 2024.2.0 requires fsspec==2024.2.0, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-2.14.6 fsspec-2023.10.0\n"
     ]
    }
   ],
   "source": [
    "# 2.21.0 was the last 2 series but it asks for trust_remote_code\n",
    "!source {activate_script} &&  pip install datasets==2.14.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9S-foNPFjfwH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gpt-neox\n",
      "[2024-12-01 08:07:55,740] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "/content/gpt-neox/megatron/neox_arguments/arguments.py:1101: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert (\n",
      "/content/gpt-neox/megatron/neox_arguments/arguments.py:1110: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert (\n",
      "NeoXArgs.from_ymls() ['/content/GPT-NeoX-Colab/configs/shakespeare.yml', '/content/GPT-NeoX-Colab/configs/shakespeare_gen.yml']\n",
      "INFO:root:NeoXArgs.calculate_derived() Total number of GPUs determined to be: 1\n",
      "-------------------- arguments --------------------\n",
      "  attention_config ................ ['global', 'global', 'global', 'global']updated\n",
      "  batch_size ...................... 8...........................updated\n",
      "  checkpoint_factor ............... 50..........................updated\n",
      "  config_files .................... {'shakespeare.yml': '{\\n  \"pipe_parallel_size\": 0, # Because running on one GPU\\n  \"model_parallel_size\": 1, # Because running on one GPU\\n\\n  # model settings\\n  \"num_layers\": 4,\\n  \"hidden_size\": 256,\\n  \"num_attention_heads\": 4,\\n  \"seq_length\": 512,\\n  \"max_position_embeddings\": 512,\\n  \"pos_emb\": \"rotary\",\\n  \"no_weight_tying\": false, # Sharing embedding and output weights\\n  \"gpt_j_residual\": false,\\n  \"output_layer_parallelism\": \"column\",\\n\\n  \"scaled_upper_triang_masked_softmax_fusion\": false,\\n  \"bias_gelu_fusion\": false,\\n  \"rope_fusion\": false,\\n  \"layernorm_fusion\": false,\\n\\n  # init methods\\n  \"init_method\": \"small_init\",\\n  \"output_layer_init_method\": \"wang_init\",\\n\\n  \"optimizer\": {\\n    \"type\": \"Adam\",\\n    \"params\": {\\n      \"lr\": 0.001,\\n      \"betas\": [0.9, 0.95],\\n      \"eps\": 1.0e-8\\n    }\\n  },\\n  \"min_lr\": 0.0001,\\n\\n  \"zero_optimization\": {\\n    \"stage\": 1,\\n    \"allgather_partitions\": true,\\n    \"allgather_bucket_size\": 500000000,\\n    \"overlap_comm\": true,\\n    \"reduce_scatter\": true,\\n    \"reduce_bucket_size\": 500000000,\\n    \"contiguous_gradients\": true\\n  },\\n\\n  \"train_micro_batch_size_per_gpu\": 8, #256, # 8, #8 for 4GB #256 for 16GB\\n  \"gradient_accumulation_steps\": 1,\\n  \"data_impl\": \"mmap\",\\n  \"num_workers\": 1,\\n\\n  # activation checkpointing\\n  \"checkpoint_activations\": false, # We are not memory bound\\n  \"checkpoint_num_layers\": 1,\\n  \"partition_activations\": true,\\n  \"synchronize_each_layer\": true,\\n\\n  # regularization\\n  \"gradient_clipping\": 1.0,\\n  \"weight_decay\": 0.1,\\n  \"hidden_dropout\": 0,\\n  \"attention_dropout\": 0,\\n\\n  # precision settings\\n  \"fp16\": {\\n    \"fp16\": true,\\n    \"enabled\": true,\\n    \"loss_scale\": 0,\\n    \"loss_scale_window\": 1000,\\n    \"initial_scale_power\": 12,\\n    \"hysteresis\": 2,\\n    \"min_loss_scale\": 1\\n  },\\n\\n  \"train_iters\": 800,\\n  \"lr_decay_iters\": 800,\\n  \"distributed_backend\": \"nccl\",\\n  \"lr_decay_style\": \"linear\",\\n  \"warmup\": 0.01,\\n  \"checkpoint_factor\": 50, # Must be defined if save is set\\n  \"eval_interval\": 30,\\n  \"eval_iters\": 2,\\n\\n  \"log_interval\": 10,\\n  \"steps_per_print\": 10,\\n  \"wall_clock_breakdown\": true,\\n\\n  # Required for model conversion into HF format\\n  \"tokenizer_type\": \"CharLevelTokenizer\",\\n\\n  # additional deepspeed args not specified above\\n  \"deepspeed_extra_args\": {\\n    \"comms_logger\": {\\n      \"enabled\": true,\\n      \"verbose\": false,\\n      \"prof_all\": true,\\n      \"debug\": false\\n    }\\n  }\\n}\\n', 'shakespeare_gen.yml': '# Parameters used for text generation\\n{\\n  # Text gen type: `input-file`, `unconditional` or `interactive`\\n  \"text_gen_type\": \"unconditional\",\\n\\n  # Params for all\\n  \"maximum_tokens\": 102,\\n  \"prompt_end\": \"\\\\n\",\\n  \"temperature\": 1.0,\\n  \"top_p\": 0.0,\\n  \"top_k\": 0,\\n  \"recompute\": false,\\n\\n  # `unconditional`: samples\\n  \"num_samples\": 10,\\n\\n  # input/output file\\n  \"sample_input_file\": \"sample_input.txt\",\\n  \"sample_output_file\": \"sample_output.txt\",\\n\\n  \"data_path\": \"processed_data/shakespeare_text_document\",\\n\\n  \"save\": \"checkpoints\",\\n  \"load\": \"checkpoints\",\\n  \"checkpoint_validation_with_forward_pass\": False,\\n\\n  \"tensorboard_dir\": \"tensorboard_gen\",\\n  \"log_dir\": \"logs_gen\",\\n}'}updated\n",
      "  data_impl ....................... mmap........................updated\n",
      "  data_path ....................... processed_data/shakespeare_text_documentupdated\n",
      "  deepspeed_extra_args ............ {'comms_logger': {'enabled': True, 'verbose': False, 'prof_all': True, 'debug': False}}updated\n",
      "  dynamic_loss_scale .............. True........................updated\n",
      "  eval_interval ................... 30..........................updated\n",
      "  eval_iters ...................... 2...........................updated\n",
      "  eval_tasks ...................... ['hellaswag']...............updated\n",
      "  fp16 ............................ {'fp16': True, 'enabled': True, 'loss_scale': 0, 'loss_scale_window': 1000, 'initial_scale_power': 12, 'hysteresis': 2, 'min_loss_scale': 1}updated\n",
      "  global_num_gpus ................. 1...........................updated\n",
      "  hidden_size ..................... 256.........................updated\n",
      "  init_method ..................... small_init..................updated\n",
      "  load ............................ checkpoints.................updated\n",
      "  log_dir ......................... logs_gen....................updated\n",
      "  log_interval .................... 10..........................updated\n",
      "  lr .............................. 0.001.......................updated\n",
      "  lr_decay_iters .................. 800.........................updated\n",
      "  max_position_embeddings ......... 512.........................updated\n",
      "  maximum_tokens .................. 102.........................updated\n",
      "  min_lr .......................... 0.0001......................updated\n",
      "  num_attention_heads ............. 4...........................updated\n",
      "  num_layers ...................... 4...........................updated\n",
      "  num_samples ..................... 10..........................updated\n",
      "  num_workers ..................... 1...........................updated\n",
      "  optimizer ....................... {'type': 'Adam', 'params': {'lr': 0.001, 'betas': [0.9, 0.95], 'eps': 1e-08}}updated\n",
      "  optimizer_type .................. Adam........................updated\n",
      "  output_layer_init_method ........ wang_init...................updated\n",
      "  partition_activations ........... True........................updated\n",
      "  pos_emb ......................... rotary......................updated\n",
      "  precision ....................... fp16........................updated\n",
      "  sample_input_file ............... sample_input.txt............updated\n",
      "  sample_output_file .............. sample_output.txt...........updated\n",
      "  save ............................ checkpoints.................updated\n",
      "  seq_length ...................... 512.........................updated\n",
      "  sparsity_config ................. {}..........................updated\n",
      "  synchronize_each_layer .......... True........................updated\n",
      "  temperature ..................... 1.0.........................updated\n",
      "  tensorboard_dir ................. tensorboard_gen.............updated\n",
      "  text_gen_type ................... unconditional...............updated\n",
      "  tokenizer_type .................. CharLevelTokenizer..........updated\n",
      "  train_batch_size ................ 8...........................updated\n",
      "  train_iters ..................... 800.........................updated\n",
      "  train_micro_batch_size_per_gpu .. 8...........................updated\n",
      "  user_script ..................... eval.py.....................updated\n",
      "  wall_clock_breakdown ............ True........................updated\n",
      "  zero_allgather_bucket_size ...... 500000000...................updated\n",
      "  zero_contiguous_gradients ....... True........................updated\n",
      "  zero_optimization ............... {'stage': 1, 'allgather_partitions': True, 'allgather_bucket_size': 500000000, 'overlap_comm': True, 'reduce_scatter': True, 'reduce_bucket_size': 500000000, 'contiguous_gradients': True}updated\n",
      "  zero_reduce_bucket_size ......... 500000000...................updated\n",
      "  zero_reduce_scatter ............. True........................updated\n",
      "  zero_stage ...................... 1...........................updated\n",
      "  account ......................... None........................default\n",
      "  activation ...................... gelu........................default\n",
      "  activation_checkpointing ........ None........................default\n",
      "  adlr_autoresume ................. False.......................default\n",
      "  adlr_autoresume_interval ........ 1000........................default\n",
      "  allow_chopped ................... True........................default\n",
      "  amp ............................. None........................default\n",
      "  apply_query_key_layer_scaling ... False.......................default\n",
      "  attention_dropout ............... 0...........................default\n",
      "  attention_softmax_in_fp32 ....... False.......................default\n",
      "  autotuning ...................... None........................default\n",
      "  autotuning_run .................. None........................default\n",
      "  base_shapes_file ................ None........................default\n",
      "  bf16 ............................ None........................default\n",
      "  bias_dropout_fusion ............. False.......................default\n",
      "  bias_gelu_fusion ................ False.......................default\n",
      "  char_level_ppl .................. False.......................default\n",
      "  checkpoint ...................... None........................default\n",
      "  checkpoint_activations .......... False.......................default\n",
      "  checkpoint_in_cpu ............... False.......................default\n",
      "  checkpoint_num_layers ........... 1...........................default\n",
      "  checkpoint_scale ................ linear......................default\n",
      "  checkpoint_validation_with_forward_pass  False................default\n",
      "  clip_grad ....................... 1.0.........................default\n",
      "  comet_experiment ................ None........................default\n",
      "  comet_experiment_name ........... None........................default\n",
      "  comet_others .................... None........................default\n",
      "  comet_project ................... None........................default\n",
      "  comet_tags ...................... None........................default\n",
      "  comet_workspace ................. None........................default\n",
      "  comment ......................... None........................default\n",
      "  comms_logger .................... None........................default\n",
      "  communication_data_type ......... None........................default\n",
      "  compression_training ............ None........................default\n",
      "  contiguous_checkpointing ........ False.......................default\n",
      "  coord_check ..................... False.......................default\n",
      "  create_moe_param_group .......... True........................default\n",
      "  csv_monitor ..................... None........................default\n",
      "  curriculum_learning ............. None........................default\n",
      "  curriculum_seqlen ............... 0...........................default\n",
      "  data_efficiency ................. None........................default\n",
      "  data_types ...................... None........................default\n",
      "  dataset_impl .................... gpt2........................default\n",
      "  deepscale ....................... False.......................default\n",
      "  deepscale_config ................ None........................default\n",
      "  deepspeed ....................... True........................default\n",
      "  deepspeed_activation_checkpointing  True......................default\n",
      "  deepspeed_mpi ................... False.......................default\n",
      "  deepspeed_slurm ................. False.......................default\n",
      "  detect_nvlink_pairs ............. False.......................default\n",
      "  dim_att ......................... None........................default\n",
      "  distributed_backend ............. nccl........................default\n",
      "  do_test ......................... None........................default\n",
      "  do_train ........................ None........................default\n",
      "  do_valid ........................ None........................default\n",
      "  dpo_beta ........................ 0.1.........................default\n",
      "  dpo_fp32 ........................ True........................default\n",
      "  dpo_reference_free .............. False.......................default\n",
      "  dump_state ...................... False.......................default\n",
      "  elasticity ...................... None........................default\n",
      "  enable_expert_tensor_parallelism  False.......................default\n",
      "  eod_mask_loss ................... False.......................default\n",
      "  eval_results_prefix ............. ............................default\n",
      "  exclude ......................... None........................default\n",
      "  exit_interval ................... None........................default\n",
      "  expansion_factor ................ None........................default\n",
      "  expert_interval ................. 2...........................default\n",
      "  extra_save_iters ................ None........................default\n",
      "  ffn_dim ......................... None........................default\n",
      "  finetune ........................ False.......................default\n",
      "  flops_profiler .................. None........................default\n",
      "  force_multi ..................... False.......................default\n",
      "  fp16_lm_cross_entropy ........... False.......................default\n",
      "  fp32_allreduce .................. False.......................default\n",
      "  git_hash ........................ 73865bc.....................default\n",
      "  gmlp_attn_dim ................... 64..........................default\n",
      "  gpt_j_residual .................. False.......................default\n",
      "  gpt_j_tied ...................... False.......................default\n",
      "  gradient_accumulation_steps ..... 1...........................default\n",
      "  gradient_clipping ............... 1.0.........................default\n",
      "  gradient_noise_scale_cpu_offload  False.......................default\n",
      "  gradient_noise_scale_n_batches .. 5...........................default\n",
      "  gradient_predivide_factor ....... 1.0.........................default\n",
      "  head_size ....................... None........................default\n",
      "  hidden_dropout .................. 0...........................default\n",
      "  hostfile ........................ None........................default\n",
      "  hysteresis ...................... 2...........................default\n",
      "  include ......................... None........................default\n",
      "  init_method_std ................. 0.02........................default\n",
      "  intermediate_size ............... None........................default\n",
      "  is_pipe_parallel ................ False.......................default\n",
      "  iteration ....................... None........................default\n",
      "  keep_last_n_checkpoints ......... None........................default\n",
      "  kto_beta ........................ 0.1.........................default\n",
      "  kto_desirable_weight ............ 1.0.........................default\n",
      "  kto_fp32 ........................ True........................default\n",
      "  kto_undesirable_weight .......... 1.0.........................default\n",
      "  launcher ........................ pdsh........................default\n",
      "  layernorm_epsilon ............... 1e-05.......................default\n",
      "  layernorm_fusion ................ False.......................default\n",
      "  lazy_mpu_init ................... False.......................default\n",
      "  local_rank ...................... None........................default\n",
      "  log_grad_norm ................... False.......................default\n",
      "  log_grad_pct_zeros .............. False.......................default\n",
      "  log_gradient_noise_scale ........ False.......................default\n",
      "  log_optimizer_states ............ False.......................default\n",
      "  log_param_norm .................. False.......................default\n",
      "  loss_scale ...................... None........................default\n",
      "  loss_scale_window ............... 1000.0......................default\n",
      "  lr_decay_fraction ............... None........................default\n",
      "  lr_decay_style .................. linear......................default\n",
      "  make_vocab_size_divisible_by .... 128.........................default\n",
      "  mamba_causal_conv_fusion ........ False.......................default\n",
      "  mamba_inner_func_fusion ......... False.......................default\n",
      "  mamba_selective_fp32_params ..... True........................default\n",
      "  mamba_selective_scan_fusion ..... False.......................default\n",
      "  mamba_use_bias_in_conv .......... True........................default\n",
      "  mamba_use_bias_in_linears ....... False.......................default\n",
      "  master_addr ..................... None........................default\n",
      "  master_port ..................... 29500.......................default\n",
      "  memory_profiling ................ False.......................default\n",
      "  memory_profiling_path ........... None........................default\n",
      "  merge_file ...................... None........................default\n",
      "  min_scale ....................... 1.0.........................default\n",
      "  mlp_multiple_of ................. 1...........................default\n",
      "  mmap_warmup ..................... False.......................default\n",
      "  model_parallel_size ............. 1...........................default\n",
      "  moe_eval_capacity_factor ........ 1.0.........................default\n",
      "  moe_expert_parallel_size ........ 1...........................default\n",
      "  moe_glu ......................... False.......................default\n",
      "  moe_jitter_eps .................. None........................default\n",
      "  moe_lbl_in_fp32 ................. False.......................default\n",
      "  moe_loss_coeff .................. 0.1.........................default\n",
      "  moe_min_capacity ................ 4...........................default\n",
      "  moe_num_experts ................. 1...........................default\n",
      "  moe_token_dropping .............. False.......................default\n",
      "  moe_top_k ....................... 1...........................default\n",
      "  moe_train_capacity_factor ....... 1.0.........................default\n",
      "  moe_type ........................ megablocks..................default\n",
      "  moe_use_residual ................ True........................default\n",
      "  mup_attn_temp ................... 1.0.........................default\n",
      "  mup_embedding_mult .............. 1.0.........................default\n",
      "  mup_init_scale .................. 1.0.........................default\n",
      "  mup_output_temp ................. 1.0.........................default\n",
      "  mup_rp_embedding_mult ........... 1.0.........................default\n",
      "  mup_width_scale ................. 2...........................default\n",
      "  neg_test_data_paths ............. None........................default\n",
      "  neg_test_label_data_paths ....... None........................default\n",
      "  neg_train_data_paths ............ None........................default\n",
      "  neg_train_label_data_paths ...... None........................default\n",
      "  neg_valid_data_paths ............ None........................default\n",
      "  neg_valid_label_data_paths ...... None........................default\n",
      "  no_load_optim ................... False.......................default\n",
      "  no_load_rng ..................... False.......................default\n",
      "  no_save_optim ................... False.......................default\n",
      "  no_save_rng ..................... False.......................default\n",
      "  no_ssh_check .................... False.......................default\n",
      "  no_weight_tying ................. False.......................default\n",
      "  norm ............................ layernorm...................default\n",
      "  num_gpus ........................ None........................default\n",
      "  num_kv_heads .................... None........................default\n",
      "  num_nodes ....................... -1..........................default\n",
      "  num_unique_layers ............... None........................default\n",
      "  onnx_safe ....................... False.......................default\n",
      "  opt_pos_emb_offset .............. 0...........................default\n",
      "  output_layer_parallelism ........ column......................default\n",
      "  override_lr_scheduler ........... False.......................default\n",
      "  pack_impl ....................... packed......................default\n",
      "  padded_vocab_size ............... None........................default\n",
      "  param_sharing_style ............. grouped.....................default\n",
      "  pipe_parallel_size .............. 0...........................default\n",
      "  pipe_partition_method ........... type:transformer|mlp........default\n",
      "  pos_test_data_paths ............. None........................default\n",
      "  pos_test_label_data_paths ....... None........................default\n",
      "  pos_train_data_paths ............ None........................default\n",
      "  pos_train_label_data_paths ...... None........................default\n",
      "  pos_valid_data_paths ............ None........................default\n",
      "  pos_valid_label_data_paths ...... None........................default\n",
      "  precompute_model_name ........... None........................default\n",
      "  prescale_gradients .............. False.......................default\n",
      "  profile ......................... False.......................default\n",
      "  profile_backward ................ False.......................default\n",
      "  profile_step_start .............. 10..........................default\n",
      "  profile_step_stop ............... 12..........................default\n",
      "  prompt_end ...................... \n",
      "...........................default\n",
      "  rank ............................ None........................default\n",
      "  recompute ....................... False.......................default\n",
      "  return_logits ................... False.......................default\n",
      "  rms_norm_epsilon ................ 1e-08.......................default\n",
      "  rmsnorm_fusion .................. False.......................default\n",
      "  rope_fusion ..................... False.......................default\n",
      "  rotary_emb_base ................. 10000.......................default\n",
      "  rotary_pct ...................... 1.0.........................default\n",
      "  rotary_save_freqs_buffer ........ False.......................default\n",
      "  rpe_max_distance ................ 128.........................default\n",
      "  rpe_num_buckets ................. 32..........................default\n",
      "  s3_chunk_size ................... 104857600...................default\n",
      "  s3_path ......................... None........................default\n",
      "  save_base_shapes ................ False.......................default\n",
      "  scaled_masked_softmax_fusion .... False.......................default\n",
      "  scaled_upper_triang_masked_softmax_fusion  False..............default\n",
      "  scalenorm_epsilon ............... 1e-08.......................default\n",
      "  scheduler ....................... None........................default\n",
      "  seed ............................ 1234........................default\n",
      "  sequence_parallel ............... False.......................default\n",
      "  short_seq_prob .................. 0.1.........................default\n",
      "  sliding_window_width ............ None........................default\n",
      "  soft_prompt_tuning .............. None........................default\n",
      "  sparse_attention ................ None........................default\n",
      "  sparse_gradients ................ False.......................default\n",
      "  split ........................... 969, 30, 1..................default\n",
      "  steps_per_print ................. 10..........................default\n",
      "  tensorboard ..................... None........................default\n",
      "  test_data_paths ................. None........................default\n",
      "  test_data_weights ............... None........................default\n",
      "  test_label_data_paths ........... None........................default\n",
      "  test_reward_data_paths .......... None........................default\n",
      "  top_k ........................... 0...........................default\n",
      "  top_p ........................... 0.0.........................default\n",
      "  train_data_paths ................ None........................default\n",
      "  train_data_weights .............. None........................default\n",
      "  train_epochs .................... None........................default\n",
      "  train_impl ...................... normal......................default\n",
      "  train_label_data_paths .......... None........................default\n",
      "  train_reward_data_paths ......... None........................default\n",
      "  use_bias_in_attn_linear ......... True........................default\n",
      "  use_bias_in_mlp ................. True........................default\n",
      "  use_bias_in_norms ............... True........................default\n",
      "  use_bnb_optimizer ............... False.......................default\n",
      "  use_checkpoint_lr_scheduler ..... False.......................default\n",
      "  use_comet ....................... None........................default\n",
      "  use_cpu_initialization .......... False.......................default\n",
      "  use_flashattn_swiglu ............ False.......................default\n",
      "  use_mup ......................... False.......................default\n",
      "  use_qk_layernorm ................ False.......................default\n",
      "  use_shared_fs ................... True........................default\n",
      "  use_tutel ....................... False.......................default\n",
      "  use_wandb ....................... None........................default\n",
      "  valid_data_paths ................ None........................default\n",
      "  valid_data_weights .............. None........................default\n",
      "  valid_label_data_paths .......... None........................default\n",
      "  valid_reward_data_paths ......... None........................default\n",
      "  vocab_file ...................... None........................default\n",
      "  wandb ........................... None........................default\n",
      "  wandb_group ..................... None........................default\n",
      "  wandb_host ...................... https://api.wandb.ai........default\n",
      "  wandb_init_all_ranks ............ False.......................default\n",
      "  wandb_project ................... neox........................default\n",
      "  wandb_team ...................... None........................default\n",
      "  warmup .......................... 0.01........................default\n",
      "  weight_by_num_documents ......... False.......................default\n",
      "  weight_decay .................... 0.1.........................default\n",
      "  weighted_sampler_alpha .......... 1.0.........................default\n",
      "  world_size ...................... None........................default\n",
      "  z_loss .......................... 0.0.........................default\n",
      "---------------- end of arguments ----------------\n",
      "NeoXArgs.configure_distributed_args() using world size: 1 and model-parallel size: 1 \n",
      "[2024-12-01 08:07:57,224] [WARNING] [runner.py:217:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
      "[2024-12-01 08:07:57,224] [INFO] [runner.py:586:main] cmd = /content/GPT-NeoX-Colab/.venv/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None eval.py --deepspeed_config eyJ0cmFpbl9iYXRjaF9zaXplIjogOCwgInRyYWluX21pY3JvX2JhdGNoX3NpemVfcGVyX2dwdSI6IDgsICJvcHRpbWl6ZXIiOiB7InR5cGUiOiAiQWRhbSIsICJwYXJhbXMiOiB7ImxyIjogMC4wMDEsICJiZXRhcyI6IFswLjksIDAuOTVdLCAiZXBzIjogMWUtMDh9fSwgImZwMTYiOiB7ImZwMTYiOiB0cnVlLCAiZW5hYmxlZCI6IHRydWUsICJsb3NzX3NjYWxlIjogMCwgImxvc3Nfc2NhbGVfd2luZG93IjogMTAwMCwgImluaXRpYWxfc2NhbGVfcG93ZXIiOiAxMiwgImh5c3RlcmVzaXMiOiAyLCAibWluX2xvc3Nfc2NhbGUiOiAxfSwgInplcm9fb3B0aW1pemF0aW9uIjogeyJzdGFnZSI6IDEsICJhbGxnYXRoZXJfcGFydGl0aW9ucyI6IHRydWUsICJhbGxnYXRoZXJfYnVja2V0X3NpemUiOiA1MDAwMDAwMDAsICJvdmVybGFwX2NvbW0iOiB0cnVlLCAicmVkdWNlX3NjYXR0ZXIiOiB0cnVlLCAicmVkdWNlX2J1Y2tldF9zaXplIjogNTAwMDAwMDAwLCAiY29udGlndW91c19ncmFkaWVudHMiOiB0cnVlfSwgIndhbGxfY2xvY2tfYnJlYWtkb3duIjogdHJ1ZSwgImNvbW1zX2xvZ2dlciI6IHsiZW5hYmxlZCI6IHRydWUsICJ2ZXJib3NlIjogZmFsc2UsICJwcm9mX2FsbCI6IHRydWUsICJkZWJ1ZyI6IGZhbHNlfX0= --megatron_config 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\n",
      "[2024-12-01 08:07:58,237] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-12-01 08:07:59,579] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0]}\n",
      "[2024-12-01 08:07:59,579] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0\n",
      "[2024-12-01 08:07:59,579] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
      "[2024-12-01 08:07:59,579] [INFO] [launch.py:163:main] dist_world_size=1\n",
      "[2024-12-01 08:07:59,579] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0\n",
      "/content/gpt-neox/megatron/neox_arguments/arguments.py:1101: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert (\n",
      "/content/gpt-neox/megatron/neox_arguments/arguments.py:1110: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert (\n",
      "[2024-12-01 08:08:00,920] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Unable to import Mamba kernels. Install them from our requirements/requirements-mamba.txt,     or directly from https://github.com/state-spaces/mamba\n",
      "For s3 checkpointing, please install hf_transfer either using requirements/requirements-s3.txt or https://github.com/huggingface/hf_transfer\n",
      "2024-12-01 08:08:03.575152: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-01 08:08:03.586344: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-01 08:08:03.600226: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-01 08:08:03.604268: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-01 08:08:03.614286: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-01 08:08:04.315347: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Downloading builder script: 100%|██████████| 5.67k/5.67k [00:00<00:00, 10.8MB/s]\n",
      "2024-12-01:08:08:07,913 INFO     [arguments.py:903] NeoXArgs.calculate_derived() Total number of GPUs determined to be: 1\n",
      "NeoXArgs.configure_distributed_args() using world size: 1 and model-parallel size: 1 \n",
      "> building CharLevelTokenizer tokenizer ...\n",
      " > padded vocab (size: 512) with 0 dummy tokens (new size: 512)\n",
      "> initializing torch distributed ...\n",
      "[2024-12-01 08:08:07,920] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-12-01 08:08:07,920] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "> initializing model parallel with size 1\n",
      "MPU DP: [0]\n",
      "MPU PP: [0]\n",
      "MPU MP: [0]\n",
      "> setting random seeds to 1234 ...\n",
      "[2024-12-01 08:08:07,924] [INFO] [checkpointing.py:227:model_parallel_cuda_manual_seed] > initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234\n",
      "make: Entering directory '/content/gpt-neox/megatron/data'\n",
      "make: Nothing to be done for 'default'.\n",
      "make: Leaving directory '/content/gpt-neox/megatron/data'\n",
      "building GPT2 model ...\n",
      "SEED_LAYERS=False BASE_SEED=1234 SEED_FN=None\n",
      "Using topology: {ProcessCoord(pipe=0, data=0, model=0): 0}\n",
      "[2024-12-01 08:08:07,951] [INFO] [module.py:375:_partition_layers] Partitioning pipeline stages with method type:transformer|mlp\n",
      "stage=0 layers=9\n",
      "     0: EmbeddingPipe\n",
      "     1: _pre_transformer_block\n",
      "     2: ParallelTransformerLayerPipe\n",
      "     3: ParallelTransformerLayerPipe\n",
      "     4: ParallelTransformerLayerPipe\n",
      "     5: ParallelTransformerLayerPipe\n",
      "     6: _post_transformer_block\n",
      "     7: NormPipe\n",
      "     8: EmbeddingPipe\n",
      "  loss: partial\n",
      "Configuring Optimizer type: adam with params: {'lr': 0.0}\n",
      "WARNING: APEX not installed - defaulting to deepspeed's fused adam\n",
      "Using /home/vscode/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/vscode/.cache/torch_extensions/py310_cu121/fused_adam/build.ninja...\n",
      "/content/GPT-NeoX-Colab/.venv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Building extension module fused_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.02681708335876465 seconds\n",
      "/content/GPT-NeoX-Colab/.venv/lib/python3.10/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "> learning rate decay style: linear\n",
      "DeepSpeed is enabled.\n",
      "[2024-12-01 08:08:08,839] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.12.4+02e2ebf, git-hash=02e2ebf, git-branch=HEAD\n",
      "[2024-12-01 08:08:08,970] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-12-01 08:08:08,970] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-12-01 08:08:08,970] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-12-01 08:08:08,970] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam\n",
      "[2024-12-01 08:08:08,970] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>\n",
      "[2024-12-01 08:08:08,970] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 1 optimizer\n",
      "[2024-12-01 08:08:08,970] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 500000000\n",
      "[2024-12-01 08:08:08,970] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 500000000\n",
      "[2024-12-01 08:08:08,970] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-12-01 08:08:08,970] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-12-01 08:08:09,190] [INFO] [utils.py:802:see_memory_usage] Before initializing optimizer states\n",
      "[2024-12-01 08:08:09,191] [INFO] [utils.py:803:see_memory_usage] MA 0.01 GB         Max_MA 0.01 GB         CA 0.01 GB         Max_CA 0 GB \n",
      "[2024-12-01 08:08:09,191] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 8.77 GB, percent = 28.2%\n",
      "[2024-12-01 08:08:09,416] [INFO] [utils.py:802:see_memory_usage] After initializing optimizer states\n",
      "[2024-12-01 08:08:09,417] [INFO] [utils.py:803:see_memory_usage] MA 0.01 GB         Max_MA 0.01 GB         CA 0.02 GB         Max_CA 0 GB \n",
      "[2024-12-01 08:08:09,417] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 8.74 GB, percent = 28.1%\n",
      "[2024-12-01 08:08:09,417] [INFO] [stage_1_and_2.py:517:__init__] optimizer state initialized\n",
      "[2024-12-01 08:08:09,633] [INFO] [utils.py:802:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-12-01 08:08:09,634] [INFO] [utils.py:803:see_memory_usage] MA 0.01 GB         Max_MA 0.01 GB         CA 0.02 GB         Max_CA 0 GB \n",
      "[2024-12-01 08:08:09,634] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 8.74 GB, percent = 28.1%\n",
      "[2024-12-01 08:08:09,634] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam\n",
      "[2024-12-01 08:08:09,634] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-12-01 08:08:09,634] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <megatron.learning_rates.AnnealingLR object at 0x7942dbb14280>\n",
      "[2024-12-01 08:08:09,634] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0], mom=[(0.9, 0.999)]\n",
      "[2024-12-01 08:08:09,634] [INFO] [config.py:979:print] DeepSpeedEngine configuration:\n",
      "[2024-12-01 08:08:09,635] [INFO] [config.py:983:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-12-01 08:08:09,635] [INFO] [config.py:983:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-12-01 08:08:09,635] [INFO] [config.py:983:print]   amp_enabled .................. False\n",
      "[2024-12-01 08:08:09,635] [INFO] [config.py:983:print]   amp_params ................... False\n",
      "[2024-12-01 08:08:09,635] [INFO] [config.py:983:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-12-01 08:08:09,635] [INFO] [config.py:983:print]   bfloat16_enabled ............. False\n",
      "[2024-12-01 08:08:09,635] [INFO] [config.py:983:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-12-01 08:08:09,635] [INFO] [config.py:983:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-12-01 08:08:09,635] [INFO] [config.py:983:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-12-01 08:08:09,635] [INFO] [config.py:983:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7942d2b561a0>\n",
      "[2024-12-01 08:08:09,635] [INFO] [config.py:983:print]   communication_data_type ...... None\n",
      "[2024-12-01 08:08:09,635] [INFO] [config.py:983:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-12-01 08:08:09,635] [INFO] [config.py:983:print]   curriculum_enabled_legacy .... False\n",
      "[2024-12-01 08:08:09,635] [INFO] [config.py:983:print]   curriculum_params_legacy ..... False\n",
      "[2024-12-01 08:08:09,635] [INFO] [config.py:983:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-12-01 08:08:09,635] [INFO] [config.py:983:print]   data_efficiency_enabled ...... False\n",
      "[2024-12-01 08:08:09,635] [INFO] [config.py:983:print]   dataloader_drop_last ......... False\n",
      "[2024-12-01 08:08:09,635] [INFO] [config.py:983:print]   disable_allgather ............ False\n",
      "[2024-12-01 08:08:09,635] [INFO] [config.py:983:print]   dump_state ................... False\n",
      "[2024-12-01 08:08:09,635] [INFO] [config.py:983:print]   dynamic_loss_scale_args ...... {'init_scale': 4096, 'scale_window': 1000, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}\n",
      "[2024-12-01 08:08:09,635] [INFO] [config.py:983:print]   eigenvalue_enabled ........... False\n",
      "[2024-12-01 08:08:09,635] [INFO] [config.py:983:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-12-01 08:08:09,635] [INFO] [config.py:983:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-12-01 08:08:09,635] [INFO] [config.py:983:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-12-01 08:08:09,635] [INFO] [config.py:983:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-12-01 08:08:09,635] [INFO] [config.py:983:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-12-01 08:08:09,635] [INFO] [config.py:983:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-12-01 08:08:09,635] [INFO] [config.py:983:print]   eigenvalue_verbose ........... False\n",
      "[2024-12-01 08:08:09,635] [INFO] [config.py:983:print]   elasticity_enabled ........... False\n",
      "[2024-12-01 08:08:09,635] [INFO] [config.py:983:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   fp16_auto_cast ............... False\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   fp16_enabled ................. True\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   global_rank .................. 0\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   grad_accum_dtype ............. None\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   gradient_accumulation_steps .. 1\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   gradient_clipping ............ 0.0\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   initial_dynamic_scale ........ 4096\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   load_universal_checkpoint .... False\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   loss_scale ................... 0\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   memory_breakdown ............. False\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   mics_hierarchial_params_gather  False\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   mics_shard_size .............. -1\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   optimizer_name ............... None\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   optimizer_params ............. None\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   pld_enabled .................. False\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   pld_params ................... False\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   prescale_gradients ........... False\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   scheduler_name ............... None\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   scheduler_params ............. None\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   sparse_attention ............. None\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   sparse_gradients_enabled ..... False\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   steps_per_print .............. 10\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   train_batch_size ............. 8\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   train_micro_batch_size_per_gpu  8\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   use_data_before_expert_parallel_  False\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   use_node_local_storage ....... False\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   wall_clock_breakdown ......... True\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   weight_quantization_config ... None\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   world_size ................... 1\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   zero_allow_untested_optimizer  False\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   zero_config .................. stage=1 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   zero_enabled ................. True\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-12-01 08:08:09,636] [INFO] [config.py:983:print]   zero_optimization_stage ...... 1\n",
      "[2024-12-01 08:08:09,637] [INFO] [config.py:969:print_user_config]   json = {\n",
      "    \"train_batch_size\": 8, \n",
      "    \"train_micro_batch_size_per_gpu\": 8, \n",
      "    \"optimizer\": {\n",
      "        \"params\": {\n",
      "            \"lr\": 0.0\n",
      "        }\n",
      "    }, \n",
      "    \"fp16\": {\n",
      "        \"fp16\": true, \n",
      "        \"enabled\": true, \n",
      "        \"loss_scale\": 0, \n",
      "        \"loss_scale_window\": 1000, \n",
      "        \"initial_scale_power\": 12, \n",
      "        \"hysteresis\": 2, \n",
      "        \"min_loss_scale\": 1\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 1, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 5.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 5.000000e+08, \n",
      "        \"contiguous_gradients\": true\n",
      "    }, \n",
      "    \"wall_clock_breakdown\": true, \n",
      "    \"comms_logger\": {\n",
      "        \"enabled\": true, \n",
      "        \"verbose\": false, \n",
      "        \"prof_all\": true, \n",
      "        \"debug\": false\n",
      "    }\n",
      "}\n",
      " > number of parameters on model parallel rank 0: 3290624\n",
      " > total params: 3,290,624\n",
      "[2024-12-01 08:08:09,669] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from checkpoints/global_step800/mp_rank_00_model_states.pt...\n",
      "[2024-12-01 08:08:09,672] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from checkpoints/global_step800/mp_rank_00_model_states.pt.\n",
      "[2024-12-01 08:08:09,672] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from checkpoints/global_step800/mp_rank_00_model_states.pt...\n",
      "[2024-12-01 08:08:09,675] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from checkpoints/global_step800/mp_rank_00_model_states.pt.\n",
      " > validated currently set args with arguments in the checkpoint ...\n",
      "  successfully loaded checkpoints/global_step800/mp_rank_00_model_states.pt\n",
      "Loading checkpoint and starting from iteration 800\n",
      "Finished loading model\n",
      "Running evaluation harness...\n",
      "2024-12-01:08:08:12,728 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.\n",
      "2024-12-01:08:08:15,197 WARNING  [__init__.py:194] Some tasks could not be loaded due to missing dependencies. Run with `--verbosity DEBUG` for full details.\n",
      "Found tasks: ['hellaswag']\n",
      "Downloading builder script: 100%|##########| 4.36k/4.36k [00:00<00:00, 13.7MB/s]\n",
      "Downloading metadata: 100%|##########| 2.53k/2.53k [00:00<00:00, 9.29MB/s]\n",
      "Downloading readme: 100%|##########| 6.84k/6.84k [00:00<00:00, 17.1MB/s]\n",
      "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Downloading data:   0%|          | 0.00/12.1M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data:  11%|#1        | 1.37M/12.1M [00:00<00:00, 13.3MB/s]\u001b[A\n",
      "Downloading data:  27%|##7       | 3.32M/12.1M [00:00<00:00, 15.6MB/s]\u001b[A\n",
      "Downloading data:  40%|####      | 4.88M/12.1M [00:00<00:00, 15.2MB/s]\u001b[A\n",
      "Downloading data:  57%|#####6    | 6.88M/12.1M [00:00<00:00, 16.7MB/s]\u001b[A\n",
      "Downloading data:  71%|#######   | 8.55M/12.1M [00:00<00:00, 16.6MB/s]\u001b[A\n",
      "Downloading data:  85%|########4 | 10.2M/12.1M [00:00<00:00, 15.5MB/s]\u001b[A\n",
      "Downloading data:  98%|#########8| 11.9M/12.1M [00:00<00:00, 15.3MB/s]\u001b[A\n",
      "Downloading data: 13.4MB [00:00, 13.3MB/s]                            \u001b[A\n",
      "Downloading data: 14.8MB [00:01, 13.3MB/s]\u001b[A\n",
      "Downloading data: 16.2MB [00:01, 13.1MB/s]\u001b[A\n",
      "Downloading data: 17.7MB [00:01, 13.3MB/s]\u001b[A\n",
      "Downloading data: 19.0MB [00:01, 13.2MB/s]\u001b[A\n",
      "Downloading data: 20.3MB [00:01, 13.2MB/s]\u001b[A\n",
      "Downloading data: 21.8MB [00:01, 13.6MB/s]\u001b[A\n",
      "Downloading data: 23.1MB [00:01, 13.5MB/s]\u001b[A\n",
      "Downloading data: 24.5MB [00:01, 13.4MB/s]\u001b[A\n",
      "Downloading data: 26.0MB [00:01, 13.6MB/s]\u001b[A\n",
      "Downloading data: 27.3MB [00:01, 13.1MB/s]\u001b[A\n",
      "Downloading data: 29.0MB [00:02, 14.1MB/s]\u001b[A\n",
      "Downloading data: 30.5MB [00:02, 13.8MB/s]\u001b[A\n",
      "Downloading data: 32.2MB [00:02, 14.7MB/s]\u001b[A\n",
      "Downloading data: 33.9MB [00:02, 15.4MB/s]\u001b[A\n",
      "Downloading data: 35.5MB [00:02, 14.6MB/s]\u001b[A\n",
      "Downloading data: 37.1MB [00:02, 14.7MB/s]\u001b[A\n",
      "Downloading data: 38.7MB [00:02, 15.1MB/s]\u001b[A\n",
      "Downloading data: 40.3MB [00:02, 14.2MB/s]\u001b[A\n",
      "Downloading data: 41.7MB [00:02, 14.3MB/s]\u001b[A\n",
      "Downloading data: 43.6MB [00:03, 15.3MB/s]\u001b[A\n",
      "Downloading data: 45.1MB [00:03, 13.2MB/s]\u001b[A\n",
      "Downloading data: 47.5MB [00:03, 14.2MB/s]\u001b[A\n",
      "Downloading data files:  33%|###3      | 1/3 [00:08<00:16,  8.23s/it]\n",
      "Downloading data:   0%|          | 0.00/3.04M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data:  19%|#9        | 592k/3.04M [00:00<00:00, 5.83MB/s]\u001b[A\n",
      "Downloading data:  75%|#######4  | 2.27M/3.04M [00:00<00:00, 12.2MB/s]\u001b[A\n",
      "Downloading data: 3.75MB [00:00, 13.1MB/s]                            \u001b[A\n",
      "Downloading data: 5.39MB [00:00, 13.5MB/s]\u001b[A\n",
      "Downloading data: 6.92MB [00:00, 14.0MB/s]\u001b[A\n",
      "Downloading data: 8.43MB [00:00, 14.4MB/s]\u001b[A\n",
      "Downloading data: 9.87MB [00:00, 14.1MB/s]\u001b[A\n",
      "Downloading data: 11.8MB [00:00, 13.6MB/s]\u001b[A\n",
      "Downloading data files:  67%|######6   | 2/3 [00:10<00:04,  4.89s/it]\n",
      "Downloading data:   0%|          | 0.00/3.14M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data:  45%|####5     | 1.43M/3.14M [00:00<00:00, 13.8MB/s]\u001b[A\n",
      "Downloading data: 3.33MB [00:00, 16.3MB/s]                            \u001b[A\n",
      "Downloading data: 5.20MB [00:00, 16.6MB/s]\u001b[A\n",
      "Downloading data: 7.10MB [00:00, 17.5MB/s]\u001b[A\n",
      "Downloading data: 8.85MB [00:00, 17.5MB/s]\u001b[A\n",
      "Downloading data: 12.2MB [00:00, 17.1MB/s]\u001b[A\n",
      "Downloading data files: 100%|##########| 3/3 [00:13<00:00,  4.41s/it]\n",
      "Extracting data files: 100%|##########| 3/3 [00:00<00:00, 2980.32it/s]\n",
      "Generating train split: 100%|##########| 39905/39905 [00:02<00:00, 16243.72 examples/s]\n",
      "Generating test split: 100%|##########| 10003/10003 [00:00<00:00, 15988.93 examples/s]\n",
      "Generating validation split: 100%|##########| 10042/10042 [00:00<00:00, 13845.72 examples/s]\n",
      "Map: 100%|##########| 39905/39905 [00:04<00:00, 8543.06 examples/s] \n",
      "Map: 100%|##########| 10042/10042 [00:01<00:00, 9796.38 examples/s]\n",
      "2024-12-01:08:08:50,362 WARNING  [eval_adapter.py:483] Overwriting default num_fewshot of hellaswag from None to 0\n",
      "2024-12-01:08:08:50,367 INFO     [task.py:363] Building contexts for task on rank 0...\n",
      "2024-12-01:08:08:50,370 INFO     [evaluator.py:324] Running loglikelihood requests\n",
      "100%|##########| 40/40 [00:00<00:00, 60.60it/s]\n",
      "dict_keys(['results', 'configs', 'versions', 'n-shot', 'config', 'git_hash'])\n",
      "{'config': {'batch_size': 8,\n",
      "            'bootstrap_iters': 10000,\n",
      "            'device': 'cuda:0',\n",
      "            'limit': None,\n",
      "            'model': 'neox',\n",
      "            'model_args': {'account': None,\n",
      "                           'activation': 'gelu',\n",
      "                           'activation_checkpointing': None,\n",
      "                           'adlr_autoresume': False,\n",
      "                           'adlr_autoresume_interval': 1000,\n",
      "                           'allow_chopped': True,\n",
      "                           'amp': None,\n",
      "                           'apply_query_key_layer_scaling': False,\n",
      "                           'attention_config': ['global',\n",
      "                                                'global',\n",
      "                                                'global',\n",
      "                                                'global'],\n",
      "                           'attention_dropout': 0.0,\n",
      "                           'attention_softmax_in_fp32': False,\n",
      "                           'autotuning': None,\n",
      "                           'autotuning_run': None,\n",
      "                           'base_shapes_file': None,\n",
      "                           'batch_size': 8,\n",
      "                           'bf16': None,\n",
      "                           'bias_dropout_fusion': False,\n",
      "                           'bias_gelu_fusion': False,\n",
      "                           'char_level_ppl': False,\n",
      "                           'checkpoint': None,\n",
      "                           'checkpoint_activations': False,\n",
      "                           'checkpoint_factor': 50,\n",
      "                           'checkpoint_in_cpu': False,\n",
      "                           'checkpoint_num_layers': 1,\n",
      "                           'checkpoint_scale': 'linear',\n",
      "                           'checkpoint_validation_with_forward_pass': False,\n",
      "                           'clip_grad': 1.0,\n",
      "                           'comet_experiment': None,\n",
      "                           'comet_experiment_name': None,\n",
      "                           'comet_others': None,\n",
      "                           'comet_project': None,\n",
      "                           'comet_tags': None,\n",
      "                           'comet_workspace': None,\n",
      "                           'comment': None,\n",
      "                           'comms_logger': None,\n",
      "                           'communication_data_type': None,\n",
      "                           'compression_training': None,\n",
      "                           'config_files': {'shakespeare.yml': '{\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"pipe_parallel_size\": '\n",
      "                                                               '0, # Because '\n",
      "                                                               'running on one '\n",
      "                                                               'GPU\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"model_parallel_size\": '\n",
      "                                                               '1, # Because '\n",
      "                                                               'running on one '\n",
      "                                                               'GPU\\n'\n",
      "                                                               '\\n'\n",
      "                                                               '  # model '\n",
      "                                                               'settings\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"num_layers\": '\n",
      "                                                               '4,\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"hidden_size\": '\n",
      "                                                               '256,\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"num_attention_heads\": '\n",
      "                                                               '4,\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"seq_length\": '\n",
      "                                                               '512,\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"max_position_embeddings\": '\n",
      "                                                               '512,\\n'\n",
      "                                                               '  \"pos_emb\": '\n",
      "                                                               '\"rotary\",\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"no_weight_tying\": '\n",
      "                                                               'false, # '\n",
      "                                                               'Sharing '\n",
      "                                                               'embedding and '\n",
      "                                                               'output '\n",
      "                                                               'weights\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"gpt_j_residual\": '\n",
      "                                                               'false,\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"output_layer_parallelism\": '\n",
      "                                                               '\"column\",\\n'\n",
      "                                                               '\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"scaled_upper_triang_masked_softmax_fusion\": '\n",
      "                                                               'false,\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"bias_gelu_fusion\": '\n",
      "                                                               'false,\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"rope_fusion\": '\n",
      "                                                               'false,\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"layernorm_fusion\": '\n",
      "                                                               'false,\\n'\n",
      "                                                               '\\n'\n",
      "                                                               '  # init '\n",
      "                                                               'methods\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"init_method\": '\n",
      "                                                               '\"small_init\",\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"output_layer_init_method\": '\n",
      "                                                               '\"wang_init\",\\n'\n",
      "                                                               '\\n'\n",
      "                                                               '  \"optimizer\": '\n",
      "                                                               '{\\n'\n",
      "                                                               '    \"type\": '\n",
      "                                                               '\"Adam\",\\n'\n",
      "                                                               '    \"params\": '\n",
      "                                                               '{\\n'\n",
      "                                                               '      \"lr\": '\n",
      "                                                               '0.001,\\n'\n",
      "                                                               '      \"betas\": '\n",
      "                                                               '[0.9, 0.95],\\n'\n",
      "                                                               '      \"eps\": '\n",
      "                                                               '1.0e-8\\n'\n",
      "                                                               '    }\\n'\n",
      "                                                               '  },\\n'\n",
      "                                                               '  \"min_lr\": '\n",
      "                                                               '0.0001,\\n'\n",
      "                                                               '\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"zero_optimization\": '\n",
      "                                                               '{\\n'\n",
      "                                                               '    \"stage\": '\n",
      "                                                               '1,\\n'\n",
      "                                                               '    '\n",
      "                                                               '\"allgather_partitions\": '\n",
      "                                                               'true,\\n'\n",
      "                                                               '    '\n",
      "                                                               '\"allgather_bucket_size\": '\n",
      "                                                               '500000000,\\n'\n",
      "                                                               '    '\n",
      "                                                               '\"overlap_comm\": '\n",
      "                                                               'true,\\n'\n",
      "                                                               '    '\n",
      "                                                               '\"reduce_scatter\": '\n",
      "                                                               'true,\\n'\n",
      "                                                               '    '\n",
      "                                                               '\"reduce_bucket_size\": '\n",
      "                                                               '500000000,\\n'\n",
      "                                                               '    '\n",
      "                                                               '\"contiguous_gradients\": '\n",
      "                                                               'true\\n'\n",
      "                                                               '  },\\n'\n",
      "                                                               '\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"train_micro_batch_size_per_gpu\": '\n",
      "                                                               '8, #256, # 8, '\n",
      "                                                               '#8 for 4GB '\n",
      "                                                               '#256 for 16GB\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"gradient_accumulation_steps\": '\n",
      "                                                               '1,\\n'\n",
      "                                                               '  \"data_impl\": '\n",
      "                                                               '\"mmap\",\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"num_workers\": '\n",
      "                                                               '1,\\n'\n",
      "                                                               '\\n'\n",
      "                                                               '  # activation '\n",
      "                                                               'checkpointing\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"checkpoint_activations\": '\n",
      "                                                               'false, # We '\n",
      "                                                               'are not memory '\n",
      "                                                               'bound\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"checkpoint_num_layers\": '\n",
      "                                                               '1,\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"partition_activations\": '\n",
      "                                                               'true,\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"synchronize_each_layer\": '\n",
      "                                                               'true,\\n'\n",
      "                                                               '\\n'\n",
      "                                                               '  # '\n",
      "                                                               'regularization\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"gradient_clipping\": '\n",
      "                                                               '1.0,\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"weight_decay\": '\n",
      "                                                               '0.1,\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"hidden_dropout\": '\n",
      "                                                               '0,\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"attention_dropout\": '\n",
      "                                                               '0,\\n'\n",
      "                                                               '\\n'\n",
      "                                                               '  # precision '\n",
      "                                                               'settings\\n'\n",
      "                                                               '  \"fp16\": {\\n'\n",
      "                                                               '    \"fp16\": '\n",
      "                                                               'true,\\n'\n",
      "                                                               '    \"enabled\": '\n",
      "                                                               'true,\\n'\n",
      "                                                               '    '\n",
      "                                                               '\"loss_scale\": '\n",
      "                                                               '0,\\n'\n",
      "                                                               '    '\n",
      "                                                               '\"loss_scale_window\": '\n",
      "                                                               '1000,\\n'\n",
      "                                                               '    '\n",
      "                                                               '\"initial_scale_power\": '\n",
      "                                                               '12,\\n'\n",
      "                                                               '    '\n",
      "                                                               '\"hysteresis\": '\n",
      "                                                               '2,\\n'\n",
      "                                                               '    '\n",
      "                                                               '\"min_loss_scale\": '\n",
      "                                                               '1\\n'\n",
      "                                                               '  },\\n'\n",
      "                                                               '\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"train_iters\": '\n",
      "                                                               '800,\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"lr_decay_iters\": '\n",
      "                                                               '800,\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"distributed_backend\": '\n",
      "                                                               '\"nccl\",\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"lr_decay_style\": '\n",
      "                                                               '\"linear\",\\n'\n",
      "                                                               '  \"warmup\": '\n",
      "                                                               '0.01,\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"checkpoint_factor\": '\n",
      "                                                               '50, # Must be '\n",
      "                                                               'defined if '\n",
      "                                                               'save is set\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"eval_interval\": '\n",
      "                                                               '30,\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"eval_iters\": '\n",
      "                                                               '2,\\n'\n",
      "                                                               '\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"log_interval\": '\n",
      "                                                               '10,\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"steps_per_print\": '\n",
      "                                                               '10,\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"wall_clock_breakdown\": '\n",
      "                                                               'true,\\n'\n",
      "                                                               '\\n'\n",
      "                                                               '  # Required '\n",
      "                                                               'for model '\n",
      "                                                               'conversion '\n",
      "                                                               'into HF '\n",
      "                                                               'format\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"tokenizer_type\": '\n",
      "                                                               '\"CharLevelTokenizer\",\\n'\n",
      "                                                               '\\n'\n",
      "                                                               '  # additional '\n",
      "                                                               'deepspeed args '\n",
      "                                                               'not specified '\n",
      "                                                               'above\\n'\n",
      "                                                               '  '\n",
      "                                                               '\"deepspeed_extra_args\": '\n",
      "                                                               '{\\n'\n",
      "                                                               '    '\n",
      "                                                               '\"comms_logger\": '\n",
      "                                                               '{\\n'\n",
      "                                                               '      '\n",
      "                                                               '\"enabled\": '\n",
      "                                                               'true,\\n'\n",
      "                                                               '      '\n",
      "                                                               '\"verbose\": '\n",
      "                                                               'false,\\n'\n",
      "                                                               '      '\n",
      "                                                               '\"prof_all\": '\n",
      "                                                               'true,\\n'\n",
      "                                                               '      \"debug\": '\n",
      "                                                               'false\\n'\n",
      "                                                               '    }\\n'\n",
      "                                                               '  }\\n'\n",
      "                                                               '}\\n',\n",
      "                                            'shakespeare_gen.yml': '# '\n",
      "                                                                   'Parameters '\n",
      "                                                                   'used for '\n",
      "                                                                   'text '\n",
      "                                                                   'generation\\n'\n",
      "                                                                   '{\\n'\n",
      "                                                                   '  # Text '\n",
      "                                                                   'gen type: '\n",
      "                                                                   '`input-file`, '\n",
      "                                                                   '`unconditional` '\n",
      "                                                                   'or '\n",
      "                                                                   '`interactive`\\n'\n",
      "                                                                   '  '\n",
      "                                                                   '\"text_gen_type\": '\n",
      "                                                                   '\"unconditional\",\\n'\n",
      "                                                                   '\\n'\n",
      "                                                                   '  # Params '\n",
      "                                                                   'for all\\n'\n",
      "                                                                   '  '\n",
      "                                                                   '\"maximum_tokens\": '\n",
      "                                                                   '102,\\n'\n",
      "                                                                   '  '\n",
      "                                                                   '\"prompt_end\": '\n",
      "                                                                   '\"\\\\n\",\\n'\n",
      "                                                                   '  '\n",
      "                                                                   '\"temperature\": '\n",
      "                                                                   '1.0,\\n'\n",
      "                                                                   '  \"top_p\": '\n",
      "                                                                   '0.0,\\n'\n",
      "                                                                   '  \"top_k\": '\n",
      "                                                                   '0,\\n'\n",
      "                                                                   '  '\n",
      "                                                                   '\"recompute\": '\n",
      "                                                                   'false,\\n'\n",
      "                                                                   '\\n'\n",
      "                                                                   '  # '\n",
      "                                                                   '`unconditional`: '\n",
      "                                                                   'samples\\n'\n",
      "                                                                   '  '\n",
      "                                                                   '\"num_samples\": '\n",
      "                                                                   '10,\\n'\n",
      "                                                                   '\\n'\n",
      "                                                                   '  # '\n",
      "                                                                   'input/output '\n",
      "                                                                   'file\\n'\n",
      "                                                                   '  '\n",
      "                                                                   '\"sample_input_file\": '\n",
      "                                                                   '\"sample_input.txt\",\\n'\n",
      "                                                                   '  '\n",
      "                                                                   '\"sample_output_file\": '\n",
      "                                                                   '\"sample_output.txt\",\\n'\n",
      "                                                                   '\\n'\n",
      "                                                                   '  '\n",
      "                                                                   '\"data_path\": '\n",
      "                                                                   '\"processed_data/shakespeare_text_document\",\\n'\n",
      "                                                                   '\\n'\n",
      "                                                                   '  \"save\": '\n",
      "                                                                   '\"checkpoints\",\\n'\n",
      "                                                                   '  \"load\": '\n",
      "                                                                   '\"checkpoints\",\\n'\n",
      "                                                                   '  '\n",
      "                                                                   '\"checkpoint_validation_with_forward_pass\": '\n",
      "                                                                   'False,\\n'\n",
      "                                                                   '\\n'\n",
      "                                                                   '  '\n",
      "                                                                   '\"tensorboard_dir\": '\n",
      "                                                                   '\"tensorboard_gen\",\\n'\n",
      "                                                                   '  '\n",
      "                                                                   '\"log_dir\": '\n",
      "                                                                   '\"logs_gen\",\\n'\n",
      "                                                                   '}'},\n",
      "                           'contiguous_checkpointing': False,\n",
      "                           'coord_check': False,\n",
      "                           'create_moe_param_group': True,\n",
      "                           'csv_monitor': None,\n",
      "                           'curriculum_learning': None,\n",
      "                           'curriculum_seqlen': 0,\n",
      "                           'data_efficiency': None,\n",
      "                           'data_impl': 'mmap',\n",
      "                           'data_path': 'processed_data/shakespeare_text_document',\n",
      "                           'data_types': None,\n",
      "                           'dataset_impl': 'gpt2',\n",
      "                           'deepscale': False,\n",
      "                           'deepscale_config': None,\n",
      "                           'deepspeed': True,\n",
      "                           'deepspeed_activation_checkpointing': True,\n",
      "                           'deepspeed_extra_args': {'comms_logger': {'debug': False,\n",
      "                                                                     'enabled': True,\n",
      "                                                                     'prof_all': True,\n",
      "                                                                     'verbose': False}},\n",
      "                           'deepspeed_mpi': False,\n",
      "                           'deepspeed_slurm': False,\n",
      "                           'detect_nvlink_pairs': False,\n",
      "                           'dim_att': None,\n",
      "                           'distributed_backend': 'nccl',\n",
      "                           'do_test': None,\n",
      "                           'do_train': None,\n",
      "                           'do_valid': None,\n",
      "                           'dpo_beta': 0.1,\n",
      "                           'dpo_fp32': True,\n",
      "                           'dpo_reference_free': False,\n",
      "                           'dump_state': False,\n",
      "                           'dynamic_loss_scale': True,\n",
      "                           'elasticity': None,\n",
      "                           'enable_expert_tensor_parallelism': False,\n",
      "                           'eod_mask_loss': False,\n",
      "                           'eval_interval': 30,\n",
      "                           'eval_iters': 2,\n",
      "                           'eval_results_prefix': '',\n",
      "                           'eval_tasks': ['hellaswag'],\n",
      "                           'exclude': None,\n",
      "                           'exit_interval': None,\n",
      "                           'expansion_factor': None,\n",
      "                           'expert_interval': 2,\n",
      "                           'extra_save_iters': None,\n",
      "                           'ffn_dim': None,\n",
      "                           'finetune': False,\n",
      "                           'flops_profiler': None,\n",
      "                           'force_multi': False,\n",
      "                           'fp16': {'enabled': True,\n",
      "                                    'fp16': True,\n",
      "                                    'hysteresis': 2,\n",
      "                                    'initial_scale_power': 12,\n",
      "                                    'loss_scale': 0,\n",
      "                                    'loss_scale_window': 1000,\n",
      "                                    'min_loss_scale': 1},\n",
      "                           'fp16_lm_cross_entropy': False,\n",
      "                           'fp32_allreduce': False,\n",
      "                           'git_hash': '73865bc',\n",
      "                           'global_num_gpus': 1,\n",
      "                           'gmlp_attn_dim': 64,\n",
      "                           'gpt_j_residual': False,\n",
      "                           'gpt_j_tied': False,\n",
      "                           'gradient_accumulation_steps': 1,\n",
      "                           'gradient_clipping': 1.0,\n",
      "                           'gradient_noise_scale_cpu_offload': False,\n",
      "                           'gradient_noise_scale_n_batches': 5,\n",
      "                           'gradient_predivide_factor': 1.0,\n",
      "                           'head_size': None,\n",
      "                           'hidden_dropout': 0.0,\n",
      "                           'hidden_size': 256,\n",
      "                           'hostfile': None,\n",
      "                           'hysteresis': 2,\n",
      "                           'include': None,\n",
      "                           'init_method': 'small_init',\n",
      "                           'init_method_std': 0.02,\n",
      "                           'intermediate_size': None,\n",
      "                           'is_pipe_parallel': False,\n",
      "                           'iteration': 800,\n",
      "                           'keep_last_n_checkpoints': None,\n",
      "                           'kto_beta': 0.1,\n",
      "                           'kto_desirable_weight': 1.0,\n",
      "                           'kto_fp32': True,\n",
      "                           'kto_undesirable_weight': 1.0,\n",
      "                           'launcher': 'pdsh',\n",
      "                           'layernorm_epsilon': 1e-05,\n",
      "                           'layernorm_fusion': False,\n",
      "                           'lazy_mpu_init': False,\n",
      "                           'load': 'checkpoints',\n",
      "                           'local_rank': 0,\n",
      "                           'log_dir': 'logs_gen',\n",
      "                           'log_grad_norm': False,\n",
      "                           'log_grad_pct_zeros': False,\n",
      "                           'log_gradient_noise_scale': False,\n",
      "                           'log_interval': 10,\n",
      "                           'log_optimizer_states': False,\n",
      "                           'log_param_norm': False,\n",
      "                           'loss_scale': None,\n",
      "                           'loss_scale_window': 1000.0,\n",
      "                           'lr': 0.001,\n",
      "                           'lr_decay_fraction': None,\n",
      "                           'lr_decay_iters': 800,\n",
      "                           'lr_decay_style': 'linear',\n",
      "                           'make_vocab_size_divisible_by': 128,\n",
      "                           'mamba_causal_conv_fusion': False,\n",
      "                           'mamba_inner_func_fusion': False,\n",
      "                           'mamba_selective_fp32_params': True,\n",
      "                           'mamba_selective_scan_fusion': False,\n",
      "                           'mamba_use_bias_in_conv': True,\n",
      "                           'mamba_use_bias_in_linears': False,\n",
      "                           'master_addr': None,\n",
      "                           'master_port': 29500,\n",
      "                           'max_position_embeddings': 512,\n",
      "                           'maximum_tokens': 102,\n",
      "                           'memory_profiling': False,\n",
      "                           'memory_profiling_path': None,\n",
      "                           'merge_file': None,\n",
      "                           'min_lr': 0.0001,\n",
      "                           'min_scale': 1.0,\n",
      "                           'mlp_multiple_of': 1,\n",
      "                           'mmap_warmup': False,\n",
      "                           'model_parallel_size': 1,\n",
      "                           'moe_eval_capacity_factor': 1.0,\n",
      "                           'moe_expert_parallel_size': 1,\n",
      "                           'moe_glu': False,\n",
      "                           'moe_jitter_eps': None,\n",
      "                           'moe_lbl_in_fp32': False,\n",
      "                           'moe_loss_coeff': 0.1,\n",
      "                           'moe_min_capacity': 4,\n",
      "                           'moe_num_experts': 1,\n",
      "                           'moe_token_dropping': False,\n",
      "                           'moe_top_k': 1,\n",
      "                           'moe_train_capacity_factor': 1.0,\n",
      "                           'moe_type': 'megablocks',\n",
      "                           'moe_use_residual': True,\n",
      "                           'mup_attn_temp': 1.0,\n",
      "                           'mup_embedding_mult': 1.0,\n",
      "                           'mup_init_scale': 1.0,\n",
      "                           'mup_output_temp': 1.0,\n",
      "                           'mup_rp_embedding_mult': 1.0,\n",
      "                           'mup_width_scale': 2,\n",
      "                           'neg_test_data_paths': None,\n",
      "                           'neg_test_label_data_paths': None,\n",
      "                           'neg_train_data_paths': None,\n",
      "                           'neg_train_label_data_paths': None,\n",
      "                           'neg_valid_data_paths': None,\n",
      "                           'neg_valid_label_data_paths': None,\n",
      "                           'no_load_optim': True,\n",
      "                           'no_load_rng': False,\n",
      "                           'no_save_optim': False,\n",
      "                           'no_save_rng': False,\n",
      "                           'no_ssh_check': False,\n",
      "                           'no_weight_tying': False,\n",
      "                           'norm': 'layernorm',\n",
      "                           'num_attention_heads': 4,\n",
      "                           'num_gpus': None,\n",
      "                           'num_kv_heads': None,\n",
      "                           'num_layers': 4,\n",
      "                           'num_nodes': -1,\n",
      "                           'num_samples': 10,\n",
      "                           'num_unique_layers': None,\n",
      "                           'num_workers': 1,\n",
      "                           'onnx_safe': False,\n",
      "                           'opt_pos_emb_offset': 0,\n",
      "                           'optimizer': {'params': {'lr': 0.0}},\n",
      "                           'optimizer_type': 'adam',\n",
      "                           'output_layer_init_method': 'wang_init',\n",
      "                           'output_layer_parallelism': 'column',\n",
      "                           'override_lr_scheduler': False,\n",
      "                           'pack_impl': 'packed',\n",
      "                           'padded_vocab_size': 512,\n",
      "                           'param_sharing_style': 'grouped',\n",
      "                           'partition_activations': False,\n",
      "                           'pipe_parallel_size': 0,\n",
      "                           'pipe_partition_method': 'type:transformer|mlp',\n",
      "                           'pos_emb': 'rotary',\n",
      "                           'pos_test_data_paths': None,\n",
      "                           'pos_test_label_data_paths': None,\n",
      "                           'pos_train_data_paths': None,\n",
      "                           'pos_train_label_data_paths': None,\n",
      "                           'pos_valid_data_paths': None,\n",
      "                           'pos_valid_label_data_paths': None,\n",
      "                           'precision': 'fp16',\n",
      "                           'precompute_model_name': None,\n",
      "                           'prescale_gradients': False,\n",
      "                           'profile': False,\n",
      "                           'profile_backward': False,\n",
      "                           'profile_step_start': 10,\n",
      "                           'profile_step_stop': 12,\n",
      "                           'prompt_end': '\\n',\n",
      "                           'rank': 0,\n",
      "                           'recompute': False,\n",
      "                           'return_logits': False,\n",
      "                           'rms_norm_epsilon': 1e-08,\n",
      "                           'rmsnorm_fusion': False,\n",
      "                           'rope_fusion': False,\n",
      "                           'rotary_emb_base': 10000,\n",
      "                           'rotary_pct': 1.0,\n",
      "                           'rotary_save_freqs_buffer': False,\n",
      "                           'rpe_max_distance': 128,\n",
      "                           'rpe_num_buckets': 32,\n",
      "                           's3_chunk_size': 104857600,\n",
      "                           's3_path': None,\n",
      "                           'sample_input_file': 'sample_input.txt',\n",
      "                           'sample_output_file': 'sample_output.txt',\n",
      "                           'save': 'checkpoints',\n",
      "                           'save_base_shapes': False,\n",
      "                           'scaled_masked_softmax_fusion': False,\n",
      "                           'scaled_upper_triang_masked_softmax_fusion': False,\n",
      "                           'scalenorm_epsilon': 1e-08,\n",
      "                           'scheduler': None,\n",
      "                           'seed': 1234,\n",
      "                           'seq_length': 512,\n",
      "                           'sequence_parallel': False,\n",
      "                           'short_seq_prob': 0.1,\n",
      "                           'sliding_window_width': None,\n",
      "                           'soft_prompt_tuning': None,\n",
      "                           'sparse_attention': None,\n",
      "                           'sparse_gradients': False,\n",
      "                           'sparsity_config': {},\n",
      "                           'split': '969, 30, 1',\n",
      "                           'steps_per_print': 10,\n",
      "                           'synchronize_each_layer': True,\n",
      "                           'temperature': 1.0,\n",
      "                           'tensorboard': None,\n",
      "                           'tensorboard_dir': 'tensorboard_gen',\n",
      "                           'test_data_paths': None,\n",
      "                           'test_data_weights': None,\n",
      "                           'test_label_data_paths': None,\n",
      "                           'test_reward_data_paths': None,\n",
      "                           'text_gen_type': 'unconditional',\n",
      "                           'tokenizer_type': 'CharLevelTokenizer',\n",
      "                           'top_k': 0,\n",
      "                           'top_p': 0.0,\n",
      "                           'train_batch_size': 8,\n",
      "                           'train_data_paths': None,\n",
      "                           'train_data_weights': None,\n",
      "                           'train_epochs': None,\n",
      "                           'train_impl': 'normal',\n",
      "                           'train_iters': 800,\n",
      "                           'train_label_data_paths': None,\n",
      "                           'train_micro_batch_size_per_gpu': 8,\n",
      "                           'train_reward_data_paths': None,\n",
      "                           'use_bias_in_attn_linear': True,\n",
      "                           'use_bias_in_mlp': True,\n",
      "                           'use_bias_in_norms': True,\n",
      "                           'use_bnb_optimizer': False,\n",
      "                           'use_checkpoint_lr_scheduler': False,\n",
      "                           'use_comet': None,\n",
      "                           'use_cpu_initialization': False,\n",
      "                           'use_flashattn_swiglu': False,\n",
      "                           'use_mup': False,\n",
      "                           'use_qk_layernorm': False,\n",
      "                           'use_shared_fs': True,\n",
      "                           'use_tutel': False,\n",
      "                           'use_wandb': False,\n",
      "                           'user_script': 'eval.py',\n",
      "                           'valid_data_paths': None,\n",
      "                           'valid_data_weights': None,\n",
      "                           'valid_label_data_paths': None,\n",
      "                           'valid_reward_data_paths': None,\n",
      "                           'vocab_file': None,\n",
      "                           'wall_clock_breakdown': True,\n",
      "                           'wandb': None,\n",
      "                           'wandb_group': None,\n",
      "                           'wandb_host': 'https://api.wandb.ai',\n",
      "                           'wandb_init_all_ranks': False,\n",
      "                           'wandb_project': 'neox',\n",
      "                           'wandb_team': None,\n",
      "                           'warmup': 0.01,\n",
      "                           'weight_by_num_documents': False,\n",
      "                           'weight_decay': 0.1,\n",
      "                           'weighted_sampler_alpha': 1.0,\n",
      "                           'world_size': 1,\n",
      "                           'z_loss': 0.0,\n",
      "                           'zero_allgather_bucket_size': 500000000,\n",
      "                           'zero_contiguous_gradients': True,\n",
      "                           'zero_optimization': {'allgather_bucket_size': 500000000,\n",
      "                                                 'allgather_partitions': True,\n",
      "                                                 'contiguous_gradients': True,\n",
      "                                                 'overlap_comm': True,\n",
      "                                                 'reduce_bucket_size': 500000000,\n",
      "                                                 'reduce_scatter': True,\n",
      "                                                 'stage': 1},\n",
      "                           'zero_reduce_bucket_size': 500000000,\n",
      "                           'zero_reduce_scatter': True,\n",
      "                           'zero_stage': 1},\n",
      "            'use_cache': False},\n",
      " 'configs': {'hellaswag': {'dataset_path': 'hellaswag',\n",
      "                           'description': '',\n",
      "                           'doc_to_choice': 'choices',\n",
      "                           'doc_to_target': '{{label}}',\n",
      "                           'doc_to_text': '{{query}}',\n",
      "                           'fewshot_delimiter': '\\n\\n',\n",
      "                           'group': ['multiple_choice'],\n",
      "                           'metadata': {'version': 1.0},\n",
      "                           'metric_list': [{'aggregation': 'mean',\n",
      "                                            'higher_is_better': True,\n",
      "                                            'metric': 'acc'},\n",
      "                                           {'aggregation': 'mean',\n",
      "                                            'higher_is_better': True,\n",
      "                                            'metric': 'acc_norm'}],\n",
      "                           'num_fewshot': 0,\n",
      "                           'output_type': 'multiple_choice',\n",
      "                           'process_docs': 'def process_docs(dataset: '\n",
      "                                           'datasets.Dataset) -> '\n",
      "                                           'datasets.Dataset:\\n'\n",
      "                                           '    def _process_doc(doc):\\n'\n",
      "                                           '        ctx = doc[\"ctx_a\"] + \" \" + '\n",
      "                                           'doc[\"ctx_b\"].capitalize()\\n'\n",
      "                                           '        out_doc = {\\n'\n",
      "                                           '            \"query\": '\n",
      "                                           'preprocess(doc[\"activity_label\"] + '\n",
      "                                           '\": \" + ctx),\\n'\n",
      "                                           '            \"choices\": '\n",
      "                                           '[preprocess(ending) for ending in '\n",
      "                                           'doc[\"endings\"]],\\n'\n",
      "                                           '            \"gold\": '\n",
      "                                           'int(doc[\"label\"]),\\n'\n",
      "                                           '        }\\n'\n",
      "                                           '        return out_doc\\n'\n",
      "                                           '\\n'\n",
      "                                           '    return '\n",
      "                                           'dataset.map(_process_doc)\\n',\n",
      "                           'repeats': 1,\n",
      "                           'should_decontaminate': False,\n",
      "                           'target_delimiter': ' ',\n",
      "                           'task': 'hellaswag',\n",
      "                           'training_split': 'train',\n",
      "                           'validation_split': 'validation'}},\n",
      " 'git_hash': '73865bc',\n",
      " 'n-shot': {'hellaswag': 0},\n",
      " 'results': {'hellaswag': {'acc,none': 0.4,\n",
      "                           'acc_norm,none': 0.4,\n",
      "                           'acc_norm_stderr,none': 0.16329931618554522,\n",
      "                           'acc_stderr,none': 0.16329931618554522}},\n",
      " 'versions': {'hellaswag': 1.0}}\n",
      "[2024-12-01 08:08:54,636] [INFO] [launch.py:347:main] Process 78272 exits successfully.\n",
      "{\"context\": \"\", \"text\": \"HEBIONO:\", \"length\": 8, \"finished\": true, \"message\": null, \"duration_seconds\": 0.4449276924133301}\n",
      "{\"context\": \"\", \"text\": \"Thirdly by loes: brief, you haste caple-short:\", \"length\": 46, \"finished\": true, \"message\": null, \"duration_seconds\": 0.17642927169799805}\n",
      "{\"context\": \"\", \"text\": \"Sets all forth thee, distressive death; and you:\", \"length\": 48, \"finished\": true, \"message\": null, \"duration_seconds\": 0.1887218952178955}\n",
      "{\"context\": \"\", \"text\": \"DUKE VINCENTIO:\", \"length\": 15, \"finished\": true, \"message\": null, \"duration_seconds\": 0.059146881103515625}\n",
      "{\"context\": \"\", \"text\": \"Be lues? and die, friends purpose when hone\", \"length\": 43, \"finished\": true, \"message\": null, \"duration_seconds\": 0.16297364234924316}\n",
      "{\"context\": \"\", \"text\": \"Your hands the row small well?\", \"length\": 30, \"finished\": true, \"message\": null, \"duration_seconds\": 0.1116030216217041}\n",
      "{\"context\": \"\", \"text\": \"whictlem, in night one?\", \"length\": 23, \"finished\": true, \"message\": null, \"duration_seconds\": 0.09055852890014648}\n",
      "{\"context\": \"\", \"text\": \"Ramerly, because, I can lang no little Roler.\", \"length\": 45, \"finished\": true, \"message\": null, \"duration_seconds\": 0.1740272045135498}\n",
      "{\"context\": \"\", \"text\": \"Good for ser! nay, I shall I stay be wast's ride.\", \"length\": 49, \"finished\": true, \"message\": null, \"duration_seconds\": 0.1929950714111328}\n",
      "{\"context\": \"\", \"text\": \"Lyband well your neight her lears a consey.\", \"length\": 43, \"finished\": true, \"message\": null, \"duration_seconds\": 0.1609330177307129}\n",
      "CPU times: user 1.21 s, sys: 208 ms, total: 1.42 s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This has issues if used during training -  The server socket has failed to bind to [::]:29500 (errno: 98 - Address already\n",
    "# This will write over the logs\n",
    "# python ./deepy.py eval.py -d configs your_configs.yml --eval_tasks task1 task2 ... taskn\n",
    "# NOTE this will prompt for permission to run a download script - would need an older datasetse library to avoid this\n",
    "%cd {GPTNeoXDir}\n",
    "!source {activate_script} && python ./deepy.py eval.py -d configs {gpt_neox_colabDir}/configs/shakespeare {gpt_neox_colabDir}/configs/shakespeare_gen --eval_tasks hellaswag\n",
    "!cat sample_output.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rb7AOL1NJ43e"
   },
   "source": [
    "# Inference with Hugging Face\n",
    "\n",
    "## Convert model to HF format\n",
    "Here we are converting our model to `HuggingFace Format`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VNdWrrkWfyT-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to the latest checkpoint: /content/gpt-neox/checkpoints/global_step800\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the path to the checkpoints directory\n",
    "checkpoints_dir = f\"{GPTNeoXDir}/checkpoints\"\n",
    "\n",
    "# Read the 'latest' file to get the latest checkpoint name\n",
    "with open(os.path.join(checkpoints_dir, \"latest\"), \"r\") as f:\n",
    "    latest_checkpoint_name = f.read().strip()\n",
    "\n",
    "# Construct the full path to the latest checkpoint directory\n",
    "latest_checkpoint_path = os.path.join(checkpoints_dir, latest_checkpoint_name)\n",
    "print(\"Path to the latest checkpoint:\", latest_checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rplkNclPXgkH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gpt-neox\n",
      "/content/gpt-neox/megatron/neox_arguments/arguments.py:1101: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert (\n",
      "/content/gpt-neox/megatron/neox_arguments/arguments.py:1110: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert (\n",
      "[2024-12-01 08:08:58,310] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Detected 'pipe-parallel-size' of 0, assuming model is saved as Sequential...\n",
      "> building CharLevelTokenizer tokenizer ...\n",
      " > padded vocab (size: 512) with 0 dummy tokens (new size: 512)\n",
      "Auto-detecting precision to save model into...\n",
      "Saving weights in fp16 precision...\n",
      "Detected MLP naming convention: new\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 287.10it/s]\n"
     ]
    }
   ],
   "source": [
    "#@title Convert last checkpoint to huggingface model\n",
    "%cd {GPTNeoXDir}\n",
    "!source {activate_script} && python ./tools/ckpts/convert_neox_to_hf.py --input_dir {latest_checkpoint_path} --config_file {gpt_neox_colabDir}/configs/shakespeare.yml --output_dir {gpt_neox_colabDir}/data/shakespeare --architecture neox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qra1qQtC2oiI"
   },
   "source": [
    "## Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01ZRN2IceM8a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/workspace/.venv/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n",
      "Generated text: Thou art thou come the days, The see the warer be see And to his shall me, And, he discant of shall The down the learness, I do lose the haste agains, The was not me to make And, let you thought it be\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, f\"{gpt_neox_colabDir}/my_env/lib/python3.10/site-packages\")\n",
    "\n",
    "from transformers import GPTNeoXForCausalLM\n",
    "import torch\n",
    "\n",
    "# Move to model directory\n",
    "%cd {gpt_neox_colabDir}\n",
    "\n",
    "# Assuming CharLevelTokenizer is properly imported and instantiated\n",
    "from src.gpt_neox_colab.CharLevelTokenizer import CharLevelTokenizer\n",
    "tokenizer = CharLevelTokenizer(vocab_size=512)\n",
    "\n",
    "# Load your model\n",
    "model_path = f\"{gpt_neox_colabDir}/data/shakespeare\"\n",
    "model = GPTNeoXForCausalLM.from_pretrained(model_path)\n",
    "\n",
    "# Define a simple char-level tokenizer if not provided\n",
    "def char_level_tokenize(text):\n",
    "    return tokenizer.tokenize(text)\n",
    "\n",
    "def char_level_detokenize(tokens):\n",
    "    return tokenizer.detokenize(tokens)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Prompt the user for input\n",
    "#input_text = input(\"Enter your prompt: \")\n",
    "input_text = \"Thou art\"\n",
    "\n",
    "# Tokenize and prepare input\n",
    "input_ids = torch.tensor([char_level_tokenize(input_text)], dtype=torch.long)\n",
    "attention_mask = torch.ones_like(input_ids)  # Create an attention mask for non-padded input\n",
    "\n",
    "# Generate text with specified pad_token_id and attention_mask\n",
    "with torch.no_grad():\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=200,          # Adjust this for desired output length\n",
    "        temperature=0.7,        # Controls creativity\n",
    "        top_k=50,               # Controls diversity\n",
    "        top_p=0.9,              # Nucleus sampling\n",
    "        num_return_sequences=1, # Number of sequences to return\n",
    "        pad_token_id=model.config.eos_token_id,  # Set pad_token_id explicitly\n",
    "        do_sample=True           # Enable sampling mode to use temperature and top_p\n",
    "    )\n",
    "\n",
    "# Decode and print the generated text\n",
    "generated_text = char_level_detokenize(output[0].tolist())\n",
    "print(\"Generated text:\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UNCboCsapOPa"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n        new Audio(\"https://upload.wikimedia.org/wikipedia/commons/e/e6/Coins_dropped_in_metallic_moneybox_0.ogg\").play()\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n        new Audio(\"https://upload.wikimedia.org/wikipedia/commons/e/e6/Coins_dropped_in_metallic_moneybox_0.ogg\").play()\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n        new Audio(\"https://upload.wikimedia.org/wikipedia/commons/e/e6/Coins_dropped_in_metallic_moneybox_0.ogg\").play()\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n        new Audio(\"https://upload.wikimedia.org/wikipedia/commons/e/e6/Coins_dropped_in_metallic_moneybox_0.ogg\").play()\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m     display(Javascript(\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124m        new Audio(\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://upload.wikimedia.org/wikipedia/commons/e/e6/Coins_dropped_in_metallic_moneybox_0.ogg\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m).play()\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m'''\u001b[39m))\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Wait for 30 seconds before replaying\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Javascript\n",
    "import time\n",
    "\n",
    "# Play the audio repeatedly\n",
    "while True:\n",
    "    display(Javascript('''\n",
    "        new Audio(\"https://upload.wikimedia.org/wikipedia/commons/e/e6/Coins_dropped_in_metallic_moneybox_0.ogg\").play()\n",
    "    '''))\n",
    "    time.sleep(30)  # Wait for 30 seconds before replaying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e60SXzNLiinb"
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "# Autplay does not work in VSCode\n",
    "IPython.display.Audio(filename=f\"{gpt_neox_colabDir}/notebooks/beep-01a.mp3\", autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uoOuzaRkiinb"
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "import numpy as np\n",
    "fs = 16000.\n",
    "# Autplay does not work in VSCode\n",
    "IPython.display.Audio(np.sin(2*np.pi*440*np.arange(1 * fs)/fs), rate=fs, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S8W3kedId_Bf"
   },
   "outputs": [],
   "source": [
    "# Here we could disconnect from the Colab GPU resource but we will lose all results\n",
    "#from google.colab import runtime\n",
    "#runtime.unassign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YmBmP2UE-amo"
   },
   "outputs": [],
   "source": [
    "input_text = input(\"Enter your prompt: \")\n",
    "\n",
    "# Tokenize and prepare input\n",
    "input_ids = torch.tensor([char_level_tokenize(input_text)], dtype=torch.long)\n",
    "attention_mask = torch.ones_like(input_ids)  # Create an attention mask for non-padded input\n",
    "\n",
    "# Generate text with specified pad_token_id and attention_mask\n",
    "with torch.no_grad():\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=200,          # Adjust this for desired output length\n",
    "        temperature=0.7,        # Controls creativity\n",
    "        top_k=50,               # Controls diversity\n",
    "        top_p=0.9,              # Nucleus sampling\n",
    "        num_return_sequences=1, # Number of sequences to return\n",
    "        pad_token_id=model.config.eos_token_id,  # Set pad_token_id explicitly\n",
    "        do_sample=True           # Enable sampling mode to use temperature and top_p\n",
    "    )\n",
    "\n",
    "# Decode and print the generated text\n",
    "generated_text = char_level_detokenize(output[0].tolist())\n",
    "print(\"Generated text:\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ASPRn9EMWzBL"
   },
   "outputs": [],
   "source": [
    "UPDATE_VENV = False\n",
    "if not USE_VENV and UPDATE_VENV:\n",
    "  %cd {gpt_neox_colabDir}\n",
    "  %pip install dvc[s3]\n",
    "  !dvc add .venv.tar.gz\n",
    "  !git add .venv.tar.gz.dvc .gitignore\n",
    "  !git commit -m \"Add .venv.tar.gz.dvc to DVC\"\n",
    "  !dvc push -q"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
