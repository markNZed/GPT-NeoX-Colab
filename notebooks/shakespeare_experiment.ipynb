{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/markNZed/GPT-NeoX-Colab/blob/main/notebooks/shakespeare_experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flp2Dht6ytqE"
      },
      "source": [
        "# Experiment\n",
        "This is a demonstration of how experiments can be run using DagsHub and MLflow.\n",
        "We will train three different versions of the tiny LLM using different batch sizes and compare the results.\n",
        "\n",
        "## ToDo\n",
        "- Shorten the training time for testing\n",
        "- Run tests in parallel\n",
        "- Extract functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LECzxKWK8CyS"
      },
      "source": [
        "## Login to Dagshub\n",
        "To avoid requirest in the middle of the experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wxd2wfpq1F9u",
        "outputId": "9eff51b9-ec95-4d97-8ce8-d08c81630ef7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/251.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.7/251.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.6/82.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "import os\n",
        "%pip install -q dagshub\n",
        "import dagshub\n",
        "try:\n",
        "  from google.colab import userdata\n",
        "  os.environ[\"DAGSHUB_USER_TOKEN\"] = userdata.get(\"DAGSHUB_USER_TOKEN\")\n",
        "except:\n",
        "  pass\n",
        "try:\n",
        "  if os.environ[\"DAGSHUB_USER_TOKEN\"]:\n",
        "    pass\n",
        "except:\n",
        "  os.environ[\"DAGSHUB_USER_TOKEN\"] = dagshub.auth.get_token()\n",
        "dagshub.auth.add_app_token(token=os.environ[\"DAGSHUB_USER_TOKEN\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Iega62GjytqH"
      },
      "outputs": [],
      "source": [
        "#@title Setup paths\n",
        "# We could modify these paths to \"stub\" behavior for test/dev\n",
        "# A file like .ipython/profile_default/startup/10-test.py could restore these vars\n",
        "workspaceDir = \"/content\"\n",
        "GPTNeoXDirName = \"gpt-neox\"\n",
        "GPTNeoXDir = f\"{workspaceDir}/{GPTNeoXDirName}\"\n",
        "GPTNeoXColabDirName = \"GPT-NeoX-Colab\"\n",
        "GPTNeoXColabDir = f\"{workspaceDir}/{GPTNeoXColabDirName}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUxVImVvytqL",
        "outputId": "8049fd36-329d-43fa-8568-28fa345c557c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'GPT-NeoX-Colab'...\n",
            "remote: Enumerating objects: 1227, done.\u001b[K\n",
            "remote: Counting objects: 100% (175/175), done.\u001b[K\n",
            "remote: Compressing objects: 100% (125/125), done.\u001b[K\n",
            "remote: Total 1227 (delta 95), reused 98 (delta 46), pack-reused 1052 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1227/1227), 13.82 MiB | 19.82 MiB/s, done.\n",
            "Resolving deltas: 100% (672/672), done.\n",
            "/content/GPT-NeoX-Colab\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.5/101.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.0/426.0 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.6/46.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.4/77.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.5/456.5 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m367.6/367.6 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.9/198.9 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m901.4/901.4 kB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m548.7/548.7 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m569.1/569.1 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.1/113.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m722.2/722.2 kB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for configobj (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pysftp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for GPTNeoXColab (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Data retrieval successful.\n",
            "Data retrieval successful.\n",
            "CPU times: user 7.02 s, sys: 842 ms, total: 7.86 s\n",
            "Wall time: 2min 41s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "#@title Clone GPT-NeoX-Colab\n",
        "%cd {workspaceDir}\n",
        "# Don't use --depth 1 because that does not play nice with git-annex\n",
        "!git clone https://github.com/markNZed/GPT-NeoX-Colab.git\n",
        "%cd {GPTNeoXColabDir}\n",
        "%pip install -q -r requirements_colab.txt\n",
        "%pip install -q .\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "load_dotenv(f\"{GPTNeoXColabDir}/.env\")\n",
        "import GPTNeoXColab\n",
        "GPTNeoXColab.utils.colab.fetch_data(\"data/shakespeare/shakespeare_text_document.bin\")\n",
        "GPTNeoXColab.utils.colab.fetch_data(\"data/shakespeare/shakespeare_text_document.idx\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvpVaIbLytqM",
        "outputId": "0cf8040c-452a-4792-9756-9bdc78ee5d06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'gpt-neox'...\n",
            "remote: Enumerating objects: 296, done.\u001b[K\n",
            "remote: Counting objects: 100% (296/296), done.\u001b[K\n",
            "remote: Compressing objects: 100% (231/231), done.\u001b[K\n",
            "remote: Total 296 (delta 74), reused 136 (delta 43), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (296/296), 2.50 MiB | 24.38 MiB/s, done.\n",
            "Resolving deltas: 100% (74/74), done.\n",
            "CPU times: user 15.7 ms, sys: 0 ns, total: 15.7 ms\n",
            "Wall time: 725 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "#@title Clone GPT-NeoX\n",
        "%cd {workspaceDir}\n",
        "!git clone --depth 1 https://github.com/EleutherAI/gpt-neox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6EJBRBSpiSXF"
      },
      "outputs": [],
      "source": [
        "!mkdir -p {GPTNeoXDir}/processed_data\n",
        "!cp {GPTNeoXColabDir}/data/shakespeare/shakespeare_text_document.* {GPTNeoXDir}/processed_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WH8eetUBytqN",
        "outputId": "ae88f2dd-0e35-45d3-ed82-949fde8b2c31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Downloading my_env.tar.gz\n",
            "Unzipping my_env.tar.gz\n",
            "Untarring my_env.tar.gz\n",
            "CPU times: user 10.8 s, sys: 8.48 s, total: 19.3 s\n",
            "Wall time: 2min 39s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "#@title Load prebuilt Python environment for Colab\n",
        "import GPTNeoXColab\n",
        "%cd {workspaceDir}\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    GPTNeoXColab.utils.colab.download_my_env()\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTyERIkj8elu"
      },
      "source": [
        "# Run Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "umfYbg3TytqJ"
      },
      "outputs": [],
      "source": [
        "import GPTNeoXColab\n",
        "import os\n",
        "from pathlib import Path\n",
        "ROOT_DIR = GPTNeoXColab.utils.colab.find_project_root()\n",
        "RELATIVE_ROOT_DIR = os.path.relpath(ROOT_DIR, Path.cwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6PTFQWG08tKv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import glob\n",
        "import time\n",
        "\n",
        "# File to store the last read position (persistence between script runs)\n",
        "file_position = 0\n",
        "# Regular expression to match \"iteration <number> / <total>\"\n",
        "iteration_pattern = re.compile(r\"iteration\\s+(\\d+)\\s*/\\s*\\d+\")\n",
        "\n",
        "def get_latest_file(dir, pattern = \"*_stdout.txt\"):\n",
        "  # Define the log directory and pattern for log files\n",
        "  glob_pattern = os.path.join(dir, pattern)\n",
        "  # Get the list of log files that match the pattern\n",
        "  files = glob.glob(glob_pattern)\n",
        "  # Ensure there are log files in the directory\n",
        "  if files:\n",
        "      # Find the latest log file based on modification time\n",
        "      file = max(files, key=os.path.getmtime)\n",
        "      print(\"Latest file:\", file)\n",
        "  else:\n",
        "      file = None\n",
        "      print(\"No files found. Waiting and retrying.\")\n",
        "      time.sleep(10)  # Check every X seconds\n",
        "      file = get_latest_file(dir, pattern)\n",
        "  return file\n",
        "\n",
        "def read_new_iterations(latest_log):\n",
        "    global file_position\n",
        "    # Open the log file and seek to the last position\n",
        "    with open(latest_log, \"r\") as file:\n",
        "        file.seek(file_position)\n",
        "        # Read new lines\n",
        "        new_lines = file.readlines()\n",
        "        file_position = file.tell()\n",
        "        # Process lines containing \"iteration\"\n",
        "        last_match = None\n",
        "        for line in new_lines:\n",
        "            match = iteration_pattern.search(line)\n",
        "            if match:\n",
        "                last_match = match\n",
        "        if last_match:\n",
        "            # Extract the iteration count from the regex match\n",
        "            iteration_count = int(last_match.group(1))\n",
        "            print(f\"{iteration_count} iterations\")\n",
        "\n",
        "# Function to check if the process is running\n",
        "def is_process_running(pid):\n",
        "    try:\n",
        "        os.kill(pid, 0)  # Sending signal 0 to check if the process exists\n",
        "        return True\n",
        "    except OSError:\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
        "import os\n",
        "\n",
        "def get_scalar_from_tensorboard(file, key):\n",
        "    # Load TensorBoard events\n",
        "    event_acc = EventAccumulator(file)\n",
        "    event_acc.Reload()\n",
        "    print(event_acc.Tags())\n",
        "    # Extract loss scalar events\n",
        "    if key in event_acc.Tags().get('scalars', []):\n",
        "        events = event_acc.Scalars(key)\n",
        "        value = events[-1].value  # Get the last logged value\n",
        "        return value\n",
        "    else:\n",
        "        print(f\"{key} not found in TensorBoard logs.\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "XtEiZxZBV2iD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iaBFYofFytqP",
        "outputId": "d3808202-8856-46ec-9b8b-bf2eec702aaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gpt-neox\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Accessing as MarkNZed\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as MarkNZed\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Initialized MLflow to track repo \u001b[32m\"MarkNZed/GPT-NeoX-Colab\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"MarkNZed/GPT-NeoX-Colab\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Repository MarkNZed/GPT-NeoX-Colab initialized!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository MarkNZed/GPT-NeoX-Colab initialized!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/hydra/plugins/config_source.py:125: UserWarning: Support for .yml files is deprecated. Use .yaml extension for Hydra config files\n",
            "  deprecation_warning(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train_micro_batch_size_per_gpu': 4, 'train_iters': 5120, 'lr_decay_iters': 5120, 'save': 'experiments/experiment1/checkpoints', 'load': 'experiments/experiment1/checkpoints', 'tensorboard_dir': 'experiments/experiment1/tensorboard', 'log_dir': 'experiments/experiment1/logs'}\n",
            "Running experiment: experiment1\n",
            "Running command: nohup bash -c \"source /content/my_env/bin/activate &&         cd /content/gpt-neox &&         python ./deepy.py train.py --conf_dir /tmp/tmp86sxyhmc         temp_config\" & echo $! > train_process.pid\n",
            "Training initiated.\n",
            "Waiting for train_process.pid to be created...\n",
            "PID: 3461\n",
            "Latest file: /content/gpt-neox/experiments/experiment1/logs/01f814ec6246_stdout.txt\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "480 iterations\n",
            "Training is still running...\n",
            "1170 iterations\n",
            "Training is still running...\n",
            "1850 iterations\n",
            "Training is still running...\n",
            "2510 iterations\n",
            "Training is still running...\n",
            "3190 iterations\n",
            "Training is still running...\n",
            "3860 iterations\n",
            "Training is still running...\n",
            "4530 iterations\n",
            "Training is still running...\n",
            "5120 iterations\n",
            "Training is still running...\n",
            "Training has finished.\n",
            "Latest file: /content/gpt-neox/experiments/experiment1/tensorboard/events.out.tfevents.1731411064.01f814ec6246.3504.0\n",
            "{'images': [], 'audio': [], 'histograms': [], 'scalars': ['timers/forward', 'timers/backward', 'timers/backward-backward', 'timers/backward-allreduce', 'timers/optimizer', 'timers/batch generator', 'train/learning_rate', 'train/lm_loss', 'train/loss_scale', 'runtime/samples_per_sec', 'runtime/iteration_time', 'runtime/flops_per_sec_per_gpu', 'validation/lm_loss', 'validation/lm_loss_ppl', 'test/lm_loss', 'test/lm_loss_ppl'], 'distributions': [], 'tensors': ['distributed_backend/text_summary', 'local_rank/text_summary', 'rank/text_summary', 'lazy_mpu_init/text_summary', 'short_seq_prob/text_summary', 'eod_mask_loss/text_summary', 'adlr_autoresume/text_summary', 'adlr_autoresume_interval/text_summary', 'seed/text_summary', 'onnx_safe/text_summary', 'deepscale/text_summary', 'deepscale_config/text_summary', 'deepspeed_mpi/text_summary', 'deepspeed_slurm/text_summary', 'user_script/text_summary', 'iteration/text_summary', 'do_train/text_summary', 'do_valid/text_summary', 'do_test/text_summary', 'global_num_gpus/text_summary', 'text_gen_type/text_summary', 'precompute_model_name/text_summary', 'temperature/text_summary', 'top_p/text_summary', 'top_k/text_summary', 'return_logits/text_summary', 'maximum_tokens/text_summary', 'prompt_end/text_summary', 'sample_input_file/text_summary', 'sample_output_file/text_summary', 'num_samples/text_summary', 'recompute/text_summary', 'eval_results_prefix/text_summary', 'eval_tasks/text_summary', 'moe_top_k/text_summary', 'use_tutel/text_summary', 'moe_num_experts/text_summary', 'moe_loss_coeff/text_summary', 'moe_train_capacity_factor/text_summary', 'moe_eval_capacity_factor/text_summary', 'moe_min_capacity/text_summary', 'moe_token_dropping/text_summary', 'create_moe_param_group/text_summary', 'moe_use_residual/text_summary', 'moe_expert_parallel_size/text_summary', 'moe_type/text_summary', 'moe_glu/text_summary', 'moe_lbl_in_fp32/text_summary', 'moe_jitter_eps/text_summary', 'enable_expert_tensor_parallelism/text_summary', 'use_wandb/text_summary', 'wandb_group/text_summary', 'wandb_team/text_summary', 'wandb_project/text_summary', 'wandb_host/text_summary', 'wandb_init_all_ranks/text_summary', 'git_hash/text_summary', 'log_dir/text_summary', 'tensorboard_dir/text_summary', 'use_comet/text_summary', 'comet_workspace/text_summary', 'comet_project/text_summary', 'comet_experiment_name/text_summary', 'comet_tags/text_summary', 'comet_others/text_summary', 'comet_experiment/text_summary', 'log_interval/text_summary', 'log_grad_pct_zeros/text_summary', 'log_param_norm/text_summary', 'log_grad_norm/text_summary', 'log_optimizer_states/text_summary', 'log_gradient_noise_scale/text_summary', 'gradient_noise_scale_n_batches/text_summary', 'gradient_noise_scale_cpu_offload/text_summary', 'memory_profiling/text_summary', 'memory_profiling_path/text_summary', 'profile/text_summary', 'profile_step_start/text_summary', 'profile_step_stop/text_summary', 'pipe_parallel_size/text_summary', 'model_parallel_size/text_summary', 'pipe_partition_method/text_summary', 'world_size/text_summary', 'is_pipe_parallel/text_summary', 'sequence_parallel/text_summary', 'expert_interval/text_summary', 'data_path/text_summary', 'use_shared_fs/text_summary', 'train_data_paths/text_summary', 'train_label_data_paths/text_summary', 'train_reward_data_paths/text_summary', 'test_data_paths/text_summary', 'test_label_data_paths/text_summary', 'test_reward_data_paths/text_summary', 'valid_data_paths/text_summary', 'valid_label_data_paths/text_summary', 'valid_reward_data_paths/text_summary', 'pos_train_data_paths/text_summary', 'neg_train_data_paths/text_summary', 'pos_train_label_data_paths/text_summary', 'neg_train_label_data_paths/text_summary', 'pos_valid_data_paths/text_summary', 'neg_valid_data_paths/text_summary', 'pos_valid_label_data_paths/text_summary', 'neg_valid_label_data_paths/text_summary', 'pos_test_data_paths/text_summary', 'neg_test_data_paths/text_summary', 'pos_test_label_data_paths/text_summary', 'neg_test_label_data_paths/text_summary', 'train_data_weights/text_summary', 'valid_data_weights/text_summary', 'test_data_weights/text_summary', 'weight_by_num_documents/text_summary', 'weighted_sampler_alpha/text_summary', 'data_impl/text_summary', 'pack_impl/text_summary', 'dataset_impl/text_summary', 'train_impl/text_summary', 'dpo_fp32/text_summary', 'dpo_reference_free/text_summary', 'dpo_beta/text_summary', 'kto_fp32/text_summary', 'kto_desirable_weight/text_summary', 'kto_undesirable_weight/text_summary', 'z_loss/text_summary', 'kto_beta/text_summary', 'allow_chopped/text_summary', 'mmap_warmup/text_summary', 'save/text_summary', 's3_path/text_summary', 's3_chunk_size/text_summary', 'config_files/text_summary', 'load/text_summary', 'checkpoint_validation_with_forward_pass/text_summary', 'checkpoint_scale/text_summary', 'checkpoint_factor/text_summary', 'extra_save_iters/text_summary', 'no_save_optim/text_summary', 'no_save_rng/text_summary', 'no_load_optim/text_summary', 'no_load_rng/text_summary', 'finetune/text_summary', 'batch_size/text_summary', 'train_iters/text_summary', 'train_epochs/text_summary', 'eval_iters/text_summary', 'keep_last_n_checkpoints/text_summary', 'eval_interval/text_summary', 'split/text_summary', 'vocab_file/text_summary', 'merge_file/text_summary', 'num_workers/text_summary', 'exit_interval/text_summary', 'attention_dropout/text_summary', 'hidden_dropout/text_summary', 'weight_decay/text_summary', 'checkpoint_activations/text_summary', 'checkpoint_num_layers/text_summary', 'deepspeed_activation_checkpointing/text_summary', 'contiguous_checkpointing/text_summary', 'checkpoint_in_cpu/text_summary', 'synchronize_each_layer/text_summary', 'profile_backward/text_summary', 'partition_activations/text_summary', 'clip_grad/text_summary', 'hysteresis/text_summary', 'dynamic_loss_scale/text_summary', 'loss_scale/text_summary', 'loss_scale_window/text_summary', 'min_scale/text_summary', 'char_level_ppl/text_summary', 'use_mup/text_summary', 'coord_check/text_summary', 'save_base_shapes/text_summary', 'base_shapes_file/text_summary', 'mup_init_scale/text_summary', 'mup_attn_temp/text_summary', 'mup_output_temp/text_summary', 'mup_embedding_mult/text_summary', 'mup_rp_embedding_mult/text_summary', 'mup_width_scale/text_summary', 'tokenizer_type/text_summary', 'padded_vocab_size/text_summary', 'optimizer_type/text_summary', 'use_bnb_optimizer/text_summary', 'zero_stage/text_summary', 'zero_reduce_scatter/text_summary', 'zero_contiguous_gradients/text_summary', 'zero_reduce_bucket_size/text_summary', 'zero_allgather_bucket_size/text_summary', 'lr/text_summary', 'lr_decay_style/text_summary', 'lr_decay_iters/text_summary', 'lr_decay_fraction/text_summary', 'min_lr/text_summary', 'warmup/text_summary', 'override_lr_scheduler/text_summary', 'use_checkpoint_lr_scheduler/text_summary', 'precision/text_summary', 'num_layers/text_summary', 'hidden_size/text_summary', 'intermediate_size/text_summary', 'mlp_multiple_of/text_summary', 'expansion_factor/text_summary', 'num_attention_heads/text_summary', 'num_kv_heads/text_summary', 'seq_length/text_summary', 'sliding_window_width/text_summary', 'max_position_embeddings/text_summary', 'norm/text_summary', 'layernorm_fusion/text_summary', 'rmsnorm_fusion/text_summary', 'use_qk_layernorm/text_summary', 'layernorm_epsilon/text_summary', 'rms_norm_epsilon/text_summary', 'scalenorm_epsilon/text_summary', 'pos_emb/text_summary', 'rpe_num_buckets/text_summary', 'rpe_max_distance/text_summary', 'opt_pos_emb_offset/text_summary', 'no_weight_tying/text_summary', 'attention_config/text_summary', 'sparsity_config/text_summary', 'num_unique_layers/text_summary', 'param_sharing_style/text_summary', 'make_vocab_size_divisible_by/text_summary', 'activation/text_summary', 'use_flashattn_swiglu/text_summary', 'scaled_upper_triang_masked_softmax_fusion/text_summary', 'scaled_masked_softmax_fusion/text_summary', 'bias_gelu_fusion/text_summary', 'bias_dropout_fusion/text_summary', 'rope_fusion/text_summary', 'fp16_lm_cross_entropy/text_summary', 'init_method_std/text_summary', 'apply_query_key_layer_scaling/text_summary', 'use_cpu_initialization/text_summary', 'attention_softmax_in_fp32/text_summary', 'rotary_pct/text_summary', 'rotary_emb_base/text_summary', 'rotary_save_freqs_buffer/text_summary', 'init_method/text_summary', 'output_layer_init_method/text_summary', 'gmlp_attn_dim/text_summary', 'gpt_j_residual/text_summary', 'gpt_j_tied/text_summary', 'use_bias_in_norms/text_summary', 'use_bias_in_attn_linear/text_summary', 'use_bias_in_mlp/text_summary', 'soft_prompt_tuning/text_summary', 'mamba_selective_scan_fusion/text_summary', 'mamba_causal_conv_fusion/text_summary', 'mamba_inner_func_fusion/text_summary', 'mamba_selective_fp32_params/text_summary', 'mamba_use_bias_in_conv/text_summary', 'mamba_use_bias_in_linears/text_summary', 'output_layer_parallelism/text_summary', 'dim_att/text_summary', 'head_size/text_summary', 'ffn_dim/text_summary', 'deepspeed/text_summary', 'train_batch_size/text_summary', 'train_micro_batch_size_per_gpu/text_summary', 'gradient_accumulation_steps/text_summary', 'optimizer/text_summary', 'scheduler/text_summary', 'fp32_allreduce/text_summary', 'prescale_gradients/text_summary', 'gradient_predivide_factor/text_summary', 'sparse_gradients/text_summary', 'fp16/text_summary', 'bf16/text_summary', 'amp/text_summary', 'gradient_clipping/text_summary', 'zero_optimization/text_summary', 'curriculum_learning/text_summary', 'curriculum_seqlen/text_summary', 'steps_per_print/text_summary', 'wall_clock_breakdown/text_summary', 'dump_state/text_summary', 'flops_profiler/text_summary', 'communication_data_type/text_summary', 'autotuning/text_summary', 'activation_checkpointing/text_summary', 'sparse_attention/text_summary', 'data_efficiency/text_summary', 'tensorboard/text_summary', 'wandb/text_summary', 'csv_monitor/text_summary', 'elasticity/text_summary', 'comms_logger/text_summary', 'compression_training/text_summary', 'checkpoint/text_summary', 'data_types/text_summary', 'deepspeed_extra_args/text_summary', 'hostfile/text_summary', 'include/text_summary', 'exclude/text_summary', 'num_nodes/text_summary', 'num_gpus/text_summary', 'master_port/text_summary', 'master_addr/text_summary', 'launcher/text_summary', 'force_multi/text_summary', 'detect_nvlink_pairs/text_summary', 'autotuning_run/text_summary', 'no_ssh_check/text_summary', 'comment/text_summary', 'account/text_summary', 'tokenizer/text_summary', 'tensorboard_writer/text_summary'], 'graph': False, 'meta_graph': False, 'run_metadata': []}\n",
            "Logging metric test/lm_loss 1.4527772665023804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/11/12 11:36:40 INFO mlflow.tracking._tracking_service.client: 🏃 View run merciful-dove-136 at: https://dagshub.com/MarkNZed/GPT-NeoX-Colab.mlflow/#/experiments/6/runs/5e6ab6ff14dd44328cb1b11abe4de6d6.\n",
            "2024/11/12 11:36:40 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dagshub.com/MarkNZed/GPT-NeoX-Colab.mlflow/#/experiments/6.\n",
            "/usr/local/lib/python3.10/dist-packages/hydra/plugins/config_source.py:125: UserWarning: Support for .yml files is deprecated. Use .yaml extension for Hydra config files\n",
            "  deprecation_warning(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train_micro_batch_size_per_gpu': 64, 'train_iters': 320, 'lr_decay_iters': 320, 'save': 'experiments/experiment2/checkpoints', 'load': 'experiments/experiment2/checkpoints', 'tensorboard_dir': 'experiments/experiment2/tensorboard', 'log_dir': 'experiments/experiment2/logs'}\n",
            "Running experiment: experiment2\n",
            "Running command: nohup bash -c \"source /content/my_env/bin/activate &&         cd /content/gpt-neox &&         python ./deepy.py train.py --conf_dir /tmp/tmp8bg4qhql         temp_config\" & echo $! > train_process.pid\n",
            "Training initiated.\n",
            "Waiting for train_process.pid to be created...\n",
            "PID: 5055\n",
            "Latest file: /content/gpt-neox/experiments/experiment2/logs/01f814ec6246_stdout.txt\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training has finished.\n",
            "Latest file: /content/gpt-neox/experiments/experiment2/tensorboard/events.out.tfevents.1731411411.01f814ec6246.5092.0\n",
            "{'images': [], 'audio': [], 'histograms': [], 'scalars': ['timers/forward', 'timers/backward', 'timers/backward-backward', 'timers/backward-allreduce', 'timers/optimizer', 'timers/batch generator', 'train/learning_rate', 'train/lm_loss', 'train/loss_scale', 'runtime/samples_per_sec', 'runtime/iteration_time', 'runtime/flops_per_sec_per_gpu', 'validation/lm_loss', 'validation/lm_loss_ppl', 'test/lm_loss', 'test/lm_loss_ppl'], 'distributions': [], 'tensors': ['distributed_backend/text_summary', 'local_rank/text_summary', 'rank/text_summary', 'lazy_mpu_init/text_summary', 'short_seq_prob/text_summary', 'eod_mask_loss/text_summary', 'adlr_autoresume/text_summary', 'adlr_autoresume_interval/text_summary', 'seed/text_summary', 'onnx_safe/text_summary', 'deepscale/text_summary', 'deepscale_config/text_summary', 'deepspeed_mpi/text_summary', 'deepspeed_slurm/text_summary', 'user_script/text_summary', 'iteration/text_summary', 'do_train/text_summary', 'do_valid/text_summary', 'do_test/text_summary', 'global_num_gpus/text_summary', 'text_gen_type/text_summary', 'precompute_model_name/text_summary', 'temperature/text_summary', 'top_p/text_summary', 'top_k/text_summary', 'return_logits/text_summary', 'maximum_tokens/text_summary', 'prompt_end/text_summary', 'sample_input_file/text_summary', 'sample_output_file/text_summary', 'num_samples/text_summary', 'recompute/text_summary', 'eval_results_prefix/text_summary', 'eval_tasks/text_summary', 'moe_top_k/text_summary', 'use_tutel/text_summary', 'moe_num_experts/text_summary', 'moe_loss_coeff/text_summary', 'moe_train_capacity_factor/text_summary', 'moe_eval_capacity_factor/text_summary', 'moe_min_capacity/text_summary', 'moe_token_dropping/text_summary', 'create_moe_param_group/text_summary', 'moe_use_residual/text_summary', 'moe_expert_parallel_size/text_summary', 'moe_type/text_summary', 'moe_glu/text_summary', 'moe_lbl_in_fp32/text_summary', 'moe_jitter_eps/text_summary', 'enable_expert_tensor_parallelism/text_summary', 'use_wandb/text_summary', 'wandb_group/text_summary', 'wandb_team/text_summary', 'wandb_project/text_summary', 'wandb_host/text_summary', 'wandb_init_all_ranks/text_summary', 'git_hash/text_summary', 'log_dir/text_summary', 'tensorboard_dir/text_summary', 'use_comet/text_summary', 'comet_workspace/text_summary', 'comet_project/text_summary', 'comet_experiment_name/text_summary', 'comet_tags/text_summary', 'comet_others/text_summary', 'comet_experiment/text_summary', 'log_interval/text_summary', 'log_grad_pct_zeros/text_summary', 'log_param_norm/text_summary', 'log_grad_norm/text_summary', 'log_optimizer_states/text_summary', 'log_gradient_noise_scale/text_summary', 'gradient_noise_scale_n_batches/text_summary', 'gradient_noise_scale_cpu_offload/text_summary', 'memory_profiling/text_summary', 'memory_profiling_path/text_summary', 'profile/text_summary', 'profile_step_start/text_summary', 'profile_step_stop/text_summary', 'pipe_parallel_size/text_summary', 'model_parallel_size/text_summary', 'pipe_partition_method/text_summary', 'world_size/text_summary', 'is_pipe_parallel/text_summary', 'sequence_parallel/text_summary', 'expert_interval/text_summary', 'data_path/text_summary', 'use_shared_fs/text_summary', 'train_data_paths/text_summary', 'train_label_data_paths/text_summary', 'train_reward_data_paths/text_summary', 'test_data_paths/text_summary', 'test_label_data_paths/text_summary', 'test_reward_data_paths/text_summary', 'valid_data_paths/text_summary', 'valid_label_data_paths/text_summary', 'valid_reward_data_paths/text_summary', 'pos_train_data_paths/text_summary', 'neg_train_data_paths/text_summary', 'pos_train_label_data_paths/text_summary', 'neg_train_label_data_paths/text_summary', 'pos_valid_data_paths/text_summary', 'neg_valid_data_paths/text_summary', 'pos_valid_label_data_paths/text_summary', 'neg_valid_label_data_paths/text_summary', 'pos_test_data_paths/text_summary', 'neg_test_data_paths/text_summary', 'pos_test_label_data_paths/text_summary', 'neg_test_label_data_paths/text_summary', 'train_data_weights/text_summary', 'valid_data_weights/text_summary', 'test_data_weights/text_summary', 'weight_by_num_documents/text_summary', 'weighted_sampler_alpha/text_summary', 'data_impl/text_summary', 'pack_impl/text_summary', 'dataset_impl/text_summary', 'train_impl/text_summary', 'dpo_fp32/text_summary', 'dpo_reference_free/text_summary', 'dpo_beta/text_summary', 'kto_fp32/text_summary', 'kto_desirable_weight/text_summary', 'kto_undesirable_weight/text_summary', 'z_loss/text_summary', 'kto_beta/text_summary', 'allow_chopped/text_summary', 'mmap_warmup/text_summary', 'save/text_summary', 's3_path/text_summary', 's3_chunk_size/text_summary', 'config_files/text_summary', 'load/text_summary', 'checkpoint_validation_with_forward_pass/text_summary', 'checkpoint_scale/text_summary', 'checkpoint_factor/text_summary', 'extra_save_iters/text_summary', 'no_save_optim/text_summary', 'no_save_rng/text_summary', 'no_load_optim/text_summary', 'no_load_rng/text_summary', 'finetune/text_summary', 'batch_size/text_summary', 'train_iters/text_summary', 'train_epochs/text_summary', 'eval_iters/text_summary', 'keep_last_n_checkpoints/text_summary', 'eval_interval/text_summary', 'split/text_summary', 'vocab_file/text_summary', 'merge_file/text_summary', 'num_workers/text_summary', 'exit_interval/text_summary', 'attention_dropout/text_summary', 'hidden_dropout/text_summary', 'weight_decay/text_summary', 'checkpoint_activations/text_summary', 'checkpoint_num_layers/text_summary', 'deepspeed_activation_checkpointing/text_summary', 'contiguous_checkpointing/text_summary', 'checkpoint_in_cpu/text_summary', 'synchronize_each_layer/text_summary', 'profile_backward/text_summary', 'partition_activations/text_summary', 'clip_grad/text_summary', 'hysteresis/text_summary', 'dynamic_loss_scale/text_summary', 'loss_scale/text_summary', 'loss_scale_window/text_summary', 'min_scale/text_summary', 'char_level_ppl/text_summary', 'use_mup/text_summary', 'coord_check/text_summary', 'save_base_shapes/text_summary', 'base_shapes_file/text_summary', 'mup_init_scale/text_summary', 'mup_attn_temp/text_summary', 'mup_output_temp/text_summary', 'mup_embedding_mult/text_summary', 'mup_rp_embedding_mult/text_summary', 'mup_width_scale/text_summary', 'tokenizer_type/text_summary', 'padded_vocab_size/text_summary', 'optimizer_type/text_summary', 'use_bnb_optimizer/text_summary', 'zero_stage/text_summary', 'zero_reduce_scatter/text_summary', 'zero_contiguous_gradients/text_summary', 'zero_reduce_bucket_size/text_summary', 'zero_allgather_bucket_size/text_summary', 'lr/text_summary', 'lr_decay_style/text_summary', 'lr_decay_iters/text_summary', 'lr_decay_fraction/text_summary', 'min_lr/text_summary', 'warmup/text_summary', 'override_lr_scheduler/text_summary', 'use_checkpoint_lr_scheduler/text_summary', 'precision/text_summary', 'num_layers/text_summary', 'hidden_size/text_summary', 'intermediate_size/text_summary', 'mlp_multiple_of/text_summary', 'expansion_factor/text_summary', 'num_attention_heads/text_summary', 'num_kv_heads/text_summary', 'seq_length/text_summary', 'sliding_window_width/text_summary', 'max_position_embeddings/text_summary', 'norm/text_summary', 'layernorm_fusion/text_summary', 'rmsnorm_fusion/text_summary', 'use_qk_layernorm/text_summary', 'layernorm_epsilon/text_summary', 'rms_norm_epsilon/text_summary', 'scalenorm_epsilon/text_summary', 'pos_emb/text_summary', 'rpe_num_buckets/text_summary', 'rpe_max_distance/text_summary', 'opt_pos_emb_offset/text_summary', 'no_weight_tying/text_summary', 'attention_config/text_summary', 'sparsity_config/text_summary', 'num_unique_layers/text_summary', 'param_sharing_style/text_summary', 'make_vocab_size_divisible_by/text_summary', 'activation/text_summary', 'use_flashattn_swiglu/text_summary', 'scaled_upper_triang_masked_softmax_fusion/text_summary', 'scaled_masked_softmax_fusion/text_summary', 'bias_gelu_fusion/text_summary', 'bias_dropout_fusion/text_summary', 'rope_fusion/text_summary', 'fp16_lm_cross_entropy/text_summary', 'init_method_std/text_summary', 'apply_query_key_layer_scaling/text_summary', 'use_cpu_initialization/text_summary', 'attention_softmax_in_fp32/text_summary', 'rotary_pct/text_summary', 'rotary_emb_base/text_summary', 'rotary_save_freqs_buffer/text_summary', 'init_method/text_summary', 'output_layer_init_method/text_summary', 'gmlp_attn_dim/text_summary', 'gpt_j_residual/text_summary', 'gpt_j_tied/text_summary', 'use_bias_in_norms/text_summary', 'use_bias_in_attn_linear/text_summary', 'use_bias_in_mlp/text_summary', 'soft_prompt_tuning/text_summary', 'mamba_selective_scan_fusion/text_summary', 'mamba_causal_conv_fusion/text_summary', 'mamba_inner_func_fusion/text_summary', 'mamba_selective_fp32_params/text_summary', 'mamba_use_bias_in_conv/text_summary', 'mamba_use_bias_in_linears/text_summary', 'output_layer_parallelism/text_summary', 'dim_att/text_summary', 'head_size/text_summary', 'ffn_dim/text_summary', 'deepspeed/text_summary', 'train_batch_size/text_summary', 'train_micro_batch_size_per_gpu/text_summary', 'gradient_accumulation_steps/text_summary', 'optimizer/text_summary', 'scheduler/text_summary', 'fp32_allreduce/text_summary', 'prescale_gradients/text_summary', 'gradient_predivide_factor/text_summary', 'sparse_gradients/text_summary', 'fp16/text_summary', 'bf16/text_summary', 'amp/text_summary', 'gradient_clipping/text_summary', 'zero_optimization/text_summary', 'curriculum_learning/text_summary', 'curriculum_seqlen/text_summary', 'steps_per_print/text_summary', 'wall_clock_breakdown/text_summary', 'dump_state/text_summary', 'flops_profiler/text_summary', 'communication_data_type/text_summary', 'autotuning/text_summary', 'activation_checkpointing/text_summary', 'sparse_attention/text_summary', 'data_efficiency/text_summary', 'tensorboard/text_summary', 'wandb/text_summary', 'csv_monitor/text_summary', 'elasticity/text_summary', 'comms_logger/text_summary', 'compression_training/text_summary', 'checkpoint/text_summary', 'data_types/text_summary', 'deepspeed_extra_args/text_summary', 'hostfile/text_summary', 'include/text_summary', 'exclude/text_summary', 'num_nodes/text_summary', 'num_gpus/text_summary', 'master_port/text_summary', 'master_addr/text_summary', 'launcher/text_summary', 'force_multi/text_summary', 'detect_nvlink_pairs/text_summary', 'autotuning_run/text_summary', 'no_ssh_check/text_summary', 'comment/text_summary', 'account/text_summary', 'tokenizer/text_summary', 'tensorboard_writer/text_summary'], 'graph': False, 'meta_graph': False, 'run_metadata': []}\n",
            "Logging metric test/lm_loss 1.8774449825286865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/11/12 11:38:22 INFO mlflow.tracking._tracking_service.client: 🏃 View run placid-skunk-947 at: https://dagshub.com/MarkNZed/GPT-NeoX-Colab.mlflow/#/experiments/6/runs/8080fe13e4d0488a8ceae9a64f759bee.\n",
            "2024/11/12 11:38:22 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dagshub.com/MarkNZed/GPT-NeoX-Colab.mlflow/#/experiments/6.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train_micro_batch_size_per_gpu': 256, 'train_iters': 80, 'lr_decay_iters': 80, 'save': 'experiments/experiment3/checkpoints', 'load': 'experiments/experiment3/checkpoints', 'tensorboard_dir': 'experiments/experiment3/tensorboard', 'log_dir': 'experiments/experiment3/logs'}\n",
            "Running experiment: experiment3\n",
            "Running command: nohup bash -c \"source /content/my_env/bin/activate &&         cd /content/gpt-neox &&         python ./deepy.py train.py --conf_dir /tmp/tmprwhoe_ye         temp_config\" & echo $! > train_process.pid\n",
            "Training initiated.\n",
            "Waiting for train_process.pid to be created...\n",
            "PID: 5625\n",
            "Latest file: /content/gpt-neox/experiments/experiment3/logs/01f814ec6246_stdout.txt\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training has finished.\n",
            "Latest file: /content/gpt-neox/experiments/experiment3/tensorboard/events.out.tfevents.1731411512.01f814ec6246.5658.0\n",
            "{'images': [], 'audio': [], 'histograms': [], 'scalars': ['timers/forward', 'timers/backward', 'timers/backward-backward', 'timers/backward-allreduce', 'timers/optimizer', 'timers/batch generator', 'train/learning_rate', 'train/lm_loss', 'train/loss_scale', 'runtime/samples_per_sec', 'runtime/iteration_time', 'runtime/flops_per_sec_per_gpu', 'validation/lm_loss', 'validation/lm_loss_ppl', 'test/lm_loss', 'test/lm_loss_ppl'], 'distributions': [], 'tensors': ['distributed_backend/text_summary', 'local_rank/text_summary', 'rank/text_summary', 'lazy_mpu_init/text_summary', 'short_seq_prob/text_summary', 'eod_mask_loss/text_summary', 'adlr_autoresume/text_summary', 'adlr_autoresume_interval/text_summary', 'seed/text_summary', 'onnx_safe/text_summary', 'deepscale/text_summary', 'deepscale_config/text_summary', 'deepspeed_mpi/text_summary', 'deepspeed_slurm/text_summary', 'user_script/text_summary', 'iteration/text_summary', 'do_train/text_summary', 'do_valid/text_summary', 'do_test/text_summary', 'global_num_gpus/text_summary', 'text_gen_type/text_summary', 'precompute_model_name/text_summary', 'temperature/text_summary', 'top_p/text_summary', 'top_k/text_summary', 'return_logits/text_summary', 'maximum_tokens/text_summary', 'prompt_end/text_summary', 'sample_input_file/text_summary', 'sample_output_file/text_summary', 'num_samples/text_summary', 'recompute/text_summary', 'eval_results_prefix/text_summary', 'eval_tasks/text_summary', 'moe_top_k/text_summary', 'use_tutel/text_summary', 'moe_num_experts/text_summary', 'moe_loss_coeff/text_summary', 'moe_train_capacity_factor/text_summary', 'moe_eval_capacity_factor/text_summary', 'moe_min_capacity/text_summary', 'moe_token_dropping/text_summary', 'create_moe_param_group/text_summary', 'moe_use_residual/text_summary', 'moe_expert_parallel_size/text_summary', 'moe_type/text_summary', 'moe_glu/text_summary', 'moe_lbl_in_fp32/text_summary', 'moe_jitter_eps/text_summary', 'enable_expert_tensor_parallelism/text_summary', 'use_wandb/text_summary', 'wandb_group/text_summary', 'wandb_team/text_summary', 'wandb_project/text_summary', 'wandb_host/text_summary', 'wandb_init_all_ranks/text_summary', 'git_hash/text_summary', 'log_dir/text_summary', 'tensorboard_dir/text_summary', 'use_comet/text_summary', 'comet_workspace/text_summary', 'comet_project/text_summary', 'comet_experiment_name/text_summary', 'comet_tags/text_summary', 'comet_others/text_summary', 'comet_experiment/text_summary', 'log_interval/text_summary', 'log_grad_pct_zeros/text_summary', 'log_param_norm/text_summary', 'log_grad_norm/text_summary', 'log_optimizer_states/text_summary', 'log_gradient_noise_scale/text_summary', 'gradient_noise_scale_n_batches/text_summary', 'gradient_noise_scale_cpu_offload/text_summary', 'memory_profiling/text_summary', 'memory_profiling_path/text_summary', 'profile/text_summary', 'profile_step_start/text_summary', 'profile_step_stop/text_summary', 'pipe_parallel_size/text_summary', 'model_parallel_size/text_summary', 'pipe_partition_method/text_summary', 'world_size/text_summary', 'is_pipe_parallel/text_summary', 'sequence_parallel/text_summary', 'expert_interval/text_summary', 'data_path/text_summary', 'use_shared_fs/text_summary', 'train_data_paths/text_summary', 'train_label_data_paths/text_summary', 'train_reward_data_paths/text_summary', 'test_data_paths/text_summary', 'test_label_data_paths/text_summary', 'test_reward_data_paths/text_summary', 'valid_data_paths/text_summary', 'valid_label_data_paths/text_summary', 'valid_reward_data_paths/text_summary', 'pos_train_data_paths/text_summary', 'neg_train_data_paths/text_summary', 'pos_train_label_data_paths/text_summary', 'neg_train_label_data_paths/text_summary', 'pos_valid_data_paths/text_summary', 'neg_valid_data_paths/text_summary', 'pos_valid_label_data_paths/text_summary', 'neg_valid_label_data_paths/text_summary', 'pos_test_data_paths/text_summary', 'neg_test_data_paths/text_summary', 'pos_test_label_data_paths/text_summary', 'neg_test_label_data_paths/text_summary', 'train_data_weights/text_summary', 'valid_data_weights/text_summary', 'test_data_weights/text_summary', 'weight_by_num_documents/text_summary', 'weighted_sampler_alpha/text_summary', 'data_impl/text_summary', 'pack_impl/text_summary', 'dataset_impl/text_summary', 'train_impl/text_summary', 'dpo_fp32/text_summary', 'dpo_reference_free/text_summary', 'dpo_beta/text_summary', 'kto_fp32/text_summary', 'kto_desirable_weight/text_summary', 'kto_undesirable_weight/text_summary', 'z_loss/text_summary', 'kto_beta/text_summary', 'allow_chopped/text_summary', 'mmap_warmup/text_summary', 'save/text_summary', 's3_path/text_summary', 's3_chunk_size/text_summary', 'config_files/text_summary', 'load/text_summary', 'checkpoint_validation_with_forward_pass/text_summary', 'checkpoint_scale/text_summary', 'checkpoint_factor/text_summary', 'extra_save_iters/text_summary', 'no_save_optim/text_summary', 'no_save_rng/text_summary', 'no_load_optim/text_summary', 'no_load_rng/text_summary', 'finetune/text_summary', 'batch_size/text_summary', 'train_iters/text_summary', 'train_epochs/text_summary', 'eval_iters/text_summary', 'keep_last_n_checkpoints/text_summary', 'eval_interval/text_summary', 'split/text_summary', 'vocab_file/text_summary', 'merge_file/text_summary', 'num_workers/text_summary', 'exit_interval/text_summary', 'attention_dropout/text_summary', 'hidden_dropout/text_summary', 'weight_decay/text_summary', 'checkpoint_activations/text_summary', 'checkpoint_num_layers/text_summary', 'deepspeed_activation_checkpointing/text_summary', 'contiguous_checkpointing/text_summary', 'checkpoint_in_cpu/text_summary', 'synchronize_each_layer/text_summary', 'profile_backward/text_summary', 'partition_activations/text_summary', 'clip_grad/text_summary', 'hysteresis/text_summary', 'dynamic_loss_scale/text_summary', 'loss_scale/text_summary', 'loss_scale_window/text_summary', 'min_scale/text_summary', 'char_level_ppl/text_summary', 'use_mup/text_summary', 'coord_check/text_summary', 'save_base_shapes/text_summary', 'base_shapes_file/text_summary', 'mup_init_scale/text_summary', 'mup_attn_temp/text_summary', 'mup_output_temp/text_summary', 'mup_embedding_mult/text_summary', 'mup_rp_embedding_mult/text_summary', 'mup_width_scale/text_summary', 'tokenizer_type/text_summary', 'padded_vocab_size/text_summary', 'optimizer_type/text_summary', 'use_bnb_optimizer/text_summary', 'zero_stage/text_summary', 'zero_reduce_scatter/text_summary', 'zero_contiguous_gradients/text_summary', 'zero_reduce_bucket_size/text_summary', 'zero_allgather_bucket_size/text_summary', 'lr/text_summary', 'lr_decay_style/text_summary', 'lr_decay_iters/text_summary', 'lr_decay_fraction/text_summary', 'min_lr/text_summary', 'warmup/text_summary', 'override_lr_scheduler/text_summary', 'use_checkpoint_lr_scheduler/text_summary', 'precision/text_summary', 'num_layers/text_summary', 'hidden_size/text_summary', 'intermediate_size/text_summary', 'mlp_multiple_of/text_summary', 'expansion_factor/text_summary', 'num_attention_heads/text_summary', 'num_kv_heads/text_summary', 'seq_length/text_summary', 'sliding_window_width/text_summary', 'max_position_embeddings/text_summary', 'norm/text_summary', 'layernorm_fusion/text_summary', 'rmsnorm_fusion/text_summary', 'use_qk_layernorm/text_summary', 'layernorm_epsilon/text_summary', 'rms_norm_epsilon/text_summary', 'scalenorm_epsilon/text_summary', 'pos_emb/text_summary', 'rpe_num_buckets/text_summary', 'rpe_max_distance/text_summary', 'opt_pos_emb_offset/text_summary', 'no_weight_tying/text_summary', 'attention_config/text_summary', 'sparsity_config/text_summary', 'num_unique_layers/text_summary', 'param_sharing_style/text_summary', 'make_vocab_size_divisible_by/text_summary', 'activation/text_summary', 'use_flashattn_swiglu/text_summary', 'scaled_upper_triang_masked_softmax_fusion/text_summary', 'scaled_masked_softmax_fusion/text_summary', 'bias_gelu_fusion/text_summary', 'bias_dropout_fusion/text_summary', 'rope_fusion/text_summary', 'fp16_lm_cross_entropy/text_summary', 'init_method_std/text_summary', 'apply_query_key_layer_scaling/text_summary', 'use_cpu_initialization/text_summary', 'attention_softmax_in_fp32/text_summary', 'rotary_pct/text_summary', 'rotary_emb_base/text_summary', 'rotary_save_freqs_buffer/text_summary', 'init_method/text_summary', 'output_layer_init_method/text_summary', 'gmlp_attn_dim/text_summary', 'gpt_j_residual/text_summary', 'gpt_j_tied/text_summary', 'use_bias_in_norms/text_summary', 'use_bias_in_attn_linear/text_summary', 'use_bias_in_mlp/text_summary', 'soft_prompt_tuning/text_summary', 'mamba_selective_scan_fusion/text_summary', 'mamba_causal_conv_fusion/text_summary', 'mamba_inner_func_fusion/text_summary', 'mamba_selective_fp32_params/text_summary', 'mamba_use_bias_in_conv/text_summary', 'mamba_use_bias_in_linears/text_summary', 'output_layer_parallelism/text_summary', 'dim_att/text_summary', 'head_size/text_summary', 'ffn_dim/text_summary', 'deepspeed/text_summary', 'train_batch_size/text_summary', 'train_micro_batch_size_per_gpu/text_summary', 'gradient_accumulation_steps/text_summary', 'optimizer/text_summary', 'scheduler/text_summary', 'fp32_allreduce/text_summary', 'prescale_gradients/text_summary', 'gradient_predivide_factor/text_summary', 'sparse_gradients/text_summary', 'fp16/text_summary', 'bf16/text_summary', 'amp/text_summary', 'gradient_clipping/text_summary', 'zero_optimization/text_summary', 'curriculum_learning/text_summary', 'curriculum_seqlen/text_summary', 'steps_per_print/text_summary', 'wall_clock_breakdown/text_summary', 'dump_state/text_summary', 'flops_profiler/text_summary', 'communication_data_type/text_summary', 'autotuning/text_summary', 'activation_checkpointing/text_summary', 'sparse_attention/text_summary', 'data_efficiency/text_summary', 'tensorboard/text_summary', 'wandb/text_summary', 'csv_monitor/text_summary', 'elasticity/text_summary', 'comms_logger/text_summary', 'compression_training/text_summary', 'checkpoint/text_summary', 'data_types/text_summary', 'deepspeed_extra_args/text_summary', 'hostfile/text_summary', 'include/text_summary', 'exclude/text_summary', 'num_nodes/text_summary', 'num_gpus/text_summary', 'master_port/text_summary', 'master_addr/text_summary', 'launcher/text_summary', 'force_multi/text_summary', 'detect_nvlink_pairs/text_summary', 'autotuning_run/text_summary', 'no_ssh_check/text_summary', 'comment/text_summary', 'account/text_summary', 'tokenizer/text_summary', 'tensorboard_writer/text_summary'], 'graph': False, 'meta_graph': False, 'run_metadata': []}\n",
            "Logging metric test/lm_loss 2.5290021896362305\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/11/12 11:40:03 INFO mlflow.tracking._tracking_service.client: 🏃 View run fearless-steed-269 at: https://dagshub.com/MarkNZed/GPT-NeoX-Colab.mlflow/#/experiments/6/runs/248da562e7b64cf8ba9ecfb84dda9b0f.\n",
            "2024/11/12 11:40:03 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dagshub.com/MarkNZed/GPT-NeoX-Colab.mlflow/#/experiments/6.\n"
          ]
        }
      ],
      "source": [
        "import tempfile\n",
        "import subprocess\n",
        "import os\n",
        "from omegaconf import OmegaConf\n",
        "from hydra import initialize_config_dir, compose\n",
        "from hydra.core.global_hydra import GlobalHydra\n",
        "import mlflow\n",
        "import time\n",
        "import dagshub\n",
        "\n",
        "%cd {GPTNeoXDir}\n",
        "\n",
        "dagshub.init(repo_owner='MarkNZed', repo_name='GPT-NeoX-Colab', mlflow=True)\n",
        "experiment_group = \"Testing2\"\n",
        "mlflow.set_experiment(experiment_group)\n",
        "\n",
        "def load_and_merge_configs(base_conf_dir, experiment_name):\n",
        "    # Initialize Hydra with the base config directory\n",
        "    initialize_config_dir(config_dir=base_conf_dir, version_base=\"1.1\")\n",
        "\n",
        "    # Load the base configurations (shakespeare and shakespeare_deepy) and experiment overrides\n",
        "    base_cfg = compose(config_name=\"shakespeare.yml\")\n",
        "    OmegaConf.set_struct(base_cfg, False) # No struct checking for matching structure in merge\n",
        "    deepy_cfg = compose(config_name=\"shakespeare_deepy.yml\")\n",
        "    OmegaConf.set_struct(deepy_cfg, False) # No struct checking for matching structure in merge\n",
        "    experiment_cfg = compose(config_name=\"hydra\", overrides=[f\"experiments={experiment_name}\"])\n",
        "    OmegaConf.set_struct(experiment_cfg, False) # No struct checking for matching structure in merge\n",
        "\n",
        "    experiment_overrides = experiment_cfg.get(\"experiments\", {})\n",
        "    OmegaConf.set_struct(experiment_overrides, False) # No struct checking for matching structure in merge\n",
        "\n",
        "    print(experiment_overrides)\n",
        "\n",
        "    # Merge the configurations: base -> deepy -> experiment\n",
        "    cfg = OmegaConf.merge(base_cfg, deepy_cfg, experiment_overrides)\n",
        "\n",
        "    return cfg\n",
        "\n",
        "def run_experiment(cfg, experiment_name):\n",
        "    print(\"Running experiment:\", experiment_name)\n",
        "    experimentDir = f\"{GPTNeoXDir}/experiments/{experiment_name}\"\n",
        "    !sudo rm -rf {experimentDir}\n",
        "    !mkdir -p {experimentDir}\n",
        "    #print(OmegaConf.to_yaml(cfg))\n",
        "\n",
        "    # Log parameters\n",
        "    mlflow.log_params(OmegaConf.to_container(cfg, resolve=True))\n",
        "\n",
        "    # Create a temporary directory for configs\n",
        "    temp_config_dir = tempfile.mkdtemp()\n",
        "    temp_config_file = os.path.join(temp_config_dir, 'temp_config.yml')\n",
        "\n",
        "    # Save the modified config to the temporary file in JSON-like structure within a YAML file\n",
        "    with open(temp_config_file, 'w') as f:\n",
        "        # Dump the config as JSON but save it with a .yml extension\n",
        "        OmegaConf.save(OmegaConf.create(OmegaConf.to_container(cfg, resolve=True)), f)\n",
        "\n",
        "    # Start a detached background process using the temp config\n",
        "    cmd = f\"\"\"nohup bash -c \"source {workspaceDir}/my_env/bin/activate && \\\n",
        "        cd {GPTNeoXDir} && \\\n",
        "        python ./deepy.py train.py --conf_dir {temp_config_dir} \\\n",
        "        temp_config\" & echo $! > train_process.pid\"\"\"\n",
        "    print(\"Running command:\", cmd)\n",
        "    process = subprocess.Popen(\n",
        "        cmd,\n",
        "        shell=True,\n",
        "        executable='/bin/bash',\n",
        "        preexec_fn=os.setsid  # Starts the process in a new session\n",
        "    )\n",
        "\n",
        "    print(\"Training initiated.\")\n",
        "\n",
        "    while not os.path.exists(\"train_process.pid\"):\n",
        "        print(\"Waiting for train_process.pid to be created...\")\n",
        "        time.sleep(10)  # Check every X seconds\n",
        "\n",
        "    # Read the PID from the file\n",
        "    with open(\"train_process.pid\", \"r\") as f:\n",
        "        pid = int(f.read().strip())\n",
        "        print(\"PID:\", pid)\n",
        "\n",
        "    while not os.path.exists(f\"{experimentDir}/logs\"):\n",
        "        print(\"Waiting for logs to be created...\")\n",
        "        time.sleep(10)  # Check every X seconds\n",
        "\n",
        "    latest_log = get_latest_file(f\"{experimentDir}/logs\", \"*_stdout.txt\")\n",
        "\n",
        "    # Monitor the training process\n",
        "    while is_process_running(pid):\n",
        "        read_new_iterations(latest_log)\n",
        "        print(\"Training is still running...\")\n",
        "        time.sleep(30)  # Check every X seconds\n",
        "\n",
        "    print(\"Training has finished.\")\n",
        "\n",
        "    latest_events_file = get_latest_file(f\"{experimentDir}/tensorboard\", \"events.out.tfevents.*\")\n",
        "    loss_key = \"test/lm_loss\"\n",
        "    loss = get_scalar_from_tensorboard(latest_events_file, loss_key)\n",
        "    print(f\"Logging metric {loss_key} {loss}\")\n",
        "    mlflow.log_metric(loss_key, loss)\n",
        "\n",
        "    !rm \"train_process.pid\"\n",
        "\n",
        "    # Clean up the temporary directory after training\n",
        "    # (Optional: You might want to keep it for debugging)\n",
        "    # shutil.rmtree(temp_config_dir)\n",
        "\n",
        "# List of experiment names\n",
        "experiments = [\"experiment1\", \"experiment2\", \"experiment3\"]\n",
        "\n",
        "for experiment in experiments:\n",
        "\n",
        "    exp_id = GPTNeoXColab.utils.ml.get_or_create_experiment_id(experiment_group)\n",
        "    # Set the experiment name and start the run\n",
        "    #with mlflow.start_run(experiment_id=exp_id, nested=True):\n",
        "    with mlflow.start_run(nested=True):\n",
        "    #with mlflow.start_run():\n",
        "        # Clear Hydra's global state if it’s already initialized\n",
        "        if GlobalHydra.instance().is_initialized():\n",
        "            GlobalHydra.instance().clear()\n",
        "        # Load and merge configurations\n",
        "        base_conf_dir = f\"{GPTNeoXColabDir}/configs\"\n",
        "        cfg = load_and_merge_configs(base_conf_dir, experiment)\n",
        "        # Start training with the merged configuration\n",
        "        run_experiment(cfg, experiment)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0JGqO-azytqR"
      },
      "outputs": [],
      "source": [
        "# Here we could disconnect from the GPU resource\n",
        "#from google.colab import runtime\n",
        "#runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}