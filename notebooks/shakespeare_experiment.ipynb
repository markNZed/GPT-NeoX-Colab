{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/markNZed/GPT-NeoX-Colab/blob/main/notebooks/shakespeare_experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flp2Dht6ytqE"
   },
   "source": [
    "# Experiment\n",
    "This is a demonstration of how experiments can be run using DagsHub and MLflow.\n",
    "We will train three different versions of the tiny LLM using different batch sizes and compare the results.\n",
    "\n",
    "## ToDo\n",
    "- Shorten the training time for testing\n",
    "- Run tests in parallel\n",
    "- Extract functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LECzxKWK8CyS"
   },
   "source": [
    "## Login to Dagshub\n",
    "To avoid requirest in the middle of the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wxd2wfpq1F9u",
    "outputId": "52f72a4a-4163-44f0-f5e1-951f1c23aeed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/251.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.7/251.7 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/139.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m115.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.6/82.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "import os\n",
    "%pip install -q dagshub\n",
    "import dagshub\n",
    "try:\n",
    "  from google.colab import userdata\n",
    "  os.environ[\"DAGSHUB_USER_TOKEN\"] = userdata.get(\"DAGSHUB_USER_TOKEN\")\n",
    "except:\n",
    "  pass\n",
    "try:\n",
    "  if os.environ[\"DAGSHUB_USER_TOKEN\"]:\n",
    "    pass\n",
    "except:\n",
    "  os.environ[\"DAGSHUB_USER_TOKEN\"] = dagshub.auth.get_token()\n",
    "dagshub.auth.add_app_token(token=os.environ[\"DAGSHUB_USER_TOKEN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Iega62GjytqH"
   },
   "outputs": [],
   "source": [
    "#@title Setup paths\n",
    "# We could modify these paths to \"stub\" behavior for test/dev\n",
    "# A file like .ipython/profile_default/startup/10-test.py could restore these vars\n",
    "workspaceDir = \"/content\"\n",
    "GPTNeoXDirName = \"gpt-neox\"\n",
    "GPTNeoXDir = f\"{workspaceDir}/{GPTNeoXDirName}\"\n",
    "GPTNeoXColabDirName = \"GPT-NeoX-Colab\"\n",
    "GPTNeoXColabDir = f\"{workspaceDir}/{GPTNeoXColabDirName}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LUxVImVvytqL",
    "outputId": "e29ce565-da87-4483-b1b5-29e83a70acdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "fatal: destination path 'GPT-NeoX-Colab' already exists and is not an empty directory.\n",
      "/content/GPT-NeoX-Colab\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for GPTNeoXColab (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Data retrieval successful.\n",
      "Data retrieval successful.\n",
      "CPU times: user 111 ms, sys: 17.4 ms, total: 128 ms\n",
      "Wall time: 23.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#@title Clone GPT-NeoX-Colab\n",
    "%cd {workspaceDir}\n",
    "# Don't use --depth 1 because that does not play nice with git-annex\n",
    "!git clone https://github.com/markNZed/GPT-NeoX-Colab.git\n",
    "%cd {GPTNeoXColabDir}\n",
    "%pip install -q -r requirements_colab.txt\n",
    "%pip install -q .\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(f\"{GPTNeoXColabDir}/.env\")\n",
    "import GPTNeoXColab\n",
    "GPTNeoXColab.utils.colab.fetch_data(\"data/shakespeare/shakespeare_text_document.bin\")\n",
    "GPTNeoXColab.utils.colab.fetch_data(\"data/shakespeare/shakespeare_text_document.idx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OvpVaIbLytqM"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#@title Clone GPT-NeoX\n",
    "%cd {workspaceDir}\n",
    "#!git clone --depth 1 https://github.com/EleutherAI/gpt-neox\n",
    "!git clone -b pipe_parallel_size_1 --depth 1 https://github.com/markNZed/gpt-neox.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "6EJBRBSpiSXF"
   },
   "outputs": [],
   "source": [
    "!mkdir -p {GPTNeoXDir}/processed_data\n",
    "!cp {GPTNeoXColabDir}/data/shakespeare/shakespeare_text_document.* {GPTNeoXDir}/processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WH8eetUBytqN",
    "outputId": "2e975e84-e3a1-4c9d-a988-0a6dfcde88a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "Downloading my_env.tar.gz\n",
      "Unzipping my_env.tar.gz\n",
      "Untarring my_env.tar.gz\n",
      "CPU times: user 19.2 s, sys: 8.33 s, total: 27.5 s\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#@title Load prebuilt Python environment for Colab\n",
    "import GPTNeoXColab\n",
    "%cd {workspaceDir}\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    GPTNeoXColab.utils.colab.download_my_env()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTyERIkj8elu"
   },
   "source": [
    "# Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7RmiyhUgSSt7",
    "outputId": "9bbdd4d5-cc82-4da7-8d09-ceb7067cdb01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (5.9.5)\n",
      "Collecting pynvml\n",
      "  Downloading pynvml-11.5.3-py3-none-any.whl.metadata (8.8 kB)\n",
      "Downloading pynvml-11.5.3-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pynvml\n",
      "Successfully installed pynvml-11.5.3\n"
     ]
    }
   ],
   "source": [
    "!pip install psutil\n",
    "# Install this for GPU metric logging\n",
    "!pip install pynvml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "umfYbg3TytqJ"
   },
   "outputs": [],
   "source": [
    "import GPTNeoXColab\n",
    "import os\n",
    "from pathlib import Path\n",
    "ROOT_DIR = GPTNeoXColab.utils.colab.find_project_root()\n",
    "RELATIVE_ROOT_DIR = os.path.relpath(ROOT_DIR, Path.cwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "6PTFQWG08tKv"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import time\n",
    "\n",
    "# File to store the last read position (persistence between script runs)\n",
    "file_position = 0\n",
    "# Regular expression to match \"iteration <number> / <total>\"\n",
    "iteration_pattern = re.compile(r\"iteration\\s+(\\d+)\\s*/\\s*\\d+\")\n",
    "\n",
    "def get_latest_file(dir, pattern = \"*_stdout.txt\"):\n",
    "  # Define the log directory and pattern for log files\n",
    "  glob_pattern = os.path.join(dir, pattern)\n",
    "  # Get the list of log files that match the pattern\n",
    "  files = glob.glob(glob_pattern)\n",
    "  # Ensure there are log files in the directory\n",
    "  if files:\n",
    "      # Find the latest log file based on modification time\n",
    "      file = max(files, key=os.path.getmtime)\n",
    "      print(\"Latest file:\", file)\n",
    "  else:\n",
    "      file = None\n",
    "      print(\"No files found. Waiting and retrying.\")\n",
    "      time.sleep(10)  # Check every X seconds\n",
    "      file = get_latest_file(dir, pattern)\n",
    "  return file\n",
    "\n",
    "def read_new_iterations(latest_log):\n",
    "    global file_position\n",
    "    # Open the log file and seek to the last position\n",
    "    with open(latest_log, \"r\") as file:\n",
    "        file.seek(file_position)\n",
    "        # Read new lines\n",
    "        new_lines = file.readlines()\n",
    "        file_position = file.tell()\n",
    "        # Process lines containing \"iteration\"\n",
    "        last_match = None\n",
    "        for line in new_lines:\n",
    "            match = iteration_pattern.search(line)\n",
    "            if match:\n",
    "                last_match = match\n",
    "        if last_match:\n",
    "            # Extract the iteration count from the regex match\n",
    "            iteration_count = int(last_match.group(1))\n",
    "            print(f\"{iteration_count} iterations\")\n",
    "\n",
    "# Function to check if the process is running\n",
    "def is_process_running(pid):\n",
    "    try:\n",
    "        os.kill(pid, 0)  # Sending signal 0 to check if the process exists\n",
    "        return True\n",
    "    except OSError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "XtEiZxZBV2iD"
   },
   "outputs": [],
   "source": [
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "import os\n",
    "\n",
    "def get_scalar_from_tensorboard(file, key):\n",
    "    # Load TensorBoard events\n",
    "    event_acc = EventAccumulator(file)\n",
    "    event_acc.Reload()\n",
    "    print(event_acc.Tags())\n",
    "    # Extract loss scalar events\n",
    "    if key in event_acc.Tags().get('scalars', []):\n",
    "        events = event_acc.Scalars(key)\n",
    "        value = events[-1].value  # Get the last logged value\n",
    "        return value\n",
    "    else:\n",
    "        print(f\"{key} not found in TensorBoard logs.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install GitPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "\n",
    "repo = Repo(GPTNeoXColabDir)\n",
    "commit_id = repo.head.commit.hexsha\n",
    "branch_name = repo.active_branch.name\n",
    "repo_url = next(repo.remotes.origin.urls)\n",
    "print(f\"Commit ID: {commit_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iaBFYofFytqP",
    "outputId": "a15f017b-aca7-40f2-d52d-e2e48050b490"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gpt-neox\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"MarkNZed/GPT-NeoX-Colab\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"MarkNZed/GPT-NeoX-Colab\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository MarkNZed/GPT-NeoX-Colab initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository MarkNZed/GPT-NeoX-Colab initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/13 08:24:45 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "/usr/local/lib/python3.10/dist-packages/hydra/plugins/config_source.py:125: UserWarning: Support for .yml files is deprecated. Use .yaml extension for Hydra config files\n",
      "  deprecation_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_micro_batch_size_per_gpu': 4, 'train_iters': 51200, 'lr_decay_iters': 51200, 'save': 'experiments/experiment1/checkpoints', 'load': 'experiments/experiment1/checkpoints', 'tensorboard_dir': 'experiments/experiment1/tensorboard', 'log_dir': 'experiments/experiment1/logs'}\n",
      "Running experiment: experiment1\n",
      "rm: cannot remove '/content/gpt-neox/experiments/experiment1/checkpoints': Directory not empty\n",
      "Running command: nohup bash -c \"source /content/my_env/bin/activate &&         cd /content/gpt-neox &&         python ./deepy.py train.py --conf_dir /tmp/tmp7s5yig4_         temp_config\" & echo $! > train_process.pid\n",
      "Training initiated.\n",
      "Waiting for train_process.pid to be created...\n",
      "PID: 25671\n",
      "Latest file: /content/gpt-neox/experiments/experiment1/logs/5518ca645c4c_stdout.txt\n",
      "Training is still running...\n",
      "840 iterations\n",
      "Training is still running...\n",
      "1760 iterations\n",
      "Training is still running...\n",
      "2680 iterations\n",
      "Training is still running...\n",
      "3580 iterations\n",
      "Training is still running...\n",
      "4490 iterations\n",
      "Training is still running...\n",
      "5400 iterations\n",
      "Training is still running...\n",
      "6300 iterations\n",
      "Training is still running...\n",
      "7210 iterations\n",
      "Training is still running...\n",
      "8100 iterations\n",
      "Training is still running...\n",
      "9000 iterations\n",
      "Training is still running...\n",
      "9880 iterations\n",
      "Training is still running...\n",
      "10770 iterations\n",
      "Training is still running...\n",
      "11660 iterations\n",
      "Training is still running...\n",
      "12570 iterations\n",
      "Training is still running...\n",
      "13480 iterations\n",
      "Training is still running...\n",
      "14380 iterations\n",
      "Training is still running...\n",
      "15280 iterations\n",
      "Training is still running...\n",
      "16190 iterations\n",
      "Training is still running...\n",
      "17100 iterations\n",
      "Training is still running...\n",
      "18000 iterations\n",
      "Training is still running...\n",
      "18910 iterations\n",
      "Training is still running...\n",
      "19820 iterations\n",
      "Training is still running...\n",
      "20730 iterations\n",
      "Training is still running...\n",
      "21640 iterations\n",
      "Training is still running...\n",
      "22540 iterations\n",
      "Training is still running...\n",
      "23420 iterations\n",
      "Training is still running...\n",
      "24310 iterations\n",
      "Training is still running...\n",
      "25200 iterations\n",
      "Training is still running...\n",
      "26090 iterations\n",
      "Training is still running...\n",
      "26960 iterations\n",
      "Training is still running...\n",
      "27850 iterations\n",
      "Training is still running...\n",
      "28740 iterations\n",
      "Training is still running...\n",
      "29620 iterations\n",
      "Training is still running...\n",
      "30510 iterations\n",
      "Training is still running...\n",
      "31400 iterations\n",
      "Training is still running...\n",
      "32290 iterations\n",
      "Training is still running...\n",
      "33170 iterations\n",
      "Training is still running...\n",
      "34060 iterations\n",
      "Training is still running...\n",
      "34950 iterations\n",
      "Training is still running...\n",
      "35830 iterations\n",
      "Training is still running...\n",
      "36720 iterations\n",
      "Training is still running...\n",
      "37600 iterations\n",
      "Training is still running...\n",
      "38490 iterations\n",
      "Training is still running...\n",
      "39380 iterations\n",
      "Training is still running...\n",
      "40260 iterations\n",
      "Training is still running...\n",
      "41150 iterations\n",
      "Training is still running...\n",
      "42030 iterations\n",
      "Training is still running...\n",
      "42910 iterations\n",
      "Training is still running...\n",
      "43790 iterations\n",
      "Training is still running...\n",
      "44660 iterations\n",
      "Training is still running...\n",
      "45540 iterations\n",
      "Training is still running...\n",
      "46410 iterations\n",
      "Training is still running...\n",
      "47300 iterations\n",
      "Training is still running...\n",
      "48170 iterations\n",
      "Training is still running...\n",
      "49050 iterations\n",
      "Training is still running...\n",
      "49910 iterations\n",
      "Training is still running...\n",
      "50770 iterations\n",
      "Training is still running...\n",
      "Training has finished.\n",
      "Latest file: /content/gpt-neox/experiments/experiment1/tensorboard/events.out.tfevents.1731486295.5518ca645c4c.25730.0\n",
      "{'images': [], 'audio': [], 'histograms': [], 'scalars': ['train/learning_rate', 'train/lm_loss', 'train/loss_scale', 'runtime/samples_per_sec', 'runtime/iteration_time', 'runtime/flops_per_sec_per_gpu', 'validation/lm_loss', 'validation/lm_loss_ppl', 'test/lm_loss', 'test/lm_loss_ppl'], 'distributions': [], 'tensors': ['distributed_backend/text_summary', 'local_rank/text_summary', 'rank/text_summary', 'lazy_mpu_init/text_summary', 'short_seq_prob/text_summary', 'eod_mask_loss/text_summary', 'adlr_autoresume/text_summary', 'adlr_autoresume_interval/text_summary', 'seed/text_summary', 'onnx_safe/text_summary', 'deepscale/text_summary', 'deepscale_config/text_summary', 'deepspeed_mpi/text_summary', 'deepspeed_slurm/text_summary', 'user_script/text_summary', 'iteration/text_summary', 'do_train/text_summary', 'do_valid/text_summary', 'do_test/text_summary', 'global_num_gpus/text_summary', 'text_gen_type/text_summary', 'precompute_model_name/text_summary', 'temperature/text_summary', 'top_p/text_summary', 'top_k/text_summary', 'return_logits/text_summary', 'maximum_tokens/text_summary', 'prompt_end/text_summary', 'sample_input_file/text_summary', 'sample_output_file/text_summary', 'num_samples/text_summary', 'recompute/text_summary', 'eval_results_prefix/text_summary', 'eval_tasks/text_summary', 'moe_top_k/text_summary', 'use_tutel/text_summary', 'moe_num_experts/text_summary', 'moe_loss_coeff/text_summary', 'moe_train_capacity_factor/text_summary', 'moe_eval_capacity_factor/text_summary', 'moe_min_capacity/text_summary', 'moe_token_dropping/text_summary', 'create_moe_param_group/text_summary', 'moe_use_residual/text_summary', 'moe_expert_parallel_size/text_summary', 'moe_type/text_summary', 'moe_glu/text_summary', 'moe_lbl_in_fp32/text_summary', 'moe_jitter_eps/text_summary', 'enable_expert_tensor_parallelism/text_summary', 'use_wandb/text_summary', 'wandb_group/text_summary', 'wandb_team/text_summary', 'wandb_project/text_summary', 'wandb_host/text_summary', 'wandb_init_all_ranks/text_summary', 'git_hash/text_summary', 'log_dir/text_summary', 'tensorboard_dir/text_summary', 'use_comet/text_summary', 'comet_workspace/text_summary', 'comet_project/text_summary', 'comet_experiment_name/text_summary', 'comet_tags/text_summary', 'comet_others/text_summary', 'comet_experiment/text_summary', 'log_interval/text_summary', 'log_grad_pct_zeros/text_summary', 'log_param_norm/text_summary', 'log_grad_norm/text_summary', 'log_optimizer_states/text_summary', 'log_gradient_noise_scale/text_summary', 'gradient_noise_scale_n_batches/text_summary', 'gradient_noise_scale_cpu_offload/text_summary', 'memory_profiling/text_summary', 'memory_profiling_path/text_summary', 'profile/text_summary', 'profile_step_start/text_summary', 'profile_step_stop/text_summary', 'pipe_parallel_size/text_summary', 'model_parallel_size/text_summary', 'pipe_partition_method/text_summary', 'world_size/text_summary', 'is_pipe_parallel/text_summary', 'sequence_parallel/text_summary', 'expert_interval/text_summary', 'data_path/text_summary', 'use_shared_fs/text_summary', 'train_data_paths/text_summary', 'train_label_data_paths/text_summary', 'train_reward_data_paths/text_summary', 'test_data_paths/text_summary', 'test_label_data_paths/text_summary', 'test_reward_data_paths/text_summary', 'valid_data_paths/text_summary', 'valid_label_data_paths/text_summary', 'valid_reward_data_paths/text_summary', 'pos_train_data_paths/text_summary', 'neg_train_data_paths/text_summary', 'pos_train_label_data_paths/text_summary', 'neg_train_label_data_paths/text_summary', 'pos_valid_data_paths/text_summary', 'neg_valid_data_paths/text_summary', 'pos_valid_label_data_paths/text_summary', 'neg_valid_label_data_paths/text_summary', 'pos_test_data_paths/text_summary', 'neg_test_data_paths/text_summary', 'pos_test_label_data_paths/text_summary', 'neg_test_label_data_paths/text_summary', 'train_data_weights/text_summary', 'valid_data_weights/text_summary', 'test_data_weights/text_summary', 'weight_by_num_documents/text_summary', 'weighted_sampler_alpha/text_summary', 'data_impl/text_summary', 'pack_impl/text_summary', 'dataset_impl/text_summary', 'train_impl/text_summary', 'dpo_fp32/text_summary', 'dpo_reference_free/text_summary', 'dpo_beta/text_summary', 'kto_fp32/text_summary', 'kto_desirable_weight/text_summary', 'kto_undesirable_weight/text_summary', 'z_loss/text_summary', 'kto_beta/text_summary', 'allow_chopped/text_summary', 'mmap_warmup/text_summary', 'save/text_summary', 's3_path/text_summary', 's3_chunk_size/text_summary', 'config_files/text_summary', 'load/text_summary', 'checkpoint_validation_with_forward_pass/text_summary', 'checkpoint_scale/text_summary', 'checkpoint_factor/text_summary', 'extra_save_iters/text_summary', 'no_save_optim/text_summary', 'no_save_rng/text_summary', 'no_load_optim/text_summary', 'no_load_rng/text_summary', 'finetune/text_summary', 'batch_size/text_summary', 'train_iters/text_summary', 'train_epochs/text_summary', 'eval_iters/text_summary', 'keep_last_n_checkpoints/text_summary', 'eval_interval/text_summary', 'split/text_summary', 'vocab_file/text_summary', 'merge_file/text_summary', 'num_workers/text_summary', 'exit_interval/text_summary', 'attention_dropout/text_summary', 'hidden_dropout/text_summary', 'weight_decay/text_summary', 'checkpoint_activations/text_summary', 'checkpoint_num_layers/text_summary', 'deepspeed_activation_checkpointing/text_summary', 'contiguous_checkpointing/text_summary', 'checkpoint_in_cpu/text_summary', 'synchronize_each_layer/text_summary', 'profile_backward/text_summary', 'partition_activations/text_summary', 'clip_grad/text_summary', 'hysteresis/text_summary', 'dynamic_loss_scale/text_summary', 'loss_scale/text_summary', 'loss_scale_window/text_summary', 'min_scale/text_summary', 'char_level_ppl/text_summary', 'use_mup/text_summary', 'coord_check/text_summary', 'save_base_shapes/text_summary', 'base_shapes_file/text_summary', 'mup_init_scale/text_summary', 'mup_attn_temp/text_summary', 'mup_output_temp/text_summary', 'mup_embedding_mult/text_summary', 'mup_rp_embedding_mult/text_summary', 'mup_width_scale/text_summary', 'tokenizer_type/text_summary', 'padded_vocab_size/text_summary', 'optimizer_type/text_summary', 'use_bnb_optimizer/text_summary', 'zero_stage/text_summary', 'zero_reduce_scatter/text_summary', 'zero_contiguous_gradients/text_summary', 'zero_reduce_bucket_size/text_summary', 'zero_allgather_bucket_size/text_summary', 'lr/text_summary', 'lr_decay_style/text_summary', 'lr_decay_iters/text_summary', 'lr_decay_fraction/text_summary', 'min_lr/text_summary', 'warmup/text_summary', 'override_lr_scheduler/text_summary', 'use_checkpoint_lr_scheduler/text_summary', 'precision/text_summary', 'num_layers/text_summary', 'hidden_size/text_summary', 'intermediate_size/text_summary', 'mlp_multiple_of/text_summary', 'expansion_factor/text_summary', 'num_attention_heads/text_summary', 'num_kv_heads/text_summary', 'seq_length/text_summary', 'sliding_window_width/text_summary', 'max_position_embeddings/text_summary', 'norm/text_summary', 'layernorm_fusion/text_summary', 'rmsnorm_fusion/text_summary', 'use_qk_layernorm/text_summary', 'layernorm_epsilon/text_summary', 'rms_norm_epsilon/text_summary', 'scalenorm_epsilon/text_summary', 'pos_emb/text_summary', 'rpe_num_buckets/text_summary', 'rpe_max_distance/text_summary', 'opt_pos_emb_offset/text_summary', 'no_weight_tying/text_summary', 'attention_config/text_summary', 'sparsity_config/text_summary', 'num_unique_layers/text_summary', 'param_sharing_style/text_summary', 'make_vocab_size_divisible_by/text_summary', 'activation/text_summary', 'use_flashattn_swiglu/text_summary', 'scaled_upper_triang_masked_softmax_fusion/text_summary', 'scaled_masked_softmax_fusion/text_summary', 'bias_gelu_fusion/text_summary', 'bias_dropout_fusion/text_summary', 'rope_fusion/text_summary', 'fp16_lm_cross_entropy/text_summary', 'init_method_std/text_summary', 'apply_query_key_layer_scaling/text_summary', 'use_cpu_initialization/text_summary', 'attention_softmax_in_fp32/text_summary', 'rotary_pct/text_summary', 'rotary_emb_base/text_summary', 'rotary_save_freqs_buffer/text_summary', 'init_method/text_summary', 'output_layer_init_method/text_summary', 'gmlp_attn_dim/text_summary', 'gpt_j_residual/text_summary', 'gpt_j_tied/text_summary', 'use_bias_in_norms/text_summary', 'use_bias_in_attn_linear/text_summary', 'use_bias_in_mlp/text_summary', 'soft_prompt_tuning/text_summary', 'mamba_selective_scan_fusion/text_summary', 'mamba_causal_conv_fusion/text_summary', 'mamba_inner_func_fusion/text_summary', 'mamba_selective_fp32_params/text_summary', 'mamba_use_bias_in_conv/text_summary', 'mamba_use_bias_in_linears/text_summary', 'output_layer_parallelism/text_summary', 'dim_att/text_summary', 'head_size/text_summary', 'ffn_dim/text_summary', 'deepspeed/text_summary', 'train_batch_size/text_summary', 'train_micro_batch_size_per_gpu/text_summary', 'gradient_accumulation_steps/text_summary', 'optimizer/text_summary', 'scheduler/text_summary', 'fp32_allreduce/text_summary', 'prescale_gradients/text_summary', 'gradient_predivide_factor/text_summary', 'sparse_gradients/text_summary', 'fp16/text_summary', 'bf16/text_summary', 'amp/text_summary', 'gradient_clipping/text_summary', 'zero_optimization/text_summary', 'curriculum_learning/text_summary', 'curriculum_seqlen/text_summary', 'steps_per_print/text_summary', 'wall_clock_breakdown/text_summary', 'dump_state/text_summary', 'flops_profiler/text_summary', 'communication_data_type/text_summary', 'autotuning/text_summary', 'activation_checkpointing/text_summary', 'sparse_attention/text_summary', 'data_efficiency/text_summary', 'tensorboard/text_summary', 'wandb/text_summary', 'csv_monitor/text_summary', 'elasticity/text_summary', 'comms_logger/text_summary', 'compression_training/text_summary', 'checkpoint/text_summary', 'data_types/text_summary', 'deepspeed_extra_args/text_summary', 'hostfile/text_summary', 'include/text_summary', 'exclude/text_summary', 'num_nodes/text_summary', 'num_gpus/text_summary', 'master_port/text_summary', 'master_addr/text_summary', 'launcher/text_summary', 'force_multi/text_summary', 'detect_nvlink_pairs/text_summary', 'autotuning_run/text_summary', 'no_ssh_check/text_summary', 'comment/text_summary', 'account/text_summary', 'tokenizer/text_summary', 'tensorboard_writer/text_summary'], 'graph': False, 'meta_graph': False, 'run_metadata': []}\n",
      "Logging metric test/lm_loss 3.5635628700256348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/13 08:54:01 INFO mlflow.tracking._tracking_service.client: 🏃 View run luxuriant-steed-985 at: https://dagshub.com/MarkNZed/GPT-NeoX-Colab.mlflow/#/experiments/7/runs/aa40cc474ed545dfbc62a4203353dea3.\n",
      "2024/11/13 08:54:01 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dagshub.com/MarkNZed/GPT-NeoX-Colab.mlflow/#/experiments/7.\n",
      "2024/11/13 08:54:01 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2024/11/13 08:54:02 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "2024/11/13 08:54:03 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_micro_batch_size_per_gpu': 64, 'train_iters': 3200, 'lr_decay_iters': 3200, 'save': 'experiments/experiment2/checkpoints', 'load': 'experiments/experiment2/checkpoints', 'tensorboard_dir': 'experiments/experiment2/tensorboard', 'log_dir': 'experiments/experiment2/logs'}\n",
      "Running experiment: experiment2\n",
      "Running command: nohup bash -c \"source /content/my_env/bin/activate &&         cd /content/gpt-neox &&         python ./deepy.py train.py --conf_dir /tmp/tmpjmcb4aqq         temp_config\" & echo $! > train_process.pid\n",
      "Training initiated.\n",
      "Waiting for train_process.pid to be created...\n",
      "PID: 33017\n",
      "Latest file: /content/gpt-neox/experiments/experiment2/logs/5518ca645c4c_stdout.txt\n",
      "Training is still running...\n",
      "Training is still running...\n",
      "Training is still running...\n",
      "Training is still running...\n",
      "Training is still running...\n",
      "Training is still running...\n",
      "Training is still running...\n",
      "Training is still running...\n",
      "Training is still running...\n",
      "Training is still running...\n",
      "Training is still running...\n",
      "Training is still running...\n",
      "Training is still running...\n",
      "Training is still running...\n",
      "Training is still running...\n",
      "Training is still running...\n",
      "Training has finished.\n",
      "Latest file: /content/gpt-neox/experiments/experiment2/tensorboard/events.out.tfevents.1731488053.5518ca645c4c.33074.0\n",
      "{'images': [], 'audio': [], 'histograms': [], 'scalars': ['train/learning_rate', 'train/lm_loss', 'train/loss_scale', 'runtime/samples_per_sec', 'runtime/iteration_time', 'runtime/flops_per_sec_per_gpu', 'validation/lm_loss', 'validation/lm_loss_ppl', 'test/lm_loss', 'test/lm_loss_ppl'], 'distributions': [], 'tensors': ['distributed_backend/text_summary', 'local_rank/text_summary', 'rank/text_summary', 'lazy_mpu_init/text_summary', 'short_seq_prob/text_summary', 'eod_mask_loss/text_summary', 'adlr_autoresume/text_summary', 'adlr_autoresume_interval/text_summary', 'seed/text_summary', 'onnx_safe/text_summary', 'deepscale/text_summary', 'deepscale_config/text_summary', 'deepspeed_mpi/text_summary', 'deepspeed_slurm/text_summary', 'user_script/text_summary', 'iteration/text_summary', 'do_train/text_summary', 'do_valid/text_summary', 'do_test/text_summary', 'global_num_gpus/text_summary', 'text_gen_type/text_summary', 'precompute_model_name/text_summary', 'temperature/text_summary', 'top_p/text_summary', 'top_k/text_summary', 'return_logits/text_summary', 'maximum_tokens/text_summary', 'prompt_end/text_summary', 'sample_input_file/text_summary', 'sample_output_file/text_summary', 'num_samples/text_summary', 'recompute/text_summary', 'eval_results_prefix/text_summary', 'eval_tasks/text_summary', 'moe_top_k/text_summary', 'use_tutel/text_summary', 'moe_num_experts/text_summary', 'moe_loss_coeff/text_summary', 'moe_train_capacity_factor/text_summary', 'moe_eval_capacity_factor/text_summary', 'moe_min_capacity/text_summary', 'moe_token_dropping/text_summary', 'create_moe_param_group/text_summary', 'moe_use_residual/text_summary', 'moe_expert_parallel_size/text_summary', 'moe_type/text_summary', 'moe_glu/text_summary', 'moe_lbl_in_fp32/text_summary', 'moe_jitter_eps/text_summary', 'enable_expert_tensor_parallelism/text_summary', 'use_wandb/text_summary', 'wandb_group/text_summary', 'wandb_team/text_summary', 'wandb_project/text_summary', 'wandb_host/text_summary', 'wandb_init_all_ranks/text_summary', 'git_hash/text_summary', 'log_dir/text_summary', 'tensorboard_dir/text_summary', 'use_comet/text_summary', 'comet_workspace/text_summary', 'comet_project/text_summary', 'comet_experiment_name/text_summary', 'comet_tags/text_summary', 'comet_others/text_summary', 'comet_experiment/text_summary', 'log_interval/text_summary', 'log_grad_pct_zeros/text_summary', 'log_param_norm/text_summary', 'log_grad_norm/text_summary', 'log_optimizer_states/text_summary', 'log_gradient_noise_scale/text_summary', 'gradient_noise_scale_n_batches/text_summary', 'gradient_noise_scale_cpu_offload/text_summary', 'memory_profiling/text_summary', 'memory_profiling_path/text_summary', 'profile/text_summary', 'profile_step_start/text_summary', 'profile_step_stop/text_summary', 'pipe_parallel_size/text_summary', 'model_parallel_size/text_summary', 'pipe_partition_method/text_summary', 'world_size/text_summary', 'is_pipe_parallel/text_summary', 'sequence_parallel/text_summary', 'expert_interval/text_summary', 'data_path/text_summary', 'use_shared_fs/text_summary', 'train_data_paths/text_summary', 'train_label_data_paths/text_summary', 'train_reward_data_paths/text_summary', 'test_data_paths/text_summary', 'test_label_data_paths/text_summary', 'test_reward_data_paths/text_summary', 'valid_data_paths/text_summary', 'valid_label_data_paths/text_summary', 'valid_reward_data_paths/text_summary', 'pos_train_data_paths/text_summary', 'neg_train_data_paths/text_summary', 'pos_train_label_data_paths/text_summary', 'neg_train_label_data_paths/text_summary', 'pos_valid_data_paths/text_summary', 'neg_valid_data_paths/text_summary', 'pos_valid_label_data_paths/text_summary', 'neg_valid_label_data_paths/text_summary', 'pos_test_data_paths/text_summary', 'neg_test_data_paths/text_summary', 'pos_test_label_data_paths/text_summary', 'neg_test_label_data_paths/text_summary', 'train_data_weights/text_summary', 'valid_data_weights/text_summary', 'test_data_weights/text_summary', 'weight_by_num_documents/text_summary', 'weighted_sampler_alpha/text_summary', 'data_impl/text_summary', 'pack_impl/text_summary', 'dataset_impl/text_summary', 'train_impl/text_summary', 'dpo_fp32/text_summary', 'dpo_reference_free/text_summary', 'dpo_beta/text_summary', 'kto_fp32/text_summary', 'kto_desirable_weight/text_summary', 'kto_undesirable_weight/text_summary', 'z_loss/text_summary', 'kto_beta/text_summary', 'allow_chopped/text_summary', 'mmap_warmup/text_summary', 'save/text_summary', 's3_path/text_summary', 's3_chunk_size/text_summary', 'config_files/text_summary', 'load/text_summary', 'checkpoint_validation_with_forward_pass/text_summary', 'checkpoint_scale/text_summary', 'checkpoint_factor/text_summary', 'extra_save_iters/text_summary', 'no_save_optim/text_summary', 'no_save_rng/text_summary', 'no_load_optim/text_summary', 'no_load_rng/text_summary', 'finetune/text_summary', 'batch_size/text_summary', 'train_iters/text_summary', 'train_epochs/text_summary', 'eval_iters/text_summary', 'keep_last_n_checkpoints/text_summary', 'eval_interval/text_summary', 'split/text_summary', 'vocab_file/text_summary', 'merge_file/text_summary', 'num_workers/text_summary', 'exit_interval/text_summary', 'attention_dropout/text_summary', 'hidden_dropout/text_summary', 'weight_decay/text_summary', 'checkpoint_activations/text_summary', 'checkpoint_num_layers/text_summary', 'deepspeed_activation_checkpointing/text_summary', 'contiguous_checkpointing/text_summary', 'checkpoint_in_cpu/text_summary', 'synchronize_each_layer/text_summary', 'profile_backward/text_summary', 'partition_activations/text_summary', 'clip_grad/text_summary', 'hysteresis/text_summary', 'dynamic_loss_scale/text_summary', 'loss_scale/text_summary', 'loss_scale_window/text_summary', 'min_scale/text_summary', 'char_level_ppl/text_summary', 'use_mup/text_summary', 'coord_check/text_summary', 'save_base_shapes/text_summary', 'base_shapes_file/text_summary', 'mup_init_scale/text_summary', 'mup_attn_temp/text_summary', 'mup_output_temp/text_summary', 'mup_embedding_mult/text_summary', 'mup_rp_embedding_mult/text_summary', 'mup_width_scale/text_summary', 'tokenizer_type/text_summary', 'padded_vocab_size/text_summary', 'optimizer_type/text_summary', 'use_bnb_optimizer/text_summary', 'zero_stage/text_summary', 'zero_reduce_scatter/text_summary', 'zero_contiguous_gradients/text_summary', 'zero_reduce_bucket_size/text_summary', 'zero_allgather_bucket_size/text_summary', 'lr/text_summary', 'lr_decay_style/text_summary', 'lr_decay_iters/text_summary', 'lr_decay_fraction/text_summary', 'min_lr/text_summary', 'warmup/text_summary', 'override_lr_scheduler/text_summary', 'use_checkpoint_lr_scheduler/text_summary', 'precision/text_summary', 'num_layers/text_summary', 'hidden_size/text_summary', 'intermediate_size/text_summary', 'mlp_multiple_of/text_summary', 'expansion_factor/text_summary', 'num_attention_heads/text_summary', 'num_kv_heads/text_summary', 'seq_length/text_summary', 'sliding_window_width/text_summary', 'max_position_embeddings/text_summary', 'norm/text_summary', 'layernorm_fusion/text_summary', 'rmsnorm_fusion/text_summary', 'use_qk_layernorm/text_summary', 'layernorm_epsilon/text_summary', 'rms_norm_epsilon/text_summary', 'scalenorm_epsilon/text_summary', 'pos_emb/text_summary', 'rpe_num_buckets/text_summary', 'rpe_max_distance/text_summary', 'opt_pos_emb_offset/text_summary', 'no_weight_tying/text_summary', 'attention_config/text_summary', 'sparsity_config/text_summary', 'num_unique_layers/text_summary', 'param_sharing_style/text_summary', 'make_vocab_size_divisible_by/text_summary', 'activation/text_summary', 'use_flashattn_swiglu/text_summary', 'scaled_upper_triang_masked_softmax_fusion/text_summary', 'scaled_masked_softmax_fusion/text_summary', 'bias_gelu_fusion/text_summary', 'bias_dropout_fusion/text_summary', 'rope_fusion/text_summary', 'fp16_lm_cross_entropy/text_summary', 'init_method_std/text_summary', 'apply_query_key_layer_scaling/text_summary', 'use_cpu_initialization/text_summary', 'attention_softmax_in_fp32/text_summary', 'rotary_pct/text_summary', 'rotary_emb_base/text_summary', 'rotary_save_freqs_buffer/text_summary', 'init_method/text_summary', 'output_layer_init_method/text_summary', 'gmlp_attn_dim/text_summary', 'gpt_j_residual/text_summary', 'gpt_j_tied/text_summary', 'use_bias_in_norms/text_summary', 'use_bias_in_attn_linear/text_summary', 'use_bias_in_mlp/text_summary', 'soft_prompt_tuning/text_summary', 'mamba_selective_scan_fusion/text_summary', 'mamba_causal_conv_fusion/text_summary', 'mamba_inner_func_fusion/text_summary', 'mamba_selective_fp32_params/text_summary', 'mamba_use_bias_in_conv/text_summary', 'mamba_use_bias_in_linears/text_summary', 'output_layer_parallelism/text_summary', 'dim_att/text_summary', 'head_size/text_summary', 'ffn_dim/text_summary', 'deepspeed/text_summary', 'train_batch_size/text_summary', 'train_micro_batch_size_per_gpu/text_summary', 'gradient_accumulation_steps/text_summary', 'optimizer/text_summary', 'scheduler/text_summary', 'fp32_allreduce/text_summary', 'prescale_gradients/text_summary', 'gradient_predivide_factor/text_summary', 'sparse_gradients/text_summary', 'fp16/text_summary', 'bf16/text_summary', 'amp/text_summary', 'gradient_clipping/text_summary', 'zero_optimization/text_summary', 'curriculum_learning/text_summary', 'curriculum_seqlen/text_summary', 'steps_per_print/text_summary', 'wall_clock_breakdown/text_summary', 'dump_state/text_summary', 'flops_profiler/text_summary', 'communication_data_type/text_summary', 'autotuning/text_summary', 'activation_checkpointing/text_summary', 'sparse_attention/text_summary', 'data_efficiency/text_summary', 'tensorboard/text_summary', 'wandb/text_summary', 'csv_monitor/text_summary', 'elasticity/text_summary', 'comms_logger/text_summary', 'compression_training/text_summary', 'checkpoint/text_summary', 'data_types/text_summary', 'deepspeed_extra_args/text_summary', 'hostfile/text_summary', 'include/text_summary', 'exclude/text_summary', 'num_nodes/text_summary', 'num_gpus/text_summary', 'master_port/text_summary', 'master_addr/text_summary', 'launcher/text_summary', 'force_multi/text_summary', 'detect_nvlink_pairs/text_summary', 'autotuning_run/text_summary', 'no_ssh_check/text_summary', 'comment/text_summary', 'account/text_summary', 'tokenizer/text_summary', 'tensorboard_writer/text_summary'], 'graph': False, 'meta_graph': False, 'run_metadata': []}\n",
      "Logging metric test/lm_loss 3.2894349098205566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/13 09:02:15 INFO mlflow.tracking._tracking_service.client: 🏃 View run spiffy-penguin-349 at: https://dagshub.com/MarkNZed/GPT-NeoX-Colab.mlflow/#/experiments/7/runs/313b086afedb4b34a4fec1335d43dece.\n",
      "2024/11/13 09:02:15 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dagshub.com/MarkNZed/GPT-NeoX-Colab.mlflow/#/experiments/7.\n",
      "2024/11/13 09:02:15 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2024/11/13 09:02:16 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "2024/11/13 09:02:16 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_micro_batch_size_per_gpu': 256, 'train_iters': 800, 'lr_decay_iters': 800, 'save': 'experiments/experiment3/checkpoints', 'load': 'experiments/experiment3/checkpoints', 'tensorboard_dir': 'experiments/experiment3/tensorboard', 'log_dir': 'experiments/experiment3/logs'}\n",
      "Running experiment: experiment3\n",
      "Running command: nohup bash -c \"source /content/my_env/bin/activate &&         cd /content/gpt-neox &&         python ./deepy.py train.py --conf_dir /tmp/tmp6mfgxnc1         temp_config\" & echo $! > train_process.pid\n",
      "Training initiated.\n",
      "Waiting for train_process.pid to be created...\n",
      "PID: 35263\n",
      "Latest file: /content/gpt-neox/experiments/experiment3/logs/5518ca645c4c_stdout.txt\n",
      "Training is still running...\n",
      "Training is still running...\n",
      "Training is still running...\n",
      "Training is still running...\n",
      "Training is still running...\n",
      "Training is still running...\n",
      "Training is still running...\n",
      "Training is still running...\n",
      "Training is still running...\n",
      "Training is still running...\n",
      "Training is still running...\n",
      "Training is still running...\n",
      "Training is still running...\n",
      "Training is still running...\n",
      "Training is still running...\n",
      "Training has finished.\n",
      "Latest file: /content/gpt-neox/experiments/experiment3/tensorboard/events.out.tfevents.1731488546.5518ca645c4c.35316.0\n",
      "{'images': [], 'audio': [], 'histograms': [], 'scalars': ['train/learning_rate', 'train/lm_loss', 'train/loss_scale', 'runtime/samples_per_sec', 'runtime/iteration_time', 'runtime/flops_per_sec_per_gpu', 'validation/lm_loss', 'validation/lm_loss_ppl', 'test/lm_loss', 'test/lm_loss_ppl'], 'distributions': [], 'tensors': ['distributed_backend/text_summary', 'local_rank/text_summary', 'rank/text_summary', 'lazy_mpu_init/text_summary', 'short_seq_prob/text_summary', 'eod_mask_loss/text_summary', 'adlr_autoresume/text_summary', 'adlr_autoresume_interval/text_summary', 'seed/text_summary', 'onnx_safe/text_summary', 'deepscale/text_summary', 'deepscale_config/text_summary', 'deepspeed_mpi/text_summary', 'deepspeed_slurm/text_summary', 'user_script/text_summary', 'iteration/text_summary', 'do_train/text_summary', 'do_valid/text_summary', 'do_test/text_summary', 'global_num_gpus/text_summary', 'text_gen_type/text_summary', 'precompute_model_name/text_summary', 'temperature/text_summary', 'top_p/text_summary', 'top_k/text_summary', 'return_logits/text_summary', 'maximum_tokens/text_summary', 'prompt_end/text_summary', 'sample_input_file/text_summary', 'sample_output_file/text_summary', 'num_samples/text_summary', 'recompute/text_summary', 'eval_results_prefix/text_summary', 'eval_tasks/text_summary', 'moe_top_k/text_summary', 'use_tutel/text_summary', 'moe_num_experts/text_summary', 'moe_loss_coeff/text_summary', 'moe_train_capacity_factor/text_summary', 'moe_eval_capacity_factor/text_summary', 'moe_min_capacity/text_summary', 'moe_token_dropping/text_summary', 'create_moe_param_group/text_summary', 'moe_use_residual/text_summary', 'moe_expert_parallel_size/text_summary', 'moe_type/text_summary', 'moe_glu/text_summary', 'moe_lbl_in_fp32/text_summary', 'moe_jitter_eps/text_summary', 'enable_expert_tensor_parallelism/text_summary', 'use_wandb/text_summary', 'wandb_group/text_summary', 'wandb_team/text_summary', 'wandb_project/text_summary', 'wandb_host/text_summary', 'wandb_init_all_ranks/text_summary', 'git_hash/text_summary', 'log_dir/text_summary', 'tensorboard_dir/text_summary', 'use_comet/text_summary', 'comet_workspace/text_summary', 'comet_project/text_summary', 'comet_experiment_name/text_summary', 'comet_tags/text_summary', 'comet_others/text_summary', 'comet_experiment/text_summary', 'log_interval/text_summary', 'log_grad_pct_zeros/text_summary', 'log_param_norm/text_summary', 'log_grad_norm/text_summary', 'log_optimizer_states/text_summary', 'log_gradient_noise_scale/text_summary', 'gradient_noise_scale_n_batches/text_summary', 'gradient_noise_scale_cpu_offload/text_summary', 'memory_profiling/text_summary', 'memory_profiling_path/text_summary', 'profile/text_summary', 'profile_step_start/text_summary', 'profile_step_stop/text_summary', 'pipe_parallel_size/text_summary', 'model_parallel_size/text_summary', 'pipe_partition_method/text_summary', 'world_size/text_summary', 'is_pipe_parallel/text_summary', 'sequence_parallel/text_summary', 'expert_interval/text_summary', 'data_path/text_summary', 'use_shared_fs/text_summary', 'train_data_paths/text_summary', 'train_label_data_paths/text_summary', 'train_reward_data_paths/text_summary', 'test_data_paths/text_summary', 'test_label_data_paths/text_summary', 'test_reward_data_paths/text_summary', 'valid_data_paths/text_summary', 'valid_label_data_paths/text_summary', 'valid_reward_data_paths/text_summary', 'pos_train_data_paths/text_summary', 'neg_train_data_paths/text_summary', 'pos_train_label_data_paths/text_summary', 'neg_train_label_data_paths/text_summary', 'pos_valid_data_paths/text_summary', 'neg_valid_data_paths/text_summary', 'pos_valid_label_data_paths/text_summary', 'neg_valid_label_data_paths/text_summary', 'pos_test_data_paths/text_summary', 'neg_test_data_paths/text_summary', 'pos_test_label_data_paths/text_summary', 'neg_test_label_data_paths/text_summary', 'train_data_weights/text_summary', 'valid_data_weights/text_summary', 'test_data_weights/text_summary', 'weight_by_num_documents/text_summary', 'weighted_sampler_alpha/text_summary', 'data_impl/text_summary', 'pack_impl/text_summary', 'dataset_impl/text_summary', 'train_impl/text_summary', 'dpo_fp32/text_summary', 'dpo_reference_free/text_summary', 'dpo_beta/text_summary', 'kto_fp32/text_summary', 'kto_desirable_weight/text_summary', 'kto_undesirable_weight/text_summary', 'z_loss/text_summary', 'kto_beta/text_summary', 'allow_chopped/text_summary', 'mmap_warmup/text_summary', 'save/text_summary', 's3_path/text_summary', 's3_chunk_size/text_summary', 'config_files/text_summary', 'load/text_summary', 'checkpoint_validation_with_forward_pass/text_summary', 'checkpoint_scale/text_summary', 'checkpoint_factor/text_summary', 'extra_save_iters/text_summary', 'no_save_optim/text_summary', 'no_save_rng/text_summary', 'no_load_optim/text_summary', 'no_load_rng/text_summary', 'finetune/text_summary', 'batch_size/text_summary', 'train_iters/text_summary', 'train_epochs/text_summary', 'eval_iters/text_summary', 'keep_last_n_checkpoints/text_summary', 'eval_interval/text_summary', 'split/text_summary', 'vocab_file/text_summary', 'merge_file/text_summary', 'num_workers/text_summary', 'exit_interval/text_summary', 'attention_dropout/text_summary', 'hidden_dropout/text_summary', 'weight_decay/text_summary', 'checkpoint_activations/text_summary', 'checkpoint_num_layers/text_summary', 'deepspeed_activation_checkpointing/text_summary', 'contiguous_checkpointing/text_summary', 'checkpoint_in_cpu/text_summary', 'synchronize_each_layer/text_summary', 'profile_backward/text_summary', 'partition_activations/text_summary', 'clip_grad/text_summary', 'hysteresis/text_summary', 'dynamic_loss_scale/text_summary', 'loss_scale/text_summary', 'loss_scale_window/text_summary', 'min_scale/text_summary', 'char_level_ppl/text_summary', 'use_mup/text_summary', 'coord_check/text_summary', 'save_base_shapes/text_summary', 'base_shapes_file/text_summary', 'mup_init_scale/text_summary', 'mup_attn_temp/text_summary', 'mup_output_temp/text_summary', 'mup_embedding_mult/text_summary', 'mup_rp_embedding_mult/text_summary', 'mup_width_scale/text_summary', 'tokenizer_type/text_summary', 'padded_vocab_size/text_summary', 'optimizer_type/text_summary', 'use_bnb_optimizer/text_summary', 'zero_stage/text_summary', 'zero_reduce_scatter/text_summary', 'zero_contiguous_gradients/text_summary', 'zero_reduce_bucket_size/text_summary', 'zero_allgather_bucket_size/text_summary', 'lr/text_summary', 'lr_decay_style/text_summary', 'lr_decay_iters/text_summary', 'lr_decay_fraction/text_summary', 'min_lr/text_summary', 'warmup/text_summary', 'override_lr_scheduler/text_summary', 'use_checkpoint_lr_scheduler/text_summary', 'precision/text_summary', 'num_layers/text_summary', 'hidden_size/text_summary', 'intermediate_size/text_summary', 'mlp_multiple_of/text_summary', 'expansion_factor/text_summary', 'num_attention_heads/text_summary', 'num_kv_heads/text_summary', 'seq_length/text_summary', 'sliding_window_width/text_summary', 'max_position_embeddings/text_summary', 'norm/text_summary', 'layernorm_fusion/text_summary', 'rmsnorm_fusion/text_summary', 'use_qk_layernorm/text_summary', 'layernorm_epsilon/text_summary', 'rms_norm_epsilon/text_summary', 'scalenorm_epsilon/text_summary', 'pos_emb/text_summary', 'rpe_num_buckets/text_summary', 'rpe_max_distance/text_summary', 'opt_pos_emb_offset/text_summary', 'no_weight_tying/text_summary', 'attention_config/text_summary', 'sparsity_config/text_summary', 'num_unique_layers/text_summary', 'param_sharing_style/text_summary', 'make_vocab_size_divisible_by/text_summary', 'activation/text_summary', 'use_flashattn_swiglu/text_summary', 'scaled_upper_triang_masked_softmax_fusion/text_summary', 'scaled_masked_softmax_fusion/text_summary', 'bias_gelu_fusion/text_summary', 'bias_dropout_fusion/text_summary', 'rope_fusion/text_summary', 'fp16_lm_cross_entropy/text_summary', 'init_method_std/text_summary', 'apply_query_key_layer_scaling/text_summary', 'use_cpu_initialization/text_summary', 'attention_softmax_in_fp32/text_summary', 'rotary_pct/text_summary', 'rotary_emb_base/text_summary', 'rotary_save_freqs_buffer/text_summary', 'init_method/text_summary', 'output_layer_init_method/text_summary', 'gmlp_attn_dim/text_summary', 'gpt_j_residual/text_summary', 'gpt_j_tied/text_summary', 'use_bias_in_norms/text_summary', 'use_bias_in_attn_linear/text_summary', 'use_bias_in_mlp/text_summary', 'soft_prompt_tuning/text_summary', 'mamba_selective_scan_fusion/text_summary', 'mamba_causal_conv_fusion/text_summary', 'mamba_inner_func_fusion/text_summary', 'mamba_selective_fp32_params/text_summary', 'mamba_use_bias_in_conv/text_summary', 'mamba_use_bias_in_linears/text_summary', 'output_layer_parallelism/text_summary', 'dim_att/text_summary', 'head_size/text_summary', 'ffn_dim/text_summary', 'deepspeed/text_summary', 'train_batch_size/text_summary', 'train_micro_batch_size_per_gpu/text_summary', 'gradient_accumulation_steps/text_summary', 'optimizer/text_summary', 'scheduler/text_summary', 'fp32_allreduce/text_summary', 'prescale_gradients/text_summary', 'gradient_predivide_factor/text_summary', 'sparse_gradients/text_summary', 'fp16/text_summary', 'bf16/text_summary', 'amp/text_summary', 'gradient_clipping/text_summary', 'zero_optimization/text_summary', 'curriculum_learning/text_summary', 'curriculum_seqlen/text_summary', 'steps_per_print/text_summary', 'wall_clock_breakdown/text_summary', 'dump_state/text_summary', 'flops_profiler/text_summary', 'communication_data_type/text_summary', 'autotuning/text_summary', 'activation_checkpointing/text_summary', 'sparse_attention/text_summary', 'data_efficiency/text_summary', 'tensorboard/text_summary', 'wandb/text_summary', 'csv_monitor/text_summary', 'elasticity/text_summary', 'comms_logger/text_summary', 'compression_training/text_summary', 'checkpoint/text_summary', 'data_types/text_summary', 'deepspeed_extra_args/text_summary', 'hostfile/text_summary', 'include/text_summary', 'exclude/text_summary', 'num_nodes/text_summary', 'num_gpus/text_summary', 'master_port/text_summary', 'master_addr/text_summary', 'launcher/text_summary', 'force_multi/text_summary', 'detect_nvlink_pairs/text_summary', 'autotuning_run/text_summary', 'no_ssh_check/text_summary', 'comment/text_summary', 'account/text_summary', 'tokenizer/text_summary', 'tensorboard_writer/text_summary'], 'graph': False, 'meta_graph': False, 'run_metadata': []}\n",
      "Logging metric test/lm_loss 1.5117993354797363\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import subprocess\n",
    "import os\n",
    "from omegaconf import OmegaConf\n",
    "from hydra import initialize_config_dir, compose\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "import mlflow\n",
    "import time\n",
    "import dagshub\n",
    "\n",
    "%cd {GPTNeoXDir}\n",
    "\n",
    "dagshub.init(repo_owner='MarkNZed', repo_name='GPT-NeoX-Colab', mlflow=True)\n",
    "experiment_group = \"Added System Metrics\"\n",
    "mlflow.set_experiment(experiment_group)\n",
    "mlflow.enable_system_metrics_logging()\n",
    "\n",
    "def load_and_merge_configs(base_conf_dir, experiment_name):\n",
    "    # Initialize Hydra with the base config directory\n",
    "    initialize_config_dir(config_dir=base_conf_dir, version_base=\"1.1\")\n",
    "\n",
    "    # Load the base configurations (shakespeare and shakespeare_deepy) and experiment overrides\n",
    "    base_cfg = compose(config_name=\"shakespeare.yml\")\n",
    "    OmegaConf.set_struct(base_cfg, False) # No struct checking for matching structure in merge\n",
    "    deepy_cfg = compose(config_name=\"shakespeare_deepy.yml\")\n",
    "    OmegaConf.set_struct(deepy_cfg, False) # No struct checking for matching structure in merge\n",
    "    experiment_cfg = compose(config_name=\"hydra\", overrides=[f\"experiments={experiment_name}\"])\n",
    "    OmegaConf.set_struct(experiment_cfg, False) # No struct checking for matching structure in merge\n",
    "\n",
    "    mlflow.log_params(OmegaConf.to_container(experiment_cfg, resolve=True))\n",
    "\n",
    "    experiment_overrides = experiment_cfg.get(\"experiments\", {})\n",
    "    OmegaConf.set_struct(experiment_overrides, False) # No struct checking for matching structure in merge\n",
    "\n",
    "    print(experiment_overrides)\n",
    "\n",
    "    # Merge the configurations: base -> deepy -> experiment\n",
    "    cfg = OmegaConf.merge(base_cfg, deepy_cfg, experiment_overrides)\n",
    "\n",
    "    return cfg\n",
    "\n",
    "def run_experiment(cfg, experiment_name):\n",
    "    print(\"Running experiment:\", experiment_name)\n",
    "    experimentDir = f\"{GPTNeoXDir}/experiments/{experiment_name}\"\n",
    "    !sudo rm -rf {experimentDir}\n",
    "    !mkdir -p {experimentDir}\n",
    "    !rm -f train_process.pid\n",
    "    #print(OmegaConf.to_yaml(cfg))\n",
    "\n",
    "    # Create a temporary directory for configs\n",
    "    temp_config_dir = tempfile.mkdtemp()\n",
    "    temp_config_file = os.path.join(temp_config_dir, 'temp_config.yml')\n",
    "\n",
    "    # Save the modified config to the temporary file in JSON-like structure within a YAML file\n",
    "    with open(temp_config_file, 'w') as f:\n",
    "        # Dump the config as JSON but save it with a .yml extension\n",
    "        OmegaConf.save(OmegaConf.create(OmegaConf.to_container(cfg, resolve=True)), f)\n",
    "\n",
    "    # Start a detached background process using the temp config\n",
    "    cmd = f\"\"\"nohup bash -c \"source {workspaceDir}/my_env/bin/activate && \\\n",
    "        cd {GPTNeoXDir} && \\\n",
    "        python ./deepy.py train.py --conf_dir {temp_config_dir} \\\n",
    "        temp_config\" & echo $! > train_process.pid\"\"\"\n",
    "    print(\"Running command:\", cmd)\n",
    "    process = subprocess.Popen(\n",
    "        cmd,\n",
    "        shell=True,\n",
    "        executable='/bin/bash',\n",
    "        preexec_fn=os.setsid  # Starts the process in a new session\n",
    "    )\n",
    "\n",
    "    print(\"Training initiated.\")\n",
    "\n",
    "    while not os.path.exists(\"train_process.pid\"):\n",
    "        print(\"Waiting for train_process.pid to be created...\")\n",
    "        time.sleep(10)  # Check every X seconds\n",
    "\n",
    "    # Read the PID from the file\n",
    "    with open(\"train_process.pid\", \"r\") as f:\n",
    "        pid = int(f.read().strip())\n",
    "        print(\"Found train_process.pid \", pid)\n",
    "\n",
    "    while not os.path.exists(f\"{experimentDir}/logs\"):\n",
    "        print(\"Waiting for logs to be created...\")\n",
    "        time.sleep(10)  # Check every X seconds\n",
    "\n",
    "    latest_log = get_latest_file(f\"{experimentDir}/logs\", \"*_stdout.txt\")\n",
    "\n",
    "    # Monitor the training process\n",
    "    while is_process_running(pid):\n",
    "        read_new_iterations(latest_log)\n",
    "        print(\"Training is still running...\")\n",
    "        time.sleep(30)  # Check every X seconds\n",
    "\n",
    "    print(\"Training has finished.\")\n",
    "\n",
    "    latest_events_file = get_latest_file(f\"{experimentDir}/tensorboard\", \"events.out.tfevents.*\")\n",
    "    loss_key = \"test/lm_loss\"\n",
    "    loss = get_scalar_from_tensorboard(latest_events_file, loss_key)\n",
    "    print(f\"Logging metric {loss_key} {loss}\")\n",
    "    mlflow.log_metric(loss_key, loss)\n",
    "\n",
    "    # Clean up the temporary directory after training\n",
    "    # (Optional: You might want to keep it for debugging)\n",
    "    # shutil.rmtree(temp_config_dir)\n",
    "\n",
    "# List of experiment names\n",
    "experiments = [\"experiment1\", \"experiment2\", \"experiment3\"]\n",
    "\n",
    "for experiment in experiments:\n",
    "\n",
    "    exp_id = GPTNeoXColab.utils.ml.get_or_create_experiment_id(experiment_group)\n",
    "\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    # https://mlflow.org/docs/latest/tracking/tracking-api.html#system-tags\n",
    "    client.set_tag(exp_id, \"mlflow.source.git.commit\", commit_id)\n",
    "    client.set_tag(exp_id, \"mlflow.source.git.branch\", commit_id)\n",
    "    client.set_tag(exp_id, \"mlflow.source.git.repoURL\", commit_id)\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        # Clear Hydra's global state if it’s already initialized\n",
    "        if GlobalHydra.instance().is_initialized():\n",
    "            GlobalHydra.instance().clear()\n",
    "        # Load and merge configurations\n",
    "        base_conf_dir = f\"{GPTNeoXColabDir}/configs\"\n",
    "        cfg = load_and_merge_configs(base_conf_dir, experiment)\n",
    "        # Start training with the merged configuration\n",
    "        run_experiment(cfg, experiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0JGqO-azytqR"
   },
   "outputs": [],
   "source": [
    "# Here we could disconnect from the GPU resource\n",
    "from google.colab import runtime\n",
    "runtime.unassign()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
