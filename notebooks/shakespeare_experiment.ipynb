{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/markNZed/GPT-NeoX-Colab/blob/main/notebooks/shakespeare_experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flp2Dht6ytqE"
      },
      "source": [
        "# Experiment\n",
        "This is a demonstration of how experiments can be run using DagsHub and MLflow.\n",
        "We will train three different versions of the tiny LLM using different batch sizes and compare the results.\n",
        "\n",
        "## ToDo\n",
        "- Shorten the training time for testing\n",
        "- Run tests in parallel\n",
        "- Extract functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LECzxKWK8CyS"
      },
      "source": [
        "## Login to Dagshub\n",
        "To avoid requirest in the middle of the experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxd2wfpq1F9u",
        "outputId": "ccb5758b-65e5-4bec-8d81-ef0d1e0be612"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/251.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.7/251.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.6/82.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "import os\n",
        "%pip install -q dagshub\n",
        "import dagshub\n",
        "try:\n",
        "  from google.colab import userdata\n",
        "  os.environ[\"DAGSHUB_USER_TOKEN\"] = userdata.get(\"DAGSHUB_USER_TOKEN\")\n",
        "except:\n",
        "  pass\n",
        "try:\n",
        "  if os.environ[\"DAGSHUB_USER_TOKEN\"]:\n",
        "    pass\n",
        "except:\n",
        "  os.environ[\"DAGSHUB_USER_TOKEN\"] = dagshub.auth.get_token()\n",
        "dagshub.auth.add_app_token(token=os.environ[\"DAGSHUB_USER_TOKEN\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Iega62GjytqH"
      },
      "outputs": [],
      "source": [
        "#@title Setup paths\n",
        "# We could modify these paths to \"stub\" behavior for test/dev\n",
        "# A file like .ipython/profile_default/startup/10-test.py could restore these vars\n",
        "workspaceDir = \"/content\"\n",
        "GPTNeoXDirName = \"gpt-neox\"\n",
        "GPTNeoXDir = f\"{workspaceDir}/{GPTNeoXDirName}\"\n",
        "GPTNeoXColabDirName = \"GPT-NeoX-Colab\"\n",
        "GPTNeoXColabDir = f\"{workspaceDir}/{GPTNeoXColabDirName}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUxVImVvytqL",
        "outputId": "a850fb3e-1a6b-47a4-a844-a291016f1bc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'GPT-NeoX-Colab'...\n",
            "remote: Enumerating objects: 1310, done.\u001b[K\n",
            "remote: Counting objects: 100% (258/258), done.\u001b[K\n",
            "remote: Compressing objects: 100% (191/191), done.\u001b[K\n",
            "remote: Total 1310 (delta 154), reused 128 (delta 62), pack-reused 1052 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1310/1310), 13.89 MiB | 5.86 MiB/s, done.\n",
            "Resolving deltas: 100% (731/731), done.\n",
            "/content/GPT-NeoX-Colab\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.5/101.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.0/426.0 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.6/46.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.4/77.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.5/456.5 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m367.6/367.6 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.9/198.9 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m901.4/901.4 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m548.7/548.7 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m569.1/569.1 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.1/113.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m722.2/722.2 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for configobj (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pysftp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for GPTNeoXColab (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Data retrieval successful.\n",
            "Data retrieval successful.\n",
            "CPU times: user 11.8 s, sys: 1.3 s, total: 13.1 s\n",
            "Wall time: 3min\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "#@title Clone GPT-NeoX-Colab\n",
        "%cd {workspaceDir}\n",
        "# Don't use --depth 1 because that does not play nice with git-annex\n",
        "!git clone https://github.com/markNZed/GPT-NeoX-Colab.git\n",
        "%cd {GPTNeoXColabDir}\n",
        "%pip install -q -r requirements_colab.txt\n",
        "%pip install -q .\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "load_dotenv(f\"{GPTNeoXColabDir}/.env\")\n",
        "import GPTNeoXColab\n",
        "GPTNeoXColab.utils.colab.fetch_data(\"data/shakespeare/shakespeare_text_document.bin\")\n",
        "GPTNeoXColab.utils.colab.fetch_data(\"data/shakespeare/shakespeare_text_document.idx\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OvpVaIbLytqM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5660025e-0f32-4d5f-abb2-1b96175c2724"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'gpt-neox'...\n",
            "remote: Enumerating objects: 296, done.\u001b[K\n",
            "remote: Counting objects: 100% (296/296), done.\u001b[K\n",
            "remote: Compressing objects: 100% (231/231), done.\u001b[K\n",
            "remote: Total 296 (delta 74), reused 136 (delta 43), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (296/296), 2.50 MiB | 18.41 MiB/s, done.\n",
            "Resolving deltas: 100% (74/74), done.\n",
            "CPU times: user 14.2 ms, sys: 3.26 ms, total: 17.4 ms\n",
            "Wall time: 1.22 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "#@title Clone GPT-NeoX\n",
        "%cd {workspaceDir}\n",
        "#!git clone --depth 1 https://github.com/EleutherAI/gpt-neox\n",
        "!git clone -b pipe_parallel_size_1 --depth 1 https://github.com/markNZed/gpt-neox.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6EJBRBSpiSXF"
      },
      "outputs": [],
      "source": [
        "!mkdir -p {GPTNeoXDir}/processed_data\n",
        "!cp {GPTNeoXColabDir}/data/shakespeare/shakespeare_text_document.* {GPTNeoXDir}/processed_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WH8eetUBytqN",
        "outputId": "f9cfa466-a2b0-4590-dd11-0d2aef80321e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Downloading my_env.tar.gz\n",
            "Unzipping my_env.tar.gz\n",
            "Untarring my_env.tar.gz\n",
            "CPU times: user 11.5 s, sys: 9.4 s, total: 20.9 s\n",
            "Wall time: 3min 11s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "#@title Load prebuilt Python environment for Colab\n",
        "import GPTNeoXColab\n",
        "%cd {workspaceDir}\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    GPTNeoXColab.utils.colab.download_my_env()\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTyERIkj8elu"
      },
      "source": [
        "# Run Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RmiyhUgSSt7",
        "outputId": "9f87f57b-0ebf-4542-c279-140988abc9c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (5.9.5)\n",
            "Collecting pynvml\n",
            "  Downloading pynvml-11.5.3-py3-none-any.whl.metadata (8.8 kB)\n",
            "Downloading pynvml-11.5.3-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pynvml\n",
            "Successfully installed pynvml-11.5.3\n"
          ]
        }
      ],
      "source": [
        "!pip install psutil\n",
        "# Install this for GPU metric logging\n",
        "!pip install pynvml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "umfYbg3TytqJ"
      },
      "outputs": [],
      "source": [
        "import GPTNeoXColab\n",
        "import os\n",
        "from pathlib import Path\n",
        "ROOT_DIR = GPTNeoXColab.utils.colab.find_project_root()\n",
        "RELATIVE_ROOT_DIR = os.path.relpath(ROOT_DIR, Path.cwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6PTFQWG08tKv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import glob\n",
        "import time\n",
        "\n",
        "# File to store the last read position (persistence between script runs)\n",
        "file_position = 0\n",
        "# Regular expression to match \"iteration <number> / <total>\"\n",
        "iteration_pattern = re.compile(r\"iteration\\s+(\\d+)\\s*/\\s*\\d+\")\n",
        "\n",
        "def get_latest_file(dir, pattern = \"*_stdout.txt\"):\n",
        "  # Define the log directory and pattern for log files\n",
        "  glob_pattern = os.path.join(dir, pattern)\n",
        "  # Get the list of log files that match the pattern\n",
        "  files = glob.glob(glob_pattern)\n",
        "  # Ensure there are log files in the directory\n",
        "  if files:\n",
        "      # Find the latest log file based on modification time\n",
        "      file = max(files, key=os.path.getmtime)\n",
        "      print(\"Latest file:\", file)\n",
        "  else:\n",
        "      file = None\n",
        "      print(\"No files found. Waiting and retrying.\")\n",
        "      time.sleep(10)  # Check every X seconds\n",
        "      file = get_latest_file(dir, pattern)\n",
        "  return file\n",
        "\n",
        "def read_new_iterations(latest_log):\n",
        "    global file_position\n",
        "    # Open the log file and seek to the last position\n",
        "    with open(latest_log, \"r\") as file:\n",
        "        file.seek(file_position)\n",
        "        # Read new lines\n",
        "        new_lines = file.readlines()\n",
        "        file_position = file.tell()\n",
        "        # Process lines containing \"iteration\"\n",
        "        last_match = None\n",
        "        for line in new_lines:\n",
        "            match = iteration_pattern.search(line)\n",
        "            if match:\n",
        "                last_match = match\n",
        "        if last_match:\n",
        "            # Extract the iteration count from the regex match\n",
        "            iteration_count = int(last_match.group(1))\n",
        "            print(f\"{iteration_count} iterations\")\n",
        "\n",
        "# Function to check if the process is running\n",
        "def is_process_running(pid):\n",
        "    try:\n",
        "        os.kill(pid, 0)  # Sending signal 0 to check if the process exists\n",
        "        return True\n",
        "    except OSError:\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XtEiZxZBV2iD"
      },
      "outputs": [],
      "source": [
        "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
        "import os\n",
        "\n",
        "def get_scalar_from_tensorboard(file, key):\n",
        "    # Load TensorBoard events\n",
        "    event_acc = EventAccumulator(file)\n",
        "    event_acc.Reload()\n",
        "    print(event_acc.Tags())\n",
        "    # Extract loss scalar events\n",
        "    if key in event_acc.Tags().get('scalars', []):\n",
        "        events = event_acc.Scalars(key)\n",
        "        value = events[-1].value  # Get the last logged value\n",
        "        return value\n",
        "    else:\n",
        "        print(f\"{key} not found in TensorBoard logs.\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOvOVTxbKUWQ",
        "outputId": "2d791b5e-dada-4a6e-87dd-77f3232583ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: GitPython in /usr/local/lib/python3.10/dist-packages (3.1.43)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython) (4.0.11)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython) (5.0.1)\n",
            "Collecting ipynbname\n",
            "  Downloading ipynbname-2024.1.0.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from ipynbname) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->ipynbname) (0.2.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->ipynbname) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->ipynbname) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->ipynbname) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->ipynbname) (6.3.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->ipynbname) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->ipynbname)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->ipynbname) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->ipynbname) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->ipynbname) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->ipynbname) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->ipynbname) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->ipynbname) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->ipynbname) (4.9.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->ipynbname) (5.7.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->ipynbname) (24.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->ipynbname) (2.8.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->ipynbname) (0.8.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel->ipynbname) (3.11.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.0.0->ipykernel->ipynbname) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->ipynbname) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client->ipykernel->ipynbname) (1.16.0)\n",
            "Downloading ipynbname-2024.1.0.0-py3-none-any.whl (4.3 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi, ipynbname\n",
            "Successfully installed ipynbname-2024.1.0.0 jedi-0.19.2\n"
          ]
        }
      ],
      "source": [
        "%pip install GitPython\n",
        "%pip install ipynbname"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BCbRs-3KUWR",
        "outputId": "1bcc1810-9a66-4f25-940c-31926be4dcd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Commit ID: 34d550b97005f2c4d29a752bc802f1711d6946e1\n"
          ]
        }
      ],
      "source": [
        "from git import Repo\n",
        "\n",
        "repo = Repo(GPTNeoXColabDir)\n",
        "commit_id = repo.head.commit.hexsha\n",
        "branch_name = repo.active_branch.name\n",
        "repo_url = next(repo.remotes.origin.urls)\n",
        "print(f\"Commit ID: {commit_id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iaBFYofFytqP",
        "outputId": "a6c4b4a7-ba45-49ea-da31-80467cb17e13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gpt-neox\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Initialized MLflow to track repo \u001b[32m\"MarkNZed/GPT-NeoX-Colab\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"MarkNZed/GPT-NeoX-Colab\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Repository MarkNZed/GPT-NeoX-Colab initialized!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository MarkNZed/GPT-NeoX-Colab initialized!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/11/13 12:58:46 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train_micro_batch_size_per_gpu': 4, 'train_iters': 51200, 'lr_decay_iters': 51200, 'save': 'experiments/experiment1/checkpoints', 'load': 'experiments/experiment1/checkpoints', 'tensorboard_dir': 'experiments/experiment1/tensorboard', 'log_dir': 'experiments/experiment1/logs', 'eval_interval': 5000}\n",
            "Running experiment: experiment1\n",
            "Running command: nohup bash -c \"source /content/my_env/bin/activate &&         cd /content/gpt-neox &&         python ./deepy.py train.py --conf_dir /tmp/tmp06appdqb         temp_config\" & echo $! > train_process.pid\n",
            "Training initiated.\n",
            "Waiting for train_process.pid to be created...\n",
            "Found train_process.pid  6334\n",
            "Latest file: /content/gpt-neox/experiments/experiment1/logs/56f93e83c4fa_stdout.txt\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "550 iterations\n",
            "Training is still running...\n",
            "1350 iterations\n",
            "Training is still running...\n",
            "2140 iterations\n",
            "Training is still running...\n",
            "2910 iterations\n",
            "Training is still running...\n",
            "3680 iterations\n",
            "Training is still running...\n",
            "4460 iterations\n",
            "Training is still running...\n",
            "5230 iterations\n",
            "Training is still running...\n",
            "6010 iterations\n",
            "Training is still running...\n",
            "6740 iterations\n",
            "Training is still running...\n",
            "7510 iterations\n",
            "Training is still running...\n",
            "8280 iterations\n",
            "Training is still running...\n",
            "9060 iterations\n",
            "Training is still running...\n",
            "9820 iterations\n",
            "Training is still running...\n",
            "10580 iterations\n",
            "Training is still running...\n",
            "11360 iterations\n",
            "Training is still running...\n",
            "12150 iterations\n",
            "Training is still running...\n",
            "12920 iterations\n",
            "Training is still running...\n",
            "13670 iterations\n",
            "Training is still running...\n",
            "14450 iterations\n",
            "Training is still running...\n",
            "15220 iterations\n",
            "Training is still running...\n",
            "15960 iterations\n",
            "Training is still running...\n",
            "16710 iterations\n",
            "Training is still running...\n",
            "17490 iterations\n",
            "Training is still running...\n",
            "18260 iterations\n",
            "Training is still running...\n",
            "19040 iterations\n",
            "Training is still running...\n",
            "19800 iterations\n",
            "Training is still running...\n",
            "20560 iterations\n",
            "Training is still running...\n",
            "21330 iterations\n",
            "Training is still running...\n",
            "22110 iterations\n",
            "Training is still running...\n",
            "22880 iterations\n",
            "Training is still running...\n",
            "23630 iterations\n",
            "Training is still running...\n",
            "24400 iterations\n",
            "Training is still running...\n",
            "25170 iterations\n",
            "Training is still running...\n",
            "25900 iterations\n",
            "Training is still running...\n",
            "26680 iterations\n",
            "Training is still running...\n",
            "27430 iterations\n",
            "Training is still running...\n",
            "28200 iterations\n",
            "Training is still running...\n",
            "28980 iterations\n",
            "Training is still running...\n",
            "29750 iterations\n",
            "Training is still running...\n",
            "30510 iterations\n",
            "Training is still running...\n",
            "31270 iterations\n",
            "Training is still running...\n",
            "32040 iterations\n",
            "Training is still running...\n",
            "32820 iterations\n",
            "Training is still running...\n",
            "33590 iterations\n",
            "Training is still running...\n",
            "34340 iterations\n",
            "Training is still running...\n",
            "35070 iterations\n",
            "Training is still running...\n",
            "35840 iterations\n",
            "Training is still running...\n",
            "36610 iterations\n",
            "Training is still running...\n",
            "37390 iterations\n",
            "Training is still running...\n",
            "38140 iterations\n",
            "Training is still running...\n",
            "38900 iterations\n",
            "Training is still running...\n",
            "39680 iterations\n",
            "Training is still running...\n",
            "40460 iterations\n",
            "Training is still running...\n",
            "41230 iterations\n",
            "Training is still running...\n",
            "41970 iterations\n",
            "Training is still running...\n",
            "42740 iterations\n",
            "Training is still running...\n",
            "43510 iterations\n",
            "Training is still running...\n",
            "44280 iterations\n",
            "Training is still running...\n",
            "45010 iterations\n",
            "Training is still running...\n",
            "45750 iterations\n",
            "Training is still running...\n",
            "46520 iterations\n",
            "Training is still running...\n",
            "47290 iterations\n",
            "Training is still running...\n",
            "48060 iterations\n",
            "Training is still running...\n",
            "48810 iterations\n",
            "Training is still running...\n",
            "49570 iterations\n",
            "Training is still running...\n",
            "50330 iterations\n",
            "Training is still running...\n",
            "51050 iterations\n",
            "Training is still running...\n",
            "Training has finished.\n",
            "Latest file: /content/gpt-neox/experiments/experiment1/tensorboard/events.out.tfevents.1731502742.56f93e83c4fa.6371.0\n",
            "{'images': [], 'audio': [], 'histograms': [], 'scalars': ['timers/forward', 'timers/backward', 'timers/backward-backward', 'timers/backward-allreduce', 'timers/optimizer', 'timers/batch generator', 'train/learning_rate', 'train/lm_loss', 'train/loss_scale', 'runtime/samples_per_sec', 'runtime/iteration_time', 'runtime/flops_per_sec_per_gpu', 'validation/lm_loss', 'validation/lm_loss_ppl', 'test/lm_loss', 'test/lm_loss_ppl'], 'distributions': [], 'tensors': ['distributed_backend/text_summary', 'local_rank/text_summary', 'rank/text_summary', 'lazy_mpu_init/text_summary', 'short_seq_prob/text_summary', 'eod_mask_loss/text_summary', 'adlr_autoresume/text_summary', 'adlr_autoresume_interval/text_summary', 'seed/text_summary', 'onnx_safe/text_summary', 'deepscale/text_summary', 'deepscale_config/text_summary', 'deepspeed_mpi/text_summary', 'deepspeed_slurm/text_summary', 'user_script/text_summary', 'iteration/text_summary', 'do_train/text_summary', 'do_valid/text_summary', 'do_test/text_summary', 'global_num_gpus/text_summary', 'text_gen_type/text_summary', 'precompute_model_name/text_summary', 'temperature/text_summary', 'top_p/text_summary', 'top_k/text_summary', 'return_logits/text_summary', 'maximum_tokens/text_summary', 'prompt_end/text_summary', 'sample_input_file/text_summary', 'sample_output_file/text_summary', 'num_samples/text_summary', 'recompute/text_summary', 'eval_results_prefix/text_summary', 'eval_tasks/text_summary', 'moe_top_k/text_summary', 'use_tutel/text_summary', 'moe_num_experts/text_summary', 'moe_loss_coeff/text_summary', 'moe_train_capacity_factor/text_summary', 'moe_eval_capacity_factor/text_summary', 'moe_min_capacity/text_summary', 'moe_token_dropping/text_summary', 'create_moe_param_group/text_summary', 'moe_use_residual/text_summary', 'moe_expert_parallel_size/text_summary', 'moe_type/text_summary', 'moe_glu/text_summary', 'moe_lbl_in_fp32/text_summary', 'moe_jitter_eps/text_summary', 'enable_expert_tensor_parallelism/text_summary', 'use_wandb/text_summary', 'wandb_group/text_summary', 'wandb_team/text_summary', 'wandb_project/text_summary', 'wandb_host/text_summary', 'wandb_init_all_ranks/text_summary', 'git_hash/text_summary', 'log_dir/text_summary', 'tensorboard_dir/text_summary', 'use_comet/text_summary', 'comet_workspace/text_summary', 'comet_project/text_summary', 'comet_experiment_name/text_summary', 'comet_tags/text_summary', 'comet_others/text_summary', 'comet_experiment/text_summary', 'log_interval/text_summary', 'log_grad_pct_zeros/text_summary', 'log_param_norm/text_summary', 'log_grad_norm/text_summary', 'log_optimizer_states/text_summary', 'log_gradient_noise_scale/text_summary', 'gradient_noise_scale_n_batches/text_summary', 'gradient_noise_scale_cpu_offload/text_summary', 'memory_profiling/text_summary', 'memory_profiling_path/text_summary', 'profile/text_summary', 'profile_step_start/text_summary', 'profile_step_stop/text_summary', 'pipe_parallel_size/text_summary', 'model_parallel_size/text_summary', 'pipe_partition_method/text_summary', 'world_size/text_summary', 'is_pipe_parallel/text_summary', 'sequence_parallel/text_summary', 'expert_interval/text_summary', 'data_path/text_summary', 'use_shared_fs/text_summary', 'train_data_paths/text_summary', 'train_label_data_paths/text_summary', 'train_reward_data_paths/text_summary', 'test_data_paths/text_summary', 'test_label_data_paths/text_summary', 'test_reward_data_paths/text_summary', 'valid_data_paths/text_summary', 'valid_label_data_paths/text_summary', 'valid_reward_data_paths/text_summary', 'pos_train_data_paths/text_summary', 'neg_train_data_paths/text_summary', 'pos_train_label_data_paths/text_summary', 'neg_train_label_data_paths/text_summary', 'pos_valid_data_paths/text_summary', 'neg_valid_data_paths/text_summary', 'pos_valid_label_data_paths/text_summary', 'neg_valid_label_data_paths/text_summary', 'pos_test_data_paths/text_summary', 'neg_test_data_paths/text_summary', 'pos_test_label_data_paths/text_summary', 'neg_test_label_data_paths/text_summary', 'train_data_weights/text_summary', 'valid_data_weights/text_summary', 'test_data_weights/text_summary', 'weight_by_num_documents/text_summary', 'weighted_sampler_alpha/text_summary', 'data_impl/text_summary', 'pack_impl/text_summary', 'dataset_impl/text_summary', 'train_impl/text_summary', 'dpo_fp32/text_summary', 'dpo_reference_free/text_summary', 'dpo_beta/text_summary', 'kto_fp32/text_summary', 'kto_desirable_weight/text_summary', 'kto_undesirable_weight/text_summary', 'z_loss/text_summary', 'kto_beta/text_summary', 'allow_chopped/text_summary', 'mmap_warmup/text_summary', 'save/text_summary', 's3_path/text_summary', 's3_chunk_size/text_summary', 'config_files/text_summary', 'load/text_summary', 'checkpoint_validation_with_forward_pass/text_summary', 'checkpoint_scale/text_summary', 'checkpoint_factor/text_summary', 'extra_save_iters/text_summary', 'no_save_optim/text_summary', 'no_save_rng/text_summary', 'no_load_optim/text_summary', 'no_load_rng/text_summary', 'finetune/text_summary', 'batch_size/text_summary', 'train_iters/text_summary', 'train_epochs/text_summary', 'eval_iters/text_summary', 'keep_last_n_checkpoints/text_summary', 'eval_interval/text_summary', 'split/text_summary', 'vocab_file/text_summary', 'merge_file/text_summary', 'num_workers/text_summary', 'exit_interval/text_summary', 'attention_dropout/text_summary', 'hidden_dropout/text_summary', 'weight_decay/text_summary', 'checkpoint_activations/text_summary', 'checkpoint_num_layers/text_summary', 'deepspeed_activation_checkpointing/text_summary', 'contiguous_checkpointing/text_summary', 'checkpoint_in_cpu/text_summary', 'synchronize_each_layer/text_summary', 'profile_backward/text_summary', 'partition_activations/text_summary', 'clip_grad/text_summary', 'hysteresis/text_summary', 'dynamic_loss_scale/text_summary', 'loss_scale/text_summary', 'loss_scale_window/text_summary', 'min_scale/text_summary', 'char_level_ppl/text_summary', 'use_mup/text_summary', 'coord_check/text_summary', 'save_base_shapes/text_summary', 'base_shapes_file/text_summary', 'mup_init_scale/text_summary', 'mup_attn_temp/text_summary', 'mup_output_temp/text_summary', 'mup_embedding_mult/text_summary', 'mup_rp_embedding_mult/text_summary', 'mup_width_scale/text_summary', 'tokenizer_type/text_summary', 'padded_vocab_size/text_summary', 'optimizer_type/text_summary', 'use_bnb_optimizer/text_summary', 'zero_stage/text_summary', 'zero_reduce_scatter/text_summary', 'zero_contiguous_gradients/text_summary', 'zero_reduce_bucket_size/text_summary', 'zero_allgather_bucket_size/text_summary', 'lr/text_summary', 'lr_decay_style/text_summary', 'lr_decay_iters/text_summary', 'lr_decay_fraction/text_summary', 'min_lr/text_summary', 'warmup/text_summary', 'override_lr_scheduler/text_summary', 'use_checkpoint_lr_scheduler/text_summary', 'precision/text_summary', 'num_layers/text_summary', 'hidden_size/text_summary', 'intermediate_size/text_summary', 'mlp_multiple_of/text_summary', 'expansion_factor/text_summary', 'num_attention_heads/text_summary', 'num_kv_heads/text_summary', 'seq_length/text_summary', 'sliding_window_width/text_summary', 'max_position_embeddings/text_summary', 'norm/text_summary', 'layernorm_fusion/text_summary', 'rmsnorm_fusion/text_summary', 'use_qk_layernorm/text_summary', 'layernorm_epsilon/text_summary', 'rms_norm_epsilon/text_summary', 'scalenorm_epsilon/text_summary', 'pos_emb/text_summary', 'rpe_num_buckets/text_summary', 'rpe_max_distance/text_summary', 'opt_pos_emb_offset/text_summary', 'no_weight_tying/text_summary', 'attention_config/text_summary', 'sparsity_config/text_summary', 'num_unique_layers/text_summary', 'param_sharing_style/text_summary', 'make_vocab_size_divisible_by/text_summary', 'activation/text_summary', 'use_flashattn_swiglu/text_summary', 'scaled_upper_triang_masked_softmax_fusion/text_summary', 'scaled_masked_softmax_fusion/text_summary', 'bias_gelu_fusion/text_summary', 'bias_dropout_fusion/text_summary', 'rope_fusion/text_summary', 'fp16_lm_cross_entropy/text_summary', 'init_method_std/text_summary', 'apply_query_key_layer_scaling/text_summary', 'use_cpu_initialization/text_summary', 'attention_softmax_in_fp32/text_summary', 'rotary_pct/text_summary', 'rotary_emb_base/text_summary', 'rotary_save_freqs_buffer/text_summary', 'init_method/text_summary', 'output_layer_init_method/text_summary', 'gmlp_attn_dim/text_summary', 'gpt_j_residual/text_summary', 'gpt_j_tied/text_summary', 'use_bias_in_norms/text_summary', 'use_bias_in_attn_linear/text_summary', 'use_bias_in_mlp/text_summary', 'soft_prompt_tuning/text_summary', 'mamba_selective_scan_fusion/text_summary', 'mamba_causal_conv_fusion/text_summary', 'mamba_inner_func_fusion/text_summary', 'mamba_selective_fp32_params/text_summary', 'mamba_use_bias_in_conv/text_summary', 'mamba_use_bias_in_linears/text_summary', 'output_layer_parallelism/text_summary', 'dim_att/text_summary', 'head_size/text_summary', 'ffn_dim/text_summary', 'deepspeed/text_summary', 'train_batch_size/text_summary', 'train_micro_batch_size_per_gpu/text_summary', 'gradient_accumulation_steps/text_summary', 'optimizer/text_summary', 'scheduler/text_summary', 'fp32_allreduce/text_summary', 'prescale_gradients/text_summary', 'gradient_predivide_factor/text_summary', 'sparse_gradients/text_summary', 'fp16/text_summary', 'bf16/text_summary', 'amp/text_summary', 'gradient_clipping/text_summary', 'zero_optimization/text_summary', 'curriculum_learning/text_summary', 'curriculum_seqlen/text_summary', 'steps_per_print/text_summary', 'wall_clock_breakdown/text_summary', 'dump_state/text_summary', 'flops_profiler/text_summary', 'communication_data_type/text_summary', 'autotuning/text_summary', 'activation_checkpointing/text_summary', 'sparse_attention/text_summary', 'data_efficiency/text_summary', 'tensorboard/text_summary', 'wandb/text_summary', 'csv_monitor/text_summary', 'elasticity/text_summary', 'comms_logger/text_summary', 'compression_training/text_summary', 'checkpoint/text_summary', 'data_types/text_summary', 'deepspeed_extra_args/text_summary', 'hostfile/text_summary', 'include/text_summary', 'exclude/text_summary', 'num_nodes/text_summary', 'num_gpus/text_summary', 'master_port/text_summary', 'master_addr/text_summary', 'launcher/text_summary', 'force_multi/text_summary', 'detect_nvlink_pairs/text_summary', 'autotuning_run/text_summary', 'no_ssh_check/text_summary', 'comment/text_summary', 'account/text_summary', 'tokenizer/text_summary', 'tensorboard_writer/text_summary'], 'graph': False, 'meta_graph': False, 'run_metadata': []}\n",
            "Logging metric test/lm_loss 3.538163423538208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/11/13 13:34:13 INFO mlflow.tracking._tracking_service.client: 🏃 View run carefree-robin-858 at: https://dagshub.com/MarkNZed/GPT-NeoX-Colab.mlflow/#/experiments/8/runs/201e43fbba804a28851f4f9a15006899.\n",
            "2024/11/13 13:34:13 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dagshub.com/MarkNZed/GPT-NeoX-Colab.mlflow/#/experiments/8.\n",
            "2024/11/13 13:34:13 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
            "2024/11/13 13:34:14 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
            "2024/11/13 13:34:14 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train_micro_batch_size_per_gpu': 64, 'train_iters': 3200, 'lr_decay_iters': 3200, 'save': 'experiments/experiment2/checkpoints', 'load': 'experiments/experiment2/checkpoints', 'tensorboard_dir': 'experiments/experiment2/tensorboard', 'log_dir': 'experiments/experiment2/logs', 'eval_interval': 300}\n",
            "Running experiment: experiment2\n",
            "Running command: nohup bash -c \"source /content/my_env/bin/activate &&         cd /content/gpt-neox &&         python ./deepy.py train.py --conf_dir /tmp/tmpa25638n4         temp_config\" & echo $! > train_process.pid\n",
            "Training initiated.\n",
            "Waiting for train_process.pid to be created...\n",
            "Found train_process.pid  15182\n",
            "Latest file: /content/gpt-neox/experiments/experiment2/logs/56f93e83c4fa_stdout.txt\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training has finished.\n",
            "Latest file: /content/gpt-neox/experiments/experiment2/tensorboard/events.out.tfevents.1731504870.56f93e83c4fa.15233.0\n",
            "{'images': [], 'audio': [], 'histograms': [], 'scalars': ['timers/forward', 'timers/backward', 'timers/backward-backward', 'timers/backward-allreduce', 'timers/optimizer', 'timers/batch generator', 'train/learning_rate', 'train/lm_loss', 'train/loss_scale', 'runtime/samples_per_sec', 'runtime/iteration_time', 'runtime/flops_per_sec_per_gpu', 'validation/lm_loss', 'validation/lm_loss_ppl', 'test/lm_loss', 'test/lm_loss_ppl'], 'distributions': [], 'tensors': ['distributed_backend/text_summary', 'local_rank/text_summary', 'rank/text_summary', 'lazy_mpu_init/text_summary', 'short_seq_prob/text_summary', 'eod_mask_loss/text_summary', 'adlr_autoresume/text_summary', 'adlr_autoresume_interval/text_summary', 'seed/text_summary', 'onnx_safe/text_summary', 'deepscale/text_summary', 'deepscale_config/text_summary', 'deepspeed_mpi/text_summary', 'deepspeed_slurm/text_summary', 'user_script/text_summary', 'iteration/text_summary', 'do_train/text_summary', 'do_valid/text_summary', 'do_test/text_summary', 'global_num_gpus/text_summary', 'text_gen_type/text_summary', 'precompute_model_name/text_summary', 'temperature/text_summary', 'top_p/text_summary', 'top_k/text_summary', 'return_logits/text_summary', 'maximum_tokens/text_summary', 'prompt_end/text_summary', 'sample_input_file/text_summary', 'sample_output_file/text_summary', 'num_samples/text_summary', 'recompute/text_summary', 'eval_results_prefix/text_summary', 'eval_tasks/text_summary', 'moe_top_k/text_summary', 'use_tutel/text_summary', 'moe_num_experts/text_summary', 'moe_loss_coeff/text_summary', 'moe_train_capacity_factor/text_summary', 'moe_eval_capacity_factor/text_summary', 'moe_min_capacity/text_summary', 'moe_token_dropping/text_summary', 'create_moe_param_group/text_summary', 'moe_use_residual/text_summary', 'moe_expert_parallel_size/text_summary', 'moe_type/text_summary', 'moe_glu/text_summary', 'moe_lbl_in_fp32/text_summary', 'moe_jitter_eps/text_summary', 'enable_expert_tensor_parallelism/text_summary', 'use_wandb/text_summary', 'wandb_group/text_summary', 'wandb_team/text_summary', 'wandb_project/text_summary', 'wandb_host/text_summary', 'wandb_init_all_ranks/text_summary', 'git_hash/text_summary', 'log_dir/text_summary', 'tensorboard_dir/text_summary', 'use_comet/text_summary', 'comet_workspace/text_summary', 'comet_project/text_summary', 'comet_experiment_name/text_summary', 'comet_tags/text_summary', 'comet_others/text_summary', 'comet_experiment/text_summary', 'log_interval/text_summary', 'log_grad_pct_zeros/text_summary', 'log_param_norm/text_summary', 'log_grad_norm/text_summary', 'log_optimizer_states/text_summary', 'log_gradient_noise_scale/text_summary', 'gradient_noise_scale_n_batches/text_summary', 'gradient_noise_scale_cpu_offload/text_summary', 'memory_profiling/text_summary', 'memory_profiling_path/text_summary', 'profile/text_summary', 'profile_step_start/text_summary', 'profile_step_stop/text_summary', 'pipe_parallel_size/text_summary', 'model_parallel_size/text_summary', 'pipe_partition_method/text_summary', 'world_size/text_summary', 'is_pipe_parallel/text_summary', 'sequence_parallel/text_summary', 'expert_interval/text_summary', 'data_path/text_summary', 'use_shared_fs/text_summary', 'train_data_paths/text_summary', 'train_label_data_paths/text_summary', 'train_reward_data_paths/text_summary', 'test_data_paths/text_summary', 'test_label_data_paths/text_summary', 'test_reward_data_paths/text_summary', 'valid_data_paths/text_summary', 'valid_label_data_paths/text_summary', 'valid_reward_data_paths/text_summary', 'pos_train_data_paths/text_summary', 'neg_train_data_paths/text_summary', 'pos_train_label_data_paths/text_summary', 'neg_train_label_data_paths/text_summary', 'pos_valid_data_paths/text_summary', 'neg_valid_data_paths/text_summary', 'pos_valid_label_data_paths/text_summary', 'neg_valid_label_data_paths/text_summary', 'pos_test_data_paths/text_summary', 'neg_test_data_paths/text_summary', 'pos_test_label_data_paths/text_summary', 'neg_test_label_data_paths/text_summary', 'train_data_weights/text_summary', 'valid_data_weights/text_summary', 'test_data_weights/text_summary', 'weight_by_num_documents/text_summary', 'weighted_sampler_alpha/text_summary', 'data_impl/text_summary', 'pack_impl/text_summary', 'dataset_impl/text_summary', 'train_impl/text_summary', 'dpo_fp32/text_summary', 'dpo_reference_free/text_summary', 'dpo_beta/text_summary', 'kto_fp32/text_summary', 'kto_desirable_weight/text_summary', 'kto_undesirable_weight/text_summary', 'z_loss/text_summary', 'kto_beta/text_summary', 'allow_chopped/text_summary', 'mmap_warmup/text_summary', 'save/text_summary', 's3_path/text_summary', 's3_chunk_size/text_summary', 'config_files/text_summary', 'load/text_summary', 'checkpoint_validation_with_forward_pass/text_summary', 'checkpoint_scale/text_summary', 'checkpoint_factor/text_summary', 'extra_save_iters/text_summary', 'no_save_optim/text_summary', 'no_save_rng/text_summary', 'no_load_optim/text_summary', 'no_load_rng/text_summary', 'finetune/text_summary', 'batch_size/text_summary', 'train_iters/text_summary', 'train_epochs/text_summary', 'eval_iters/text_summary', 'keep_last_n_checkpoints/text_summary', 'eval_interval/text_summary', 'split/text_summary', 'vocab_file/text_summary', 'merge_file/text_summary', 'num_workers/text_summary', 'exit_interval/text_summary', 'attention_dropout/text_summary', 'hidden_dropout/text_summary', 'weight_decay/text_summary', 'checkpoint_activations/text_summary', 'checkpoint_num_layers/text_summary', 'deepspeed_activation_checkpointing/text_summary', 'contiguous_checkpointing/text_summary', 'checkpoint_in_cpu/text_summary', 'synchronize_each_layer/text_summary', 'profile_backward/text_summary', 'partition_activations/text_summary', 'clip_grad/text_summary', 'hysteresis/text_summary', 'dynamic_loss_scale/text_summary', 'loss_scale/text_summary', 'loss_scale_window/text_summary', 'min_scale/text_summary', 'char_level_ppl/text_summary', 'use_mup/text_summary', 'coord_check/text_summary', 'save_base_shapes/text_summary', 'base_shapes_file/text_summary', 'mup_init_scale/text_summary', 'mup_attn_temp/text_summary', 'mup_output_temp/text_summary', 'mup_embedding_mult/text_summary', 'mup_rp_embedding_mult/text_summary', 'mup_width_scale/text_summary', 'tokenizer_type/text_summary', 'padded_vocab_size/text_summary', 'optimizer_type/text_summary', 'use_bnb_optimizer/text_summary', 'zero_stage/text_summary', 'zero_reduce_scatter/text_summary', 'zero_contiguous_gradients/text_summary', 'zero_reduce_bucket_size/text_summary', 'zero_allgather_bucket_size/text_summary', 'lr/text_summary', 'lr_decay_style/text_summary', 'lr_decay_iters/text_summary', 'lr_decay_fraction/text_summary', 'min_lr/text_summary', 'warmup/text_summary', 'override_lr_scheduler/text_summary', 'use_checkpoint_lr_scheduler/text_summary', 'precision/text_summary', 'num_layers/text_summary', 'hidden_size/text_summary', 'intermediate_size/text_summary', 'mlp_multiple_of/text_summary', 'expansion_factor/text_summary', 'num_attention_heads/text_summary', 'num_kv_heads/text_summary', 'seq_length/text_summary', 'sliding_window_width/text_summary', 'max_position_embeddings/text_summary', 'norm/text_summary', 'layernorm_fusion/text_summary', 'rmsnorm_fusion/text_summary', 'use_qk_layernorm/text_summary', 'layernorm_epsilon/text_summary', 'rms_norm_epsilon/text_summary', 'scalenorm_epsilon/text_summary', 'pos_emb/text_summary', 'rpe_num_buckets/text_summary', 'rpe_max_distance/text_summary', 'opt_pos_emb_offset/text_summary', 'no_weight_tying/text_summary', 'attention_config/text_summary', 'sparsity_config/text_summary', 'num_unique_layers/text_summary', 'param_sharing_style/text_summary', 'make_vocab_size_divisible_by/text_summary', 'activation/text_summary', 'use_flashattn_swiglu/text_summary', 'scaled_upper_triang_masked_softmax_fusion/text_summary', 'scaled_masked_softmax_fusion/text_summary', 'bias_gelu_fusion/text_summary', 'bias_dropout_fusion/text_summary', 'rope_fusion/text_summary', 'fp16_lm_cross_entropy/text_summary', 'init_method_std/text_summary', 'apply_query_key_layer_scaling/text_summary', 'use_cpu_initialization/text_summary', 'attention_softmax_in_fp32/text_summary', 'rotary_pct/text_summary', 'rotary_emb_base/text_summary', 'rotary_save_freqs_buffer/text_summary', 'init_method/text_summary', 'output_layer_init_method/text_summary', 'gmlp_attn_dim/text_summary', 'gpt_j_residual/text_summary', 'gpt_j_tied/text_summary', 'use_bias_in_norms/text_summary', 'use_bias_in_attn_linear/text_summary', 'use_bias_in_mlp/text_summary', 'soft_prompt_tuning/text_summary', 'mamba_selective_scan_fusion/text_summary', 'mamba_causal_conv_fusion/text_summary', 'mamba_inner_func_fusion/text_summary', 'mamba_selective_fp32_params/text_summary', 'mamba_use_bias_in_conv/text_summary', 'mamba_use_bias_in_linears/text_summary', 'output_layer_parallelism/text_summary', 'dim_att/text_summary', 'head_size/text_summary', 'ffn_dim/text_summary', 'deepspeed/text_summary', 'train_batch_size/text_summary', 'train_micro_batch_size_per_gpu/text_summary', 'gradient_accumulation_steps/text_summary', 'optimizer/text_summary', 'scheduler/text_summary', 'fp32_allreduce/text_summary', 'prescale_gradients/text_summary', 'gradient_predivide_factor/text_summary', 'sparse_gradients/text_summary', 'fp16/text_summary', 'bf16/text_summary', 'amp/text_summary', 'gradient_clipping/text_summary', 'zero_optimization/text_summary', 'curriculum_learning/text_summary', 'curriculum_seqlen/text_summary', 'steps_per_print/text_summary', 'wall_clock_breakdown/text_summary', 'dump_state/text_summary', 'flops_profiler/text_summary', 'communication_data_type/text_summary', 'autotuning/text_summary', 'activation_checkpointing/text_summary', 'sparse_attention/text_summary', 'data_efficiency/text_summary', 'tensorboard/text_summary', 'wandb/text_summary', 'csv_monitor/text_summary', 'elasticity/text_summary', 'comms_logger/text_summary', 'compression_training/text_summary', 'checkpoint/text_summary', 'data_types/text_summary', 'deepspeed_extra_args/text_summary', 'hostfile/text_summary', 'include/text_summary', 'exclude/text_summary', 'num_nodes/text_summary', 'num_gpus/text_summary', 'master_port/text_summary', 'master_addr/text_summary', 'launcher/text_summary', 'force_multi/text_summary', 'detect_nvlink_pairs/text_summary', 'autotuning_run/text_summary', 'no_ssh_check/text_summary', 'comment/text_summary', 'account/text_summary', 'tokenizer/text_summary', 'tensorboard_writer/text_summary'], 'graph': False, 'meta_graph': False, 'run_metadata': []}\n",
            "Logging metric test/lm_loss 3.22871732711792\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/11/13 13:44:58 INFO mlflow.tracking._tracking_service.client: 🏃 View run adorable-goat-613 at: https://dagshub.com/MarkNZed/GPT-NeoX-Colab.mlflow/#/experiments/8/runs/82a36edbf5fd47bda274dc4654b592a4.\n",
            "2024/11/13 13:44:58 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dagshub.com/MarkNZed/GPT-NeoX-Colab.mlflow/#/experiments/8.\n",
            "2024/11/13 13:44:59 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
            "2024/11/13 13:44:59 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
            "2024/11/13 13:44:59 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train_micro_batch_size_per_gpu': 256, 'train_iters': 800, 'lr_decay_iters': 800, 'save': 'experiments/experiment3/checkpoints', 'load': 'experiments/experiment3/checkpoints', 'tensorboard_dir': 'experiments/experiment3/tensorboard', 'log_dir': 'experiments/experiment3/logs', 'eval_interval': 80}\n",
            "Running experiment: experiment3\n",
            "Running command: nohup bash -c \"source /content/my_env/bin/activate &&         cd /content/gpt-neox &&         python ./deepy.py train.py --conf_dir /tmp/tmpbe1mruib         temp_config\" & echo $! > train_process.pid\n",
            "Training initiated.\n",
            "Waiting for train_process.pid to be created...\n",
            "Found train_process.pid  18035\n",
            "Latest file: /content/gpt-neox/experiments/experiment3/logs/56f93e83c4fa_stdout.txt\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training is still running...\n",
            "Training has finished.\n",
            "Latest file: /content/gpt-neox/experiments/experiment3/tensorboard/events.out.tfevents.1731505513.56f93e83c4fa.18076.0\n",
            "{'images': [], 'audio': [], 'histograms': [], 'scalars': ['timers/forward', 'timers/backward', 'timers/backward-backward', 'timers/backward-allreduce', 'timers/optimizer', 'timers/batch generator', 'train/learning_rate', 'train/lm_loss', 'train/loss_scale', 'runtime/samples_per_sec', 'runtime/iteration_time', 'runtime/flops_per_sec_per_gpu', 'validation/lm_loss', 'validation/lm_loss_ppl', 'test/lm_loss', 'test/lm_loss_ppl'], 'distributions': [], 'tensors': ['distributed_backend/text_summary', 'local_rank/text_summary', 'rank/text_summary', 'lazy_mpu_init/text_summary', 'short_seq_prob/text_summary', 'eod_mask_loss/text_summary', 'adlr_autoresume/text_summary', 'adlr_autoresume_interval/text_summary', 'seed/text_summary', 'onnx_safe/text_summary', 'deepscale/text_summary', 'deepscale_config/text_summary', 'deepspeed_mpi/text_summary', 'deepspeed_slurm/text_summary', 'user_script/text_summary', 'iteration/text_summary', 'do_train/text_summary', 'do_valid/text_summary', 'do_test/text_summary', 'global_num_gpus/text_summary', 'text_gen_type/text_summary', 'precompute_model_name/text_summary', 'temperature/text_summary', 'top_p/text_summary', 'top_k/text_summary', 'return_logits/text_summary', 'maximum_tokens/text_summary', 'prompt_end/text_summary', 'sample_input_file/text_summary', 'sample_output_file/text_summary', 'num_samples/text_summary', 'recompute/text_summary', 'eval_results_prefix/text_summary', 'eval_tasks/text_summary', 'moe_top_k/text_summary', 'use_tutel/text_summary', 'moe_num_experts/text_summary', 'moe_loss_coeff/text_summary', 'moe_train_capacity_factor/text_summary', 'moe_eval_capacity_factor/text_summary', 'moe_min_capacity/text_summary', 'moe_token_dropping/text_summary', 'create_moe_param_group/text_summary', 'moe_use_residual/text_summary', 'moe_expert_parallel_size/text_summary', 'moe_type/text_summary', 'moe_glu/text_summary', 'moe_lbl_in_fp32/text_summary', 'moe_jitter_eps/text_summary', 'enable_expert_tensor_parallelism/text_summary', 'use_wandb/text_summary', 'wandb_group/text_summary', 'wandb_team/text_summary', 'wandb_project/text_summary', 'wandb_host/text_summary', 'wandb_init_all_ranks/text_summary', 'git_hash/text_summary', 'log_dir/text_summary', 'tensorboard_dir/text_summary', 'use_comet/text_summary', 'comet_workspace/text_summary', 'comet_project/text_summary', 'comet_experiment_name/text_summary', 'comet_tags/text_summary', 'comet_others/text_summary', 'comet_experiment/text_summary', 'log_interval/text_summary', 'log_grad_pct_zeros/text_summary', 'log_param_norm/text_summary', 'log_grad_norm/text_summary', 'log_optimizer_states/text_summary', 'log_gradient_noise_scale/text_summary', 'gradient_noise_scale_n_batches/text_summary', 'gradient_noise_scale_cpu_offload/text_summary', 'memory_profiling/text_summary', 'memory_profiling_path/text_summary', 'profile/text_summary', 'profile_step_start/text_summary', 'profile_step_stop/text_summary', 'pipe_parallel_size/text_summary', 'model_parallel_size/text_summary', 'pipe_partition_method/text_summary', 'world_size/text_summary', 'is_pipe_parallel/text_summary', 'sequence_parallel/text_summary', 'expert_interval/text_summary', 'data_path/text_summary', 'use_shared_fs/text_summary', 'train_data_paths/text_summary', 'train_label_data_paths/text_summary', 'train_reward_data_paths/text_summary', 'test_data_paths/text_summary', 'test_label_data_paths/text_summary', 'test_reward_data_paths/text_summary', 'valid_data_paths/text_summary', 'valid_label_data_paths/text_summary', 'valid_reward_data_paths/text_summary', 'pos_train_data_paths/text_summary', 'neg_train_data_paths/text_summary', 'pos_train_label_data_paths/text_summary', 'neg_train_label_data_paths/text_summary', 'pos_valid_data_paths/text_summary', 'neg_valid_data_paths/text_summary', 'pos_valid_label_data_paths/text_summary', 'neg_valid_label_data_paths/text_summary', 'pos_test_data_paths/text_summary', 'neg_test_data_paths/text_summary', 'pos_test_label_data_paths/text_summary', 'neg_test_label_data_paths/text_summary', 'train_data_weights/text_summary', 'valid_data_weights/text_summary', 'test_data_weights/text_summary', 'weight_by_num_documents/text_summary', 'weighted_sampler_alpha/text_summary', 'data_impl/text_summary', 'pack_impl/text_summary', 'dataset_impl/text_summary', 'train_impl/text_summary', 'dpo_fp32/text_summary', 'dpo_reference_free/text_summary', 'dpo_beta/text_summary', 'kto_fp32/text_summary', 'kto_desirable_weight/text_summary', 'kto_undesirable_weight/text_summary', 'z_loss/text_summary', 'kto_beta/text_summary', 'allow_chopped/text_summary', 'mmap_warmup/text_summary', 'save/text_summary', 's3_path/text_summary', 's3_chunk_size/text_summary', 'config_files/text_summary', 'load/text_summary', 'checkpoint_validation_with_forward_pass/text_summary', 'checkpoint_scale/text_summary', 'checkpoint_factor/text_summary', 'extra_save_iters/text_summary', 'no_save_optim/text_summary', 'no_save_rng/text_summary', 'no_load_optim/text_summary', 'no_load_rng/text_summary', 'finetune/text_summary', 'batch_size/text_summary', 'train_iters/text_summary', 'train_epochs/text_summary', 'eval_iters/text_summary', 'keep_last_n_checkpoints/text_summary', 'eval_interval/text_summary', 'split/text_summary', 'vocab_file/text_summary', 'merge_file/text_summary', 'num_workers/text_summary', 'exit_interval/text_summary', 'attention_dropout/text_summary', 'hidden_dropout/text_summary', 'weight_decay/text_summary', 'checkpoint_activations/text_summary', 'checkpoint_num_layers/text_summary', 'deepspeed_activation_checkpointing/text_summary', 'contiguous_checkpointing/text_summary', 'checkpoint_in_cpu/text_summary', 'synchronize_each_layer/text_summary', 'profile_backward/text_summary', 'partition_activations/text_summary', 'clip_grad/text_summary', 'hysteresis/text_summary', 'dynamic_loss_scale/text_summary', 'loss_scale/text_summary', 'loss_scale_window/text_summary', 'min_scale/text_summary', 'char_level_ppl/text_summary', 'use_mup/text_summary', 'coord_check/text_summary', 'save_base_shapes/text_summary', 'base_shapes_file/text_summary', 'mup_init_scale/text_summary', 'mup_attn_temp/text_summary', 'mup_output_temp/text_summary', 'mup_embedding_mult/text_summary', 'mup_rp_embedding_mult/text_summary', 'mup_width_scale/text_summary', 'tokenizer_type/text_summary', 'padded_vocab_size/text_summary', 'optimizer_type/text_summary', 'use_bnb_optimizer/text_summary', 'zero_stage/text_summary', 'zero_reduce_scatter/text_summary', 'zero_contiguous_gradients/text_summary', 'zero_reduce_bucket_size/text_summary', 'zero_allgather_bucket_size/text_summary', 'lr/text_summary', 'lr_decay_style/text_summary', 'lr_decay_iters/text_summary', 'lr_decay_fraction/text_summary', 'min_lr/text_summary', 'warmup/text_summary', 'override_lr_scheduler/text_summary', 'use_checkpoint_lr_scheduler/text_summary', 'precision/text_summary', 'num_layers/text_summary', 'hidden_size/text_summary', 'intermediate_size/text_summary', 'mlp_multiple_of/text_summary', 'expansion_factor/text_summary', 'num_attention_heads/text_summary', 'num_kv_heads/text_summary', 'seq_length/text_summary', 'sliding_window_width/text_summary', 'max_position_embeddings/text_summary', 'norm/text_summary', 'layernorm_fusion/text_summary', 'rmsnorm_fusion/text_summary', 'use_qk_layernorm/text_summary', 'layernorm_epsilon/text_summary', 'rms_norm_epsilon/text_summary', 'scalenorm_epsilon/text_summary', 'pos_emb/text_summary', 'rpe_num_buckets/text_summary', 'rpe_max_distance/text_summary', 'opt_pos_emb_offset/text_summary', 'no_weight_tying/text_summary', 'attention_config/text_summary', 'sparsity_config/text_summary', 'num_unique_layers/text_summary', 'param_sharing_style/text_summary', 'make_vocab_size_divisible_by/text_summary', 'activation/text_summary', 'use_flashattn_swiglu/text_summary', 'scaled_upper_triang_masked_softmax_fusion/text_summary', 'scaled_masked_softmax_fusion/text_summary', 'bias_gelu_fusion/text_summary', 'bias_dropout_fusion/text_summary', 'rope_fusion/text_summary', 'fp16_lm_cross_entropy/text_summary', 'init_method_std/text_summary', 'apply_query_key_layer_scaling/text_summary', 'use_cpu_initialization/text_summary', 'attention_softmax_in_fp32/text_summary', 'rotary_pct/text_summary', 'rotary_emb_base/text_summary', 'rotary_save_freqs_buffer/text_summary', 'init_method/text_summary', 'output_layer_init_method/text_summary', 'gmlp_attn_dim/text_summary', 'gpt_j_residual/text_summary', 'gpt_j_tied/text_summary', 'use_bias_in_norms/text_summary', 'use_bias_in_attn_linear/text_summary', 'use_bias_in_mlp/text_summary', 'soft_prompt_tuning/text_summary', 'mamba_selective_scan_fusion/text_summary', 'mamba_causal_conv_fusion/text_summary', 'mamba_inner_func_fusion/text_summary', 'mamba_selective_fp32_params/text_summary', 'mamba_use_bias_in_conv/text_summary', 'mamba_use_bias_in_linears/text_summary', 'output_layer_parallelism/text_summary', 'dim_att/text_summary', 'head_size/text_summary', 'ffn_dim/text_summary', 'deepspeed/text_summary', 'train_batch_size/text_summary', 'train_micro_batch_size_per_gpu/text_summary', 'gradient_accumulation_steps/text_summary', 'optimizer/text_summary', 'scheduler/text_summary', 'fp32_allreduce/text_summary', 'prescale_gradients/text_summary', 'gradient_predivide_factor/text_summary', 'sparse_gradients/text_summary', 'fp16/text_summary', 'bf16/text_summary', 'amp/text_summary', 'gradient_clipping/text_summary', 'zero_optimization/text_summary', 'curriculum_learning/text_summary', 'curriculum_seqlen/text_summary', 'steps_per_print/text_summary', 'wall_clock_breakdown/text_summary', 'dump_state/text_summary', 'flops_profiler/text_summary', 'communication_data_type/text_summary', 'autotuning/text_summary', 'activation_checkpointing/text_summary', 'sparse_attention/text_summary', 'data_efficiency/text_summary', 'tensorboard/text_summary', 'wandb/text_summary', 'csv_monitor/text_summary', 'elasticity/text_summary', 'comms_logger/text_summary', 'compression_training/text_summary', 'checkpoint/text_summary', 'data_types/text_summary', 'deepspeed_extra_args/text_summary', 'hostfile/text_summary', 'include/text_summary', 'exclude/text_summary', 'num_nodes/text_summary', 'num_gpus/text_summary', 'master_port/text_summary', 'master_addr/text_summary', 'launcher/text_summary', 'force_multi/text_summary', 'detect_nvlink_pairs/text_summary', 'autotuning_run/text_summary', 'no_ssh_check/text_summary', 'comment/text_summary', 'account/text_summary', 'tokenizer/text_summary', 'tensorboard_writer/text_summary'], 'graph': False, 'meta_graph': False, 'run_metadata': []}\n",
            "Logging metric test/lm_loss 1.5286576747894287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/11/13 13:55:13 INFO mlflow.tracking._tracking_service.client: 🏃 View run kindly-elk-952 at: https://dagshub.com/MarkNZed/GPT-NeoX-Colab.mlflow/#/experiments/8/runs/043c2e0f860040e2a762b437f5c484cc.\n",
            "2024/11/13 13:55:13 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dagshub.com/MarkNZed/GPT-NeoX-Colab.mlflow/#/experiments/8.\n",
            "2024/11/13 13:55:14 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n"
          ]
        }
      ],
      "source": [
        "import tempfile\n",
        "import subprocess\n",
        "import os\n",
        "from omegaconf import OmegaConf\n",
        "from hydra import initialize_config_dir, compose\n",
        "from hydra.core.global_hydra import GlobalHydra\n",
        "import mlflow\n",
        "import time\n",
        "import dagshub\n",
        "import ipynbname\n",
        "\n",
        "%cd {GPTNeoXDir}\n",
        "\n",
        "dagshub.init(repo_owner='MarkNZed', repo_name='GPT-NeoX-Colab', mlflow=True)\n",
        "experiment_group = \"Log only experiment parameters\"\n",
        "mlflow.set_experiment(experiment_group)\n",
        "mlflow.enable_system_metrics_logging()\n",
        "\n",
        "def log_gpu_info():\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_name = torch.cuda.get_device_name(0)\n",
        "        mlflow.log_param(\"gpu_type\", gpu_name)\n",
        "    else:\n",
        "        mlflow.log_param(\"gpu_type\", \"CPU\")\n",
        "\n",
        "def load_and_merge_configs(base_conf_dir, experiment_name):\n",
        "    # Initialize Hydra with the base config directory\n",
        "    initialize_config_dir(config_dir=base_conf_dir, version_base=\"1.1\")\n",
        "\n",
        "    # Load the base configurations (shakespeare and shakespeare_deepy) and experiment overrides\n",
        "    base_cfg = compose(config_name=\"shakespeare.yml\")\n",
        "    OmegaConf.set_struct(base_cfg, False) # No struct checking for matching structure in merge\n",
        "    deepy_cfg = compose(config_name=\"shakespeare_deepy.yml\")\n",
        "    OmegaConf.set_struct(deepy_cfg, False) # No struct checking for matching structure in merge\n",
        "    experiment_cfg = compose(config_name=\"hydra\", overrides=[f\"experiments={experiment_name}\"])\n",
        "    OmegaConf.set_struct(experiment_cfg, False) # No struct checking for matching structure in merge\n",
        "\n",
        "    mlflow.log_params(OmegaConf.to_container(experiment_cfg, resolve=True))\n",
        "\n",
        "    experiment_overrides = experiment_cfg.get(\"experiments\", {})\n",
        "    OmegaConf.set_struct(experiment_overrides, False) # No struct checking for matching structure in merge\n",
        "\n",
        "    print(experiment_overrides)\n",
        "\n",
        "    # Merge the configurations: base -> deepy -> experiment\n",
        "    cfg = OmegaConf.merge(base_cfg, deepy_cfg, experiment_overrides)\n",
        "\n",
        "    return cfg\n",
        "\n",
        "def run_experiment(cfg, experiment_name):\n",
        "    print(\"Running experiment:\", experiment_name)\n",
        "    experimentDir = f\"{GPTNeoXDir}/experiments/{experiment_name}\"\n",
        "    !rm -rf {experimentDir}\n",
        "    !mkdir -p {experimentDir}\n",
        "    !rm -f train_process.pid\n",
        "    file_position = 0\n",
        "    #print(OmegaConf.to_yaml(cfg))\n",
        "\n",
        "    # Create a temporary directory for configs\n",
        "    temp_config_dir = tempfile.mkdtemp()\n",
        "    temp_config_file = os.path.join(temp_config_dir, 'temp_config.yml')\n",
        "\n",
        "    # Save the modified config to the temporary file in JSON-like structure within a YAML file\n",
        "    with open(temp_config_file, 'w') as f:\n",
        "        # Dump the config as JSON but save it with a .yml extension\n",
        "        OmegaConf.save(OmegaConf.create(OmegaConf.to_container(cfg, resolve=True)), f)\n",
        "\n",
        "    # Start a detached background process using the temp config\n",
        "    cmd = f\"\"\"nohup bash -c \"source {workspaceDir}/my_env/bin/activate && \\\n",
        "        cd {GPTNeoXDir} && \\\n",
        "        python ./deepy.py train.py --conf_dir {temp_config_dir} \\\n",
        "        temp_config\" & echo $! > train_process.pid\"\"\"\n",
        "    print(\"Running command:\", cmd)\n",
        "    process = subprocess.Popen(\n",
        "        cmd,\n",
        "        shell=True,\n",
        "        executable='/bin/bash',\n",
        "        preexec_fn=os.setsid  # Starts the process in a new session\n",
        "    )\n",
        "\n",
        "    print(\"Training initiated.\")\n",
        "\n",
        "    while not os.path.exists(\"train_process.pid\"):\n",
        "        print(\"Waiting for train_process.pid to be created...\")\n",
        "        time.sleep(10)  # Check every X seconds\n",
        "\n",
        "    # Read the PID from the file\n",
        "    with open(\"train_process.pid\", \"r\") as f:\n",
        "        pid = int(f.read().strip())\n",
        "        print(\"Found train_process.pid \", pid)\n",
        "\n",
        "    while not os.path.exists(f\"{experimentDir}/logs\"):\n",
        "        print(\"Waiting for logs to be created...\")\n",
        "        time.sleep(10)  # Check every X seconds\n",
        "\n",
        "    latest_log = get_latest_file(f\"{experimentDir}/logs\", \"*_stdout.txt\")\n",
        "\n",
        "    # Monitor the training process\n",
        "    while is_process_running(pid):\n",
        "        read_new_iterations(latest_log)\n",
        "        print(\"Training is still running...\")\n",
        "        time.sleep(30)  # Check every X seconds\n",
        "\n",
        "    print(\"Training has finished.\")\n",
        "\n",
        "    latest_events_file = get_latest_file(f\"{experimentDir}/tensorboard\", \"events.out.tfevents.*\")\n",
        "    loss_key = \"test/lm_loss\"\n",
        "    loss = get_scalar_from_tensorboard(latest_events_file, loss_key)\n",
        "    print(f\"Logging metric {loss_key} {loss}\")\n",
        "    mlflow.log_metric(loss_key, loss)\n",
        "\n",
        "    # Clean up the temporary directory after training\n",
        "    # (Optional: You might want to keep it for debugging)\n",
        "    # shutil.rmtree(temp_config_dir)\n",
        "\n",
        "try:\n",
        "    notebook_path = ipynbname.path()\n",
        "except:\n",
        "    notebook_path = \"shakespeare_experiment.ipynb\"\n",
        "\n",
        "# List of experiment names\n",
        "experiments = [\"experiment1\", \"experiment2\", \"experiment3\"]\n",
        "\n",
        "for experiment in experiments:\n",
        "\n",
        "    client = mlflow.tracking.MlflowClient()\n",
        "\n",
        "    with mlflow.start_run() as run:\n",
        "        run_id = run.info.run_id\n",
        "        # https://mlflow.org/docs/latest/tracking/tracking-api.html#system-tags\n",
        "        client.set_tag(run_id, \"mlflow.source.git.commit\", commit_id)\n",
        "        client.set_tag(run_id, \"mlflow.source.git.branch\", branch_name)\n",
        "        client.set_tag(run_id, \"mlflow.source.git.repoURL\", repo_url)\n",
        "        client.set_tag(run_id, \"mlflow.source.type\", \"NOTEBOOK\")\n",
        "        client.set_tag(run_id, \"mlflow.source.name\", notebook_path)\n",
        "        log_gpu_info()\n",
        "        # Clear Hydra's global state if it’s already initialized\n",
        "        if GlobalHydra.instance().is_initialized():\n",
        "            GlobalHydra.instance().clear()\n",
        "        # Load and merge configurations\n",
        "        base_conf_dir = f\"{GPTNeoXColabDir}/configs\"\n",
        "        cfg = load_and_merge_configs(base_conf_dir, experiment)\n",
        "        # Start training with the merged configuration\n",
        "        run_experiment(cfg, experiment)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luIf6lNkKUWT"
      },
      "outputs": [],
      "source": [
        "# Here we could disconnect from the GPU resource\n",
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}