{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/markNZed/GPT-NeoX-Colab/blob/main/notebooks/shakespeare_experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flp2Dht6ytqE"
   },
   "source": [
    "# Experiment\n",
    "This is a demonstration of how experiments can be run using DagsHub and MLflow.\n",
    "We will train three different versions of the tiny LLM using different batch sizes and compare the results.\n",
    "\n",
    "## ToDo\n",
    "- Shorten the training time for testing\n",
    "- Run tests in parallel\n",
    "- Extract functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LECzxKWK8CyS"
   },
   "source": [
    "## Login to Dagshub\n",
    "To avoid requirest in the middle of the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "wxd2wfpq1F9u"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The added token already exists in the token cache, skipping\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dagshub\n",
    "try:\n",
    "  from google.colab import userdata\n",
    "  #os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = userdata.get(\"MLFLOW_TRACKING_PASSWORD\")\n",
    "  #os.environ[\"MLFLOW_TRACKING_USERNAME\"] = userdata.get(\"MLFLOW_TRACKING_USERNAME\")\n",
    "  os.environ[\"DAGSHUB_USER_TOKEN\"] = userdata.get(\"DAGSHUB_USER_TOKEN\")\n",
    "except:\n",
    "  pass\n",
    "try:\n",
    "  if os.environ[\"DAGSHUB_USER_TOKEN\"]:\n",
    "    pass\n",
    "except:\n",
    "  os.environ[\"DAGSHUB_USER_TOKEN\"] = dagshub.auth.get_token()\n",
    "dagshub.auth.add_app_token(token=os.environ[\"DAGSHUB_USER_TOKEN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Iega62GjytqH"
   },
   "outputs": [],
   "source": [
    "#@title Setup paths\n",
    "# We could modify these paths to \"stub\" behavior for test/dev\n",
    "# A file like .ipython/profile_default/startup/10-test.py could restore these vars\n",
    "workspaceDir = \"/content\"\n",
    "GPTNeoXDirName = \"gpt-neox\"\n",
    "GPTNeoXDir = f\"{workspaceDir}/{GPTNeoXDirName}\"\n",
    "GPTNeoXColabDirName = \"GPT-NeoX-Colab\"\n",
    "GPTNeoXColabDir = f\"{workspaceDir}/{GPTNeoXColabDirName}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LUxVImVvytqL",
    "outputId": "3d11e700-8ea7-474e-db67-07a4259a2043"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "Cloning into 'GPT-NeoX-Colab'...\n",
      "remote: Enumerating objects: 1148, done.\u001b[K\n",
      "remote: Counting objects: 100% (96/96), done.\u001b[K\n",
      "remote: Compressing objects: 100% (62/62), done.\u001b[K\n",
      "remote: Total 1148 (delta 49), reused 58 (delta 30), pack-reused 1052 (from 1)\u001b[K\n",
      "Receiving objects: 100% (1148/1148), 13.79 MiB | 2.48 MiB/s, done.\n",
      "Resolving deltas: 100% (626/626), done.\n",
      "/content/GPT-NeoX-Colab\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Data retrieval successful.\n",
      "Data retrieval successful.\n",
      "CPU times: user 10.4 s, sys: 1.37 s, total: 11.8 s\n",
      "Wall time: 44.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#@title Clone GPT-NeoX-Colab\n",
    "%cd {workspaceDir}\n",
    "# Don't use --depth 1 because that does not play nice with git-annex\n",
    "!git clone https://github.com/markNZed/GPT-NeoX-Colab.git\n",
    "%cd {GPTNeoXColabDir}\n",
    "%pip install -q -r requirements_colab.txt\n",
    "%pip install -q .\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(f\"{GPTNeoXColabDir}/.env\")\n",
    "import GPTNeoXColab\n",
    "GPTNeoXColab.utils.colab.fetch_data(\"data/shakespeare/shakespeare_text_document.bin\")\n",
    "GPTNeoXColab.utils.colab.fetch_data(\"data/shakespeare/shakespeare_text_document.idx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OvpVaIbLytqM",
    "outputId": "3e3a29d7-b306-4822-8f2c-65281bf1ff4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '{workspaceDir}'\n",
      "/workspace/notebooks\n",
      "Cloning into 'gpt-neox'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 296, done.\u001b[K\n",
      "remote: Counting objects: 100% (296/296), done.\u001b[K\n",
      "remote: Compressing objects: 100% (231/231), done.\u001b[K\n",
      "remote: Total 296 (delta 74), reused 136 (delta 43), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (296/296), 2.50 MiB | 773.00 KiB/s, done.\n",
      "Resolving deltas: 100% (74/74), done.\n",
      "CPU times: user 133 ms, sys: 23.5 ms, total: 157 ms\n",
      "Wall time: 4.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#@title Clone GPT-NeoX\n",
    "%cd {workspaceDir}\n",
    "!git clone --depth 1 https://github.com/EleutherAI/gpt-neox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {GPTNeoXDir}/processed_data\n",
    "!cp {GPTNeoXColabDir}/data/shakespeare/shakespeare_text_document.* {GPTNeoXDir}/processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WH8eetUBytqN",
    "outputId": "c80d3b67-ff8f-4836-b8a9-8fccb4cc8f7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "Downloading my_env.tar.gz\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:4\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/GPTNeoXColab/utils/colab.py:180\u001b[0m, in \u001b[0;36mdownload_my_env\u001b[0;34m(upload_env)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/my_env.tar\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;66;03m# Downloading takes about 40sec\u001b[39;00m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading my_env.tar.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 180\u001b[0m     \u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBB_BUCKET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/content\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmy_env.tar.gz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmy_env.tar.gz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb2_r\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnzipping my_env.tar.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    182\u001b[0m     run(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapt-get install -y pigz pv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/GPTNeoXColab/utils/colab.py:167\u001b[0m, in \u001b[0;36mdownload_file\u001b[0;34m(bucket, directory, file, key_name, b2)\u001b[0m\n\u001b[1;32m    165\u001b[0m file_path \u001b[38;5;241m=\u001b[39m directory \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m file\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m     \u001b[43mb2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBucket\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m ce:\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m, ce)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/boto3/s3/inject.py:279\u001b[0m, in \u001b[0;36mbucket_download_file\u001b[0;34m(self, Key, Filename, ExtraArgs, Callback, Config)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbucket_download_file\u001b[39m(\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28mself\u001b[39m, Key, Filename, ExtraArgs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, Callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, Config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    247\u001b[0m ):\n\u001b[1;32m    248\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Download an S3 object to a file.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \n\u001b[1;32m    250\u001b[0m \u001b[38;5;124;03m    Usage::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m        transfer.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mBucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mKey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mKey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mFilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mExtraArgs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mExtraArgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mConfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mConfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/boto3/s3/inject.py:192\u001b[0m, in \u001b[0;36mdownload_file\u001b[0;34m(self, Bucket, Key, Filename, ExtraArgs, Callback, Config)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Download an S3 object to a file.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03mUsage::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03m    transfer.\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m S3Transfer(\u001b[38;5;28mself\u001b[39m, Config) \u001b[38;5;28;01mas\u001b[39;00m transfer:\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransfer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBucket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mKey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mExtraArgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/boto3/s3/transfer.py:406\u001b[0m, in \u001b[0;36mS3Transfer.download_file\u001b[0;34m(self, bucket, key, filename, extra_args, callback)\u001b[0m\n\u001b[1;32m    402\u001b[0m future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39mdownload(\n\u001b[1;32m    403\u001b[0m     bucket, key, filename, extra_args, subscribers\n\u001b[1;32m    404\u001b[0m )\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 406\u001b[0m     \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;66;03m# This is for backwards compatibility where when retries are\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# exceeded we need to throw the same error from boto3 instead of\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;66;03m# s3transfer's built in RetriesExceededError as current users are\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;66;03m# catching the boto3 one instead of the s3transfer exception to do\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;66;03m# their own retries.\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m S3TransferRetriesExceededError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/s3transfer/futures.py:106\u001b[0m, in \u001b[0;36mTransferFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[0;32m--> 106\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/s3transfer/futures.py:103\u001b[0m, in \u001b[0;36mTransferFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;66;03m# Usually the result() method blocks until the transfer is done,\u001b[39;00m\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;66;03m# however if a KeyboardInterrupt is raised we want want to exit\u001b[39;00m\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;66;03m# out of this and propagate the exception.\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_coordinator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/s3transfer/futures.py:259\u001b[0m, in \u001b[0;36mTransferCoordinator.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Waits until TransferFuture is done and returns the result\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \n\u001b[1;32m    251\u001b[0m \u001b[38;5;124;03mIf the TransferFuture succeeded, it will return the result. If the\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;124;03mTransferFuture failed, it will raise the exception associated to the\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;124;03mfailure.\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m# Doing a wait() with no timeout cannot be interrupted in python2 but\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# can be interrupted in python3 so we just wait with the largest\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# possible value integer value, which is on the scale of billions of\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# years...\u001b[39;00m\n\u001b[0;32m--> 259\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_done_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMAXINT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# Once done waiting, raise an exception if present or return the\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# final result.\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#@title Load prebuilt Python environment for Colab\n",
    "import GPTNeoXColab\n",
    "%cd {workspaceDir}\n",
    "GPTNeoXColab.utils.colab.download_my_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTyERIkj8elu"
   },
   "source": [
    "# Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "umfYbg3TytqJ"
   },
   "outputs": [],
   "source": [
    "import GPTNeoXColab\n",
    "import os\n",
    "from pathlib import Path\n",
    "ROOT_DIR = GPTNeoXColab.utils.colab.find_project_root()\n",
    "RELATIVE_ROOT_DIR = os.path.relpath(ROOT_DIR, Path.cwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "oE-4NPwkytqO"
   },
   "outputs": [],
   "source": [
    "experiment_name = \"experiment1\"  # Change this to dynamically load different experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "iaBFYofFytqP",
    "outputId": "262bd060-db3e-447b-c5fc-bed64dcec7e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"MarkNZed/GPT-NeoX-Colab\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"MarkNZed/GPT-NeoX-Colab\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository MarkNZed/GPT-NeoX-Colab initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository MarkNZed/GPT-NeoX-Colab initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment: base_experiment\n",
      "dagshub:\n",
      "  repo_owner: MarkNZed\n",
      "  repo_name: GPT-NeoX-Colab\n",
      "output_dir: ../outputs\n",
      "experiment_name: base_experiment\n",
      "seed: 42\n",
      "model:\n",
      "  hidden_dim: 64\n",
      "training:\n",
      "  batch_size: 32\n",
      "  learning_rate: 0.001\n",
      "  epochs: 2\n",
      "data: null\n",
      "experiments:\n",
      "  experiment_name: experiment_1\n",
      "  seed: 123\n",
      "\n",
      "/content/gpt-neox\n",
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/11 11:22:14 INFO mlflow.tracking._tracking_service.client: 🏃 View run thundering-bee-987 at: https://dagshub.com/MarkNZed/GPT-NeoX-Colab.mlflow/#/experiments/3/runs/21f714bd429e48ffbe7fb31a1626c73d.\n",
      "2024/11/11 11:22:14 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://dagshub.com/MarkNZed/GPT-NeoX-Colab.mlflow/#/experiments/3.\n"
     ]
    }
   ],
   "source": [
    "#@title Run the training in a detached background process\n",
    "%cd {workspaceDir}\n",
    "import subprocess\n",
    "import os\n",
    "import dagshub\n",
    "import mlflow\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "from hydra import initialize, compose\n",
    "\n",
    "# Clear Hydra's global state if it’s already initialized\n",
    "if GlobalHydra.instance().is_initialized():\n",
    "    GlobalHydra.instance().clear()\n",
    "\n",
    "initialize(config_path=f\"{RELATIVE_ROOT_DIR}/configs\", version_base=\"1.1\")\n",
    "\n",
    "cfg = compose(config_name=\"hydra\", overrides=[f\"experiments={experiment_name}\"])\n",
    "\n",
    "# Set MLflow tracking URI for DagsHub\n",
    "#MLFLOW_TRACKING_URI = f\"https://dagshub.com/{cfg.dagshub.repo_owner}/{cfg.dagshub.repo_name}.mlflow\"\n",
    "\n",
    "os.environ[\"DAGSHUB_USER\"] = cfg.dagshub.repo_owner\n",
    "\n",
    "# Initialize DagsHub logging\n",
    "try:\n",
    "    # Will setup MLFLOW_TRACKING_URI MLFLOW_TRACKING_USERNAME MLFLOW_TRACKING_PASSWORD\n",
    "    dagshub.init(repo_owner=cfg.dagshub.repo_owner, repo_name=cfg.dagshub.repo_name, mlflow=True)\n",
    "except Exception as e:\n",
    "    print(f\"Failed to initialize DagsHub logging: {e}\")\n",
    "\n",
    "def train_model(cfg: DictConfig):\n",
    "    print(\"Running experiment:\", cfg.experiment_name)\n",
    "    print(OmegaConf.to_yaml(cfg))\n",
    "\n",
    "    # Log parameters\n",
    "    mlflow.log_params(OmegaConf.to_container(cfg, resolve=True))\n",
    "\n",
    "    %cd {GPTNeoXDir}\n",
    "    # The deepy.py script assumes it is running in the root of GTP-NeoX repo\n",
    "    # Start a detached background process\n",
    "    process = subprocess.Popen(\n",
    "        f\"nohup bash -c \\\"source {workspaceDir}/my_env/bin/activate && python ./deepy.py train.py --conf_dir {GPTNeoXColabDir}/configs shakespeare shakespeare_deepy\\\" & echo $! > train_process.pid\",\n",
    "        shell=True,\n",
    "        executable='/bin/bash',\n",
    "        preexec_fn=subprocess.os.setsid  # Starts the process in a new session so interrupting Notebook does not kill the training\n",
    "    )\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "exp_id = GPTNeoXColab.utils.ml.get_or_create_experiment_id(\"tutorial\")\n",
    "\n",
    "# Set the experiment name and start the run\n",
    "# mlflow.set_experiment(experiment_name)\n",
    "with mlflow.start_run(experiment_id=exp_id):\n",
    "    train_model(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lXW4XGr-93pR"
   },
   "outputs": [],
   "source": [
    "#@title Wait until logs directory is created\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Path to the log directory\n",
    "logs_dir = f\"{GPTNeoXDir}/logs\"\n",
    "\n",
    "# Wait for the directory to be created\n",
    "while not os.path.exists(logs_dir):\n",
    "    print(\"Waiting for logs directory to be created...\")\n",
    "    time.sleep(10)  # Check every X seconds\n",
    "\n",
    "print(\"ogs directory found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UCU9AaWO9sMb",
    "outputId": "2ed7ddf1-735a-4668-a79b-2cf7664b5a3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest log file: /content/gpt-neox/logs/d1d8af4f6537_stdout.txt\n"
     ]
    }
   ],
   "source": [
    "#@title Find the latest log file\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Define the log directory and pattern for log files\n",
    "log_dir = f\"{GPTNeoXDir}/logs\"\n",
    "log_pattern = os.path.join(log_dir, \"*_stdout.txt\")\n",
    "\n",
    "# Get the list of log files that match the pattern\n",
    "log_files = glob.glob(log_pattern)\n",
    "\n",
    "# Ensure there are log files in the directory\n",
    "if log_files:\n",
    "    # Find the latest log file based on modification time\n",
    "    latest_log = max(log_files, key=os.path.getmtime)\n",
    "    print(\"Latest log file:\", latest_log)\n",
    "else:\n",
    "    latest_log = None\n",
    "    print(\"No log files found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6PTFQWG08tKv",
    "outputId": "dbad1910-e5ea-4614-9c91-4bb70a0561dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PID: 7889\n",
      "Training is still running...\n",
      "40 iterations\n",
      "Training is still running...\n",
      "80 iterations\n",
      "Training is still running...\n",
      "120 iterations\n",
      "Training is still running...\n",
      "160 iterations\n",
      "Training is still running...\n",
      "200 iterations\n",
      "Training is still running...\n"
     ]
    }
   ],
   "source": [
    "#@title Read the latest log file and extract the iteration count\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "\n",
    "# File to store the last read position (persistence between script runs)\n",
    "file_position = 0\n",
    "# Regular expression to match \"iteration <number> / <total>\"\n",
    "iteration_pattern = re.compile(r\"iteration\\s+(\\d+)\\s*/\\s*\\d+\")\n",
    "\n",
    "def read_new_iterations():\n",
    "    global file_position\n",
    "    # Open the log file and seek to the last position\n",
    "    with open(latest_log, \"r\") as file:\n",
    "        file.seek(file_position)\n",
    "        # Read new lines\n",
    "        new_lines = file.readlines()\n",
    "        file_position = file.tell()\n",
    "        # Process lines containing \"iteration\"\n",
    "        last_match = None\n",
    "        for line in new_lines:\n",
    "            match = iteration_pattern.search(line)\n",
    "            if match:\n",
    "                last_match = match\n",
    "        if last_match:\n",
    "            # Extract the iteration count from the regex match\n",
    "            iteration_count = int(last_match.group(1))\n",
    "            print(f\"{iteration_count} iterations\")\n",
    "\n",
    "# Read the PID from the file\n",
    "with open(\"train_process.pid\", \"r\") as f:\n",
    "    pid = int(f.read().strip())\n",
    "    print(\"PID:\", pid)\n",
    "\n",
    "# Function to check if the process is running\n",
    "def is_process_running(pid):\n",
    "    try:\n",
    "        os.kill(pid, 0)  # Sending signal 0 to check if the process exists\n",
    "        return True\n",
    "    except OSError:\n",
    "        return False\n",
    "\n",
    "# Monitor the training process\n",
    "while is_process_running(pid):\n",
    "    read_new_iterations()\n",
    "    print(\"Training is still running...\")\n",
    "    time.sleep(30)  # Check every X seconds\n",
    "\n",
    "print(\"Training has finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0JGqO-azytqR"
   },
   "outputs": [],
   "source": [
    "# Here we could disconnect from the GPU resource\n",
    "#from google.colab import runtime\n",
    "#runtime.unassign()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
